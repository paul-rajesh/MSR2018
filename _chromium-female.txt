===Database gerrit_chromiumos

== Dumping data for table JOINED_TABLE

|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I don't think it is.

The old code was used to handle exporting interface 3 (the GPS port) of gobi2ks.

The new code handles this as part of the ifnum == 3 case for all modems. We shouldn't lose any interfaces this way, although I will try hacking export_non_qmi back in and seeing if we're missing any with a G3k.
|Done
|Doing that causes it to not discard the rest of the line.
|Done
|Done
|The red indicates 'tab after space'; there's a single space (from diff's context output), then a tab (from openssl). I can't get rid of these lines, sorry.
|Done
|Done
|Not sure.
|Added in the next upstream CL I'm about to merge :-)
|Hm, oops. Fixed.
|No; it was for my reference when porting uses of the old interface over.
|Done
|Done
|Yes.
|It's not necessarily a device either. What verity (this tool) does is hash a payload and produce a hashtree for it. I can't think of a good name for 'payload' that doesn't exclude one of the things it does.
|Done
|Done
|Hrm. Yes, and I think that's how it should be, because those are not normally exposed to crosh. Do you object strongly?
|I wasn't even thinking of flimflamd so much as that root can do whatever it wants. That said, I'll add a comment.
|Yes. They are not normally exposed to crosh, so they shouldn't be invokable from chronos.
|Done
|Done
|Done
|Done
|Done
|Done
|I think spaces around &lt; and &gt; are not canonical for template invocations.
|Please don't change the whitespace like this. It makes the diff impossible to read.
|What is an 'implicit input', and why does it appear in the interface?
|See above
|Please don't add a bunch of blank lines at the end
|Please remove trailing whitespace.
|Don't we want a{st} here?
|Ditto here - a{st}?
|'in' is for arguments that are read by the method; 'out' is for arguments that are written by it.
|dbus path of a user?
|This seems like it should never happen
|dbus doesn't use '_' as a name separator.
|I'm not sure either. Perhaps there is documentation out there?
|This method doesn't print anything. It just returns some strings.

I'm pretty sure we want a{stx} here.
|Done
|Done
|Done
|All the names we've thought of for this suck, unfortunately. :(
|Changing this would require a bunch of other changes in verity and the build tools. I am not particularly thrilled by this idea, but I can change it if you feel strongly.
|See above re 'bunch of other changes' :-\. We originally used &quot;hexdigest&quot; to differentiate it (in the verity source) from &quot;digest&quot;, which was the raw bytes of the digest.
|Ok. No change made.
|I believe it is propagated (or at least, I have seen that specific error before when I screwed up a command line).
|That's because it doesn't have one yet. I'm still thinking about where to mount it; it will be a separate CL.
|Done
|Done
|Done
|'mountpoint' is totally a noun, per mount(1) ;)
|Done
|Deleted this code.
|Deleted.

(For future use, I left them uncommented because I felt 'directory' and 'recursive' were descriptive by themselves).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Is there an autotest that will measure this for me, or do I just want to log a timestamp on either side of this?
|Done
|Done
|Done
|The caller logs it (with more context).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I didn't try that. I can try it, but it's not clear what the benefit is.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Yes. Otherwise we get an error about trying to assign an integer to an enum.
|I tried that but it made the line so long that I couldn't really tell what was happening. I'd prefer to trade space for clarity, I think.
|Done
|Done
|Done
|Done
|Done
|Done
|Hm.

When we CLONE_NEWNS, we get a new mount namespace (fine) which has a reference to existing mounts (bad), so if we use MS_REMOUNT, we change the mount options for the parent too. The solution is to umount, then mount, which gives us a new instance of procfs.
|The new namespace is a clone of the old one, which means it already has a /proc mounted in it.
|Done
|part_pack_uuid() does no sanity checking at all.
|I am a clown
|Done
|Done
|Done
|Done
|Done
|Done
|It doesn't make much difference, since uid_t is 32 bits... but sure.
|Done
|Why? If the input is bogus, getpwnam() will fail.
|same question as above
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Ok, removed. Unnecessary code is unnecessary code.
|Nope.
|Done
|Done
|Done
|Yes.
|I undid this whole change.
|Done?
|Done
|I think we do not want to settle there.
|Oops. The i &lt; 10 thing was a debug hack to keep the kernel from hanging :) removed it.
|I prefer it as part of the target args.
|Done
|We kstrdup() once per target; we can't allocate it in advance unless we first look through all the targets to find the one with the largest args, which I guess we could do, but it seems unnecessary.
|No spaces around the []
|This is probably not WARNING material.
|Why?
|So bytes_just_used is a delta?
|aggregator?
|cashew style seems to leave a space between the '*' and the variable name.
|Why do we re-set the delegate each time this happens?
|There's no particular reason to change the spacing here
|This function makes me nervous...
|Shouldn't these just be virtual to begin with?
|I don't think this belongs here
|Or this
|Or this
|&quot;strncpy()&quot;
|base::StringToInt or similar
|This leaks 'line'
|What are the two files? Why do they have the same contents?
|This is a bad way to solve this problem.

A more canonical way:
1) write new data to foo.new
2) rename(&quot;foo.new&quot;, &quot;foo&quot;)

The kernel guarantees that foo.new is renamed to foo, or that the operation fails and the old foo is left.
|no newlines please
|newlines...
|I feel like these three cases are BUG_ON() material?
|Ditto these
|No newlines please
|This should never happen... BUG_ON()?
|ditto this
|This is impossible, BUG_ON()
|Impossible, BUG_ON()
|Newlines are unnecessary for printk()
|&quot;data buffer too small (%d &lt; %d)&quot;?
|(cid &gt;&gt; 8) == 0xFF means &quot;broadcast to all clients for whom the low half of their cid matches the low half of this cid&quot; -- see line 232
|Why'd you remove this DBG() statement?
|No, BUG_ON() is right.
|Allocated cids are always positive, so we can just return them as values if we want.
|cid = 0, then remove the else later?
|braces around single-line ifs are considered unnecessary in the kernel, IIRC.
|A *tab* between ) and {? :(
|If we log this here, having every caller also log that it failed seems redundant.
|Without having logged the urb's address when adding it, this debug info is not so useful
|WRN?
|WRN?
|&quot;I don't even know *how* to %08x!&quot;
|Why did this get rearranged? it seems to have switched from guard-clause back to one-big-indented-block.
|KERN_WARNING
|Done
|Since blocks are 4096 bytes in verity (right now), this gives us an 8TB limit for an individual verity partition. Is that desired?
|I don't think these parens are needed
|Done
|Done
|Done
|Done (in libminijail.h)
|Done
|Done
|No, but I documented why.
|minijail_remount_readonly() forces vfs namespacing on, and -h says so.
|Done
|Done
|Done
|Done
|minijail0 it is.
|Done
|Done
|Done
|Done
|Done
|I don't think that we gain anything from using getpwnam_r over getpwnam, but I will do it anyway. Done.
|Done
|Done
|linux/capability.h: #define cap_valid(x) ((x) &gt;= 0 &amp;&amp; (x) &lt;= CAP_LAST_CAP)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|In my mental universe, libx.c and libx.h implement the guts of the program whose main() is in x.c.
|Done
|Done
|Done
|getpwnam_r() is still not reentrant; it holds a file descriptor open to /etc/passwd behind your back, which means if our caller was inside getpwent or something at call-time, they'll lose. Using getpwnam_r() earns us nothing. I've filed crosbug.com/18473 for this.
|ditto
|Done
|Done
|Done
|Yes.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Right now it only remounts /proc, but notionally it remounts all filesystems that need to be remounted readonly, which might include /sys or /dev in future.
|Done.
|Done
|No. That path seems to be basically ignored; the ebuild handles actually installing into the target image.
|I swear I've posted a reply twice, but maybe Gerrit is eating it. I compiled this on arm and disassembled it, and the result used a single 32-bit integer for it.
|Done
|Done
|Done
|Done
|I neglected to hit send on my comments to this the first time. On Arm, gcc does the right thing:

0000000c &lt;minijail_use_seccomp&gt;:
   c:   7803            ldrb    r3, [r0, #0]
   e:   f043 0320       orr.w   r3, r3, #32
  12:   7003            strb    r3, [r0, #0]
  14:   4770            bx      lr
  16:   bf00            nop

I haven't tried on x86.
|Oops. Done.
|Done
|? there's an exit() call the line before it.
|Done
|It is static so that it cannot possibly alias a symbol present in the binary we're preloading into. I could share this string between libminijail and libminijailpreload, but then it couldn't be static :\.
|Done
|Done
|Done
|Yes, and the comment at line 305 is incorrect about that. I mixed up putenv() (which doesn't dup) and setenv() (which does).
|Done
|I thought about it, but I think the most common use cases will be:

1) const char *kServiceUser = &quot;cromo&quot;;
2) minijail_change_user(argv[1])
|Done
|Done
|Such a change would be incompatible with a program that uses child processes, since we would necessarily have to implement it by stealing the SIGCHLD handler and wait()ing ourselves, which would prevent them from getting their children's exit statuses.
|Done
|Done
|Done
|I fixed this by dropping the handle just before real_main() above.
|Done
|Done
|Done
|Done
|The goal is that every place that handles verity arguments will support both the positional style and the key-value style, so that I can land a verity change to switch over to the new style, and if anything goes wrong, I only have to revert that change (pushing a bunch of interdependent CLs with gerrit makes a huge mess of the tree, and reverting them is just as bad). After I switch verity over to the new argument format (in one easily-reverted CL), I will go through and remove all the support for the old behavior. It will generate more CLs than otherwise, but avoid having a moment when I need to atomically land four or five CLs :)

Desired sequence:
1) Support both old and new everywhere
2) Switch verity over to generating new
3) Drop support for old

Step 2 being easy to revert in case of loss, hopefully :)
|Yes. Done.
|Done
|Done
|Okay, sense made.
|Done
|Done
|Done
|Done
|Done
|Ack! Sorry, it got lost in the shuffle of new revisions. I still don't understand what using strncmp protects us against.
|What value would I pass for n?
|Yes, but if kValidSessionServices[i] isn't null-terminated somehow, something's _really_ wrong.
|Done
|Done
|Done
|Done
|Done
|Done
|Why?
|Done
|Done
|Yes. Done.
|Done
|Done
|If gboolean is different (numerically) from C++ bool, you deserve everything that happens to you.

That said, these are documented to contain 0 and &quot;!0&quot;:
http://developer.gnome.org/glib/unstable/glib-Standard-Macros.html#TRUE:CAPS

The C++ documentation says that &quot;!0&quot; is equivalent to &quot;(0 == 0)&quot;, which will actually give us C++ true. Ugh.
|Baleeted.
|Done
|I think as long as the migration is idempotent and we only write back at the end, it doesn't matter.
|The migration gets redone the next time, but it should find nothing new to migrate, since it skips the user dir.

I don't really see what setting it to false buys us.
|Double-migrations _should_ be idempotent...
|Done
|CopySkeletonForUser() uses home_dir_, which is still /home/chronos/user, so I think we're good here. There's no support for a root skeleton, but I don't think we need one yet.
|I think so, yes. It's 077, which leaves the vault 0700.
|Oops. It should be untracked, and we'll just use a keyset entry to remember whether we migrated or not.
|Delorted.
|Message made more opaque.
|Yes, wad@chromium.org is right - we should mount it somewhere stable. As such, I propose:

1) A DBus method to return the current mount point, and
2) A stable per-user mount point.

I've added a TODO.
|I think we can just consider it a loss. We're looking at a file which (for some reason) we can't even move between directories. Something's already badly wrong.
|No, not yet.
|Done
|Done
|Done
|Done
|Done
|Dot dirs are encrypted just like everything else.
|Done
|UMA metric can be added separately, I think.
|Well, we can either bail or not bail here.

If we bail, then we have to propagate that error all the way back up to the user, which sucks a lot; if we don't bail, we'll never migrate those directories. If we do propagate it up, the user's stuck with half of their cryptohome moved and half of it not moved. Ugh.
|Ownership is right; I didn't check the umask, but the default (systemwide) umask for root daemons should be 077.
|Done
|It is a consequence of the platform API :-\
|I don't think that is right.
|Done
|There already exists platform::Rename, I just forgot to use it :)
|yeah; removed :)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Nah. Done.
|Done
|Done
|Done
|Done
|Done
|Done
|What happens if we tear the client down while we're here (e.g. due to an ioctl)? Does the urb get freed out from under us?
|I *think* this is ok, as long as nobody adds any other notifies for this client...
|Can this be called unlocked? We should probably assert that we have a lock here.
|HasBytesRemaining?
|Non-idempotent getter methods are a bit surprising...
|I don't see how there could be. Lack of ASLR?
|/usr/include/chromeos works for me, or just /usr/include :)
|Done
|I'm about to refactor all this anyway, so I'll do it then.
|Done
|Done
|If the user wants a salt, but doesn't specify anything, we should zero-pad it to the full width anyway. This seems like an entirely correct base-case to me. I have documented this behavior.
|No, good catch. Added a unit test to catch this in future, too.
|Done
|Wlat else would we use? malloc + strncpy? It seems strictly worse.
|free(NULL) is a noop so this is pointless
|The restrictions may not be meaningful for the child process, or it may be about to chroot itself or something. I'd err on the side of not inheriting them.
|Could you document this? It took me a couple of minutes to figure out.

(Rochberg wants me to suggest on his behalf that you rewrite this in a programming language.)
|Why &quot;&#124;&#124; true&quot;? rm -f ignores nonexistent files and if it fails for some other reason we probably want to know :)
|ought to be enough for anybody ;)
|Can we use sizeof(*sf) here instead? Duplicating the type can only lead to pain later.
|There is a constant for this somewhere already
|&amp;&amp; filter? We didn't get here if !filter
|I don't think entry can ever be null; maybe you mean entry-&gt;name
|Blank lines aren't allowed?
|If the filter file is empty, use_filters is still set to 1, but trying to use sf-&gt;nr below will cause lossage
|does 13 have any particular meaning?
|?
|while (f) { n = f-&gt;next; free(...); f = n; }
|?
|Fair enough.
|you can just say 'missing endpoint(s) %u %u' or whatever
|I don't believe this can ever happen
|print what you found, perhaps
|probably 30 now :) (or remove this field and let the compiler pad as needed)
|the lack of subject/verb agreement here hurts me.
|Can't this race against a modification (not deletion) of the parent's filter set?
|We don't really need to track ret at all, or have the out label - we can just return filters ? -EACCES : 0;
|Because I don't want builds to block for possibly arbitrarily long, esp. on low-entropy machines like the buildbots.
|Also, I don't think it helps: the salt will become public immediately when we ship the image. Ability to predict the _next_ salt is of vanishingly small value, since one still has to collide verity's hash function; the purpose of the salting is just to ensure that if someone finds a collision in one release, they can't reuse it.
|Done
|please put these in order
|can these just be static const ints for int_callback()?
|buf[0]
|buf[1]
|is there a constant for this in usb.h?
|I documented why this is commented out.

The pkcs11 patch we have (above) sticks a hardcoded path into the openssl.cnf file.
|Yes, sorry. My intent was to leave this patch exactly as it was before.
|This is about to be fixed in the following CL :).
|is_blacklisted should just return false, yes. Having no blacklist file is not an error.
|Separate patch.
|I was not sure enough of that to actually go through with it.
|openssl static functions rarely check arguments for validity.
|I left them apart because it makes subsequent diffs that add or remove flags smaller :-P
|That's not what EFAULT means. EINVAL? ENXIO?
|Neither is that :(
|Actually, maybe it wouldn't...
|Instead of duplicating the function body, can we do:

void minijail_marshal(const struct minijail *j, int (*append)(void *state, void *data, size_t sz))

Then minijail_size() can have append() be:
  *(size_t *)state += sz;

and minijail_marshal() can have append() be:
  struct marshal_state *s = state;
  if (sz &gt; s-&gt;remaining) ...

I think that'll result in less code and less macros.
|Can the body of this loop be a helper function somehow?
|I think this can't happen
|Done
|Done
|Done
|Done
|strtok is non-reentrant, which will cause difficult-to-diagnose failures in future. strsep is 4.4BSD, strtok_r is POSIX.1-2001. Neither is C89 or C99, so I don't feel bad using strsep here.
|Done
|Done
|Done
|Done
|Actually, there's a pretty bad bug here - loff_t is signed, so sizeof(keystash-&gt;buf) - pos can be negative. Corrected.
|Which part of this might be factored out into a helper?
|We can't do the same for read(), since common tools rely on getting a read() of length 0 to indicate end-of-file. I'll implement offset support here.
|These defines are per-platform because the preserved RAM base is per-platform. I don't think ramoops exports any way to get at its backing store.
|It is logically a chardev
|No; usergid != gid. We use usergid when we're assuming supplementary groups from a user.
|Done
|Done
|Done
|I'm intentionally using a magic number there to make it plain that the value is totally arbitrary. USHRT_MAX + 1 looks like it might have some kind of significance :-P.
|Done
|Done
|Intentionally arbitrary-looking.
|Done
|Fixed
|Fixed
|Fixed
|&quot;In case of error, an error number is returned, and NULL is stored in *result.&quot; -- getpwnam_r(3).
|Done
|It gets ugly out of proportion to the gain :(
|http://gerrit.chromium.org/gerrit/4585 briefly explains the differences, but the most important new feature is that we support detailed syscall filtering now. :)
|Yes, because it still is and is still used (see line 19)
|Oops indeed :)
|verity will bail if that happens and the whole script will exit, but the salt should never be &quot;&quot; (our caller is supposed to ensure that).
|I don't think so.
|Done
|No.
|Done
|Done
|Done
|Done
|I never did run bootperf, but it'd be literally shocking if this caused a change.
|Fixed as boot.desc
|Removed :)
|This will not play nice when used like TEST_API(LOL(name)) or similar.
http://stackoverflow.com/questions/1489932/c-preprocessor-and-concatenation
|Must not by whom? The user of the API?
|global as compared to what?
|Gross D:
|no uintptr_t? :)
|This is the best argument name ever.
|Does this mean there's an implicit global fixture with no setup/teardown that TEST() tests run inside?
|while (t &amp;&amp; (!count &#124;&#124; t != __test_list)), or just don't use a circular linked list
|Even if child_pid &lt; 0?
|We don't need separate rules for libminijail_unittest and libminijail_unittest.o. I only have separate rules for libminijail.o because otherwise it gets built twice, but that's unlikely to happen for the unit test.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|If it does change, then anything I can put here will become a lie. I've added an example, at least.
|I still need to go through chrome://system and make sure they're all doable. I added mentions of what we can do if we have a special uid/gid to the &quot;security considerations&quot; section.

I generally write the design doc as though it will be read once the implementation exists :).
|That is up to the implementor of the method, who I assume can also update the seccomp rules as necessary.
|Done
|I have documented the plusses and minuses of the listed mitigations and what they protect us against.

I was not maying much attention to execution time. The same thing will happen if one of our own DBus methods takes unbounded time as if a DBus method in flimflam or cromo takes unbounded time: that subsystem will hang.
|I fleshed this out a bit more. I still need to get more specific.
|I moved the synchronousness into the design doc. I'll reserve the implementation doc for describing how the actual code works.
|Done
|Done. Need to talk to trond.
|Done
|Done
|It is not yet another dbus API - it is the official one, atop which all the other ones are built, and which flimflam uses directly. I picked it because dbus-c++ seemed like overkill when we're only using a single object.
|It's documented as working. It's present in our header files.
|Documentated.
|One of the use cases I have in mind involves /bin/ping, which is currently setuid. If we want no setuid binaries on the system, and we want to use ping, either:

1) ping needs to have fs caps attached to it, which means we use fs xattrs, or
2) we need to be running as root

We could also try pulling in openwall's non-root-ping support for the kernel...
|Done
|I believe I have documented this better.
|How will people add features: To be documented in the implementation doc.
How do we ensure root privileges are not abused: Documented here.

We can meet those two competing requirements with delicious seccomp filtering, although it means someone who wants to add a debug hook has to figure out the right filter policy for it too.
|We'll just be very fast :D
|Done
|Why does using C need to be justified?
|Chrome can't do this (ping) right now anyway. It _could_ use this interface by creating a pipe and passing one end of it, though, and having a thread that blocks on reads from the pipe and updates an output window when it gets data.
|Done
|No, but there will be a default.
|Done
|There are limits imposed by ping(1) and the ICMP protocol. I do not know what they are :)
|Not sure yet. They should exit in fairly short order.
|I don't see why we'd care about a maximum wait time.
|It's already included by string_util.h I think?
|Done
|I don't understand. My code is &quot;const char* name = username.c_str()&quot;, which seems exactly as requested.
|Done
|It seems to work fine with just StringPrintf()
|Done
|Done
|StringPrintf()
|Done
|Done
|Done, although I assert that it does not matter in this case.
|Done
|ReadFile, for reasons known but to our ancestors, takes an int for its size argument instead of a size_t.
|The max is implicit, and the size of the read salt file is already logged.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This does not return a directory name. It returns a sanitized user name.
|I think an empty string is okay. Tossing an exception or abort()ing seem very antisocial.
|Done
|Done
|Done
|Finding mistakes is not a pain :) Thank you for reviewing!
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|checkpatch complains about that. I can use calloc() though.
|Noted.
|Done
|No. We first need to check whether there are _any_ bytes left in the buffer, so that we can know whether it's safe to use strlen() at all; even if we can use strlen(), we need to ensure that the string is null-terminated, which consumebytes() doesn't do.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Well-spotted :)
|Done
|Done, sorta messily :)
|I will rebase this onto http://gerrit.chromium.org/gerrit/8732 once it lands.
|Fixed
|Fixed
|Done
|Since I'm going to rebase this anyway, I'll leave the comment style alone. I consider not cleaning up file descriptors a feature, not a bug.
|Done
|Done
|Done
|you mean (name), l.strip()? The l.strip() is not part of the interpolation.
|Done
|It's not _documented_ that it always throws an exception, but looking at the source, it always returns a valid directory or raises IOError.
|Done
|Done
|I modified the test to set up a mock environment that doesn't rely on the external environment as much. I'm not sure what the benefit is of parsing /proc/self/mounts since we can just test for the desired properties directly (i.e., by making sure certain mounts are rw and others are ro).
|Done
|That seems like a bad plan. Ideally it should be possible to use the API without having to read the source of the implementation, which argues for these comments to go here, not there.
|No, indent(1) is dumb. Fixed.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Same objection.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Fixed a bit?
|That's 7 spaces.
|Go for it, then LGTM.
|Can this ever happen?
|Done
|Done
|Done
|Done
|Done
|I didn't touch this code, but I can fix this anyway.
|I'm not sure. It doesn't make sense to have that be part of this CL either way.
|Done
|Done
|Done
|Yes, Stat() uses lstat(2) which is NOFOLLOW.
|It seems not. The code compiles fine without them.
|EnsureDirHasOwner?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No. An attacker cannot manipulate dirents under /, only under /var.
|No deps yet, but I imagine it will be used by startup scripts.
|Oops.
|Done
|Yes.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No; that's what is_mountpoint() does. This is specifically a convenience wrapper for people that want an exception :).
|Done
|Done
|Done
|Done
|Done. I'll do the dbus call thing later.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|New test added. I still need to rebase those tests, I think.
|Done
|Done. Renamed to LogIfAnyMounts().
|Done
|Done
|It's used. See user-&gt;PushMount(dest) at line 383.
|It does.
|It does not fit on a line with GetVaultUserPath(). I have split it onto a separate line to make it more visible.
|Done
|If we ever hit that CHECK, it means we're destroying a UserSession while it still has live mounts, which means we're leaking mounts by definition. The only case where this is okay is if we're shutting down the machine, in which case I don't _think_ the destructor will be run, since we just get SIGTERM from upstart and exit. That said, I can make this a logged error instead; that way at least other people will still be able to log in. I'll think about if/how we can make cryptohome recover from crashes.
|I'm trying to keep the dependency between Mount and UserSession unidirectional as much as possible. Changed this to just LOG(ERROR).
|Okay. I like the look of = &quot;&quot; more, so I'll leave it.
|This seems like a *massive* duplication of information - instead of being in one place (the Unmount definition), the meanings of the arguments are now reproduced at every call site as well.
|Wait, we don't? Is the reason documented somewhere? Cleanup goto is a pretty widely-used idiom, I think.
|I switched to using cleanup gotos. Much nicer, saved code.
|Done
|Done
|Done
|Alright, I can get behind that plan. I will put the comment in here and go through and eliminate uninformative comments in a separate CL. Keep your battles well-contained, as they say :P
|It's called mount_point. Repeating in a comment that it is a mount point will not add anything.
|Done
|Why?
|It is magic. Its presence within a scope requires that expectations in that scope be fulfilled in sequence; see &lt;http://code.google.com/p/googlemock/wiki/CheatSheet&gt; &quot;To put many expectations in a sequence conveniently:&quot;
|Agreed.
|Done
|Done
|Deleted it.
|Done
|Done
|-w
|Done
|Done
|I split it up.
|Done
|Done
|Done
|Done
|Done
|What is a 'real' non-root uid/gid? uid=1, gid=1 is not root.
|Done
|Done
|I thought about it, but it's difficult to generalize this nicely; the cleanup, path, and username all vary, and creating a function that is parametric in all of those things would be uglier than the duplication. :(
|Done
|Done
|Done
|Done re cleanup. I don't understand why you prefer open_write_close(), since file(f, 'w') has the effect of creating the file and truncating it to zero bytes.
|Done
|Oops. Fixed :)
|Done
|I think file(..., 'w') is nicer.
|Done
|Done
|Done
|I believe this name is the 'standard' naming for DBus proxy objects using dbus-python. If you feel it is confusing, how about CryptohomeProxy?
|Done
|Done
|Done
|Done
|See the comment on cryptohome.py
|Done
|Done
|Done
|Done
|Done
|/home/user needs to be owned by root. Only /home/user/&lt;hash&gt; is not.
|I prefer to specify them explicitly.
|Done
|Done
|Done
|*headdesk*. Fixed.
|Done
|Done
|Done
|Done
|Done
|Done
|Don't I want -fvisibility=internal for _all_ my object files, not just debugd?
|Sounds like it will be enjoyable.
|Done
|These are our interface methods from dbus-c++. I've documented this.
|Done
|Done
|Yes. It will be created by the debugd ebuild.
|Done
|I was going to have them jail themselves, I think. Not sure yet.
|Done
|Done
|I will check that it is inherited.
|It blocks.

I suspect not. SIGTERM will do the job.
|Done
|That might be a feature.
|Done
|Done
|Done
|Helpers are background tasks that do stats-gathering and run all the time. I expect there to be very few of these. They do not handle method calls directly; rather they leave files in /debugd for methods in debugd to read as needed.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Okay, I believe this.
|Why does this reordering not introduce a race where the reader thread touches the partly-destroyed device?
|Done
|Working on it. Needs a dbus-python uprev :)
|Done
|Done
|They are random - as Kees pointed out, they _can_ collide, in theory. You guys can fight about whether this is worth doing or not :P
|Restructuring the loop to check for this is ugly, but okay.
|I looked and did not find such a thing in base. If it becomes important, I'll factor it out later.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Yes. See /share/org.chromium.debugd.xml for conceptual documentation about that.
|Done
|Done
|True dat. The fact that you can't x[y] on a const map is very irritating.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|crosbug.com/23964, sorry
|Done
|Done
|crosbug.com/23964, sorry
|Done
|Done
|Done
|If I turn out to need it elsewhere, it's easy to factor it out.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Deleted.
|Moved to the heretofore-unimplemented Init() method.
|Done
|Done
|Done
|Done
|Done
|It's not. Done.
|Done
|Done
|Not all of them are needed. I removed some.
|So that we can chromeos::InitLog(kLogToSyslog), I believe.
|Comment is dead.
|The underlying process is never supposed to be killed (it is a persistent helper process), but I can avoid leaking the Process we use to track it at least.
|'start_debugd' seems weird, since the whole process is debugd. I think 'start_dbus' is right, but I've added a comment to explain.
|The attribute? The default visibility of symbols in these modules is static (see the Makefile), so this attribute causes main to be exported.
|the logging code (chromeos::InitLog) CHECKs that the commandline has been parsed, even if you take no arguments.
|Done
|Done
|Done
|'debugd', now.
|Done
|Done
|Done. It does work fine as-is, though.
|Done
|Done
|c++lint complains about use of sprintf :(
|Added more explanation.
|No. There should probably be a PingStopAll that we call on logout or something...
|I think it does. Removed.
|I've punted on this for now by now even tracking the helper processes.
|Nope.
|Nope.
|Done
|Done
|Now dead code.
|Now dead code.
|Done
|I have now exposed every option crosh supports.
|Obsoleted.
|Done
|I switched to the chromeos implementation.
|The randomness is generated from /dev/urandom, which does not steal much entropy from the system pool.
|It needs to be unmasked on the host, and I do not know where to put that.
|It was fixed, apparently. I cannot reproduce the failure, at any rate.
|Style elsewhere in this file seems to use a newline between { }
|Hm. I guess, but that error case should be _phenomenally_ rare, and all that happens is the user has to hit C-c in crosh, which is itself a debugging tool. *shrug*
|Done
|Done
|I can't check its exit status since the open() of $fifo blocks, but I can ensure that it'll write _something_ by also sending stderr from dbus-send to it.
|I always quote options here and the resulting string is passed to dbus-send quoted. dbus-send has a very strict view of what constitutes valid syntax, so I think we're good there.
|This isn't the right place for that to happen, I think. Hmm. dbus-send coerces non-integer values down to 0, and the remote ping method will complain if it gets bad counts, so perhaps the right thing to do is just to relay the complaint back?
|No; it's for debugging. DELORTED
|We can get into trouble here if we get SIGHUP. I have put up a separate CL (https://gerrit.chromium.org/gerrit/12574) to trap it. Other than that, I think we're good.
|Like the burning of a thousand suns.
|Done
|Done
|Done
|Done
|:[
|bool?
|:[
|int?
|Done
|Done
|I would need to strip out a lot of stuff. I will refactor this soon instead.
|Please do.
|No. We don't enter the dispatcher in Run() (and therefore can't process any messages) before Init() has been called.
|Done
|Done
|Done
|Done
|I will do this in a separate CL.
|Done
|Done
|Done
|No. It didn't seem beneficial.
|is-flag?
|I did 4.
|Well, there's a problem: Value can't handle those types, but I'm afraid to introduce new arms of the Value type, because people might switch() on them. Value is supposed to map pretty directly onto JSON, too, and JSON doesn't distinguish integer types. It seems like I can:
1) hack stuff into Value,
2) coerce them down to int32 and hope nobody needs the extra range,
3) range-check and fail if they're out of int32 range,
4) store them as strings instead
|Done
|I believe this is unnecessary if we drop the -I below
|Hm. It does, but it seems like so far every other package that uses libchromeos also includes those for its own use. Filed as http://crosbug.com/24967
|No - people always include libchromeos headers as &lt;chromeos/...&gt; because their names alias the names of many other common headers otherwise.
|Done
|Done
|Done
|:( @ 1
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Hm. I think a recursive delete here is the right thing to do, since we're already destroying the cryptohome at line 470; even if it was still mounted after UnmountCryptohome() above, we've already deleted the files, so there really shouldn't be anything under the directory. That said, better safe than sorry...
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Hm...
|Done
|Done
|I think we're good here.
|Why would it not be private?
|Currently nobody. They're about to be managed by Mount/Unmount in a future cleanup CL. As of this CL there's only ever one of them.
|and here
|and here
|Please put parens around the argument to sizeof(). It's cool that it's an operator, but :).
|This is done now, right?
|It is added as part of &lt;https://gerrit.chromium.org/gerrit/#change,15237&gt;, upon which this change should depend.
|When would this be true and when would it be false?
|Compiles for me. Previous code does it.
|Done
|Done
|Yes - I compiled debugd against these XML files and called one of the interfaces presented therein. Once that code is into debugd, that will serve to test this.
|Done
|Done
|Done
|There is now - subsystem &quot;none&quot;.
|Yes, because /bin is bind-mounted in.
|I think all readable logs.
|Done
|Done
|Done
|Done
|Done
|How come?
|Done
|Planning to clean it up in my next CL :)
|DELORTED
|Well, they need to exist, so that other files that include them will compile with gcc -MM/-MD. We could touch empty ones with epoch timestamps or something.
|Overrated.
|Done
|Done
|Done
|We still have to include it, yeah, but I don't think -I.. is a good thing for us to do here.
|ditto
|ditto
|There should not need to be a build command given for a .o file...?
|can this fail?
|return strcmp(fw, &quot;nonchrome&quot;);
|all_zero &#124;= value[i]; all_ff &amp;= value[i];
|and then all_zero &#124;&#124; all_ff != 0xff? Might be too much of a cute trick, though.
|Does this need a separate case? Why not just let g_file_get_contents() fail?
|I am super curious why we need to supply '/.' there.
|wtb bug number
|this function is way too generically named
|so's this
|the rest of this code uses C-style comments
|!okay
|char or gchar?
|Done
|Done
|I can change this as desired. When bartfab@ and I discussed this we decided upon 'foo/ephemeral' (no @ sign at all) meaning &quot;this is a special ephemeral user&quot;. I've changed the existing code to ensure that there's no @ sign in the username either.
|Whether the mount object is owned by the asynchronous callback itself (and hence needs to be cleaned up at the end) or by the service (and hence not) is not something that the MountTaskResult can know unless we tell it. I was toying with introducing reference counting, but I don't really want to have shared_ptr&lt;&gt;s everywhere.
|Done
|static inline functions &gt; macros
|it is widely considered rude for libraries to abort()
|one-letter variable names: not sure if want
|no tabs please
|?
|y u no list.h?
|Good catch.
|CHECK(mount) is probably better, since it's a programming error if we ever get here with no mount.
|Done
|Why is this a warning?
|Why move this?
|Why did this need to be moved?
|No - CreateTrackedSubdirectories takes the Credentials precisely so it can get the homedir path from it.
|? Why are we no longer creating the passthrough dirs in dest?
|Is this something you're worried will happen?
|WARNING
|Hm, I was only imagining one keyset per Mount. We can support multiples with a list pretty handily.
|Done
|Done
|Done
|Updated the commit message.
|Not yet. Added a TODO.
|It emits pretty-printed JSON instead of the old format. As far as I can tell, nobody relies on the output format.
|It is actually a piece of global state (whether we've sent an UMA report for pkcs11 failure).
|Done
|Done
|There is a later CL to introduce this change.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Store it on disk? Yeah, seriously. Filed as crosbug.com/27798.
|Done
|Done
|Done
|Done
|Yeah, tell me about it.
|Done
|Yep.
|Yep.
|Because I don't want that interface to exist, because I don't want Mount to call into HomeDirs at all, and I think the less I solidify it, the less people will try to use it.
|value.size() is the length of the string. Maybe sizeof(*value.c_str())?
|Done
|Done
|Done
|Done
|It doesn't like sizeof(type), preferring sizeof(var), but we're stuck here since there's no actual char-type variable involved.
|Done
|I wish!
|Yeah, invocation of atoi. We can use strtol but we still get the warning (!) with a request to use safe_strtol, which doesn't exist.
|Done
|Because (right now) first will be something bogus like &quot;&quot; or kMagicalMount (i.e., not match the actual username, if any, of the mount).
|Good idea.
|Done
|The Init() refactor comes in a CL that depends on this one, sadly. They will be gone very shortly.
|Done. Look what thou hast wrought...
|Done
|Done. In fact, the retry itself should be inside Crypto.
|It should be logged inside Crypto::DecryptVaultKeyset, yeah.
|Separate CL, I think. The logic is very simple and mocking enough stuff in Crypto will take a little while.
|Done
|Done
|Yes, as part of the homedirs tests.
|It checks the username as well.
|I think I will refactor this later.
|Done
|I've stopped doing this and added CHECK()s in the constructor.
|Done
|Done
|Done
|Done
|Done
|Only by the unit tests. They will be used shortly.
|Yeah. I think it's a hack around the not-really-unit-test nature of our unit tests.
|Done
|y u no test for NULL?
|assert that we hold the lock?
|No. See base/callback.h.
|Done
|Done
|Done
|Done
|UpdateCurrentUserActivityTimestamp would return false, which would cause the cli to print a message about there being no users logged in. Now if there are no users logged in nothing will happen. I think I'm okay with that change, as it makes more sense to me (it does successfully update the timestamps of all 0 logged-in users).
|minijail doesn't use {} around one-line if bodies.
|Done
|Done
|Yes, we do want it set on error, because the cleanup code in service.cc needs it to know which mount to remove. Credentials never persist past failure because the _mount_ does not persist past failure; mounts exist in the map iff they are currently mounted. This should not affect any other calls; I have read them and they seem not to use it incompatibly.
|Comment re-added. It shouldn't affect mount time much since it involves loading and saving the protobuf from disk again. Is there a way to get actual speed numbers?
|No, it doesn't - it clears keyring entries that were added in _this_ Crypto context. Each Mount has its own Crypto, so we'll only clear our owning Mount's keys.
|Oops. Old comment :).
|Done
|Yeah, probably. The Credentials API needs a little bit of refactoring. Separate CL, though.
|Yeah. Unfortunately there's no way, afaik, for cryptohome to tell when the device policy has been updated, so we have to reload it all over the place :(. I think Chrome should send out a dbus event when it fetches a new policy (or whoever does the policy updates), but I don't understand that subsystem well enough.
|Fixed, I think.
|Actually, yeah. Hm. The only way we can ensure that the mount hangs around is to do the timestamp update before the notify, so let's do that.
|This name is entirely internal, so it should never matter unless Chrome asks us to mount a user called that. I guess we could complain?
|Mounts aren't allowed to _exist_ if they aren't in the map, so yeah, this is a bad programming error. I think we should CHECK().
|Done
|Done
|Done
|Done
|Done
|Ugh. Not quire sure. Probably bad, since each crypto context thinks it owns the entire process's keyring. I'll sort this one out in a later CL.
|why is this in /home/chronos?
|-c 0 enables SECURE_NOROOT.
|Can these not be macros, perhaps?
|return runcmd(argv, NULL) == 0;
|Done inside Tpm::Init.
|Added.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Busted! Done
|Awful hack inserted.
|Hm. I will think about how to solve this.
|Done
|I've given this a little bit of thought:
* The X things (xrandr and setxkbmap) need X access, which I am loath to give to debugd
* We are not in a pid namespace, so 'ps' will work, but we need 'ps aux' unless we just want to see debugd
* amixer should still work fine since its config is system-wide
* network diagnostics should work as any user (haven't looked in detail yet)
|Done
|pid namespaces is what matters in this context.
|That list has properties of GetViewport (see &lt;http://www.jwz.org/xscreensaver/man1.html&gt;). It's a list of functions that are safe to reenter on the same thread that was already inside them, not a list of functions that are safe to call when your locks are broken.
|Done
|Done
|This is a good thing.
|wait, is that right? debugd's trying to talk to modem-manager with that, not to shill.
|Done
|memchr_inv(buf, '0', bufsize)
|this is good, but for bonus points, sizeof(dev-&gt;meid).
|same
|this '6' here is a bit dubious
|EFAULT is not the right error to use here - perhaps EINVAL or EIO?
|same re EFAULT
|see buffer.h
|fallible
|Done where possible.
|Done
|Done
|Done. Good catch!
|Done
|Done
|Done
|Could we change these to the (1 &lt;&lt; 1), (1 &lt;&lt; 2), ... style?
|Done
|stick this in cryptolib.cc, not crypto.cc, please :) (I am trying to ensure crypto.cc depends on tpm.cc depends on cryptolib.cc to make a future refactoring easier)
|you should not end up needing a Crypto instance at all, I think.
|This is usually present at just /home/.shadow I think
|cryptolib.cc's AesEncrypt/AesDecrypt does this.
|You may wish to put the non-RA-specific parts of this into cryptolib.cc as something like:

string HMAC(const chromeos::SecureBlob&amp; key, const chromeos::SecureBlob&amp; data)
|is it normal to have this 'version' field? I thought protobufs were supposed to handle that internally
|kWellKnownExponent already exists
|I support this refactoring so much.
|yikes... not SecureBlob?
|we lose this default?
|cd $(dirname &quot;$0&quot;)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Can we get an enum for these values?
|whence 20?
|I do not like CHECK() for out of memory conditions.
|do these have enumerated values somewhere?
|why?
|wow, that's pretty gross :( I don't suppose we can overlay a struct on the nvram buffer, can we?
|Done
|Done.
|Done
|It is created in SessionManagerService::Initialize().
|Done
|Done
|Okay, moved.
|Because it was used in exactly one scope (this one), so I declared it in the narrowest scope possible.
|Done
|Yep. We agreed that this was the least bad way to do it.
|Oops! Don't code without sleeping, kids!
|Done
|Done
|Yup.
|You are right that it should be ?1. However, we are meant to succeed _only_ if the WP switch is set, so it should still be if (!IsFirmwareWriteProtected()) return false;.
|Done
|Done
|I think that's okay.
|Done
|Hm. The comment in rotate_logs() tricked me. I have fixed this to only touch the right log files.
|On old installs, /var/log/messages will still be owned by root, so we do need the chown. However, the touch is irrelevant now.
|Done
|Hopefully more jrbarnette-friendly now
|If you insist... https://gerrit.chromium.org/gerrit/#/c/32278/
|It did not. Even the absurdly-generous default limit (200 messages over 5 seconds) is enough to kill most of shill's output (!!).
|rsyslog should be responsible for creating that file, and it's running as syslog.
|I can move it later.
|Done
|Yeah. An unhandled exception fails the test, I'm pretty sure :)
|Is it 2012 already? Jeez. Done.
|Done
|Done
|Done
|t
|not Feedback()?
|I don't understand this change
|the old name was more accurate
|can I get a version bump?
|I think you mean -fvisibility=hidden, since gcc(1) describes -fvisibility=internal as useless; if that is so, see line 5 :)
|Done
|Done
|As I was writing it, I thought to myself &quot;these three lines are the sketchiest thing I've ever written&quot;
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Hmm. Good catch :)
|I guess, but I generally prefer the transparent struct + setup/teardown pattern to the opaque struct + new/free pattern.
|Done
|Done
|Do we have one of those?
|Done
|Done
|Hm?
|Done
|I could, but I'd have to make the rtc fd global :(
|Ya, it is :\
|Done
|Check pending.
|Done
|We can't miss a route coming up that way - we open the netlink socket before the initial tlsdate() invocation, so the route-up event is still queued.
|max_tries * subprocess_tries
|Maybe. What's uma-syslog?
|Done
|Done
|Done
|Done
|I couldn't think of such a sane way, but I am all ears.
|I'm not sure. Probably a minijail launcher so I can keep the policy out of this code.
|I don't think we can corrupt the timestamp file this way, but nonetheless I will exit cleanly.
|Done
|Done
|We do: http://git.chromium.org/gitweb/?p=chromiumos/overlays/chromiumos-overlay.git;a=blob;f=net-misc/htpdate/files/htpdate.conf;h=32d8809162ed38a4f26e8b6a990cc46b2fb1935a;hb=HEAD#l4
|Changed to do this differently
|Done
|Done
|Done
|Done
|Done
|Done
|It probably won't be too bad...
|static! -fvisibility=hidden :P
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I prefer doing both :)
|Done
|Done
|Done
|Yes, definitely. The failure might be because we opened a socket to the web server and then the connection broke somehow (tls failure or whatever), and we don't want the possibility of DoSing the server.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|if the prefix is too long, it implicitly doesn't fit into a temp filename either since those have .XXXXXX appended. That said, we should just bail in this case anyway, since the user invoked tlsdated incorrectly.
|changed to exit(1), since we're permanently broken in this case.
|I was deliberately excluding O_EXCL so that this code would recover from transient rename(2) failures. Added O_NOFOLLOW, though.
|Removed.
|http://www.youtube.com/watch?v=2C2W_O9BX4g
|Done
|Done
|Done
|If no date was acquired, one of two things are true: either we did load an old time off the disk, in which case we'll save that + however long we've been running for, or we didn't, in which case we'll save the epoch + some value, and load_disk_timestamp() will reject it at the next run.
|Changed to wait for routes instead of interfaces, and changed to retry periodically once a route is up.
|It didn't have copyright boilerplate before... do you want me to try to write a boilerplate for upstream (?)
|Seemed like a sensible default thing to do
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|You mean there are people who don't have errno codes memorized? Done.
|Sadly not so easy with absolute paths, which this will probably be given :(
|Done
|Done
|Done
|Done
|A big stumbling block here is that I don't know what the default system clock looks like on systems with no battery-backed rtc. Does it start at 0, or at some random time?
|It emits 'u &lt;name&gt;' every time ifchanges_once() returns zero with *up set; ifchanges_once() returns only when it gets a read error (in which case it returns -1) or gets an interface state change (in which case it returns 0). We _can_ miss interface state change events at boot, but it doesn't matter, bceause we open the netlink socket, then always run tlsdate at least once, then begin listening for events. We could miss events from early boot, but those would not cause any additional runs of tlsdate.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No. It was left over from a long time ago.
|Done. I'm honestly not sure this is worth factoring out, given that we're meant to stop using dbus-glib.
|No. The man page implies that they just return pointers to static structures, and inspection of the source confirms this.
|it could; I haven't yet had a reason to care either way.
|Needed to tell if it worked :P
|why?
|Eh.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|cryptohome used to be full of places that said &quot;TODOBASE: thing to do when libbase is updated to 125070&quot;. most of them are gone, but I think I missed this one :) delorted
|Done
|Good catch.
|Done
|They are in a class so that they can be mocked for testing.
|delorted
|Done
|I don't think it makes much difference either way. You'd never use this class independent of the Process function that returns it.
|Done
|Done
|unsolicited feedback time
|We don't run against anything right now - see the 'subprog' line lower down, which overrides the default tlsdate command. We should eventually run against a local openssl server, though.
|Yes, we could do that.
|Done
|Done
|respawn added. No, it shouldn't expect daemon or fork; tlsdated does not background itself.
|Done
|Done
|Done
|Done
|Done
|Good call.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|oh, the XXX was &quot;can we safely dup this?&quot;. The answer's probably no.
|Done
|Share.
|Done
|Done
|Hrm. It could, but those are mostly errors. I will think about it.
|Done
|Done
|Done
|Done
|Done
|I think we just ignore it. WFM :P
|Right now debugd doesn't sandbox the individual bits of the log helpers, so for now yes. I can tighten it up more later.
|*shrug*
|Done
|Hrm. Yes, because the mount can finish (and the lockbox init then fail/go insecure) before tpm init finishes. The mount task might cause us to skip this by setting is_first_install().
|Yes - the command-line client does if you don't supply --async.
|No, this should be synchronous, since this is a synchronous Mount. It's okay for it to block until 'really done'.
|Ugh.
|needed?
|Done
|Done
|It will once the job that writes the proxy file is changed to restart tlsdate. That change itself is blocking on proxy support in tlsdate.
|Done
|Done
|Done
|The wrong answer is the previous proxy value (or 'direct' if there wasn't a proxy set before, I guess). I'm trying to find out if one second is enough.
|Not sure if it works yet :). It shouldn't confuse upstart - we launch a subprocess and then wait for it.
|Good call.
|Done
|Done
|Done
|I'd rather not, as it's a waste of effort (the exec() will change it back to being root anyway, so we're just wasting a minijail invocation).
|Done
|Same here.
|I tried that, and it made the invocations uglier for no real benefit. I prefer the extra helper function.
|That's because it is tagged Security.
|De-tagged.
|Added to platform_FilePerms: https://gerrit.chromium.org/gerrit/#/c/38121/
|Done
|I am not sure. I've seen scripts in /dev before (e.g. /dev/MAKEDEV or whatever) but I'm not sure if those are present/meaningful with devtmpfs.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The assert was just a debugging aid to see which type mismatch was happening; now that I'm done with debugging that, I can yank the assert :)
|Why return the std::vector: because that's how dbus-c++ generates the wrappers. If you only have one out argument (as you do), you return it from the handler; if you have two or more, you are void and take multiple pointers instead.
|You can fix this now.
|I don't know.
|Done
|Done
|No, this exposes the system to a compromise in any of the sandboxed helpers debugd launches as debugd. I'm not sure how important it is but we should _definitely_ fix this acl.
|these should probably be bound together too... as is, this allows debugd to a) call all methods on wpas and b) send to org.freedesktop.DBus.Properties on _all_ services.
|No.

The vector of options comes over DBus; there's no reason an element of the vector can't contain a comma. I can supply &quot;shortname=whatever,sb=1&quot; as an element of that vector and we'll happily shove that into options_, then return it nicely in ToMountFlagsAndData().
|Who do we ask?
|sadly the conf file is for tlsdated, not tlsdate, and the real-world config of tlsdated doesn't work for this test, I think (error delays are too long). I will think about it, though.
|Like what? update_engine and tlsdate use their own root sets; platform_OpenSSLActual tests that the root certs are installed where they should be and useable by openssl. I'm not sure what other coverage we need.
|agl@ and secops in general
|Done
|This test covers use of this root set. All the users of openssl that I know of on system have their own root sets anyway.
|cros-dev is the right list for system library issues. This isn't a security test.
|Done
|No. This test requires outside network connectivity, so I don't want it to randomly flake some other test suite.
|Done
|Done
|If someone makes curl statically linked, this will still test OpenSSL.

We could use the OpenSSL command line as well, I guess. Hmm.
|I don't *think* so - there are other gpl'd autotests (security_ptraceRestrictions, security_HardLinkRestrictions)
|Done
|Done
|Done.
|Done
|Done
|it's turning a text IP address (what python uses) into a network byte-order address for socks5's wire protocol. Commented.
|Done
|Previous code actually used hard tabs (!); swapped them for 4-space soft tabs
|laziness, and other autotests seem to work this way.
|Done
|Done
|Done
|Done
|typo
|is we do set cancelled, should the return status be something cooler?
|you can restructure this a bit to save indents:

if (it-&gt;substr(...) != ...) continue;

you can also kick the if (mounts) check out of the loop altogether I think.
|this pattern appears common enough that it should have a helper function
|can race against RemoveMountForUser() to end up with a NULL mount in the map for that username
|As I understand it, the indentation rules are &quot;tabs for logical indents, spaces for code alignment&quot;.
|Haha - I see the spaces-for-indent pattern all over. I thought it was the thing we always did.
|Done
|I used Platform here because it means the unit tests can run entirely without touching the filesystem (because Platform lets us mock out all filesystem accesses). Cryptohome does this too. Ideally I think all this code should switch to using Platform instead of file_util, but that would make this CL huge :)
|Done
|See above
|It is used in the MigrateUppercaseDirs() unit-test.
|default_platform_ exists so that the platform we default to (a newly-constructed one) is freed properly when this class is destroyed; platform_ exists so the default platform can be replaced with a MockPlatform for unit tests.
|I think it's nicer for unit tests not to touch the filesystem at all if they can avoid it.
|surely there's a better way to do this than sleeping?
|Maybe it is time to factor this logic out as there are now four copies of it in this file. Also, this isn't memtest.
|the pid_file here is unnecessary (and a security risk); just have the method return the pid like tracepath_tool does
|No. Please don't write arbitrary files that the caller specifies, especially since we're root (!). Instead, just return the pid from this method directly.
|can 'badblocks' run while sandboxed?
|No. The debug daemon should _not_ write arbitrary files on behalf of its caller, especially as it's running as root.

In general, I think this mechanism is unnecessary and inferior to the one in tracepath_tool.cc (i.e., where we just return the pid from this method to the caller).
|No. The function in libchromeos just returns a static string.
|Done
|Done
|this too can fall afoul of log rotation, if you care about that
|by default getmsgs returns only the last day worth of logs so this can still miss the firmware version
|this is going to be un-injectable and hence un-testable.
|these aren't percentage chances, but this example sort of makes it look like they are.
|this is basically the definition of a flaky test :(. For this to be a unit test, it needs to supply a mock RNG that returns a stream of values you 'know' are properly-distributed or similar.
|Alas, not quite. If we are native (i.e. QEMU_CMD is not set) the next thing on the cmdline will be LD_LIBRARY_PATH=... which causes an exec failure.
|hrm, it seems like this method's name is full of lies if its result needs to be anded with 0777...
|I think we can minijail ourselves as soon as we have this handle. We really should (as a dedicated uid/gid) because libpcap is exposing a lot of attack surface to the network here and this code currently runs as root.
|'continue 2' and you can drop the if statement after this loop :)
|SubprocessTool::CreateProcess(false)
|Please write this as DisableSandbox(); otherwise bad stuff will happen when we strengthen the sandbox :).
|I don't think you need/want this since:

p = new ProcessWithId();
p-&gt;DisableSandbox();
AddProcess(p)

is equivalent to:
p = CreateProcess(false);
|is this actually needed? debugd has worked fine without it
|We could; cryptohome uses a mix of both styles all over the place. I broke this out into a helper with separate constants.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|this should instead ask sessionmanager for the active user sessions, if that's what it's looking for.
|this kind of thing begs for an assertion
|yep
|fgets
|the cert is made out to CN=127.0.0.1, not CN=localhost.
|O_o
|I sure hope we shred this thoroughly later
|Done
|Mistakes were made. The chaps proxy in the CL this depends on returns a boolean, and returns false for failure, but otherwise returns an unmassaged error code from PKCS11. It happens that the 'OK' error code is 0, so the method would return false on success as well as on failure, and sometimes return true on failure.

I've fixed the chaps CL and fixed this to match.
|Done
|Done
|Renamed to 'exclude', since they are the mount points we exclude.
|I moved this down below.
|Probably, yeah.
|see the header file comment in patchset 2
|I suppose I don't understand why these are even optional here. We could have the invoker just always pass them (passing the desired defaults if necessary) and then not do any commandline parsing here other than checking argc and calling strtoul or equivalent. It seems sort of a waste of effort to add a &quot;UI&quot; with help messages and so on to an internal program.
|please leave the &lt;&gt; in place - they are there to ensure the output isn't possibly mistaken for valid JSON.
|this no longer checks that it's seen the other info it needs (packets transmitted, etc)
|this doesn't matter in practice, but these should still be quoted.
|this blank line isn't needed
|a
|?
|.WillOnce?
|what's the reason? I don't remember ever having to do this with tar
|Done
|Done
|Done
|Done
|Done
|whitespace
|MockFileEnumerator already supports something like this through its entries_ member - you could probably add an Add() method or something to MockFileEnumerator and collapse this to: files-&gt;Add(keyset_paths_[0])
|No.

This is basically unreadable and makes this code totally unmaintainable for people who don't read awk. Please write this in C++ instead. It'll be a bunch more code, but likely also more modular, more testable, and more maintainable.
|I am a fan of this
|I don't really want full shell scripts here. How about cat 2&gt;/dev/null or somesuch?
|The design doc mentioned here is in the debugd source tree itself, in /doc/design.md.
|Yes, please do :)
|Please invoke 'perf' by path like the other command does. Depending on $PATH unnecessarily is not advisable.
|does 'perf list' have to be run as root?
|whole bunch of trailing whitespace in this file
|needs a space between ) and { here and below, see https://google-styleguide.googlecode.com/svn/trunk/javascriptguide.xml#Code_formatting
|logging stuff like this should probably be conditional
|space between // and comment text here and below
|please pick one of camelCase and underscore_style to use; google style calls for camelCase. See https://google-styleguide.googlecode.com/svn/trunk/javascriptguide.xml?showone=Naming#Naming

Also, is this part of the public API that FTPClient presents? It's not marked 'INTERNAL'.
|we can just return this directly? return new Promise(...)
|space after comma
|not 'function getReply(rawData, receivedData) {'?
|this constant is only used here so it can be function-scoped
|hrm, this technique seems weirdly inefficient/C-style. We don't need to keep the entire response in a contiguous array until we're actually called upon to return it; until then, we can keep an array of Uint8Arrays that we append received chunks to as needed, then stick them together when returning the response. That would make this code much nicer to read I think.
|this constant can be function-scoped
|this function needs unit test coverage
|please don't do this - instead of RESOLVE = 0 REJECT = 1 and using an array, do:

this.pendingReads.push({ 'resolve': resolve, 'reject': reject })

above, then you can do:

this.pendingReads.shift().resolve(reply)
|BUFFER_SIZE?
|is this needed?
|'typeof(port) != &quot;undefined&quot; &amp;&amp; port != &quot;&quot;' is easier to read I think
|same here
|what is this doing?
|do we know if it worked or not?
|can all the qunit stuff (and all the third party stuff in general) live in third_party/thing so it's obvious it's not part of this project?

So for example all the qunit stuff would live in third_party/qunit
|You probably want a fixed localPort, or a steadily incrementing counter, or something similar. It's generally a good idea to avoid any sources of randomness in unit tests if you can because they can introduce intermittent failures (although I think this particular one is harmless)
|what's -9?
|what's -102?
|please don't mix camelCase and underscore_style; js code should use camelCase. Also, I think this doesn't match the name on the chrome socket API
|what's -15?
|this seems kind of dangerous - does the real socket api allow this?
|I don't think the connection window in the actual app should need to use the mock socket library...?
|I like this design
|please space this out a bit more nicely :)
|This is a non-descriptive function name. Maybe 'splitLines' or something?
|what are these?
|why?
|why is the host ignored?
|why are some of these on MockSocket and some on Socket? that seems wrong...
|unused?
|trailing whitespace here and elsewhere
|instead of tracking lineStart/lineEnd, what if we hunted for the first &quot;\n&quot;, then used subarray() to get that line and the remaining data, then continued with just the remaining data? like:

index = find(receivedData, &quot;\n&quot;)
line = receivedData.subarray(0, index)
receivedData = receivedData.subarray(index)
|rawData.parsedLines.slice(0, endOfResponse).join(&quot;&quot;)?
|don't need to do this - you can just do

var legalDigits = &quot;0123456789&quot;;
legalDigits.indexOf(replyCode[0])
|maybe throw an exception or something?
|indent the comment with the body
|this doesn't seem like it's synchronous at all...?
|upon
|cmd isn't an acronym
|you're going to have to do this encoder.encode() / uint8array dance every time you want to use sendcmd - maybe sendcmd just needs a higher-level API? like

sendcmd(&quot;USER &quot; + username + &quot;\r\nPASS &quot; + password + &quot;\r\n&quot;).then(...)
|what are 5 and 4?
|multiple mock sockets have the same local port?
|this is indented way too far
|testing typeof(peerPort) != &quot;number&quot; is redundant with typeof(peerPort) == &quot;undefined&quot;, and the isNaN test needs to go after that test
|why is this CONNECTION_REFUSED and not UNEXPECTED?
|rel = nofollow?
|this can really just be client.connect(...).then(...).catch(...)
|we should test that the underlying keepalive function was actually called?
|these would be way easier to read if they were strings, like:

var response = &quot;whatever&quot;;
var responseArray = new Uint8Array(response.split(&quot;&quot;).map(function(x) { return x.charCodeAt(0); }))
|access
|a comment describing the format of 'unixLsOutput' (with an example) might help here.
|56?
|I think it is nicer to do this by having a separate css class for selected-listed-{file,dir} and changing classes here, since this otherwise duplicates part of the css
|would handleDownload() ever be called in this situation?
|$() does this
|this is duplicated with listRemote()?
|bad merge?
|these can probably go
|as can these
|why is this done?
|what is this -100?
|this code was &quot;originally&quot; added in a subsequent CL https://chromium-review.googlesource.com/#/c/210350/ - how come it's in this CL now?
|this code and below (the &quot;parallel file writer&quot; thing) can probably be moved out into their own library
|why 5?
|on what basis?
|it seems like you can do this whole thing with an appropriately clever regex
|what is this doing?
|so excited :)
|random what?
|/^\d+$/
|this is actually called an &quot;ISO 8601 date&quot; after the document that specifies this format
|why is this here? shouldn't it be in a unit test?
|this can probably go in FTPUtil
|this stuff can still probably be split into its own library (FileWriter?)
|duplicating this regex seems unnecessary
|goodness
|this file seems to duplicate one of errol's CLs?
|I think it is better to add/remove a css class for this than edit the css directly
|return s.match(/^\d+$/) !== null?
|this generates a non-localized (en-US only) date, you may want to use the JS Date class' toLocaleString method instead.
|are seconds not allowed?
|function names should contain verbs generally
|This will do the wrong thing in locales that use different date formats. It would be much safer to use javascript's Date object, then use the toLocaleString on that to get a localized string representation of the date.
|what is this doing and why? this is kind of scary code (constructing a regex on the fly from remotely supplied input!)
|please do this :)
|you don't need collapsedSpacesEntry - you can just do entry.split(/\s+/)
|isDir being false implies isFile is true and vice versa, right? we don't need both of these?
|remove dead code please
|this logic should probably go in its own function
|what is this function adding? why not just call resolve() where we would call it?
|the indentation here is all jacked up
|don't use tabs for any of this code please
|there has to be a better way than hardcoding this...
|please remove tabs
|you can't call notifyUI after you throw
|the indentation is still wrong because the preceding code uses tabs
|this still has tabs
|what is workingWriters for? If we try to write 1000 chunks, will we fire off 1000 writes?
|what's this change?
|??
|Done
|Done
|https://gerrit.chromium.org/gerrit/#/c/47118/
|Done
|Done
|doesn't jQuery.noConflict() already do this?
|Oh, I understand. No, that's okay.
|please indent with spaces: https://google-styleguide.googlecode.com/svn/trunk/javascriptguide.xml#Code_formatting
|why is this wrong?
|trailing whitespace
|fix indents throughout please
|please pick either camelCase or dashed-style (I prefer dashed-style) for these identifiers
|fix indents please
|is this all for the unit tests?
|:)
|this is an odd pathname
|trailing whitespace
|indent
|jquery can do this more nicely I think, like $.create('li')
|&quot;client side&quot; of what?
|dead code?
|is there something else we can do here? also, indent?
|trailing whitespace
|spaces please instead of tabs
|it might be nicer to test and debug if this function got a directory listing and returned it instead of calling directly into displayEntries()
|this needs to be indented
|this seems like the wrong abstraction layer to do this - ideally the ftp library should be parsing the ls output and giving this function a parsed representation of it
|ui manipulation should probably be separated from parsing
|what's this filename?
|why is this here?
|ditto this
|does this still need to be done, or?
|I think it is better to add/remove classes than manipulate the css directly from here.
|don't use tabs to indent please
|this comment probably doesn't need to be here
|tabs -&gt; spaces
|I don't think socketIds should be exposed like this (or tested as part of the API)
|is the message really supposed to be &quot;error code -9&quot;? maybe we need a better message
|we should probably test non-anonymous logins? or is this not the right place?
|don''t use tabs to indent please
|trailing whitespace
|please use spaces instead of tabs
|please use two-space indents, not tabs
|offset
|roman numerals don't make for good var names (they are too visually similar to lowercase 'L'). I recommend arabic numbers instead.
|offset
|this isn't right at all - lines can come in as separate network reads, and multiple lines can come in in one read. This class needs to handle that.
|this file should probably be a module, and/or not be indented, and use strict
|trailing whitespace
|I think this should be in a module
|what's context?
|context is not used?
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Patch Set 1: Verified


|Change has been successfully cherry-picked as b26f62afe172a9c55fbe5ad25073bcbd9da1219a.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (2 inline comments)


|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1:

Please take a look?
|Patch Set 1: Verified


|Change has been successfully cherry-picked as aab5020d173bc81b7804ae47dd8a7c9db7bbc617.
|Patch Set 1:

Please take a look?
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1:

Please take a look.
|Patch Set 1:

I thought about handling it with the same code path, but it seemed like it would be asking for trouble later when we had something we wanted to do just at suspend and not at shutdown - the next person to try to work on it would have to untangle which effects were important to both and which weren't.

In brief: Yes, we're duplicating code, because I don't want to create a false unification between the suspend semantics and the shutdown semantics.
|Patch Set 1:

It already is disabled on suspend. See src/service.c:service_system_suspend() and src/service.c:__auto_connect().
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 923cb6f8bcece6725efde0ece60a7aca39f518d8.
|Patch Set 1:

Please take a look
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 2f9eb3fc18d6d22e69c10a5ea14b1456c4ec4398.
|Patch Set 1: Verified

The 'refcounting solution'.
|Patch Set 1: Looks good to me, approved

http://code.google.com/p/chromium-os/issues/detail?id=15017 is the test for this.
|Change has been successfully cherry-picked as 802a2d60b5a5859abf78c1289e24ce2e6a560255.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as e6ead15b3365cfea78d3ee63d4398a3dc61b4d25.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as a89e408baa6e23b0ce937b7aab41d52ef8160d3d.
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 228ee13743aa67d8af61f89a01dc33aa5c53cb1a.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as abd879164af812b5303d216a87ec3121a3ff1635.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as fab674162cad142777adad18d2be14fe12be9cc2.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (11 inline comments)

I have addressed all inline comments.

Olof, the idea you suggest is clever, but it worries me from a maintainability point of view; in particular, I fret about someone seeing 'aha, void*' and passing it to kfree/krealloc or similar. In general, I would like for it to stand out when we have a special kind of object with a nonstandard destructor.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 44c988ed74a95cd67eecc68a708c688dc763c7c4.
|Patch Set 1: Verified


|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: Abandoned
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 36a634b6e18aadc6e92af14552cc32e41a70a1fe.
|Patch Set 1:

Can you suggest another reviewer too?

(I still need to permute this patch into openssl style.)
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: (1 inline comment)

Hrm. If it's not called, whoever's doing that is in trouble, since the cert chain only seems to actually get verified here... I'll try writing the autotest mentioned in chromium-os:15581 and seeing what happens.
|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified


|Change has been successfully cherry-picked as 9e5b00e37f8e26ae2b17fe7410967a470f2a922e.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 839e402f2347ce9830c4e399a430be8cc03fe243.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified

Even if we do get a spurious wakeup, the code handles it gracefully - if there's an active urb, we just go back to sleep, and if there's no active urb and no work to do, we go back to sleep.
|Change has been successfully cherry-picked as 210a00573431af45eb515ffbfa1e108c15d447ae.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 5f9d1a8c9e86ae3cb54bb7c2b126519593f619e5.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: (2 inline comments)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 6e591e95df5a2af6ecd2849af9a2021627225a6c.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 4687afc43dd487c662c9881b2a18787709ce641e.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e9fd3c9895c7e613c6b2c680bb0893bda030817b.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 1ca433136e4984b26632de45753ee0d2b69832f7.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (4 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (3 inline comments)


|Patch Set 5: Verified


|Change has been successfully cherry-picked as 5ab639efcbe82d00b6dc40bef26a53e4d6dd6535.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 5e7a430a557353bc02aee26686e064ec3a31faa5.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 2:

?
|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 43a232a713a3e5c64e40185b5aa62252ed254d31.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 87534d4606c1adeb2a431c539740b53ef09745c3.
|Patch Set 1: (2 inline comments)

Jim: ModemManager installs policy files for the org.freedesktop.ModemManager destination, and cromo installs policy files for the org.chromium.ModemManager destination.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b64ae2dc074b4849162b38441f1dfef1c9697b2b.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 146baa95ccc9329dc693926cf10e698eca8101c5.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 7a77ce345cbf4cd36d8e075477ffc59c3bde1243.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Now with more workqueue. Thoughts?
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3: (4 inline comments)


|Patch Set 5: Verified


|Change has been successfully cherry-picked as 372b2c5dbfe9411a4dacf626745afacfc3173d13.
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Do not submit


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2:

No -rX needed, I think (or at least, I haven't needed one yet).
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 2ea51e44669062977689ff09a43ac8438f55673f.
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 8e7e299b0bb1d51a06688665b376736785fe90dd.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as f05cc7515236dd7b0fac5f8ad932c4a858b99a83.
|Patch Set 1: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 0eb20ac7561a950e27bb9e784713bb0ed02f8e36.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

LGTM, modulo david's comment.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Abandoned
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Still pending testing.
|Patch Set 1:

Tested, works.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Change has been successfully cherry-picked as a694dc0e8faa957ae268dccf3dea84fcc098459f.
|Patch Set 4: Reverted

This patchset was reverted in change: Ia86d9a301bce9d7233f2a27ebd2a5f6b1e503275
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 5fcc5fba8fa599b48958050bfd90d58d1a880b1e.
|Patch Set 2: (9 inline comments)


|Patch Set 3: (4 inline comments)


|Patch Set 11: Looks good to me, but someone else must approve


|Patch Set 13: (1 inline comment)

Otherwise LGTM :)
|Patch Set 1: Verified


|Change has been successfully cherry-picked as c871ba2df46792b17c805f2a15f72ebcb5821f84.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 8c5e9811506282a54c487d20b33f7a1928c33db8.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (8 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified


|Change has been successfully cherry-picked as f1613ae5dfe9a179d9008fd36582aa7da104848b.
|Patch Set 6: Reverted

This patchset was reverted in change: I07170b695de0447f72502a4dff5f89a13b276460
|Patch Set 1:

Upstream doesn't have the file this is a change against. If I block this change until upstream accepts the underlying do_mounts_dm change (c4d7d695f0382a49c0898825935b224cbd72833b) we will almost certainly not get this in any time soon.
|Patch Set 1: Abandoned

Obsoleted by PARTUUID support in dm-table.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as ebf35a9caf9cf3460409f60e03c9d7e4c3eaf1b5.
|Patch Set 1:

Because it's logically part of the developer-install flow, I think.

(Also, it was convenient. :))
|Patch Set 1: Abandoned
|Patch Set 1: Verified


|Change has been successfully cherry-picked as ecf7c36d0a07954f3c491fa6d5e1a9430b0f7c18.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 1af0a7e5d0f761840206b429fd75b359f3f5e601.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 8d87dbfb281ba552e71cffb0188cc9de5bfbcd37.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 124434d7c2b01422b72844beb1acb74bd1dd4280.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 0e95bbfeccf7dee51d09ed0c17e3bcb3c9cb8882.
|Patch Set 1:

If it is in chronos' .bash_profile, a .bash_profile needs to be present in both unencrypted and encrypted homes (to allow this to work both when logged in and not). How about /etc/profile?
|Patch Set 1:

I have moved this change to:

http://gerrit.chromium.org/gerrit/3382
|Patch Set 1: Abandoned
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 7c0d2e2eeac5d1465f18d37c001d4712cd77b20d.
|Uploaded patch set 2.
|Patch Set 1: (17 inline comments)

Thoughts?
|Uploaded patch set 3.
|Patch Set 2: (12 inline comments)


|Patch Set 3:

Ping?
|Uploaded patch set 4.
|Patch Set 3: (8 inline comments)


|Patch Set 4: (6 inline comments)

I'll try to get speed numbers now.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved

With my change: 2m42s for login_CryptohomeMount
Without: 2m45s

There's a heck of a lot of timing jitter :(. I can't prove anything either way. I did three runs of each of these and these are the numbers I came up with.

Since gaurav LGTMed, I'm going to land this now.
|Change has been successfully cherry-picked as 55e84d29f988361b99c7d61a8982b681b3e7daca.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 5f27baecbe2d67808d40d58fa2c27877771cf5b1.
|Patch Set 1: Looks good to me, but someone else must approve

I approve of this message.

(I don't know enough about powerd to +2 it, though.)
|Patch Set 1:

See e.g. http://build.chromium.org/p/chromiumos/builders/x86-generic-gcc_46/builds/1/steps/cbuildbot/logs/stdio
|Patch Set 1:

Ping?
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 39ba1e5891bec24d9c79e555d978bc0c37d4b9d9.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 376d4ef102685a7bb9ba0d0304d8e635d27e6eec.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as bfc441ae49974f1b144541acbbd7be4de337df5d.
|Patch Set 1: Looks good to me, approved


|Patch Set 6: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)

http://code.google.com/p/chromium-os/issues/detail?id=17245
|Patch Set 2: Abandoned

My innocent attempt to rebase this change has led to a new CL: http://gerrit.chromium.org/gerrit/#change,3900

Please resume commenting there :-)
|Patch Set 2: (3 inline comments)


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as a44802f141b9da40ac3da526c67aee93297dc54d.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as b1b46268ef7b42fd6782f1c434fd4d1028ac9eab.
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 3: Verified


|Change has been successfully cherry-picked as 12512426edb7099848235e15fc1fc27005df2364.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 8ffe9043e190cce75dfac176df94649c9b039b85.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1:

Ping?
|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 6.
|Patch Set 5: (2 inline comments)


|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 7b1d54bf50e21539283d92e1c352eac19c63cc7d.
|Patch Set 1:

olofj: none of this is upstream yet, in part because (AIUI) drewry does not want to submit it until this stuff (this CL and a forthcoming one to kill dm_substitute_devices) is fixed.
|Patch Set 1:

root_wait is specifically for the root device.
|Patch Set 1:

Hrm. I had &quot;separate root and /usr&quot; in mind, but I guess the wait for /usr can be done in userspace anyway... I will redo this using rootwait.
|Patch Set 1:

Thinking about this more, I don't really buy it. root_wait means &quot;wait for the root device&quot;, and the &quot;wait&quot; parameter to a dm target means &quot;wait for this device&quot;; they're (kinda) orthogonal, and in particular, root_wait may or may not mean that we need any particular dm device to be ready.

I feel like it will hurt our chances of getting this upstream if we treat root_wait as meaning &quot;wait for all dm devices&quot;.
|Patch Set 1:

I can't think of a use case, but that doesn't mean there isn't one. I worry that tangling the two meanings together will hurt our chances of sending the resulting code upstream.

I am not sure how we can know if the specified root device is a dm device in advance. Different distributions seem to put them in different places; I think I've seen /dev/dm-N and /dev/mapper/N in different places. It seems like it's less code to just allow separate root_wait and wait-per-dm-target and let the user figure it out.
|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Abandoned

Ditching this for now. Will re-approach the bug later.
|Patch Set 1: Abandoned

Will re-approach this later if it's still important.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

I just tried this on x86 and it also worked. In it goes :)
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 668d417e90033139dcad1e028aea88fb414c6d0d.
|Patch Set 3: Reverted

This patchset was reverted in change: Ib893569ba3285b587e60be356fbb7d9e28adc3a6
|Patch Set 1: Looks good to me, approved

This change probably needs some stress-testing before submission, but then LGTM.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 3: (17 inline comments)

Not bad :) Some feedback below.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: (20 inline comments)


|Patch Set 4: (3 inline comments)


|Patch Set 5: Looks good to me, approved

(2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 97a93b2d02cb4fa3467b90921dac8e67caf0b53a.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as ab8d0a395cf3b6cf42bea4ce2f2d3d95873a068e.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 2f549d742e9abb58625a9a3f7b5d268070ac0166.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 85c235493e253c660347f5c0bfdb46708c09fee0.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

I put this change up before, but neglected to make any corresponding changes to the unit tests, so I ended up having to revert it (oops). Here's my change again, this time with accompanying unit test changes.

I have one remaining open question: how are OldUsersCleanup* supposed to work without mocking the mount operations?
|Patch Set 1:

Yes. I believe they should use the mocks in order to be unit (as opposed to end-to-end) tests.
|Patch Set 1: Abandoned

Obsoleted by 5415.
|Patch Set 2: Reverted

This patchset was reverted in change: Ibb641b210f9ec321662610b45a0971808498e248
|Patch Set 1: (1 inline comment)

One thing, then this seems legit.
|Patch Set 1:

(and no, it doesn't fulfill #3 yet.)
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (21 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (9 inline comments)

I haven't dispatched on all your comments yet.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 7: (12 inline comments)


|Patch Set 6: (3 inline comments)


|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 10: (1 inline comment)

Also added an install target.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 13: (7 inline comments)


|Uploaded patch set 15.
|Patch Set 14: (5 inline comments)


|Uploaded patch set 16.
|Patch Set 15: (7 inline comments)


|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 16: (2 inline comments)


|Uploaded patch set 19.
|Patch Set 18: (4 inline comments)


|Uploaded patch set 20.
|Patch Set 20: Verified


|Change has been successfully cherry-picked as cd7a9046e61e243fca916a286e49d58e2331eaa7.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Reverted

This patchset was reverted in change: Ie132c1e600ab28f97337ecfe0e7cff053987717d
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b38188e702e91bdbeccae96d6e7e252fb4c59b39.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 64b2ba41cc5b9125c78b6372eb7f9ed51f4b65a6.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned
|Patch Set 1:

This doesn't fix the underlying problem (http://code.google.com/p/chromium-os/issues/detail?id=18351#c9).
|Patch Set 1:

My comment #9 mentions printf. It and vprintf both need to be fixed to not use unbounded sprintf.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 6eed0490e95d4256d07ad33279c1dae70f176b2f.
|Patch Set 3: Reverted

This patchset was reverted in change: I22389f638845eaee559f9fc7fa97e05042490b19
|Patch Set 1: Verified


|Change has been successfully cherry-picked as e85cc258bc16ab8ba62a5fd6133981af7850acf3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Change has been successfully cherry-picked as 20c735a7f5250f198abe039b3456cd022b7d37a3.
|Patch Set 4: Reverted

This patchset was reverted in change: Ie39608cef21ccb15ac151986ee195d226c0bf7d7
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 0974dd594bd4ba3350ce6dc3e293fa79885c811d.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 3d53ba103731e1f47fcb454e84beb5fc2815828f.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 3b592adaf38cf7454ba53aced7c4e300c820d717.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as ee32043a0d00f8bb4f9bac781bd362557a6cc198.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 15db03fb5284a913af5357be0702a52a045ec623.
|Patch Set 1:

The bulk of this was previously reviewed at http://gerrit.chromium.org/gerrit/5097; the only new code is the case for handling the old argument format.
|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as d5b110e6ad10eb9c3414034c56ed1b119cd25bf5.
|Patch Set 1: Abandoned
|Patch Set 1: Verified


|Change has been successfully cherry-picked as aa219ef1f020151da4a9a599dc5e5aaf08360cee.
|Patch Set 1:

This CL by itself will cause Tor to be installed but not started (the upstart job spec has no start conditions).
|Patch Set 1: Verified


|Change has been successfully cherry-picked as be615c689cb8a140754f2baa13a2ed2cd4aa2933.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as d45561469e6988ac2f9136c8874a70b5ab1e752d.
|Patch Set 1:

The &quot;dm-devel&quot; in &quot;UPSTREAM: dm-devel: ...&quot; is where. I got it from linux-next, though.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 8c8bdaabc8d3d202024e40219b15c88a3a35ae5a.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 6a04e443433b1c061daababd9e50e8ba971db217.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 61237ecd8a56715db76a30bf24b0c9e04b03a4c2.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Patch Set 4: Verified


|Change has been successfully cherry-picked as 55bc00870391087efbfd3bdd8be13445e9aba278.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as cad29b19b6925faf0c030d2b2e532352c4b0ed65.
|Patch Set 1: Abandoned

Accidental reupload
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Rebase and gogogo.
|Change has been successfully cherry-picked as fda55cafb83bd8c1b16ac9e92a9f55451ffd29e8.
|Patch Set 2: Reverted

This patchset was reverted in change: Ibd8571719a10b13c29755b62c5684d9a81dff463
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Rebased.
|Change has been successfully cherry-picked as 377939c76023532786f98c18ee9c1900e8dcf159.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as dfbd35c56887115ca6e67cd00275d4d8499be087.
|Patch Set 1:

Third time's the charm? I committed the second one with a bad rebase, so it broke the tree :(. That will teach me to not run unit tests after a rebase...
|Patch Set 1:

Once more with feeling...
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 2a30415efba6e60dff629302069415c447fd5a5a.
|Patch Set 1: Reverted

This patchset was reverted in change: I0c055a91fb111b38de7d814a3b901a0e6a035616
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

See also: http://gerrit.chromium.org/gerrit/#change,5989 :)
|Uploaded patch set 6.
|Patch Set 6: Verified


|Change has been successfully cherry-picked as 446158b646c2b7609452fa61ec4afd0e6a1df7e3.
|Patch Set 1: Abandoned

== cmasone. See crosbug.com/19040 and crosbug.com/17514
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 9948fe3dbc4abcd7967f44b75009d1640032bbdc.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 2968eb704198b82111a10cda948c11c5d3e39fa8.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as f43edc83c977bbe5d664779a3f6c9e5704a144ab.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 9dcf92dfd1e7b67b2a02ade3de7ea8c940079a4d.
|Uploaded patch set 2.
|Patch Set 2:

I had to do it in update_bootloaders, since create_legacy_bootloader_templates runs before we have a GPT table. Still, it seems rather clean, and the grub config looks right.

nsanders: I can't test grub; can you? :)
|Patch Set 2: Verified


|Change has been successfully cherry-picked as dfd369431d897994c3f71f116e072938df2f74b6.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified


|Change has been successfully cherry-picked as 1e14261f941ac0862816d958a627486f522fe0cf.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 8837cd54455cbb535b85b9ec0d655c751f6ab99f.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 88af7b8e654d42991e467a57cc757226d7c252bf.
|Uploaded patch set 2.
|Patch Set 1: (10 inline comments)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (7 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved


|Patch Set 5: Verified


|Change has been successfully cherry-picked as 541b5d6a2c22ee7b705f34fc94cc93dc8cd164d8.
|Patch Set 2: (1 inline comment)


|Patch Set 1: Abandoned

Obsolete
|Patch Set 1: Verified


|Patch Set 1: Abandoned

Already in.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 7054af213beadb164fdfc9ca2613058e4ee3bfc7.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 29ab0c55ca27f22f32c01d2a2e7480620f22e0b9.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as bd1876279d124821aaeba3562f0250a6fbb10834.
|Patch Set 1:

This is like attempt #5 at this CL. I redesigned it based on drewry's feedback on 5475 so that we use a keyset entry to remember whether we migrated instead of always trying it.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (11 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: (5 inline comments)


|Uploaded patch set 7.
|Patch Set 6: (10 inline comments)


|Uploaded patch set 8.
|Patch Set 8:

Ping?
|Uploaded patch set 9.
|Patch Set 9: (1 inline comment)


|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 10: (2 inline comments)


|Patch Set 11:

Unit tests passed. Autotests passed: login_LoginSuccess, login_Cryptohome{Unm,M}ounted, login_CryptohomeIncognitoMounted. login_CryptohomeIncognitoUnmounted failed, but I think it's not my fault. Logging in with a clean profile succeeded, and re-logging in also succeeded. Logging in over an existing profile seems okay, but I didn't actually drop a flag file in place and check that it was migrated.
|Uploaded patch set 12.
|Patch Set 12: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as be15c5f623879671729ff66f0a46760b83a677b1.
|Patch Set 12: Reverted

This patchset was reverted in change: I5a21709538a99b5d5c2bc88727cbefeb1d5076cb
|Patch Set 1:

After much more testing and a few other changes (particularly using uuids for legacy boot), here's attempt #2 for this CL...
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 854430a03c3704256a06ab2027f0138b08596ee9.
|Uploaded patch set 2.
|Patch Set 1: (8 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (9 inline comments)


|Patch Set 3: Verified


|Change has been successfully cherry-picked as 14c3fdd80b7de815bfc71efd378b3cb57a282012.
|Patch Set 1:

Now with much more testing...
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 3b668d9ceec04f9f8de88613d86a53ec8bf4d47b.
|Patch Set 3: (3 inline comments)


|Patch Set 6: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 97974a8ca3b104dfffe05aabb143e32a249c6f65.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Looks good to me, approved


|Change has been successfully cherry-picked as 1d5c9488ef55b9449731bbb9fd9fd2f25d8e849d.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as c1c228eab9e2460f110cd97ea66ed7aadb86b2d1.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 09c827d3fb1ff1d488a3e45945424c551262ec93.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 1749cf6c692b5a486b78c2f80ef2962605985a48.
|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

I have been told before that portage-stable is appropriate for unchanged gentoo ebuilds.
|Patch Set 1: Verified

The CVE is specifically &quot;&lt; 1.4.4&quot;, and the libxfont git repo shows the fix going in just before they tagged 1.4.4:

http://cgit.freedesktop.org/xorg/lib/libXfont/log/
|Change has been successfully cherry-picked as 99edbe9f744149ddc2eb38c7ca8fdb89575330cd.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as ea6f6a0998c961c777614e870de34302c20b18b2.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 1e8646c9b226832db28b31025bc4634b0c039b4e.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: (4 inline comments)


|Uploaded patch set 7.
|Patch Set 6: (3 inline comments)


|Patch Set 7: Verified


|Change has been successfully cherry-picked as 7bbe44a5721ae135436ebaa6f7c2fa256e5058dd.
|Patch Set 1: (3 inline comments)


|Patch Set 1: I would prefer that you didn't submit this


|Patch Set 2: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

(12 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 6: Looks good to me, approved

(1 inline comment)


|Patch Set 7: Looks good to me, approved


|Change has been successfully cherry-picked as 40bf2c548be1015634cd6a7ef996485c8e0731cd.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as e13e6c5a83f8c1ee6edd07fc22898f647e9637b9.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 498af3decc2999f2a4792b5c798da9ecbfb920df.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 65a9726e23c4fe33333862bba8ce769615a6099e.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 09a9cb9150107782c407f367a66a7061e93120cb.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 507b5d7769e104eb2995bdc7287c58298dc132f0.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 70857538e86b624564984775b2c4b0a45e086b44.
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Abandoned

Oops
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as d5df2458bbe36da84ad7eacd084b4aea931d3d4f.
|Patch Set 1: Abandoned

Obsolete.
|Patch Set 1:

This is copied verbatim from http://gerrit.chromium.org/gerrit/#change,6708.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as ae9ac0349f3b2d65397ffa1f569f6d7a6815d020.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 5233046d71652e67f9d989cf8d95859dc7be2121.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (2 inline comments)


|Patch Set 1: I would prefer that you didn't submit this


|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

(4 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 0fc038473c75a74ffa29f015b18bca4d0cfd913f.
|Patch Set 1: Verified; Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified


|Change has been successfully cherry-picked as ea8fcb9689861543e3302fc50853d9a180e2e474.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Rebased.
|Change has been successfully cherry-picked as 60eefe7e33b5bdaba291c24a67b7b6ac51823073.
|Patch Set 1: I would prefer that you didn't submit this

(5 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 817454e2efc5ab28c1da7295052dec783c3d5ed2.
|Patch Set 1:

This got bounced before because I forgot to make a necessary change to the installer.
|Patch Set 1:

Grepped through /src/platform this time to find any other invocations of verity - only the one in installer needs to be fixed, it looks like.
|Patch Set 1: Looks good to me, approved

Carrying over signoffs from http://gerrit.chromium.org/gerrit/#change,7174...
|Patch Set 1: Verified

Trybot runs are green for both arm-generic and x86-generic.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as d24354a5be6dc0f0e1918609bd7ce772e0340dd2.
|Patch Set 1:

Ping? :)
|Patch Set 1: Abandoned

Obsoleted by http://gerrit.chromium.org/gerrit/7939
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved


|Patch Set 3: Reverted

This patchset was reverted in change: I813807d0cd363c18877df4affae614eadaaea735
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 7e8ba8efa562dd20b37b8f66d02a823701b53162.
|Patch Set 1: Verified; Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

We should not encrust crosh's ssh command with any further features unless we absolutely have to. I would want to see an excellent justification for adding this.
|Patch Set 1:

Upstream one modified in place, same as before.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as cd863f282e20666c129ab8689f91045cde650671.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1:

Depends on http://gerrit.chromium.org/gerrit/7612 :)
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 07837735b410476f112e37d6c5184fbe5ce0117d.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified


|Change has been successfully cherry-picked as 8da8f0531a8d7fe4c9665c7948ff7c57a47a3e56.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Verified


|Change has been successfully cherry-picked as 9be0e172d2a7a605cfe91e273277fafeb4607fdc.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as d2205a94d118c41a3e045ee5b1eb7ec927a942cf.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 111bc8e9c51f0785d462141f18916a7ba460bbc3.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 19f03ff5ca540f43d87668aaab630868abd8ba28.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 2d7f665c0a0c8e8c17d804905f59698c1035b750.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as c2bf72934bc06b11ecaccc800d9f0bf3be45f86a.
|Patch Set 1: (4 inline comments)


|Patch Set 1: (2 inline comments)


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 8fda3a6cdcb0d24ff773d0da734d8af0abac0ed3.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1:

There is no CL for that yet; I need to run a huge grep across our codebase for any occurence of it first. Expect that CL today, though.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 790b63fda6fd9aa953628d2f02046589358a5cb3.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 51633a34628420287ea7d1de391caa630b5958bf.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

Dropping this for now.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as e3693a996b06309699c5c2370ed03e65ebe320fa.
|Patch Set 2: Looks good to me, approved

(3 inline comments)

Basically LGTM.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: (3 inline comments)


|Patch Set 2: I would prefer that you didn't submit this


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (5 inline comments)


|Patch Set 3: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Abandoned

Doesn't actually work :)
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 87dac69adefa81abf849111bb3a2c80e6fa3350a.
|Patch Set 1:

Ping?
|Uploaded patch set 2.
|Patch Set 1: (9 inline comments)


|Patch Set 2: Abandoned

This CL is way obsolete by now.
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (6 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: (3 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified; Ready

Tests passed. In it goes :).
|Change has been successfully cherry-picked as eb300c59634e8504d3e28fce7b9992fe12c058e7.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as fcc8d6e8161f5221211a282026f90fe4d9aff662.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as d9e267f321942d51533fc8a125c4656a6b69a513.
|Patch Set 1:

In what way did it not work? There should be no semantic change.
|Patch Set 1:

What exactly was wrong? The behavior really should not have changed at all.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Ready


|Change has been successfully cherry-picked as f28dd2042c114231062febcf49acfda3095b540f.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as ac2a96c2ef89b6733b15fd8a0d30959db7ca830d.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 8191bc1b69bfb7afc51f9c472c6519ea4eeddfbc.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (6 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

It has to be done before create_boot_desc() to have the boot desc contain it, which means it has to be done outside build_kernel_image.
|Patch Set 4: Verified; Ready

Just tested this again. Worked for me: normal image built and booted, recovery image built, booted, and completed recovery, and the resulting system booted and is useable.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready

Rebased to head...
|Patch Set 1: Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

Broken commit message
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Rebased.
|Change has been successfully cherry-picked as 97dbed32795bf0cc3c65eb65a2abcda220ac43a8.
|Patch Set 8: I would prefer that you didn't submit this

(9 inline comments)

I'm concerned by how unreadable the repeated macro invocations and swarms of underscores render this code.

I don't think the TEST_API() layer of indirection buys us anything.
|Patch Set 11: Looks good to me, approved


|Patch Set 9: I would prefer that you didn't submit this

(1 inline comment)

Seems legit otherwise.
|Patch Set 12: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (9 inline comments)


|Uploaded patch set 3.
|Patch Set 1: (6 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (5 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (14 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (3 inline comments)


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1:

Will, do you know why the hash cryptohome uses is salted, and whether this hash needs to be salted too?
|Patch Set 1:

No. The salted hash is used to locate the *shadow* directory, which nothing but cryptohome should know about. We're going to bind-mount that directory to somewhere publicly-exposed, so it doesn't matter if the hash is different.
|Uploaded patch set 2.
|Patch Set 2:

Now with salting. Will?
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (6 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (15 inline comments)


|Uploaded patch set 6.
|Patch Set 6:

We don't use readability on ChromeOS.
|Patch Set 6: (3 inline comments)


|Uploaded patch set 7.
|Patch Set 6: (3 inline comments)


|Patch Set 7: Verified; Ready


|Change has been successfully cherry-picked as e9d6297654b5f16d1620e2e49d8e95fda67e936a.
|Uploaded patch set 2.
|Patch Set 2:

Now with 100% more test :)
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as ce615049558b7e4fe50c82f320e17ce9be2593d3.
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified; Ready


|Change has been successfully cherry-picked as bb3d1ddcc533f8587184de30605c9bf2c680232e.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (7 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (5 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4: (14 inline comments)


|Uploaded patch set 7.
|Patch Set 6: (1 inline comment)


|Uploaded patch set 8.
|Patch Set 8:

Rebased :)
|Uploaded patch set 9.
|Patch Set 8: (1 inline comment)


|Patch Set 9: Verified; Ready


|Change has been successfully cherry-picked as 51a5b6c7f464100cea4c79f737fab2e582904135.
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Patch Set 5: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (24 inline comments)


|Uploaded patch set 4.
|Patch Set 4:

Ping?
|Patch Set 4: Verified; Ready


|Change has been successfully cherry-picked as e1749eb93a119bf03b5b033d74c541dbb45be00e.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: (1 inline comment)

LGTM, but I have a question.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 1:

Cryptohome will create /home/{root,user}{,/&lt;hash&gt;} as appropriate. Daemons must create their own daemon directories.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as aa9830ca8eb44b36a09902dba25c71f4b485ee2c.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (6 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (2 inline comments)


|Patch Set 5:

This CL (along with &lt;http://gerrit.chromium.org/gerrit/10670&gt;) are covered by the test added by &lt;http://gerrit.chromium.org/gerrit/10588&gt;. Do you still want unit tests too?
|Patch Set 5:

This is now covered by platform_CryptohomeMultiple.
|Patch Set 5:

The autotest is being augmented at &lt;https://gerrit.chromium.org/gerrit/10801&gt;.
|Uploaded patch set 6.
|Patch Set 6:

I can't seem to get my trybot to work right now (crosbug.com/22266). I'll build a fresh image and test this on hardware.
|Uploaded patch set 7.
|Patch Set 6: (4 inline comments)


|Patch Set 7:

Do people feel good about this CL now that all of its logic is covered by platform_Cryptohome{BadPerms,NonDirs,Multiple}?
|Uploaded patch set 8.
|Patch Set 7: (4 inline comments)


|Uploaded patch set 9.
|Patch Set 8: (1 inline comment)


|Patch Set 9: Verified; Ready


|Change has been successfully cherry-picked as 3ed6905d4685bc1705e3637b55e0c7e226144dd8.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Verified; Ready


|Change has been successfully cherry-picked as d436f69e416b6f06283660ed3a611af59ab5d484.
|Patch Set 1:

We could do that, but I fear that we actually have a hanging task referring to a file inside the mountpoint.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)

This change will still be needed either way. It actually doesn't work without the other change, but the other change is ineffective by itself.
|Patch Set 2:

Hmm, no. The change wad was referring to is actually a more elegant fix for this problem.
|Patch Set 2: Abandoned
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Thoughts?
|Patch Set 3:

msb: I could do that, but it would involve also hacking userland mount(1), which I am not especially eager to do.

taysom: Yes. This attribute is useful in the general case, which is why I'm adding a config option to disable it - but in the ChromeOS-specific case, it can be used for a lot of attacks against /var.
|Patch Set 3:

msb: do you feel strongly about implementing this using an MS_ flag?
|Patch Set 3:

Discussion with msb:
&lt;msb&gt; if I understanding correctly. we can prevent the attack without this patch but with this patch the prevention is simpler (and hence more robust).
&lt;ellyjones&gt; hm
&lt;ellyjones&gt; your comment doesn't tell the whole story
&lt;msb&gt; what am I missing?
&lt;ellyjones&gt; chattr -R -i /var would slow down boot quite a lot
&lt;ellyjones&gt; and you only need root in _dev_ mode, since /var is on the stateful partition
&lt;msb&gt; even for rm -rf, you need root, in case the attacker created a file as root, no?
&lt;ellyjones&gt; hm? that doesn't help
&lt;ellyjones&gt; /var/lib etc. need to persist across reboots, and they might be marked immutable
&lt;msb&gt; I'm suggest that for rm -rf to work, you must be root
&lt;msb&gt; the patch is trying to fix rm -rf, no?
&lt;msb&gt; s/suggest/suggesting/
&lt;ellyjones&gt; the patch is generally trying to avoid attacks against us that rely on attr +i causing mv, rm, etc. to stop working
&lt;ellyjones&gt; since many places assume that doing one of those things as root always succeeds
&lt;msb&gt; ah, mv is interesting since you just touch the dir
&lt;ellyjones&gt; yes
&lt;msb&gt; mv is much much faster chattr -R -i
&lt;ellyjones&gt; attr +i also breaks creation of hard links (!?)
&lt;msb&gt; while rm -rf is just marginally faster
&lt;msb&gt; so couldn't you just, chattr -i dir; mv dir{,.old}
&lt;msb&gt; and then in the background chattr -R
&lt;ellyjones&gt; doing it 'in the background' can race daemons trying to use /var
&lt;msb&gt; you're cleanning the dir.old in the background
&lt;msb&gt; in don't see a race
&lt;ellyjones&gt; /var/lib
&lt;ellyjones&gt; needs to store data across reboots
&lt;ellyjones&gt; we cannot move it aside
&lt;msb&gt; but the problem you're fixing is mv and rm -rf
&lt;ellyjones&gt; attr +i also affects /var/lib though
&lt;msb&gt; ok, so what is the /var/lib attack
&lt;ellyjones&gt; a lot of daemons store stuff in /var/lib that they rely upon being able to write to
&lt;ellyjones&gt; at the very least, setting attr +i on those things will break system functionality until the user does a recovery
&lt;msb&gt; so if you prevent -i, what about chown root:root
&lt;msb&gt; won't you still have a problem there
&lt;ellyjones&gt; that is also a problem, but our daemons are generally written with that in mind and many of them run as root to begin with
&lt;ellyjones&gt; whereas none of them are written with +i in mind
&lt;msb&gt; ok, so with no +i, the daemons don't need to iterate over /var/lib
&lt;msb&gt; because they run as root
&lt;ellyjones&gt; indeed
&lt;ellyjones&gt; iterating over anything is generally a losing proposition I think
&lt;msb&gt; what if files were chmod'ed read-only
&lt;ellyjones&gt; doesn't matter if you're root
&lt;msb&gt; ah, didn't know that
&lt;ellyjones&gt; root has CAP_DAC_OVERRIDE by default
&lt;msb&gt; ah
&lt;msb&gt; k, I'm convinced. feel free to paste this discussion into gerrit
|Patch Set 3: Abandoned

Obsoleted. Lack of cycles to fix this bug this way.
|Patch Set 2: Reverted

This patchset was reverted in change: If1e9a1d64a43e03d7b511259e9bfd0e97e46bbd1
|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 18b173c94661a540b5b6062070c597013c8e2595.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 77bdd9fbde90b80cf9baad94eb9e073c5d444866.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready

Passed trybots. Landing this.
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 1ff7fa151a61debf7f45d0403c5adc66ad403493.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as a8d1e1b685840bce77d4d32cb4cd52e25e5e1763.
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as b60eb1732c8a4b469dd77f4d6afd17333ceb932e.
|Patch Set 1:

R? everyone that has touched this repo recently. If you think you should be on the OWNERS list for minijail, please say so :).
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as cc6ab271da5a5371cbec5899dd47dcfb125dd444.
|Patch Set 1:

This test does not pass yet - it depends on http://gerrit.chromium.org/gerrit/10193 and a yet-to-be-written CL to bind-mount stuff into place.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)

Thanks for suggesting the refactor. The test code is now _very_ clean :)
|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (7 inline comments)


|Uploaded patch set 6.
|Patch Set 5: (1 inline comment)

This passes against a tree with &lt;https://gerrit.chromium.org/gerrit/10193&gt; and &lt;https://gerrit.chromium.org/gerrit/10670&gt; both applied.
|Patch Set 6: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Rebased.
|Change has been successfully cherry-picked as 9a036f9a79c3423ea637fc74b1a30f9853f31611.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Ping?
|Uploaded patch set 6.
|Patch Set 5: (7 inline comments)


|Uploaded patch set 7.
|Patch Set 5: (3 inline comments)


|Uploaded patch set 8.
|Patch Set 8:

I have implemented a stack of user mount points and used it for all mount+unmount operations. I also made mount.cc cpplint-clean so I can start running cpplint as part of my upload wrapper.
|Uploaded patch set 9.
|Patch Set 8: (7 inline comments)


|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 10: (5 inline comments)


|Uploaded patch set 12.
|Patch Set 11: (7 inline comments)

Still need to rebase unit tests.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15:

Unit tests now all pass. gauravsh, wad?
|Patch Set 15: (2 inline comments)


|Uploaded patch set 16.
|Patch Set 16:

Breakage found by the smoke test - I'd broken unmount on guest mounts.
|Patch Set 16: Verified; Ready


|Change has been successfully cherry-picked as 866cd831066339523bc235ff88d96f4c9d039080.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 3: Verified; Ready


|Change has been successfully cherry-picked as 322ae2f04f97870fbf5c945caca4a1542a250698.
|Patch Set 1:

Why?
|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (13 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (10 inline comments)


|Uploaded patch set 6.
|Patch Set 5: (7 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 0e1500984113085b0dbe6e902c9e415347030a88.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2:

No. debugd is going to be the first test case for this, but I know the code generation part works already.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (3 inline comments)


|Patch Set 5: Verified; Ready


|Change has been successfully cherry-picked as c7f8f00a1c4032cfe723d900e86cda4252a4d11e.
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Patch Set 2: (8 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (7 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 6: (2 inline comments)


|Uploaded patch set 9.
|Patch Set 9: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1:

You are r? on this commit if you have touched cryptohome significantly recently. If you are cool with your presence (or not) in OWNERS, please +1 this CL.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as d5e0b1b8b2c0fd79ed51bef6d032a9659a8a7855.
|Patch Set 1:

You are r? on this CL because you have touched cromo significantly recently. Please +1 it to indicate that you are okay with your presence (or lack thereof) in OWNERS.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 5ecc4d59cfb99fd71d8ccfaff10edf246d7af29f.
|Patch Set 1:

You are r? on this CL because you have touched dbus-c++ significantly recently. Please +1 it to indicate assent to your presence (or lack thereof) in the OWNERS file.
|Patch Set 1:

We do not enforce them. I have added myself.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 57d58144eb2196c06bd74a06c26a7f53ce1c6eec.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (5 inline comments)


|Patch Set 4:

Alright, please take a look now?
|Uploaded patch set 5.
|Patch Set 4: (6 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

Now with 100% more dbus config file.
|Uploaded patch set 10.
|Patch Set 10: Verified; Ready


|Change has been successfully cherry-picked as 5f63442aae0b3c424b60404eec3584f8d3a10a96.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

Turned out not to matter
|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 5ab3419bb920e320a5570b0de6fcd4842a6201d5.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 2:

Can you run an arm trybot for this too?
|Patch Set 1:

Have we always been seeing these?
|Patch Set 2: I would prefer that you didn't submit this

Have we actually been seeing this forever, or did these recently start happening?
|Patch Set 1:

Ack. I broke one of the unit tests in a very subtle way and didn't realize it: I changed the constness of MountGuestCryptohome() but did not change the constness of the mock, and as a result ended up mocking a nonexistent function. I wrote the test failure off as flake because I hadn't touched that code :(.
|Uploaded patch set 2.
|Patch Set 2:

Trybot passed.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready

All tests passed twice.
|Change has been successfully cherry-picked as 5424cd563e7879d981b79db99372638091474f3d.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 728fd83e965362949d5336377fd9a010fd6e4d1a.
|Patch Set 4: Reverted

This patchset was reverted in change: Iff12a938a203a1f9216db95be4a3dfc7fa6279d7
|Patch Set 1:

Can you recommend another reviewer?
|Patch Set 1: Ready


|Change has been successfully cherry-picked as 030a8a5b85b80900e474068231d5e8ccebf897d7.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 332be6b10bc20f6bb6d5a53cd8d3a215fbc2dab5.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Change has been successfully cherry-picked as caa52a190110952c2ffdcb3423d9f04c35ab5922.
|Patch Set 1:

It is not supported upstream by dbus 1.4.16 (the latest release). I can file a bug with upstream with the patch but IME it takes the maintainers a long time (months) to accept even small changes. I will kick off a trybot now.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 8c1329f946cc6f9351d7f51a05c2b207db67434d.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 7b9b65b3a091d056a425db9d9195e365965d3462.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (10 inline comments)


|Patch Set 3: (11 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (22 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 5: (19 inline comments)


|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8: (19 inline comments)

I can't figure out how to unit test PingTool, although there is a lot to test there. Suggestions?
|Uploaded patch set 10.
|Patch Set 9: (7 inline comments)


|Patch Set 10:

Autotest is up as https://gerrit.chromium.org/gerrit/#change,13142
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 9: (1 inline comment)


|Patch Set 12: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as cce39dedea712003063c581d2b256f8b63fa9d9e.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 859bf3de75206cb7825b1ce0a25a7dfb03e8db1f.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Verified; Ready


|Uploaded patch set 10.
|Patch Set 10: Verified; Looks good to me, approved; Ready


|Uploaded patch set 11.
|Patch Set 11:

Re-running trybot...
|Uploaded patch set 12.
|Patch Set 12: Verified; Looks good to me, approved; Ready

Unit tests passed in the trybot.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 3: Verified; Ready


|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 5ba42b5a35bc79ac455107008f2189fa26228789.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as afb14a2186f7d6c03321b2c245a8818ff7b5a5ef.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as b449e93359023918d5b50db41811ab0850e36e4c.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as fd37e2a789392fe245dca5419dde6d9a35161c96.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Change has been successfully cherry-picked as 67e3f596a7c30a9db0e504d8e25b8c643237ecd2.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 6c1d8a49c7231ebc9a42913eb490aefca3541ed1.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as a1059630647ed53a77726d9031dda0eab48bc1a4.
|Patch Set 1: Verified; Ready

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 6d403530f1025030298dbe606ab897fb8760c3c0.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as ae0bf900dfc6386b4101ded51cf7729934cf151d.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (3 inline comments)


|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified; Ready


|Patch Set 3: Not Ready


|Patch Set 3: Ready


|Patch Set 3: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 6:

Is this CL still live?
|Patch Set 3: Looks good to me, approved


|Patch Set 3:

Is this CL still live?
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (9 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

Ping for other reviewers?
|Uploaded patch set 10.
|Patch Set 9: (4 inline comments)


|Patch Set 10: (1 inline comment)


|Patch Set 10: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 3: Ready


|Patch Set 3: Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved


|Patch Set 4: Ready


|Patch Set 1: I would prefer that you didn't submit this

About to be obsoleted by https://gerrit.chromium.org/gerrit/#change,13750
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready

Rebased, reapproving.
|Patch Set 1: Verified


|Patch Set 1:

Both packages wfm.
|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: (2 inline comments)


|Patch Set 1: Verified; Ready


|Patch Set 1: (1 inline comment)


|Patch Set 1: Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

Now with more unit test runs.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 2:

There should be a corresponding change to an xml file somewhere, right?
|Patch Set 2: I would prefer that you didn't submit this


|Patch Set 2: Looks good to me, approved

Please trybot this change, but otherwise +2 :).
|Patch Set 2:

Is this CL still live?
|Patch Set 3: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 4:

Is this CL still live?
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

Is this CL still live?
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 4: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 2: (2 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 4: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

Copyright date could use updated too
|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Science fact: if you say 'expect fork' and then you don't, upstart gets really sad.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified

In this goes, per oritm's approval on http://code.google.com/p/chrome-os-partner/issues/detail?id=6562
|Change has been successfully cherry-picked as e58d3db0e51dc6e222724da09a64f3695e6ecda8.
|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (2 inline comments)


|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3:

Please don't modify the original source at all when you check it in, even if their whitespace style is different from ours. It makes it much harder to merge upstream changes later because the diff between upstream and our 'pristine' checkin gets bigger. You could make a second commit right after to fix the style if you want.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (6 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Patch Set 1:

No - I am waiting for the R18 cut, since I want this to get lots of time to soak before we ship it.
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Not Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1:

The makefile approach is to have the makefile generate flimflam-whatever.h from an xml file named org.chromium.flimflam.whatever.xml?
|Uploaded patch set 2.
|Patch Set 2:

I would prefer to do it this way, since then the files are cs-able.
|Patch Set 2: Verified; Ready

It feels bad to me too, but I can deal with it for the sake of the style guide.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Do not submit


|Patch Set 1:

What's deprecated? Flimflam?
|Patch Set 1:

(The API flimflam presents for this will presumably still be presented by shill, right?)
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 4: (1 inline comment)


|Patch Set 4: I would prefer that you didn't submit this


|Patch Set 5: (2 inline comments)


|Patch Set 6: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 4: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

The tests are still fine. As of this CL, there's only one mount instance ever, which belongs to user &quot;&quot;, so all the tests function identically.
|Uploaded patch set 2.
|Patch Set 2:

Kees?
|Uploaded patch set 3.
|Patch Set 3: Abandoned

Ditched for incremental refactors instead.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1:

I believe my https://gerrit.chromium.org/gerrit/#change,15490 will fix the observed lossage.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: I would prefer that you didn't submit this

Please fix the commit message, as gauravsh said.
|Patch Set 3: (1 inline comment)


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 2: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Abandoned

Wrong branch.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Patch Set 5: Ready


|Patch Set 1: Abandoned

Oops
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2:

The current cunning plan involves having debugd broker all accesses to /var/log.
|Patch Set 2: (2 inline comments)


|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (6 inline comments)


|Patch Set 5: Abandoned

Ditched for incremental refactors.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1:

You're on this CL because I think you should be an owner of modem-utilities. Please signal your acceptance or rejection of ownership by marking it +2 or -1 :).
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (7 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (2 inline comments)


|Patch Set 5: Verified; Ready


|Patch Set 5: Looks good to me, approved


|Patch Set 2:

Why is this in vboot_reference?
|Patch Set 9: I would prefer that you didn't submit this

(13 inline comments)


|Patch Set 12: Looks good to me, approved


|Patch Set 13: Looks good to me, approved


|Patch Set 1:

Can you expand on why having tamper-evident but publicly-known entropy is desirable?
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 4: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Abandoned

Ditching this to do incremental refactors instead.
|Patch Set 1: Looks good to me, approved


|Patch Set 7: (6 inline comments)


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved


|Patch Set 5: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved


|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Verified; Ready


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Not Ready


|Patch Set 2: Abandoned

This CL is actually dumb. We only ever get the TpmInit callback once, not once per mount, so we don't need to plumb the mount through after all.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 4: I would prefer that you didn't submit this

(5 inline comments)


|Patch Set 6: (1 inline comment)


|Patch Set 6: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved; Ready


|Patch Set 6: Ready


|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8: (16 inline comments)


|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 10: (12 inline comments)


|Uploaded patch set 13.
|Patch Set 12: (1 inline comment)


|Patch Set 13: Verified; Looks good to me, approved; Ready


|Uploaded patch set 14.
|Patch Set 14: Verified; Looks good to me, approved; Ready


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (7 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1: (9 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (2 inline comments)


|Patch Set 7: Verified; Ready


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready


|Patch Set 8: Reverted

This patchset was reverted in change: Ie37c673e1bf0cf91733763aa67d1b263d4dd6bc3
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Patch Set 2: Not Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (7 inline comments)


|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 2: (1 inline comment)


|Patch Set 1:

I suspect this needs a rebase in light of &lt;https://gerrit.chromium.org/gerrit/#change,18149&gt;?
|Patch Set 1:

That change rendered Mount::DoAutomaticFreeDiskSpaceControl() dead code, since service.cc (the only previous caller) now calls HomeDirs::FreeDiskSpace().
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Abandoned

Obsoleted by previous revert.
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

Incomplete.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 3f7bd0d05e4d18b2457ed4fd9f5a6a3f8f2ff02b.
|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

I wish I could +3 this.
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 3: Looks good to me, approved


|Patch Set 1:

Still needs style cleanup.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

I wish I could +3 this.
|Patch Set 1: Verified; Ready


|Patch Set 1:

Hi! You're a reviewer on this CL because you've made more than two commits to power_manager recently. Please +2/-2 this CL to indicate your assent to being in OWNERS (or not).
|Uploaded patch set 2.
|Patch Set 2:

snanda, bleung, and tbroch added.

kliegs: yes; see crosbug.com/28763
|Patch Set 2: Verified; Ready


|Patch Set 1:

Please +2/-2 to indicate your assent (or not) to being an owner of verity :).
|Patch Set 1: Verified; Ready

I'm gonna assume wad is okay with this and land it.
|Patch Set 1:

Please +2/-2 to indicate assent to being in OWNERS. Thanks :)
|Patch Set 1: Verified; Ready


|Patch Set 1:

Please +2/-2 to indicate assent to being in the OWNERS file :).
|Patch Set 1: Abandoned

By request from rtc.
|Patch Set 1:

Please +2/-2 to indicate assent to being in OWNERS.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1:

Please +2/-2 to indicate assent to being an OWNER for this package :).
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Patch Set 1:

Please +2/-2 to indicate assent to being in OWNERS for this package :).
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1:

Please +2/-2 to indicate assent to being in OWNERS :).
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

I approve of your message.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

TBR.
|Change has been successfully cherry-picked as 986426196316e8bc30592982a14fd83ff8a2db38.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Abandoned

Landed as a different patch.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Autotest up at https://gerrit.chromium.org/gerrit/#change,20325
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved

(1 inline comment)

One nit.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Now ready for review.
|Uploaded patch set 5.
|Patch Set 4: (12 inline comments)


|Uploaded patch set 6.
|Patch Set 5: (3 inline comments)


|Uploaded patch set 7.
|Patch Set 6: (4 inline comments)


|Patch Set 7:

I have now done the following manual test:
1) Sign in
2) Sign out
3) Sign in
4) Lock screen
5) Unlock screen
6) Sign out
7) Guest sign in
8) Guest sign out

All worked as expected.
|Patch Set 7:

I added log messages bracketing the (synchronous) update of the last user's timestamp; on average, it takes 778 microseconds (across 10 trials) to do the update. I don't think this interval matters.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Verified; Ready


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Not Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 5af6705c12f5bb53f6e2bf0565340ad59f7b2a66.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

(2 inline comments)

Looks basically okay.
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

Lots shorter with the new OPENSSL_BLACKLIST_PATH env var.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

I did this wrong.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Abandoned

Irrelevant.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Testing covered by security_OpenSSLBlacklist after https://gerrit.chromium.org/gerrit/#change,22958 lands.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2:

wad: Does running a trybot suffice to test this, because the trybot does a bunch of self-updates?
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved


|Patch Set 4: Ready


|Patch Set 4: Ready


|Patch Set 4: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1:

This is the first step of &lt;https://docs.google.com/a/google.com/document/d/18Wj6DWmIO71AcwlhqMFnZ3-029yi8CmZyPQvaU5a8ss/edit&gt; - the &quot;TPM daemon&quot;, which mediates TPM access for other parts of the system. The interface is currently very narrow since that's all that seems to be used.
|Patch Set 1:

Do explain what it is, so I can include it in the design?
|Uploaded patch set 2.
|Patch Set 2:

keescook: does the extension I just added to the NVRAM API (the IsReadPcrBound property) do what you need?
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved


|Patch Set 6: Ready


|Patch Set 6: Ready


|Patch Set 6: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4: (3 inline comments)


|Patch Set 6: Verified; Ready


|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (6 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

Tested.
|Patch Set 2: Verified; Ready


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1:

?
|Patch Set 1:

Ping?
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

?
|Patch Set 1:

Ping?
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

Pulled upstream.
|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

Added upstream
|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

Added upstream
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

Rebase was too messy.
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Ready


|Patch Set 2: Not Ready


|Patch Set 2: Abandoned

Designed around this.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

Will redesign.
|Patch Set 1: Abandoned

Moved to https://gerrit.chromium.org/gerrit/27515
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 3: Looks good to me, approved

benchan: the reason cromo has clean-shutdown is hilarious and I'll explain it somewhere else. The pertinent point is that cromo needs up to ten seconds to shut down (yes, really), which it has to be provided in all practical cases (yes, really), and upstart didn't give us enough time for that, so there's special-case code in powerd to do it with the 'clean-shutdown' task. There is also special-case code in cromo to work with it - hence the dbus-sends bracketing the actual task in the init file for clean-shutdown.

At some point, modemmanager will have the same problem, and we will need to add the same special case to modemmanager, but today is not that time.

This CL LGTM.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Not Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: I would prefer that you didn't submit this

(7 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1:

SecureBlob is not a subclass of Blob :(.
|Uploaded patch set 2.
|Patch Set 2:

Now with more SecureBlob.
|Uploaded patch set 3.
|Patch Set 2: (6 inline comments)


|Patch Set 3: Verified; Ready


|Patch Set 1:

No. Tests that do that (that &quot;know&quot; which file the implementation is going to open) are not proper unit tests, because they test whether you use a particular implementation instead of testing the interface.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 2: Verified; Ready


|Patch Set 2: No score; Looks good to me, approved; Not Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready

TBRing.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Uploaded patch set 4.
|Patch Set 4: Ready


|Patch Set 4: Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(7 inline comments)


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Patch Set 2: Not Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Looks good to me, approved


|Patch Set 1:

I do not think there is any need for callers to be able to find out the salt - the salt is a detail of the crypto layer that Mount and such should not be aware of. I'm actually thinking about having an EncryptedBlob class which handles 'encrypt this using this weak passphrase for me', which would be responsible for all the key derivation and such.

I will put up a unit test shortly.
|Patch Set 1: Abandoned

Will redo this more nicely, actually
|Patch Set 1: Verified; Ready


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved


|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved


|Patch Set 7: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 4: Looks good to me, approved

Did you do some sort of global search to make sure people aren't using LOG(FATAL) in a way they assume is nonfatal?

Other than that, LGTM.
|Patch Set 2:

/debugd/touchpad is a hack because debugd cannot write to the user data directory. If you are being run by debugd (and only then) you should put your log file somewhere it can read; /debugd works, as does /var/log or whatever.
|Patch Set 2:

Sounds okay to me, then. Do you need my review?
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Do not submit

(6 inline comments)

The currently plan is to explicitly _not_ attest developer mode vs not, correct? We can't attest developer state without possibly significantly impairing the usefulness of chromeos devices in developer mode.
|Patch Set 3:

This change is fine codewise. Conceptually, I need to talk to Will about it before I'm okay with landing it.
|Patch Set 3: Looks good to me, approved

Alright. I will discuss the feature itself with Will. This code LGTM.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1:

Fixed from the previous one. Science fact: a ScopedTssBlob actually 'contains' a byte*, not a byte, so ScopedTssBlob::ptr() returns a byte**!
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Abandoned

Doesn't work.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Verified; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 2: (3 inline comments)


|Patch Set 4: (1 inline comment)


|Patch Set 4: Verified; Ready


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3: (6 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1:

https://gerrit.chromium.org/gerrit/#/c/33203/
|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 2:

Hm... I can't confidently say I _didn't_ cause that failure, so I'm running a remote trybot.
|Patch Set 2: Ready

Trybot passed. Re-landing.
|Patch Set 2:

Okay, that failure probably _is_ my fault; looking at /var from that failed run, /var/log/messages is empty. Hmm.
|Patch Set 2: Ready


|Patch Set 3: Reverted

This patchset was reverted in change: I2fc666ff2c1aa524a8b562f6800529d14a3ee2fd
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 4: (2 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (2 inline comments)


|Patch Set 7: Verified; Ready


|Patch Set 7: Ready


|Patch Set 8: Reverted

This patchset was reverted in change: Ibc6ff1fc3f3809753fe20095e77e18a85e40c6b0
|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned

No.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned
|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (13 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (29 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 5: (28 inline comments)


|Uploaded patch set 9.
|Patch Set 8: (9 inline comments)


|Uploaded patch set 10.
|Patch Set 9: (15 inline comments)


|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 12: (16 inline comments)


|Uploaded patch set 14.
|Patch Set 13: (11 inline comments)


|Uploaded patch set 15.
|Patch Set 15: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: (3 inline comments)


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1:

How about... this!? https://gerrit.chromium.org/gerrit/#/c/33213/
|Uploaded patch set 2.
|Patch Set 2:

Yep, that works too.
|Patch Set 2: Verified; Ready


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1:

Look at this amazing ebuild!
|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 3:

Not gonna land this until the tpmd in tree compiles :P
|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Which? ClearKeyring?
|Uploaded patch set 2.
|Patch Set 2:

de-cryptohome-ified.
|Uploaded patch set 3.
|Patch Set 2: (5 inline comments)


|Uploaded patch set 4.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 2: (2 inline comments)


|Patch Set 4: (1 inline comment)


|Uploaded patch set 7.
|Patch Set 6: (3 inline comments)


|Patch Set 7: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready

Trybot passed. Landing this; autotest to come.
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)

Fixed a security bug, too :)
|Uploaded patch set 4.
|Patch Set 3: (16 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: (2 inline comments)


|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8: (3 inline comments)


|Patch Set 9: (1 inline comment)


|Uploaded patch set 10.
|Patch Set 10: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified


|Change has been successfully cherry-picked as a0d7d2d632a524bebeff7f89fd339d18fe5e9f15
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Abandoned

This was a stupid idea
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 43e1607e0064d24a8fa7adca715e7bccdca033a2
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 408599832eafc915d48d5684b6ccfab259fa1eec
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 7eed7ad50ff4abbeed1b9635ee50bd69715358cd
|Patch Set 1: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2:

kees: not for M23. Minimal change only if possible.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as c9c6bf28438346d35480c0eb279d7a060266c119
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as d05a30dd55152b605227bb70f1e351d6e2224b43
|Patch Set 1: Verified


|Change has been successfully cherry-picked as c20362f70d1cf905e60f2488111e7847b2c7a5b8
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 2: Reverted

This patchset was reverted in change: Ia587abb1bba5f10883ee1c19cd1a44ca7da3bb42
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified


|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as 803dd86f1ad2dfb0effffa42960775e07b4cbc2e
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 419a66528e53dbd309c4ae5fe6b28a3284ee748f
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Patch Set 1: Abandoned

Reuploaded due to fail
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 52684912d4d2f12d580e43589cf37b66d0fe0a27
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 9e84e113e6e9bd27d0f603cded1b32b8ed465595
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 3: Abandoned

Folded into parent CL
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: (1 inline comment)


|Patch Set 6: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 2c649e794adecbba17b149a14bc1b8c9474af1ae
|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

OBSOLORTED
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Abandoned
|Patch Set 1: Verified; Looks good to me, approved; Ready

Carrying over approvals.
|Patch Set 1: Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Carrying over reviews.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved

Sorry about this - forgot to send my review!
|Patch Set 1: Looks good to me, approved


|Patch Set 1:

It's running on canary trybots now; if they all pass, I'll consider this a successful fix and land it.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 3: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready

just crosh at the moment.
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned

ABANDONATED
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved; Ready; Verified


|Patch Set 7:

hm, I repro locally. Looking into it now.
|Patch Set 7:

Oops: https://gerrit.chromium.org/gerrit/#/c/41758/
|Patch Set 1: Verified; Ready


|Patch Set 1:

Yeah. Ideally, at some point soon I'll drop our git repo altogether and we'll switch to pulling from tlsdate's upstream git repo directly.
|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (4 inline comments)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified

Now with actual testing done :)
|Patch Set 3:

This is the standard location to mount cgroups at; see &lt;http://www.kernel.org/doc/Documentation/cgroups/cgroups.txt&gt;. /sys/fs/cgroup is created by sysfs itself.
|Patch Set 3: Ready


|Patch Set 3:

Oops.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Abandoned

Obsoleted by https://gerrit.chromium.org/gerrit/#/c/38993/
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1:

ftr, https://gerrit.chromium.org/gerrit/35947
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Ready


|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 3: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (6 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 6.
|Patch Set 5: (1 inline comment)


|Patch Set 6: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

I don't think the &quot;adjust and retry&quot; approach will be clean or simple to implement. It basically requires the unprivileged helper process to emit &quot;the cert started at time T&quot; to the parent, which then calls settimeofday() to change the system time; then we run the child process again and see if it succeeds this time. However, while we're doing this, the rest of the system sees the (attacker-controlled) future time. We could also do an LD_PRELOAD perhaps?
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 1:

You probably do not want to land these on 'master'. In the Glorious Future (possibly very soon, or maybe even now if I understand repo correctly), we will track tlsdate upstream (using our 'upstream' branch) and build that instead of the master branch.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

Landed upstream and pulled down.
|Patch Set 1: Abandoned

Landed and pulled.
|Patch Set 1: Abandoned

HUERGH
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned
|Patch Set 1: Verified

(1 inline comment)

Tested on daisy.
|Patch Set 1: Ready


|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

The change you needed (https://gerrit.chromium.org/gerrit/#/c/37843/) is now in. Sorry about that!
|Patch Set 4: Looks good to me, approved

(2 inline comments)

Looks good. If you want, you can enable the sandbox now (as root/root), but it doesn't do anything at the moment.
|Patch Set 5: Looks good to me, approved


|Patch Set 6: Looks good to me, approved


|Patch Set 1:

there are a lot of other compilation failures in shill, but this change fixes that one...
|Patch Set 1: Ready; Verified

(1 inline comment)


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Not Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Ready; Verified

Not afaik, but will check.
|Patch Set 1: Ready; Verified


|Patch Set 1: Not Ready


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready; Verified

(1 inline comment)


|Patch Set 1: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Ready; Verified


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 2: Ready


|Patch Set 1: Abandoned
|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

Please also update the docs in &lt;/share/org.chromium.debugd.xml&gt; :)
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Looks good to me, approved; Ready; Verified


|Uploaded patch set 9.
|Patch Set 9: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Ready; Verified

(2 inline comments)


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved; Not Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Reverted

This patchset was reverted in change: Ibb3827d2491ca2afdf8079fd846de3c6b5a2773a
|Patch Set 3: Reverted

This patchset was reverted in change: Ib7713c900007668bb6b393cd49039fc3c7a68af0
|Patch Set 1: Abandoned

er, I'm bad.
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved; Ready; Verified

marking as awesome from crosbug.com/36729
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved; Verified

Ready for merge to R25 for crosbug.com/39014.
|Patch Set 1: Abandoned

ddrew@ rejected merge to M25
|Patch Set 1: Ready; Verified


|Patch Set 1: Abandoned

obsoleted by https://gerrit.chromium.org/gerrit/#/c/44175/
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Ready


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Reverted

This patchset was reverted in change: I6f01c2a51cecd3b2d5fff0fb54c8d45728fd00a2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1:

&quot;some&quot;. Every tlsdate run generates a few KB of logs, and (if we don't have good network connectivity) we can try quite a few times, which might yield a couple hundred KB of logs at a time. That said, I'm not a fan of files that grow without bound, and it's not really much extra effort to throw the logs through syslog.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (9 inline comments)


|Patch Set 4: Ready; Verified


|Patch Set 1: Looks good to me, approved

good cleanups, thank you :)
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 2: Ready


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready; Verified


|Patch Set 8: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: Abandoned
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Merge per benhenry@ on crosbug.com/38801
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Ready; Verified


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Ready; Verified


|Patch Set 1: Ready; Verified


|Patch Set 2: Looks good to me, approved

(5 inline comments)

I think there is a locking problem in service.cc but otherwise lgtm
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

It was removed because the mounting code was moved to &lt;/src/platform/init/cgroups.conf&gt;; maybe we should create these cgroups there too?
|Patch Set 3: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

_wow_, am I terrible at reading autotest output. Fixed I think.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 1: Looks good to me, approved

it is what we in the industry refer to as a 'lie'
|Patch Set 1:

Relative paths actually work fine:

/usr/bin# cd /usr/bin
/usr/bin# minijail0 ./id
uid=0(root) gid=0(root) groups=0(root),1(bin),2(daemon),3(sys),4(adm),6(disk),10(wheel),11(floppy),26(tape),27(video),207(tss),208(pkcs11),219(wpa),1001(chronos-access)

The problem is paths that have to be resolved with $PATH, which we don't do; checking with access() fails those early.
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: Ready; Verified


|Patch Set 2: (1 inline comment)


|Patch Set 1: Ready; Verified

(1 inline comment)


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 2: Ready


|Patch Set 1: Verified


|Patch Set 1:

Done: https://gerrit.chromium.org/gerrit/#/c/46882/
|Patch Set 1: Ready


|Patch Set 1: Ready; Verified


|Patch Set 1:

It fits my MO. I'll get to work tracking me down...
|Patch Set 1: Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 3: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified

didn't break chromeos-setdevpasswd - landing now :)
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved; Ready; Verified

Passed chromiumos-sdk bot and {x86,amd64,arm}-generic-full bots.
|Uploaded patch set 2.
|Patch Set 2:

Yes.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 3: Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified

Talked to chris; he agreed that migrating this to use Platform is pretty pointless, so I undid that part. PTAL.
|Patch Set 3: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Do not submit

(3 inline comments)


|Patch Set 2: Looks good to me, approved

Thanks :)
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved

LGTM
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Patch Set 4: Ready; Verified

(1 inline comment)


|Patch Set 4: Ready


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Ready; Verified


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Not Ready


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Rebased and going in
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: I would prefer that you didn't submit this

(3 inline comments)

The testing for this CL needs work. Also, is there an associated bug? I'm not clear on the purpose here.
|Patch Set 4: Looks good to me, approved


|Patch Set 5: Looks good to me, approved


|Patch Set 6: Looks good to me, approved


|Patch Set 7: Looks good to me, approved


|Patch Set 15: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified

(1 inline comment)


|Patch Set 6: Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(5 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Is there a limitation on token length? If so, is this documented/checked anywhere?
|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, but someone else must approve

lgtm from a changes-to-the-ebuild perspective; no opinion on the patch itself.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (5 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Patch Set 4: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Patch Set 7: Looks good to me, approved; Ready

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 1:

is this script run from crosh?
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (4 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Uploaded patch set 7.
|Patch Set 7: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 5: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 5: Looks good to me, approved

After discussions in IM, LGTM.
|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 7: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(3 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Patch Set 5: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

you're gonna have to explain the tar thing, then it's okay
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Yeah, I think that's right (since we have no wimax status to report).
|Patch Set 1: Looks good to me, approved

after much scrutiny, I will cautiously accept this.
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)


|Patch Set 2: Ready; Verified


|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

looks good :)
|Patch Set 3: Reverted

This patchset was reverted in change: I4f0beafc20c410b7e58c43770c040883ab156f43
|Patch Set 1: Do not submit

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

good catch
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 75e3d7eec03ef16fb4a9ab454ec31f15fcca21f1
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

What happens if the compressed state is still larger than 256KB?
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

LGTM, but please update the design doc.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

Please name the CL after what the bug is rather than how it was found. Otherwise this looks okay.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review-1

(2 comments)
|Patch Set 2: Commit-Queue+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review-1

(29 comments)

First round of review. I like the overall design, but there are a bunch of small stylistic things that need to be fixed to comply with the JS style guide (https://google-styleguide.googlecode.com/svn/trunk/javascriptguide.xml) and a couple of open design questions.
|Patch Set 3: Code-Review-1

(20 comments)

Another round of comments :)
|Patch Set 8: Code-Review-1

(5 comments)

Just a few changes left, mostly documentation...
|Patch Set 1: Code-Review-1

(7 comments)

Looks pretty good. Needs some documentation/refactor changes I think.
|Patch Set 2: Code-Review-1

(3 comments)
|Patch Set 3: Code-Review-1

(13 comments)

more comments.
|Patch Set 4: Code-Review-1

(22 comments)

More minor stuff :)
|Patch Set 5: Code-Review-1

(4 comments)
|Patch Set 2: Code-Review-1

(2 comments)

Some comments.
|Patch Set 1:

Does this CL need anything from me?
|Abandoned
|Abandoned
|Abandoned
|Uploaded patch set 2.
|Abandoned
|Abandoned
|Abandoned
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Abandoned
|Abandoned
|Uploaded patch set 2.
|Abandoned
|Abandoned
|Abandoned
|Uploaded patch set 2.
|Abandoned
|Abandoned
|Abandoned
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review-1

(18 comments)

First round of review.
|Patch Set 1:

(1 comment)

Can you upload a new version so I can see what the code looks like with the changes?
|Patch Set 2: Code-Review-1

(7 comments)

getting closer, but I think the design is a little off...
|Abandoned
|Patch Set 1: Code-Review-1

(4 comments)

shouldn't this stuff be under Prototype/?
|Abandoned
|Patch Set 1: Code-Review-1

(11 comments)

comments!
|Abandoned
|Patch Set 1: Code-Review+1

Looks good to me. Needs review by rginda for style and Javascript though.
|Abandoned
|Patch Set 2: Code-Review-1

(1 comment)

Just one complaint (which we already discussed).
|Patch Set 4: Code-Review-1

(3 comments)
|Abandoned
|Abandoned
|Patch Set 2: Code-Review-1

(2 comments)

close :)
|Abandoned
|Abandoned
|Abandoned
|So umm file_bugs=False so just remove the bug_template=_BUG_TEMPLATE.
|Done
|the file names are now the project names.
|Done - its the first item in our src_paths.
|I moved them all into a quickmerge directory and prefixed with qm-
|Done
|Done
|Done
|Discussed IRL
|Done
|Done
|Accident.
|Done
|Done
|Done
|Can you put in a comment the example output you are parsing? And maybe use a regex and complain if there is no match. In case we upgrade lxc-info and the format changes.
|Add a comment here explaining why this won't loop indefinitely.
|add a new line.
|run a test
|Why not use python's tempfile.mkdtemp() function?
|2 new lines.
|Can we make a unittest around this to ensure only valid configs are checked in?
|Is this running on the container or the local system of this python file? If locally why not just use tempfile to ensure its always created/destroyed properly.
|Hmm why do we need this method? Can't you just add sudo=False to utils.run and set it to True when you need it?
|os.path.exists?
|test -f %s might be better
|We are planning to add support for Moblab to test duts not in the test vlan. Wouldn't this break here?

Ideally we could assume the container only ssh'es to DUTs but thats not true because of telemetry tests....
|K based off what you said below, lets just make the script path a constant. This looks hacky.
|Do we want to run this as its own process? Do we want to block on the script or no?, you're not now.

Why not import lxc_cleanup and just call its cleanup methods? Might require a refactor on the script though.
|Add a title to this commit like:

[autotest] Requiring lock reason to lock device.
{blank line}
{What this CL is changing}
|wrap this at 80 characters max, generally for commit messages I try to stay within 60-70 characters per line.
|align with the '
|get rid of 4 spaces here.
|For the python files use single quotes not double (unless the whole file is already using double), fix everywhere.
|align the 2 '
|align the 2 '
|if 'final String messagePrefix' fits on the line above, adjust it like that.
|alignment
|I'm curious where do all these go?
|Good thing you caught this before submitting :)
|s/requiring/require
|nit: period
|nit period
|chromiumos-overlay
|I would do emerge -C both packages, and try building the frontend first. I think you might hit an issue (look at my comment about dodir).
|I would just call this autotest-web-frontend. A bit shorter.
|no (c)
|Use Tabs. repeat everywhere.
|You might need to do a dodir before here. You'll find out when you try a trybot runs though.
|I think you need a new dep here to the frontend, otherwise nothing will pull it in.

The moblab overlay depends on this ebuild. Nothing depends on the frontend one yet.
|1) Use tabs.
2) Don't do this use the blacklist above.
|I would verify this version number before submitting to the CQ.
|Let's make all this more flexible so if we want to expand this in the future we can.

Change this to get_signal_queue_to_kill(self, process).

Return the signal queue you need to kill a certain process.
|Do the change above and we can do this all 2 lines:

signal_queue = get_signal_queue_to_kill(p)
processes_to_kill[signal_queue] = processes_to_kill.get(signal_queue, []).append(p)
|s/object/objects
|To be honest I'm not a fan of how you worked this function.

1) You go through the process_list twice.
2) The sig_count calls below are repetitive.

You below need a mapping of a given signal_queue to a list of processes.

Maybe rework this so you go through the process_list once and generate a dictionary.

Then for each unique signal_queue you pass in the list of corresponding process.pid's.

Your dictionary could be:
{signal_queue: [list of processes])

So for example:
{[SIGKILL]: [5,6,7,8,9],
 [SIGTERM, SIGKILL]: [1,2,3,4]}

Then for signal_queue,processes in dict:
utils.nuke_pid([-process.pid for process in processes], signal_queue)

Something like that.
|s/racing/a race
|Can't there be multiple hqes? You're only checking the first one.
|I assume this is for your starter project: https://docs.google.com/document/d/1oq3ySFQBc4EjaKRkL6NJgZgnAo_rLHt8glXE1-Q8-ss/edit

Please create bugs for each work item and link to them in your CLs.
|1) chromite for moblab is packaged via ebuilds so moblab always has the sources at buildtime. I don't know off the top of my head how we update autotest prod.

2) Yes use logging.
|According to pprabhu we will soon have a &quot;chromite prod&quot; branch we will update when doing pushes to prod. https://chromium-review.googlesource.com/#/c/264155/
|Done
|Ahh right, I forgot that. Thanks.
|Is that fine for the message_lines.append statement below as well?
|What changes would be required for that?
|Fang is it okay to check for aborted here?
|Done - good catch Dan, I was throwing away ABORTED logs.
|Verified on moblab as well?
|Is the container layout different for moblab?
|s/build/builds. Repeat below.
|Can you do a trybot run and make sure nothing breaks.
|Done
|Done
|Done
|Done
|Done
|Done
|just removed (c) I think its still GNU though.
|Done
|add &quot;DEPLOY=build_externals&quot; under the TEST= line
|2 new lines.
|2 new lines
|s/ATE/AFE, repeat below.
|why do we have this check? What if this drone or moblab has not yet downloaded the base container?
|Good catch.
|Part of me feels like I should throw this into a finally block and put everything above in a try block. Thoughts?
|What happens if I already had an [AUTOSERV] section in my shadow_config?
|s/horner/honor the --require....
|Looks like something that would go better in site_utils.

I think the _JobDirectory __init__ does something very similar without regex's look at site_utils/job_directories.py
|I just had a thought, it would be great if you can add some statsd calls here in case we need to investigate performance later on.

Up to you though.
|Copyright
|Capitalize U and add a period.
|Do we not already have some regex somewhere to parse build name?
|What is the reasoning behind hardcoding in this build?
|s/used/use
|I would say LXC binaries. Or &quot;LXC (Linux Kernel Containers) binaries&quot;
|the LXC control binaries.
|Why not return the result object and let the callers pull out stdout.

Future work might want stderr or the exit_code, etc.
|Where does this get raised? Shouldn't it be CMDERROR?
|2 new lines.
|Alpha order.
|Can you put something about this in the commit message?
|newline.
|Is this a time? Do we need the tick?
|new line.
|Why not use the existing utils.run()? I think that will be safer, simpler, consistent with the rest of the codebase, and cleaner.

If that does not support sudo, then just wrap the cmd with sudo and sent it to utils.run().
|alignment.
|new line between returns and raises, repeat everywhere.
|File a bug.
|You mean priviledged right?
|Describe what the output looks like.
|What is a bucket? Maybe describe in the docstring above what args[0] should be.
|What type of attributes? Maybe list them in the class docstring.
|Re: my comment above, I have no idea what the output of get_container_info looks like or has in it, especially at index 0. Maybe a dict is better?
|What if I want to run on the container:

echo 'test' &gt; /tmp/blah

That will likely not work. Might want to find a way to support it or block special characters like '&lt;'
|This is not right.

My container on Moblab:
# hostname -i
127.0.1.1
root@base:/# ifconfig
eth0      Link encap:Ethernet  HWaddr 08:9e:01:e6:e9:54  
          inet addr:192.168.231.101  Bcast:192.168.231.255  Mask:255.255.255.0
          inet6 addr: fe80::a9e:1ff:fee6:e954/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:23 errors:0 dropped:0 overruns:0 frame:0
          TX packets:17 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:2715 (2.7 KB)  TX bytes:1642 (1.6 KB)

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
|Does the caller really need to know the delta0 path? Can we determine that?
|What about /usr/local/autotest/results? That way they get written to the actual results folder.
|try/except these in case network fails or the download is corrupt.
|Should we default result_path to /usr/local/autotest/results?
|'usr', 'local'
|Put all of these in a separate function so it'll be cleaner to grow and add new args in the future.
|What if I just want to force_delete?
|let's not use /tmp for moblab.
|2 newlines
|Should this be private?
|tar -xvf implies a certain tarball type, do you want to have a check to make sure url is the right type?
|I'll take a bug and todo :)
|What if my host has the cros_version label already? Should it not be able to figure out which image to use?

I don't know how do-able it will be to determine this though...
|s/supported/support

This point does not make sense. Are you saying a drone without SSP support?
|Can you do me a favor and fix this line for me as well :)?

It should say if no image is specified, regular tests will run with the current image installed and suite runs will fail.
|Hmm I feel like theres a couple of potential issues here.

1) How does it know what image to use?
2) What happens if I just added a DUT and no job_repo_url or cros_version_label is set? (I am assuming job_repo_url or the cros_version label is what lets it know what image to use).
3) Does this work correctly if I am running a suite job?
4) Should it complain if I set this and am selecting a client side test?
|Re my comment below: This should determine if the drone has SSP support or not.
|Wait we are getting the ssp support out of global_config?

I think its best to dynamically check on the drone if it supports SSP. Easiest check is if 'which lxc-start' returns exit code 0.
|Should the default not be False or True? Why None?
|I don't agree with this.

Lets run the test with out SSP in this case and log in the test logs we did not.
|I know but most Moblab's have not set the stable version so this value is used.

Any issue with updating it?
|Done
|Done
|I'm going with MEDIUM, since provisioning a dut takes 10-15 mins.
|This is true for both V2 and V3 right?
|Is there a better way to determine if we are the primary? Like if the scheduler is actually running or something? Dan might know better.
|Thanks for the pointer.
|Nope its safe, look at the if statement above:

if hosts and SERVO_HOST_ATTR in hosts[0].attributes:
|Done
|Good catch, I forgot to amend my git commit :).
|Done
|Done
|Done
|Done
|Done
|level
|Done
|Done
|Done
|Done
|Done
|What is the default on this?
|this bug seems wrong.
|Yup.
|Can we put this code in the above try-statement and have 2 Except's?
|moved the comma inside the quotes.
|This should only happen on a moblab system. Use utils.is_moblab to check for that.
|New policy is no (c)
|whitespace
|Done
|Done
|Docstring?
|This looping over 'self' is kind of strange. Can you add a comment about what exactly is happening here?
|Thought I had to change it as part of making a class method, turns out I did not.
|Done
|I think I'm going to give refactoring a try and see how that turns out.
|Yeahhhh I know... The RemoteDeviceUpdater has 2 functions who's functionality I need to generate my update payloads.

What do you think about me refactoring them out of cros_flash. devserver_wrapper might be a good place for them?

Yu-Ju thoughts?
|Done
|Done went with the with block over the code that requires it.
|I'll expand the comment but essentially the build thinks its named with out the -a1. Therefore using this build with autotest fails as the build name on the device does not match the build name autotest wants to use.

Example: I say reimage to build R41-6576.0.2014_12_12_1535-a1 but the DUT's /etc/lsb-release says R41-6576.0.2014_12_12_1535
|Done in a different CL.
|Done
|Done
|Removed.
|Done
|Done
|Done
|Done
|deleted.
|deleted.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No longer done here.
|Done
|Done
|Done
|Done
|Done
|Done
|I thought it was a typo, my bad.
|Done
|Done
|Done
|Done
|Wahh
|Done
|Done
|Done
|Done
|Removing it.
|Done
|Done
|Going to add static_dir as an argument to where it is used and then the callers can specify it when they want.
|Done
|Done
|Done
|Done
|Done
|Moved to callers.
|Will just pass these in.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I set it to true and i think thats what you meant since its an error
|I changed it to unsigned int based off http://en.wikipedia.org/wiki/User_identifier
Let me know if this is incorrect.
|I changed it to unsigned int based off http://en.wikipedia.org/wiki/Group_identifier Let me know if this is incorrect.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No, I framed my code off mock_platform.h so I guess i forgot to remove it. I'll take it out
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Darren said it shouldn't block and should continue when I spoked to him
|Done
|Done
|Done
|Done
|I talked to darren yesterday, he said the program should continue however he suggested that we have a boolean variable originally set to true and in this case set it to false and return that var at the end of the function.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I changed it to do &lt;&lt; oct &lt;&lt; current_perms;

http://www.cplusplus.com/reference/iostream/manipulators/oct/

Please let me know if this is incorrect.
|no i didn't get compile error but i fixed it. i did check to make sure my tests ran though
|I wasn't sure if I should have InsertPkcs11Token return if theres an a mismatch since darren said log it as a warning. Since previously if the directory mismatched it still ran the install code below the checks (which I'm not sure but couldn't it have different permissions that include these?). If I returned out in this case then that code wouldn't run.

So should I have it exit out if there is a mismatch or allow the code to continue?
|Done
|Done
|Done
|Done
|i editted the code to make use of them in the good cases
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I changed it to properly initialize mount and compare to the initialized values
|Done
|Done
|Done
|Done
|Added 2 tests to check all error pathways
|Done
|Done
|Done
|Done
|Done
|This one I'm not so sure how to do since SecureBlob (the out param) is initialized by the caller before hand. how do you want me to handle that? for the mock_platform output values I simply set them to be 0 since there were numerical pointers.
|k i did this using doAll and set argumenPointee. I set the values to 0 for now. if theres a different default you would like me to use please let me know
|Done
|kk i removed the std:: in these methods do you want me to go through the whole file?
|Done
|Done
|Done
|umm i got rid of result now and am using a bool permissions_status and just returning that at the end. let me know if thats good or not
|Done
|Done
|Done
|Done
|Outputted the error as str(e). Let me know if this is incorrect
|Changed message to output file name and the error message
|Done
|Done. Also moved the imports from below into alpha order with the rest but kept tbroch's comment before those.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Surrounded the rmdir with a try except in case this occurs
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done. I added the Raises comment however my code returns if it catches an exception rather than raises, discussed this with Richard.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Made each line not pass 80 characters by adding newlines.
|Done
|Done
|Done
|Done
|Done
|Removed this sentence as the process is explained each step of the way via comments
|Done
|Done
|Done
|Done
|Done
|Rest of code uses the same Args: list, Returns: description format so sticking to that. Already discussed this with Richard and decided consistency is the best option.
|Done
|Removed comment rather than keep repeating this fact.
|went with having the function return true or false and if false referring the user to the servod logs as we discussed.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Talked to richard and decided for this file &quot; is best.
|Done
|Done
|Done
|Done
|Done
|Moved this comment above the return. And removed other mentions of being unable to return none. I can remove this comment too if desired.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|removed wait_for_completion and added a arg for host
|Done
|removed these changes since theyre part of another cl
|Me and richard decided for this file stick to '
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Race condition addressed by line 82 in _stop_processing_requests()
|Done
|Got rid of this lock
|Done
|So the condition variable allows us to block the callers until their request is completed. This way we have one working thread that spins over the queued requests and when a request is completed we release that request's condition variable. This way the caller is blocked - which is what we want- until the request is completed. I've discussed this wit scott and hes on board.
|So originally I was experiencing some deadlocking and I added this lock and the is running lock to solve it. Together it seemed to work but yes this lock may be unnecessary. I'll remove it for now and in the next patch I will add an additional check to _stop_processing_requests in case a request is pushed into the queue after we exit the while loop but before the _stop_processing_requests call is made.
|Im assuming this means just move the import dli in the second group and import rpm_controller in the 3rd. Please correct me if I am mistaken.
|Originally it was but after discussing with scottz we decided to have a separate config file for the rpm integration in order to make it not reliant on autotest/ future autotest changes. Therefore we don't utilize any autotest imports or common.py
|Done
|Done - renamed to is_running_lock
|Done
|I was following dynamic_suites.py where it appeared to be documenting private variables.
|Done
|Done
|Done
|Done
|Whoops I was going to remove these methods. They were just there to help me debug a bug late yesterday.
|Done
|Leaving as is in order to make RPM Infrastructure self sufficient as per our discussion. Please let me know if I am mistaken.
|Done - I was advised by someone (2 weeks ago so not sure who) but I will put it back as an __init__. Just wanted to make it uninstantiable but it should be fine.
|Done - Since these will be instantiated by the RPM Dispatcher Servers I will have that class set up logging to go to a specific file.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Looked into using pxssh. It simplifies the pexpect process however since I have to tell it the Sentry Prompt is not a normal prompt it tries to sync it by pressing enter over and over. However for the Sentry CDU everytime you press enter it lists all available commands and does not simply go to a new prompt line. Using pxssh seems more trouble than its worth.
|Done
|Done
|I changed it so that before the if statements it sets expected_state = new_state and in the CYCLE case it sets it to on and for OFF/ON it doesnt have to change anything. If this isn't fine let me know.
|Done
|Done
|Done - Ya im not sure why i did it this way but it works if I import directly.
|Done
|Done
|Done
|Done
|For the moment I am going to say this is OK but I won't commit/verify till I've talked it over with scott.
|Done
|Done
|Done
|Done
|Done
|Done - but i added a check to make sure its not none beforehand.
|Done
|Done
|Done - ahh ya didn't see this original bug and it still worked since it results_dir always equaled RESULTS_DIR in this script
|Done
|Done
|Assuming u're pointing out I forgot to label the param correctly. Also changed it to be 'entry/path'. Entry was scott's term for these elements but yes they are really just paths.
|So for outputting to a file it works without the communicate() which seems like thats outputting to a file. I looked into this and played with my set up here and it does indeed write to the file. But correct me if I am mistaken.
|I just followed the style already utilized by the file before I modified it. So pretty much used 2 spaces for indentation and autotest style docstrings. That was what was used before but i can update it all if you think thats best. let me know.
|Done
|Done
|Done
|i looked at is_job_complete and it appears to return 1 if it still running or 0 if it is complete. I will assign a success constant here to be:
JOB_COMPLETED = 0,
and change this to be 'if_is_job_complete.... is not JOB_COMPLETED' so that its clearer
|Done
|Done - Did not know this trick for python strings. Will remember for the future. Thanks.
|A lil confused by what u're trying to say here but I'm assuming ure saying rename RSYNC. Next patch labels it RSYNC_HOST_PATH let me know if you meant something else.
|Done
|Done
|Done
|Done
|Done
|Done
|Done - Except I made it offload_dir(dir_entry) and included the generation of cmd_list, since cmd_list is derived from dir_entry and we also still utilize dir_entry in this section.

Also TIMEOUT is a global variable/setting its visible everywhere. Unless you want a timeout variable that is only visible to this function and adjustable in which case I can add it.
|Done
|Done - and I adjusted the log file name to include the current date/time so that each process will have it's own log file.
|Yup my mistake, correcting.
|Done
|Done
|Done - Had assumed that importing logging in different modules did would not have the desired effect. Incorrect assumption, fixed.
|Done
|Done
|Done
|Done
|So targetting both but mostly minheap[0]. using the indexing method I can 'peek' into the heap since the heap maintains the constant that the head of heap is at the '0' index. So I peek at the head of the heap if its terminated, i pop it and peek again at the next element.

Both minheap and heappop can throw the IndexError. Both lines 'minheap[0]' are what I am trying to try/except. and the heappop can throw it (but shouldn't because the peeks would have before) therefore I wrapped the whole thing in a try/except. I can put it into 2 separate try/excepts but this seems cleaner. Let me know if u still want me to change it but for now I feel like its best left like this.

In the meanwhile I'll add another comment to make this clear.
|Done - and i refactored this out to another file called rpm_logging_config. set_up_logging takes in 2 args (logging, log_filename_format) and each module can pass in those 2 args in main to correctly configure their logging.
|Done
|Done
|Done - I added a global list of the 3 valid values and error out if new_state is not in the list.
|Done
|Done - Swapped out my rpm_emailer with an smtp_handler similar to how suite_scheduler works. Now we will get emails for errors that occur in the RPM infrastructure aka if servers are down, etc.
|Hmm.. so the reason for the retry is that if there are multiple dispatch servers I would like to be able to retry forwarding the request in case that the dispatch server is down. But yes if the frontend can't open a socket to any dispatcher this would cascade. Therefore I am going to add an infrastructure check method to ensure that there is indeed a dispatcher we can communicate with before I begin recursing and if they're all unreachable I then raise an exception. Let me know if you don't like the change I put in place.
|Done
|Done
|Done
|Old code I meant to delete as I replaced it with a method: _remove_terminated_dispatchers and decided to call it from _unregister_dispatcher
|if i push rpm_hostname up with the close paren im at 81 characters so seemed best to line wrap the arg with the close paren then just have the close paren by itself on the next line
|Done
|Done
|Done
|Yup appears to. I moved my logging format line here and just had to escape the '%' with another '%' and it works the same here as it did in the actual code blocks.
|Done - I had reused a similar line from something else that was longer than 80 chars, forgot to remove them when i got rid of the line wrap.
|Not sure whats the problem here. Showed it to Sosa and he doesn't see it either.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Ya it comes down to the dispatcher process needing a kick. I'm adding an emailer pathway that for now will email to me (while testing) and then once we launch the server's I'll expand the list to include chromeos-lab-infrastructure.
|Done
|Done
|Done
|Done
|Done
|Done
|Done - put it in it's own method and moved it the call to unregister dispatchers as thats where dispatchers become terminated. That way any time a dispatcher terminates the heap is automatically cleaned up then rather than waiting till the next request comes in.
|Done
|Done
|It used to happen in testing when I had hardcoded in the dispatcher port and was trying to launch multiple dispatchers on localhost without changing the port #. Now you won't hit this ever since I changed dispatcher to chose an unused port. So ill remove this if-else.
|Done
|Actually don't need this try/except so removing it and replacing the _entry_map lookup with .get()
|Done
|Done
|Done
|So I played around interrupting it in the middle of processing multiple requests. It kills the main process and the program exits once all the threads have handled all their requests.

The pro: any client calls made before SIGINT are still processed.

The con: if you try to kill the server you have to wait for the pending requests to complete.
|Done
|Done
|Done
|The dispatchers use this URI to connect to the frontend. Without the 'http://' they can't connect to the frontend. I can remove it and have them just join 'http://' to the front of this config value but that seems like unnecessary work if they're the ones using this string. let me know if you want to discuss this more when you are back or if anyone else has input please let me know.
|Done
|Done
|Done
|Yup both work. I'll update the comment describing it as ip or hostname but I'm going to leave it as _address as I feel that accurately describes both. If theres a term you feel that is more appropriate let me know.
|Done
|Done
|Done
|Done
|Done
|Done
|Done - Neat trick will remember for the future.
|Done
|I changed get_unused_port to launch_server_on_unused_port since the xmlrpc server is the code that binds the port. I open a socket that allows address reuse and share that port with the server. however there is still a possibility of a race condition with another process between opening that socket and launching the server. will investigate subclassing the xmlrpc server tomorrow to see if theres a workaround.
|Done
|Done - I have actually been running my unit tests from utils/unittest_suite.py but yes importing unittest is a good idea as it ensures this code is independent from autotest.
|How about a section in global_config.ini?
|Nit: blank line.
|Nit: do you want to store this constant as a global or elsewhere- esp since u use it twice?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Yes we can move it out and execute and connect both by default have enabled reconnecting but we can also specify it in the execute command in case the defaults change. Essentially if the execute fails it will auto-reconnect and retry 10 times then raise the error. I'll change it catch this exception and I guess return False on that just to be safe.
|Done
|Done
|Done - removed this and ya % makes more sense that join.
|Done- i hardcoded in the table name since its static.
|_AFE.run(...)  returns a list with a dump of info for that job, while if the job was not finished (or existed) it will return a blank list []. Therefore its probably best to convert it to a boolean rather than the info dump or empty.
|Done
|Ya I noticed that the name didn't really make sense and if you look at the old version the docstring was incorrect to begin with. I figured I'd fix the docstring but wasn't sure if I should change the function name.

I think I'll go ahead and fix it properly unless anyone objects.
|hmm they're accomplishing simiar tasks but through different methods with a 1 line overlap. I'll just move it all to _logout and pass in admin_override like with authenticate_with_hydra
|Done - whoops good catch.
|Not sure if you can see the alignment the way I did it but I wasn't too sure how to align this long line. It has 8 spaces on the second line, 9 on the third (to align with the bracket) then 8 on the fourth.
|Done
|Done - got rid of any config look ups only used in one place. I am also going to just remove the re compiles from here, even if its compiled every time we change state, all these expect calls are compiling re's from the strings so not much of a difference.
|Done
|I am a lil confused by what you're asking for here, lets discuss when we sync up.
|Done
|Done
|Done
|Well if I get what you're saying then thats handled in the previous section where I get the response that the connection is currently held, so therefore it goes to the main hydra control terminal and kills the session. We can discuss this more when we talk later today.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I am changing this to just check if hydra_name is not None, therefore we can have hydra's anywhere and it will be up to the caller to specify the hydra name.
|Changed to expect_list to look for the specific failure where we need to kill the logged in CLI session. Logs an error msg if this occurs.
|Done - changed to expect list and look for this error exactly before killing.
|Done - also I put it in its only if statement because this is really for devices in chromeos2 not specifically behind a hydra so in case we ever ssh to these devices directly we can still correctly change the state of the DUT's.
|Done - currently the only way we know of to disconnect.
|I can change it to be pexpect.ExcpetionPexpect but I just realized that sendline doesn't raise anything and we're trying to kill the connection so theres no more expect() calls after this. I'm just going to remove the Try/Catch and since we now have the kill previous connection code so we can recover in case the disconnection fails.
|Done
|By here the hostname should be set and the hydra_name is defaulted to None, therefore if it is None behind_hydra will = None/False.
|Done
|Added the kill session code.
|I changed it to be ExceptionPexpect, which is the base class for pexpects 2 main errors, EOF &amp; Timeout
|I set it now before sending calling the super constructor.
|Done - The connection is made in set_power_state now.
|Moved all the connection code to RPM Controller. Any devices that use ssh just need to give it the username and hostname and at this point their connection is already made.
|The request serialization and threads that manage the requests and return to the callers.
|Done
|Done
|Done
|the hostname without the .mtv is the user name we use to login to the hydra. aka for chromeos2-row2-rack3-rpm1.mtv we login by doing ssh autotest:chromeos2-row2-rack3-rpm1@[Hydra-hostname]  I can ask john to change the usernames to include '.mtv' if we want. Otherwise for now i either have to remove it or change the setup so that we don't pass in the hostname with .mtv (which is needed for all the other setups aka we would have to append it)
|Done
|Done
|Done
|Done
|Done
|Done
|Yup that works and is much cleaner- thanks
|I'll added a DB lookup similar to how we did lookups in the gs_offloader changes. And if the user autotest_system exists use that but if not just use the default (for example my system does not have that user).
|Done
|Done
|Done
|Switched to tar
|Moved to a for loop where more elements can be added in the future easily.
|For now we are reducing the scope to just the preserve directory and attestation.epb
|removing the recreation of machine-info
|Done
|Done
|Who would be best to file it against, or should I just do it myself?
|So I tried that, and it comes up as None even though its been initialized in monitor_db. Monitor_db initially sets it to None and then it is is set to an instance later on as the system initializes. I have a funny feeling that the site_importing doesn't allow me access to the same scope.
|Done
|Done
|this line was in delete_job but I wasn't sure if you wanted to delete all the rows from tko_jobs as well.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I know this is calling a private method but its the most direct way to call these complex SQL queries through db.py, I could add a public method in db.py that will call this if we want it that way.
|I made this a very general except so that if anything goes wrong we don't commit.
|Whoops copied them from CopyTo. Also I removed the acl arg since it only makes sense when uploading a file.
|Done
|ahh- gotcha. got used to autotest style
|Done
|Done
|Done
|Done
|Done - I assumed you meant no space.
|According to http://docs.python.org/library/logging.html its either error or critical. I changed to error.
|Done
|Filed: crosbug.com/34314
|Nit: Is there a reason for this space between &quot; and %r?
|Did you test this on your machine?
|actually can we move this before the reboot? that way my upstart script in test_init gets called and sets the pci bit correctly?
|Do we want to change this to chromeos-lab-infrastructure@google.com
|I'm not sure if there is a technical term but I changed it to 'power on after power failure' if thats not clear enough I can change it to something else.
|I just used -O since it was what we used for the safe stateful wipe code but -f works as well so I changed it.
|Done
|sounds good - Done
|So this does feel a little funky, the alternative would be do staticmethod instead of classmethod but then it would just be hosts.check_for_rpm_support(client.hostname)
|Done
|Done
|So my idea was to check for the DNS zone in the hostname. Another solution would be to check for the .labmachine file on the DUT.
|I played with cautotest and a simple custom control file, the DUT's do not get the DNS zone when passed in machine, so I don't think checking for .cros will work.

And I met with John and discussed about shelf/wifi-cell DUT;s and those devices follow the format of chromeX-shelfY-hostZ.

We decided that all DUT's RPM powered will follow our naming format and any others will not. So instead I will implement a regex check to ensure the hostname follows the format of chromeos[some number]-[optional row followed by a number]-rack[some number][optional letter]-rpm1.[DNS zone]
|So I'm not too sure how to test hardreset as I can't seem to create a SerialHost object in the terminal. However if you can clear this up I can run a simple test. The changes here are pretty straightforward, if you are trying to execute 'hardreset' just use the RPM Infrastructure calls this class will inherit from Site_Host
|Done
|Well the main reason I added this if, is because technically any conmux command can be put here and set wait=False and have that command be executed... So if any existing code used this to send a command that was not to reset the device it would fail.

I can add the enable_rpm_server flag but I feel like there should still be a check if the command is 'hardreset'. Let me know if the above use case does not matter however.
|Done
|Done
|Done
|Currently I check it starts with chromeos. Not sure however if the DNS zone gets passed in machine b/c checking for '.cros' may be better.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I am changing this to be True/False. See below comment.
|Done
|I am currently changing to log this message as an error and return False so the caller knows it failed. Let me know if this is not the approach you two prefer.
|Also note that currently base_utils.run raises CmdError, I was just going to leave this as is and add '@raise CmdError: the exit code of the gsutil call was not 0.' to the docstring.

So essentially if bad args are passed in return False. and if the command fails it'll raise CmdError. That will contain the commands error message, etc.

or I can try/except it and log the error and return False?
|Done
|Done
|Done
|Done
|Hey Peter so I talked to Chris, we'll move the TODO here as it still applies and will help reduce the amount of duplicate code we have.
|Done
|Done - I was following some other control file, ill remove this optional arg.
|Done
|Done
|Done
|Done
|Done
|Done
|I'll look into this tomorrow but I was following that cl of Peter's you told me to look at.
|If I ran this against my own test machine using run_remote_test, self.job.label was empty.
|Hmm good catch, on my gerrit/vi it looked fine but yes this file uses tabs rather than spaces like everything else.
|NIT: Not sure what is the style concerning &gt;&gt; but I feel like a space between &gt;&gt; and sys.stderr might look cleaner.
|NIT: It could be cleaner if you do:
if not ...:
      raise
&lt;main codepathway&gt;
|NIT: period?
|NIT: period?
|NIT: logging.error? since you are raising an exception. and ditto on the period.
|Done - Talked with Richard and reverting back to cf as we run this as root.
|After talking with Richard, we will leave this as is.
|Done
|Done
|It is less lines to do it this way but in the future if we want to add more files it could become more lines. Richard and I figured it would be best to future proof this to allow just adding of the files we want to preserve.
|Comment being added in next patch.
|So the loop is used to generate the list of parent directories which we use with --no-recursion to ensure only the files we want to preserve are kept. For example the files we want to keep are:
unencrypted/preserve/attestation.epb &amp; home/.shadow/install_attributes.pb.

Tar is told to preserve only the directories and files: home home/.shadow home/.shadow.install_attributes.pb unencrypted unencrypted/preserve unencrypted/preserve/attestation.epb

This way tar handles the permissions and only preserves the necessary directories and specified files.
|Done
|Hmm the permissions were being preserved with just cf but I'll add the options.

and the --no-recursion goes with the creation of the list/loop. We are tar-ing just a few select files but we want to also preserve their directories with the correct permissions. This recreates home, .shadow, unencrypted, and preserve with the same permissions and owner they originally had.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done- created 2 dictionaries and moved them to the setup script.
|I will then add another map for the other lab and have an option to allow us to choose the configuration to use.
|Done. The last line still sends out the same email as before but atleast we'll know we changed the value as well.
|Done
|Done
|For the purposes of nuke_pids, we actually never call pid_is_alive below here so the only check that is actually called is the one at the top of this function.
|Done
|Well for nuke_pids we're not using the while loop since check_dead=False. Checking if its alive is pretty cheap.

For now I am going to change it to not check if its alive if we sent SIGKILL, since then its most likely going to be dead for sure and theres not much we can do if it didn't die... And if we don't send sigkill (but a series of other random signals) we will still want to wait for the 6 seconds for the pids to die, and will still want to check after that final loop if they are indeed dead.

If you're still not happy with that, the other alternative I can currently partially picture is signal_pid always returns whether or not the pid is alive. But we still have the problem of wanting to wait and see if the pid dies if its not sigkill.
|Done
|Done
|Done
|Done - This whole method was pretty much completely copied from base_utils. Fixing up now
|So we don't do the wait, I'll change it to return True though.
|No idea, copied code- I know its checking every second for 6 seconds. Replacing i with _. Otherwise it can be a while loop instead.
|Done
|Done
|Done- moved it but it returns False in this situation in case another signal is sent.
|Before we waited 6 seconds before sending the next signal. I'll add more documentation.
|Done
|NIT: no need for else
|I would double check with crosbug.com/33965

When using the GSContext object and print to stdio I had to do:
gs_obj = gs.GSContext()
result = gs_obj.Copy(gs_url, '-')
print result.output

If you want the output to get to stdio here you would need to grab the result object and print out the returned output.
|Ditto, about output getting captured from crosbug.com/33965
|Host name is part of the entry name. example message:

QueueTask attempting to start on queue entry with invalid host status Verifying: chromeos1-rack5-host7.cros/6 (6) Starting [active]. Aborting Job:6-debug_user
|This all takes place in the prolog of those specific tasks which occurs after the hqe entry state has been set to that state beforehand. Aka in GatherLogsTask is ensuring that the hqe is set to gathering before beginning.

This is where I was a bit unsure of how to proceed. Say we are in the gathering task and the hqe is not GATHERING but instead RUNNING. Do we
1) Crash as before and not process jobs and get stuck in a loop?
2) Set it to the state it expects.
3) Just kill this HQE? or somehow repair/recover it? We can launch a cleanup job etc, but that would still require this Task/HQE to die because the cleanup/repair job would be queued.

Thoughts?

I believe we got to this state today as the db request to set the host state to 'Pending' did not go through properly. The logs show the state change right before it hit this error. So a complete alternative would be to add some verification that state changes are successful however this can nearly double the amount of db transactions we make if we are verifying the state is set before returning (aka do a db UPDATE then a db SELECT to verify).
|Done - that also works. I was following the example in site_readme which did site_label_create(label.label_create)

Both works but just a note of how our documentation says to do it.
|Done
|Done - not really, just the way I've seen create_host usually called.
|I was having trouble not having the comment be in the value group. Alex helped and came up with a working regex.
|Done - works. But I will move it out of the class as you suggested in chat.
|I think we should use it as is. I am going to rename the decorator to be add_function_to_list() This way its more general and if something else in site_host requires similar functionality/grouping, we'll have it already.
|Done
|Done - I did the run variable idea. The result object of utils.run matches self.run so it should work fine.
|Done
|Done
|Done
|Bfreed told me its an OR, i looked at a few devices and some may have 1, 2, or all 3 of these all being different combinations of the files.
|Done
|Had a little bit of trouble with the comment portion so i stripped that and grabbed the key value pair.
|Done - they do not.
|It now returns None.
|Need to update this docstring. will be done in the next patch.
|Done
|Done
|Ditto
|Done
|So I wanted a list of functions so it would be easy to just add a function and add it to the list. If theres some better way to do this/make it not instance based, let me know.
|If it error-ed out here it would be good to see what went wrong.
|For now I just broke it up in multiple lines so that its clearer.
|Done- Whoops ya forgot to delete this.
|Done
|Done
|Done - Hmm, it was not intentional so I'll change it to None. Here we only really care about if grep return 0 or 1.
|Done
|Done
|NIT: I doubt we will have a problem with memory but any chance we need to worry about the file being super huge?
|NIT: Get rid of the outside params
|NIT: I thought there was an email that said don't update dates...
|Done- k I figured I'd need them for the !
|Done
|From Duncan Laurie: &quot;It is that same setting for all of the current intel-based devices, and probably at least for the near future as it isn't something intel is likely to change&quot;
|Double quotes here too... even though they were already here, i believe this file mostly follows single quotes. (besides the previous utils call)
|Needs %s, look below for a better explanation.
|You still need to put the %s in the original string and pass the args in logging.error('Illegal ht40 parameter: %s ignoring ', ht40)

You need to fix all your logging messages it looks like. and the docstring
|Incorrect.
|NIT: Can you change this docstring to use &quot;&quot;&quot; instead of #. An example of this would be the super long docstring at the top of server/cros/dynamic_suite/dynamic_suite.py
|+1 on all logging messages
|Please look at the Autotest Style Guide in files/CODING_STYLE

Namely 2 lines between functions and single quotes is the most obvious violations in this file.

And we use @param and @return for function docstrings.
|if self.servo:


Or is there a  reason it has to be is not None?
|Since like 95% of this file uses single quotes and most your changes do, we may want single quotes here.
|If the host does come back up we may still want to re-run host.repair_with_protection(level) and actually complete the repair process.
|Hmm... question: if servo repair fails do we want to attempt power_cycling through the RPM's or no? Currently we would not if it servo repair fails.
|Is there a reason for the newline? This looks short enough to be 1 line, and if not you can have one argument be on the first line and the second continue right below the paren.
|2 spaces between methods
|Repeat: spacing
|Repeat: spacing
|move over 1 space align with first element in (
|alignment
|Repeat: spacing
|align with (
|can you put these at the top of the file?
|alignment
|alignment
|if not mp_images: and get rid of the previous if
|don't use the '\' character for newline. wrap it all in parens
|align with ( and if its too long break the string up
|alignment
|if not mp_images: and get rid of the previous if
|alignment
|alignment
|alignment
|alignment
|if val:
|if val:
|elif not val:
|2 blank lines
|alignment
|alignment
|use paren not \
|alignment
|alignment
|alignment
|4 spaces
|alignment
|if not payload_uri_list_len:
|alignment
|alignment
|if not image_archive_uri_list_len:
|alignment
|Done - kept max_runtime_hrs in model.
|Done
|Done
|Keeping hours till we remove it completely then.
|Done - did not mean to delete.
|Done - I also moved the scheduler_models change with this file as the scheduler will cry/die if the model does not have the correct number of columns.
|Yup :) all my old jobs were copied and multipled.
|So this is the interval we run the user cleanup which includes checking for timedout jobs. I figured every tick would be too often and every hour is too little.

This is similar but different to the 24 hour cleanup.
|If the scheduler restarts and finds the number of _fields_ does not match the number of columns it won't start. Therefore this change must go with the add column change.
|Done
|Done
|Done
|Done
|Done
|I tested this case actually with one HQE completed and the other queued, and this reduce returns True if any of these are aborted.

Thus if an abort is issued for this Try-Job and if one HQE is not completed and goes to the Abort state then the whole thing is considered aborted and it dies as does the whole suite job which just goes to complete with no results.

If this is not the desired behavior let me know.
|Done
|Done
|So I had to pass in statuses so that wait_for_and_lock_job_hosts doesn't return an empty {} and exit at the new check inside of reimager attempt.

However if you pass in statuses you go through the if statuses codepath below which says expect a call to check_and_record_reimage_results which won't happen because we are trying to throw an exception before that.
|Nit period at end of sentence
|ditto
|ditto
|Don't use '\' align with the self.
|Ya I see that now too, I'm assuming that its the same run_test() plus the host is passed in there too so you really shouldn't need to make this call...

Stanley, what happens when you try this without _install() and host is the same host passed into run_once correct?
|Umm, not sure on this. I would assume that _install should not be called outside of the object's code... 

And I don't see any other calls to it inside of server/site_tests.

According to what Richard has told me and what I find in the codebase, calling run or run_test, will call install as part of running the control file. Since it doesn't appear that this code is calling run_test, it is possible autotest would not be installed on the DUT...

Stanley which dependencies are your trying to get on the DUT? Note we have a public install() method that just calls _install() which should be used instead if this is necessary.
|Is there a reason you're not using rpm_client here...?
|use ',' for logging:
logging.debug('path is a %s', path)
|any reason to not use create_host? the packet capture machine is just a stumpy correct?
|smart_cmd = ' '.join(smart_cmd, ht40)
|use commas instead of % for logging messages:

logging.info('Connecting to %s.  Attempt %d', ssid, i)
|use comma not %
|Code extracted and change is merged, use rpm_client in site_utils/rpm_control_system
|NIT: allignment
|ditto
|Is this necessary for just your desktop or running repair using autoserv directly?

I feel like cautotest/ the scheduler may have already set up the environment correctly.
|It is entirely possible for someone to add a host with no board label. Before I had this return None in that situation. In that case we should do the same thing as if its a board not in _RPM_RECOVERY_BOARDS
|is 1
|is 0
|It is possible to add a host without a board, not sure if we want to raise an error in this situation.

Nit: period at end of sentence.
|put comment on a new line
|period
|period
|period
|period
|I think you should reorder this to be:
if not : 
  raise
actual_code
|Done
|So now the only change from your original comment is that we have extra exception catching.
|Done
|Ya this was my original idea, the problem is that you do end up waiting a long time as it tries to ssh in multiple times with a long timeout (180 seconds).

host.is_up() simply does the ping as well.

I did a blend of the 2 ideas: first ping. then check if ssh true works. and added more exceptions to catch if the get_platform or get_labels calls fial.
|it returns result==0 if its true or the exit code if its 1.

I can do if not utils.ping == 0: instead
|Use comma's instead of % in logging messages. And do you need to wrap it in str? I feel like the string handling would handle that for you.
|Done
|Done
|NIT: alpha order
|NIT: you can put the imports from the same folder on the same line
|Hmm a better name for this method please. Maybe drop the maybe and call it recover_object_from_file and add the 'maybe' part as the docstring (which is also missing)
|for issues involving daylight savings datetime.utcnow() might be better.
|Hmm since tick_count is not really attached to tick_time couldn't we just get this by tracking the number of updates to tick_time?
|Copyright
|Maybe track the number of update calls so you dont need to use SumStat as a counter?
|Put TODO as a bug
|use utcnow
|Copyright
|Done
|Done
|Done
|Interesting and good to know... Done
|Done
|the 'they' refers to the fact that there can be multiple jobs we are waiting on.
|Done to both
|Done
|Done
|Done
|Got rid of the exception
|Done - and editted the unitttests I added for the previous timeout logic
|Done
|Done
|Added a test that the try job comes up as aborted.
|Looks like I accidentally added some characters, will fix in next patch.
|NIT: a docstring of this Exception would be useful. Including the error above this.
|NIT: Put this in a global variable.
|Wrap in parens and don't use \
|Does str(e) work? May be cleaner
|Good catch, I accidentally dropped the exception type when moving the try except.
|Done
|Done
|Done
|Done
|Its allowed/done in different files in autotest, don't see why it might not be allowed in this file.
|Pass may be unnecessary but considering every other exception defined in this file follows the format of: docstring then 'pass' I'm going to leave it as is for consistency's sake.

If you really want me to remove it let me know...
|doesn't really look like it needs to be so ill change it.
|I plan to return more information in the future (as part of the todo), or maybe instead it may throw different exceptions for different messages. AKA I'm thinking of passing a board to check_lab_status and then maybe if the lab is up but that board is hosed, then throw a different BoardNotInUse(?) exception for that condition.
|Done
|Done
|In the future I shall do so.
|Done
|Done
|Done
|Kept the name the same as it will no longer return a boolean. Instead it will return safely or throw an exception if the lab is down.
|Done
|Done
|Done
|Done
|Done
|I kinda prefer the check and lock since its doing the check and we want it to be locked afterwards. Kinda like test_and_set but not actually atomic...
|Done
|Done - added quotes
|Done - added quotes
|Done - I did change it but forgot to hit save...
|Done
|Done
|Done
|Done
|Done - and I used a trap to catch syntax errors that can occur if text is in the file rather than a number.
|Done
|Adjusted as Petkov suggested. And put the PowerwashCount under Installer (discussed with Richard) but if you object let me know.
|Done
|Done
|Done - removed quotes
|Good catch, i was playing with the + vs * and had copied over the line from before..

And your single variable doesn't work: if the file does exist and bad data is inside of it, COUNT will then equal the bad data which would just be repushed into $POWERWASH_COUNT
|Done- removed quotes
|align this with the open paren, so the quotes are aligned. Generally using alignment is better than indenting on a new line.

However if alignment will not work then use the indent.
|align the e with the open paren. i.e. e is directly under s from suite_spec
|Usual format is one lined title followed by a description of the change that should be atleast 1 small paragraph.
|NIT: align for this file at 4 spaces past the start of dep_literal.

However note that in most cases for autotest we do double indent for a line like this (aka 8 spaces) but looking through this file its only 1 indent.
|Proper cleanup in this case involves removing the entries in self._drones as in the original code the drone is added before initialized.

Instead of forking this would be then:

*call super method surrounded in try/except

*delete key/value pair from self._drones
|Scott - thoughts on this? I know you prefer the try to wrap around just the function that throws the error.
|So technically this is not offloading the hosts_dir. This is offloading the main jobs' results.

So results/ is structured by:
* job result folders (i.e. sbasi-1023022)
* hosts/: with a subdirectory for each hosts with a subdirectory for a special tasks' results.

This code here only affects job result folders. So it should be named something like offload_job_results or something on those lines.
|Wrong, this will offload the result folders in results/ for finished jobs.
|Missing param process_all
|Would there be any reason we want to exit on SIGALARM though?

And if so maybe log the message and then exit, just to prove this is our problem..?
|NIT: Augh my bad..., I didn't see the internal quote on global config's... In that case you're allowed to use double quotes.
|NIT: alpha order
|NIT: default is kind of a vague term. maybe default_result
|NIT: new line between params and @return
|if old_handler: should work unless you ever expect old_handler == 0
|NIT: single quotes
|NIT: could be gerrit but timeout_min should align with func not the paren
|NIT: single quotes
|if not exc_info unless you require it to be None and 0 is a possibility
|Is this else needed?
|ds is vague
|ds is vague...
|NIT: a better varoable name then x please
|%s in the string block and use commas to bring in args to logging.

And use single quotes
|alignment
|Umm how about you put this as a global format string, and do all the % args in a single line.

Or use python string dict substitution http://thomas-cokelaer.info/blog/2011/05/python-string-substitution-using-dictionaries/ where you'd label each %s and pass in a dict with this variable assigned.
|+1: remove else
|I'd recommend launching this locally and making sure the rest of the page still works.
|Reparsing global config values isn't that big an issue, and that feature allows us to adjust a variable name without having to restart the scheduler so we should probably hold onto that one.
|continue this line after the =
|this could be gerrit displaying this weird but that should be a comma not a period.
|space between python imports and autotest
|Since this is the exact same message twice, why don't you save it as error_msg and pass it to both logging.error and the exception. That way if anyone needs to change the message they only need to do it in one place.
|Prefer a suite run atleast. And since you updated the unittests did you run them? and if so add that to the test line.
|space between python imports and autotest imports
|space around ==
|spaces around =
|just do if num:
|Done
|Done
|Done
|Done - whoops :)
|Done
|What would happen to the ebuild if python throws an exception though?

For now I'll throw the exception and have the main print '' and return if its raised there, that way it'll try to copy and package nothing so it won't break the build process.
|Done
|Done
|Done - looks really clean now, didn't know about filter before - Thanks for the tip :)
|Done
|Done
|These 2 chrome/test folders are required by telemetry as well but are already packaged by chrome_test so I'll just also use that dep when setting up telemetry, rather than copying these files twice.
|So this ebuild has access to the chrome source, would it be possible to say call the bootstrap script in the source and it just grabs the files it needs from the source around it?

then I see this as create telemetry_files folder, call bootstrap to put all required files there from the source, then just package the telemetry_files directory when building chrome-os?

Otherwise I guess I should follow how bootstrap works and parse these DEPS
|docstring: params/ returns?
|params/returns?
|why not return in the if and drop the else?
|This looks longer than 80 characters just put the comment on the line above this - and add a period and make it 'Currently'
|NIT: period
|Just move this into the try, i feel like it'll look much cleaner.
|--bypass_lab sounds like it skips the lab, how about bypass_status or bypass_labstatus
|Change it to be a flag not a value. so they just set it to true
|if this becomes a flag you can drop the =='True'
|maybe instead of checking the if outside just wrap this in if not options.bypass_lab:

You'll lose the info message but its probably not that important.
|I usually prefer not passing the = unless its an optional arg, Alex thoughts on this?
|NIT: you don't need the 'label_function_list='
|ditto
|ditto
|So I thought about it a bit this morning, I'm pretty sure add_function_to_list is only used by the label detectors (you should double check this).

Instead lets make it add_label_detector(label_function_list, label_name_list=None, label_name=None) - feel free to rename the function or args - and use one decorator for the label functions.
|so I just realized you're actually not doing anything with func, so I'm not sure a decorator is the best way to get a list of strings...

Alex, got any thoughts on this?
|File a bug on this. Probably shouldn't be part of the commit message too.
|i know this is a private variable but probably should capitalize since its not in a class
|space at end of line? - not sure if thats a gerrit thing...
|alignment
|optional nit: better name?
|2 spaces
|Unless its a new file :) which this says it is?
|2 lines
|2 lines
|ditto
|ditto
|2 lines
|2 lines
|alpha order
|I tried it with mysql already running, no problems.

Plus the set -e call is further down in this script, if that matters??
|Just saw you said it was above that call. Is that a problem?
|Remove Args, and align the param where the args was and use @returns
|do we want a sleep or wait time between pings?
|Done
|K thanks this one I was kinda confused about but I will use CommonUtilError here and catch that in both my code and _Extract
|These 2 variables don't seem to be used anywhere anymore.
|Done
|Done
|Done
|Done
|Done
|this is a class level variable please move to initialize as self.power_control
|nit period
|nit period
|there should be a better indentation here
|this indentation looks off - could be gerrit
|should be aligned with &quot;&quot;&quot;
|ditto
|this looks off too- could be gerrit :/
|this looks off, could be gerrit though.
|this still looks off, should be 8 spaces or aligned with the (
|You have CYCLE here but you don't use it, integrate it somehow or remove it.
|are parens neccessary?
|quote inconsistency with the exception above.
|store all these times as variables.
|align with '
|double indent this
|quote inconsistency
|please use one of the built in python options parser instead of parsing this yourself...
|alignment
|align with the 'S'
|ditto
|see comment below on alignment.
|this alignment looks off/funny. use 8 spaces if you can't align with the parents.
|ditto
|you have a lot of inconsistency in this file of using 1 quote or double. Please choose follow some sort of format and use that unless you have a reason for double or single quotes to be in the inside text.
|the '_' implies private and should not be accessed this way. I suggest making this arg public.
|NIT this alignment looks off, could be gerrit.
|technically this only checks if a host is powered_by an RPM, so any code that relies on this will only return true for RPM powered hosts and won't respond True to Servo/Manual. Not sure if this will be a problem for you.
|so you seem to be repeating code segments a lot here. Please refactor such that you call set_power with 'ON', 'OFF', 'CYCLE' for each type of power_control. Maybe some sort of power_control.py with a parent class with subclasses for RPM, SERVO, MANUAL? And you can have some sort of factory method to return the right type of object.

Regardless some sort of refactoring should be done.

For the moment it seems like the log/set methods are almost exactly the same for each method and these can be cleaner.
|alignment looks off but could be gerrit.
|alignment?
|please change get_lab_status to private and use check_lab_status and catch the exception instead.
|This alignment is off and funny looking, I would say take the error.* to the next line double indented.
|indentation
|while I enjoy getting your test results, you may want to put them in the proper bucket :)
|use os.path.join
|datetime.now().strftime('gs_offloader_%s_%Y_%m_%d_%H_%M_%S.log')? you may have to somehow escape that middle %s
|I assume timeout_min=0 will still allow for atleast one attempt?
|Done
|Done
|So I decided to refactor and throw the warnings/errors from here. If a test wants to catch them they can.

However I still want to be able to call the test's write_perf_keyval function so thus I passed in keyval_writer. If you can think of a better way to do this please let me know.
|Done
|Done
|Sad face - Done
|Done - updated telemetry runner. Values depend on the benchmarks, will talk to Pramod about it.

The cleanup code cleans up units types that I have seen prominently, there may be other special cases to add later but for now this should be good.
|We use it to determine if the test failed or is just warnings.

I.E. I decided any telemetry run with a Traceback in the stderr is considered a Failure. However if its just Warnings after Warnings but we still got some data in stdout, the benchmark ends with a TestWarn rather than a TestFail

And for the proper ignoring, the default for Telemetry Runner is stderr = ''
|;) - easter egg if you see it.
|Done
|Done
|Done
|Done
|!= &amp; Done
|Done
|Done
|Done
|Done and refactored references in this file.
|Done - Put the raising in the refactored test/benchmark calls.
|Done
|Write a new control file and pass in your benchmark/page_set. I replied to crosbug.com/39301 with how I'll change this to include run_tests.
|How about if I parse the output here and check for failures or not.

The failure can be in the sense that 1 page timed out out of like 25 but we still have data for the other 25. (There is a bug filed against these timeouts already)
|Sadly the format is not very consistent amongst the benchmarks :(. Some are CSV, some use some weird RESULT block formatting, which their code to parse it for their builders is all regex based.

I do like the idea of modifying it to be json as that will really simplify the parsing and not be benchmark deterministic...
|Ignore that, I discovered that the multiple formats are there at the same time.

Currently stdout will have CSV followed by their RESULT format for their builders (but actually contains the same data). I will do a cleanup pass on all of stdout and then use a CSV parser to get the data we want.

If that works for you Scott, then I will add some the cleanup/parsing code here and have that write the perf_key_vals so that the information gets to the db
|Done
|Done
|Setting to chromeos-perf since this is a performance benchmark
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|code removed
|refactored with some code in site_host that gets the board from the afe.
|Done
|Done
|That was a great idea and I tried it but no luck. On the other hand pushing on these bugs got me better results and this code is now no longer required.
|In order to get around the user select picture screen (for the first run) I need to kick off telemetry (over ssh) then kill it so that the user is created and the second run actually works.

Not sure if this is the best way to kill something running over SSH, any other suggestions??
|Done
|Done
|Done
|i could, but looking at the other server/site_tests they seem to follow this format so I will leave as is
|this alignment looks off
|Ya I just followed the same style as the rest of the file.
|Done
|this looks off could be gerrit.
|nit no space between , and cannot
|just a suggestion- you can get the label object a lot easier with:
host_labels = filter(lambda l: l.name.startswith(ds_constants.VERSION_PREFIX),
                             host_model.labels.all())

then if the resulting host_labels has a length of 0, it did not find it, if it has 1 thats the correct object if its &gt; 1 then theres multiple board labels and something is wrong.

However your code seems to remove all build labels (as it doesn't stop) after it removes the host object. Do we ever expect to have 2 or more build labels.
|nit period
|doesn't look like this follows alignment conventions.
|ditto
|why do you grab the repo_url? you don't seem to use it.

Which leads me to ask why do you do any of the 3 lines above... Doesn't the host.machine_install handle most of this? plus it doesn't seem like you have any need for the image_name or devserver_url here
|Any chance of this regex needing to be updated more in the future?
|NIT: this second line is short just align with the paren (if thats &lt; 80 chars which it looks like)
|is there a way you can put this in site and overload this/ call the actual method after you do the try/except? I know this isn't a class so not sure if that will work or not.

And yes I know you hate the whole idea of site files...
|somewhere in utils? and pass in the control file.
|Done
|Done
|Done
|Done
|Done
|meant to delete this -&gt; will remove
|No, we want to return False as a failure so this doesn't kill the running process/server. The error handling is on the client side.
|True... in that case we would not have ran autoreboot.conf and the RPM repair flow would not work...

Richard thoughts on this?
|Yes but there are times we run tests and don't reboot for a while.

I.E. lab power outage last week &gt; 50% of the stumpies were on the first boot and did not come back with the power, the rest that were on 2+ boots did.
|Done
|ran without error, thanks.
|What is the best way to test these kinds of changes?
|Nothing atm, this is more so that we start running the simple scrolling benchmark regularly and dennis can test his work on getting that data from the autotest db -&gt; perf db.

I will be asking Pramod to generate a list of benchmarks/page_sets and we can add the necessary control files later and disable the old suite (if there is one).

Once the src-internal data is available from google storage (crbug.com/174698) I will update our ebuild to use that data (trivial change) and we should have top_25 working as well which is the actual page_set we want to test against for scrolling.
|can we make this less general?
|new line would be nice
|Put the .replace on the previous line
|I have a feeling this should be type=int
|this just looks very hacky and dirty and I feel like there can be a cleaner way to do this, i.e. subclass type of (udp_soc) and override sendto and replace udp_soc instead?
|2 lines
|2 lines
|technically a global variable, capitalize?
|Why can't you just subclass socket.socket? and replace udp_sock with our instance.

This does work but just trying to get your reasoning. Is it mostly just to make us immune in case statsd changes their usage of udp_sock?

Looking at the source code for statsd.connection constructor they just do:
self.udp_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

Which I believe you can just grab the socket protocol and type from the object and replace the instance.

But then again if they actually use the socket in the parent constructor this will all break so idk which is the better/cleaner solution....
|Technically all be done in site_monitor_db... but then again I'm just as guilty for modifying tick here as well but the reasoning I modified here was that _drone_manager was global to the whole file rather than this instance of BaseDispatcher.

What you could do is put this in site_monitor_db, decorate an overriding function called tick() and inside tick() just call super.

But if you're planning to do some more changes here that require being in BaseDispatcher and not SiteDispatcher this is fine too.

I'll let you decide.
|Done
|Done - you are correct good sir.
|K i'll raise it and catch it where I catch the IOError. - Biggest thing I'm worried about is breaking the chromeos-chrome ebuild process (as this would not allow us to build :O )
|atleast one line between title and BUG=
|put some spaces around ==
|Maybe label this Test retries (attempts) something a bit more straightforward. Or just ditch the blank=obey control file
|Done - Did a replace all from Bi2c -&gt; BBi2c (or so I thought).
|Done
|This function was in Fi2c, and I wasn't sure if we will need this function on BBi2c?
|I copied the v2 interfaces and changed to bb instead, let me know if this was not correct.
|Done - tested on miniservo
|should this also become ftdi_gpiouart?
|changed to servo_interfaces
|NIT: not sure on the java style but if you can align this that would be nice, if its too long then nvm its fine.
|this doesn't need to be on a single line and would be much clearer if it wasn't.

Also why are you naming you new interface IPredicate -&gt; the meaning seems vague to me. and its not being imported.

Only api I can find of IPredicate is a thirdparty interface http://docs.oracle.com/cd/E23549_01/apirefs.1111/e15995/oracle/wcps/property/IPredicate.html

but you're not importing it, you're naming it here so technically you can name this whatever - but if you think this name is valid thats fine.
|any chance item can be null? Because this would then throw a nullpointerexception as item &gt; 0 actually equals item.getInt() &gt; 0
|multi-line this
|align these args to the args above, thought this was a line of code not inputs for a minute.
|move the parsedInt =Integer.parseInt outside of the if statement and pass it into predicate.apply

Also that is the only line you are try/catching - correct? If so then only do the try on that line.
|2 lines
|2 lines
|this alignment looks off
|@returns?
|why not default this to &quot;&quot; and assign it regardless?
|What extra lines? Isn't this a new argument?
|if statement is unnecessary if you set the board=&quot;&quot; in the __init__ definition
|add spaces
|style I believe is name matches filename... also I would prefer dummy_client_retries since its three words.
|ya... but we also have tests with underscores...

but i'll leave the decision to you
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Good catch.
|Done
|Done
|Going with site_host then, if we learn in the future we want to move these pieces of code it will be easy to do.
|Moving both here is fine. I'm kind with Richard were I feel that the attributes should be set/unset here - mostly as IMO callers shouldn't have to know about anything more about the RPM infrastructure than just calling these functions -&gt; including site_host.

The same argument can be made that nothing outside of a host object needs to know about host attributes but looking at our current code the AFE is being interacted directly in reimager, tests, site_autotest, etc https://cs.corp.google.com/#search/&amp;q=job_repo_url&amp;type=cs
|Thats fine, I can put it right about where site_host calls this function. Only thing is someone could hypothetically just import rpm_client and call set_power and we then wouldn't have the host attribute- the only thing preventing that is knowledge and the code review process.
|Done
|Done
|see if there is a way to refactor this with the above return codes please.
|why \n at the front, this should already be a new line. unless you want a blank line?
|Done
|Done
|system worked- thanks Achuith, changing to that.
|Nope, it throws an error saying browser_type is not set.

Unhandled BrowserTypeRequiredException: browser_type must be specified

and system-cros doesn't work either.
|that is autotest style
|Done
|Done
|Done
|as this descends from telemetry_test, the imports won't be visible till setup() in the parent class is ran.
|Done
|Changed it to only, seemed to be the only way to make browser_finder find a cros-local browser.
|It stopped at the select user picture page with out that.
|NIT: perhaps it'd be easier to understand if you said 'must be ran with option'
|ditto
|I'm imagine not often. And Pramod listed out the page sets he cares about in crbug.com/223995 so thats how I knew which ones to use.

Looking at that bug again it seems like he just wants to run Dromaeo's DOM Tests, so maybe I should just rename this DromaeoDomBenchmarks instead?
|Done
|Done- I am here to code not spell ;)
|Done
|changing to preformance
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|reworked comment, rest of file is segregated into sections.
|Done
|Done
|Done
|I got rid of this line now.
|Done
|so I depend on chromeos-base/autotest-chrome which depends on chromeos-base/chromeos-chrome which builds the tar ball and installs it in the build directory for me.

I tested (my newer patch I have yet to post) with a trybot and the files were where I wanted them to be.
|Done
|Done - thanks for pointing this out
|no new line
|2013
|atleast 1 or 2 lines here, whatever the style dictates.
|period
|2 lines here
|this cl looks big enough that you might as well attach a bug to track the work.
|alpha order
|no new line
|since you are saying this is an absolute path do you want to wrap it in os.path.abspath()? This only matters if f contains elements like '..'
|2 lines,

also autotest imports follow:
Standard python modules
Non-standard python modules
Autotest modules

since this is in chromite, it could be different but looking at cbuildbot.py i believe unittest and Set should go above the chromite.lib imports.
|no need for empty line here.
|align the quotes with each other.
|align by the quotes here
|supposed to do a double indent here. i.e. only 4 spaces.

i could be wrong due to being used to autotest style but this doesn't look right either.
|single quotes
|single quotes
|is this code still being used? now that you removed the call in abort it may be unnecessary.

a code search showed me the call you removed was the only call to this.

but if we want it in the future it may be useful to keep.
|wrong docstring format
|potential infinite loop if a child somehow is its parent's parent...

since this is such a fringe case logging alone may be enough so if it occurs we know where we are stuck.
|double indent
|no \
|suggestion, why not use afe.abort_host_queue_entries,

a lot of this code looks similar to the code there. and that method takes in **filter_data, which is the same stuff you are passing to filter here.

plus theres permissions checks and other checks to make sure you're not doing anything bad
|Benchmark? ditto for the rest of the Dromaeo files.

if not then maybe make the rest match this then.
|change to 'This is part of Chrome for Chrome OS performance testing.'

ditto to the rest of the dromaeo tests
|Not the one on our current images does not support block writes, already looked into this.

We could update i2cset on the image though and add support.
|Done
|Done
|Done
|@Tbroch, I made some assumptions here about block writes which may or may not be correct.

For all my test cases we only ever wrote 1-2 bytes. In general wlist's first byte was the address the rest was the data. This lead me to believe that the address byte is written to the i2c bus just like any other byte.

So in order to do a block write simply break up wlist into 3 byte chunks with the first being the address arg to i2cset (as it will be written to the bus) and the last 2 bytes as a 16-bit word.


* Alternatively if this assumption was wrong instead I could grab the first byte as the start address and instead loop over the remaining bytes, incrementing the address for each additional byte or word i need to write.

* Or we simply don't support block writes.
|Done
|Done - reworked the logic to only allow for 1 or 2 bytes and changed the logic for this flow.
|Done
|should we name this controller something that makes a bit more sense board wise? Like 2012_x86 or whatever is the underlying connection between alex, stumpy and lumpy?

I was a little taken back that stumpy inherits from AlexController and Lumpy just uses AlexController

Though if this makes sense to most people then nevermind.
|it'd be nice if there was a better test, but the code change seems sane enough.
|parts of this comment can be kept.

# Check if rsync is available on the remote host, if so use it.
|what is the cost to of running rsync --version over and over on this host?

This seems to me like it would add an additional ssh run command for everytime use_rsync is called. Leading me to believe the original code was trying to prevent exactly this...

Is there a better middle ground here? I.E. Check if rsync is avaliable when the host is created? If thats not valid (rsync somehow disappears) maybe try rsync and if that fails then instead try scp instead?
|yes use 8 spaces. and put this paren after the last arg
|8 spaces
|put this on the previous line and then align each line by the quotes.
|single quotes
|4 spaces
|4 spaces, ditto next couple of lines.
|8 spaces
|actually shouldn't all these be interface=&quot;3&quot;

on the beaglebone we are using /dev/i2c-3
|whitespace
|8 spaces plus all args should be on the new line
|please do a full perf_v2 suite run and check each test's keyvals.
|8 spaces
|i thought the RESULT lines gives us the average?
|8 spaces
|is the + required?
|no +
|no \
|no +
|8 spaces
|you shouldn't need the second +
|no \
|no +
|no \
|no \
|no \
|no +
|no +
|no \
|no +
|this change adds an _ to the end of the units if they're in parenthesis compare to the old code. Is this what you desired?
|Maybe it would be good to put an example above this line.

Also strip will remove any , that are near the front or end of the string making the split call specific to what results from the strip.

I think an example would make this more clear, just pointing out that if any combination of {,},',' are near the front or end you will lose that ,
|should be single quotes
|single quotes.

also is there a better way to align this? or maybe a double indent
|as longer as you're sure it should be 2 i dont see a problem with this.
|these 3 uarts_en and fw_wp_en are the only values from servo_v2 that had init set
|this init needs to be removed.
|Done
|Done
|Done
|No. PTAL at https://gerrit.chromium.org/gerrit/#/c/49133/

You will see all the GPIO's utilize interface=&quot;1&quot; which is set to be bbgpio. However the different pins have different chips on the beaglebone which you can see in the XML changes. Todd is saying we could potentially deprecate chip in the future. crbug.com/241507

To help clarify each entry has an instance of its driver class. Which when created was passed an interface controller (this class). So while the driver can store chip at object initialization as each instance applies to one pin, this class is shared by all the drv's thus chip depends on who is calling it.
|Done
|Done
|Well both of these interfaces are used by the same driver so I figured matching the API's is the best way to proceed.

If you don't like this, I can make a class that defines the interface have them both inherit from it?
|Done
|Done
|Done - since this logic is shared with the uart I created a new class for it.
|Done
|the mux root folder has files we're interested in and subfolders we are not - so on those just skip.
|added to docstring.
|Done
|Done
|removed
|removed
|I assume this check is to ensure the pin is outputting? I guess for this case I would just set it to DIR_OUT then.
|Done
|Done
|I can put 'if dir_val is not None' here and assume set direction always has a value to set
|Done
|Hmm so instead of refactoring this class I changed ftdi_gpio to have a consistent interface with bbgpio. Todd any issues with this?
|Done
|Done
|Done
|Done
|Done
|Done
|Well dir_val can be None, 0 or 1. We want to call it for 0/1 but not if its None so combining doesn't seem to make the most sense.
|Done - can't test exporting in this manner but can ensure direction/value are set/read correctly.
|Done
|Done
|Done
|is this line needed? this variable is only used in the else -&gt; which assumes the try succeeded and we retrieved the image name.

You mentioned scope when we talked but a simple test in python shell showed me that the scope is shared between try and else.
|this line is in stage_image_for_servo. Why redo the logic here in the control file rather than try except around the call below.
|What if I have a local AFE/db with my host saved in it and I am trying to run run_remote_tests? This is something that could occur on my system/setup for example.
|well this is just an example control file. but if we run them all you wouldn't know which worked or failed without looking at the logs.
|did you do a full trybot run?
|what does the ! mean exactly here?
|Whats the reasoning for removing chromeos-base/telemetry? The point of that ebuild is to ensure telemetry is installed on the test build.

Maybe keep that ebuild but just remove autotest-telemetry.
|That sounds good to me, lmk if that works.
|just want to make sure you did a full build_packages and build_image correct?
|Are we sure autotest_src_install is still getting called? I'm worried about this maybe overloading it and now allowing that to get installed. A full build should show whether all the autotest files got installed or not as well.

Maybe a more ebuild familiar person would know if this is the case or not.
|nit period
|ditto
|looks like you have a tab here instead of spaces
|Nit period.
|ditto
|period
|period
|period
|period
|period
|period
|period
|period
|Hmm this is a new file in our repo but you pulled it from git, not sure if we need a copyright here or not.
|align the quotes
|single quotes
|nit period at the end
|Nit period, add to all '#' comments
|align the selfs
|no need for +
|align the quotes
|period
|period
|period repeat below
|hmm these outlets may have actually been used now... for the moment I would add a comment and remove the call from main().
|alphabetical order
|add a comment here that we are dealing with an RPM
|new line between param and return
|new line
|new line
|Nit 2 lines
|new line
|alphabetical order
|Add a comment that this device is an RPM in the else case
|new line
|new line
|new line
|new line
|i don't see you setting self._mapping_last_modified to last_modified anywhere... i.e. once its modified once you would reload this everytime
|why save this as a local var? I think it should all be able to fit on the next line.
|move this to the function definition above. and maybe throw an exception if None is passed in.
|i'm not sure on the style of this but I recommend offsetting the values from the keys to make this clearer.
|I know I used a \ eariler in the file but turns out its not correct autotest style so please change this and the other string up above to use () to capture the multi-line string constant.
|if not switch_if_tuple?
|space is unneccesary
|log an error if the new_state does not match the expected state.
|'.*'.join([self.INTERFACE_STATE_MSG, self.poe_prompt])
|can some of this code be refactored? seems repetitive.
|how can this happen...? _get_rpm_controller is supposed to call _create if it does not exist already
|duplicate code... same as in frontend_server. Please refactor. and look at my comments in that version of this method.
|having in its own function is fine. I am wondering if we want to have a single 'utils' file in case we need to add more to this infrastructure in the future instead of making it 'poe_utils'
|sounds good will look at that change next.
|Run the frontend and dispatcher locally and test it with calls through rpm_client.

Did you test your rpm_dispatcher changes?
|8 spaces
|Maybe we should name this class CiscoPOE in case we use different POE devices later?
|8 spaces
|this will require the servers to be restarted whenever the file changes. Something we can do about that?
|log a warning or error
|doesnt look aligned properly, could be gerrit tho.
|i put a comment in the csv, do we need to hardcode interface?
|space after period
|This should probably trigger an email alert.
|this try block is pretty huge. I suggest breaking it up into several helper functions, like enter/exit configure terminal. That way we have a better idea where exceptions occur.
|maybe move this logic to its own function.
|Shouldn't the state change right away? if not expand the comment explaining why not.
|log the error as well so we know which line failed.
|@ return?
|2 lines
|Are these devices connected to actual DUT's? Anyone can run this file so lets just be careful we don't take down POE's.

If you noticed I used fake hosts which I tested by labeling unused outlets.
|Make this a global variable, it's not going to change.
|where is this function defined?
|Put a space after the .
|8 spaces
|So I get the point of maintaining the servo -&gt; switch mapping. But do we want to hardcode in the interface?

What if a lab admin rewires something and the interfaces change. Any way you can determine the interface once you are logged into the POE and make this part dynamic?
|align this if you can. If need be do a new line after arugula.
|2 lines
|K I guess thats fine not to have the small function but change this to:

if verbosity:
  if created:
    ...
  else:
    ...
|what is normally passed in verbosity before? If the callers aren't changing why default this to 0 now?
|these lines are all repetitive. How about a verbose_print function that takes a string and the verbosity arg then does the check and print.

then each of these lines become verbos_print('string', verbosity)
|after this is committed I will update telemetry_runner and then remove run_multipage_benchmarks
|I could add new unit tests but as you said we will be removing this code at some point in the future.
|Done
|Done
|Done
|wasn't eliminated by I can add it.
|Done
|Please use single quotes everywhere except for doc strings or when you need a single quote in the text.

Fix everywhere. Will add this to style guide.
|nit new line
|2 new lines
|list instance variables
|put 2 new lines between methods.
|don't use + user %s and comma between string and variables. Repeat everywhere.
|whats wrong with this indent? 8 spaces is right by autotest standards.
|From that section: 

&quot;For hanging indentation, use 8 spaces plus all args should be on the new line.&quot;
|this blank line should be here
|new line
|delete pass
|2 new lines between functions repeat everywhere.
|2 is right
|ahh good catch
|This whole section is repeated... Just making this guide more convoluted and confusing.
|I'd like to keep it here as its a common comment and I'd rather not redirect people too much.
|Added a new line to make this line stand out more. People seem to be missing it.
|we do 2 blank lines separating methods.
|Done
|We should add a section involving using single quotes vs double quotes.
|According to beeps, private methods don't require docstrings. Getters and setters also.
|Done
|Done
|Done
|Done - adding blank line.
|Done
|Done
|Done
|Done - ya... my spelling isn't the greatest lol...
|Done
|So I took this from the original ftdi_uart. Which that IC supported 1.5 stop bits. stty does not support this and after talking with Todd he said its fine because most people don't use 1.5 ever really. I'll remove it from this docstring though.
|Done
|Done
|Done
|Done
|ahh I assumed that was innate. Adding.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|its super ugly...  I put an example in bbuart_unittests which I supply for unit testting.

I'll put a short version that only has what I'm looking for here.
|Done
|Done
|Done - did this for all of ftdiuart as well.
|Done
|changed to check_output and added the output to the exception message. That should capture the output and return it (which if it passes we don't care about).
|As I kinda need these here so I can use both the servo v3 overlay and the link overlay at the same time, I think I will leave them here and add the TODO to add functionality later.
|Ahh these I need to run by Todd as they're specified in the servo_link_overlay as having to clobber these values. And without anything here it would fail when merging the 2 overlays.

@TBroch, can you take a look at these. There were in V2 specified but we don't have these signals elsewhere in V3, as far as I know.
|Done
|Done
|Done
|Done
|Done - Went with plural.
|Done
|So this is actually not new code (refactored from ftdi_uart) so for the purposes of old unmodified code I figured leaving it as is.

Let me know if you want me to start cleaning this up.
|Done
|do we need an else clause?
|add a comment explaining what is going on here.
|8 spaces
|new line
|2 new lines
|alpha order these imports
|period
|indent these lines relative to AttributeError
|please put in the comment why you are checking this.
|Actually, if sda is present I guess it makes sense that sda1 has to be there as well.

So ignore my previous comment.
|isn't this only true if the hub/muxes point the usb key to the host. It could be pointed to the dut.
|Honestly I don't know if we use it, but you should probably update it just in case.

As for placement since its not a keyword arg, I think its fine. As long as all callers have been updated.
|are you sure you updated all the places this is called? I kinda prefer new args go at the end of a definition then in the middle too.
|1 more newline
|nit new line
|nit 2 lines
|2 lines between functions repeat everywhere.
|no new line after docstring, repeat everywhere.
|new line before closing quotes on a multi-line docstring.
|either align ignore_status under single '

or put all args on new line with DOUBLE indent.
|ditto
|Capitalize F
|period
|8 spaces
|8 spaces
|either align ' with ' or put all the string on the next line with a DOUBLE indent.
|period
|Correct, it didn't vary by boot often, more so than it varied by the device setup. Expanded the commit message.
|Done
|For Alex, this will always set rec_mode to off by the way you call it in servo_install. Is this okay? Or would it be better to not set anything?
|What if request.status_code is not request.codes.OK, shouldnt you stop the timer or kill it?
|new line
|new line - all multiline doc strings should have blank line before closing the docstring
|use path?
|I know we really discourage the use except Exception. Could you maybe use a tuple of those 4 you've seen?
|do you really want to catch all exceptions? or something in particular?
|shouldn't verifying we're logged in be me a part of chrome?

Maybe a function in there, is_logged_in()?
|heh, if you don't agree with a comment feel free to say so in the comments before you change the code :).

But ya why keep this static? That was kinda my original question.
|Don't want to log anything? Like what might have happened?
|is there a bug tracking all these todos?
|any reason this is not part of the test class?
|new line
|double indent ;)
|actually please rename this to max_wait_sec or mins. Not sure the units here.
|maybe make the 10 a constant, you use it in a lot of places.
|Since it didn't build, remove this and copy the src_prepare from autotest-chrome
|Its not, https://gerrit-int.chromium.org/#/c/41606/
|TEST=build_packages or a try bot run. I.E. to run a trybot with this cl and the lumpy-release builder:

cbuildbot --remote -g 63526 lumpy-release
|Don't update this file. Its just a copy of -9999 and gets updated automatically.
|This file is out of date, please repo sync and rebase.
|Don't update this file.
|This file might not build. Look at src_prepare in autotest-chrome AFTER you repo sync/rebase.

Either copy the new src_prepare OR I would like you to first try adding autotest-chrome to RDEPEND. Could work and we would have less copies of that same code.
|tab here
|should be a tab I believe. Look at tests above.
|From your build output:

WARNING: The following packages failed the first time,
but succeeded upon retry. This might indicate incorrect
dependencies.
  chromeos-base/autotest-tests-ownershipapi-0.0.1-r3762


put chromeos-base/telemetry here
|2 new lines
|should something be here?
|8 spaces
|if you do double indent put all args on the next line.
|8 spaces
|8 spaces
|8 spaces
|8 spaces
|align % with '
|put this on the next line
|only 1 new line
|double indent
|nit period
|double indent.
|Should be 1 line summary, new line, then a multiline summary.

I'd do:
&quot;&quot;&quot;Verify avaliable video resolutions.

Video resolution should be 360p,....

&quot;&quot;&quot;
|This sounds kinda like a test, is this code going to be shared?
|double indent
|+1 Scottz's comment
|The order of imports should be as follows:

Standard python modules
Non-standard python modules
Autotest modules

I.E. move telemetry up before the autotest stuff and a new line in between.
|2 new lines between functions, repeat everywhere.
|Have you taken a look at client/common_lib/cros/chrome.py? Handles a lot of this for you. I suggest switching to it.

The only issue I can see is that is based of being used as part of a with statement but here you are wrapping in the xmlrpcserver.
|new line before closing &quot;&quot;&quot; repeat everywhere.
|no new line here, but you can have it if you want... not really needed.
|2 new lines between functions.
|Autotest Style Guide: http://git.chromium.org/gitweb/?p=chromiumos/third_party/autotest.git;a=blob;f=CODING_STYLE;hb=HEAD
|nit 8 spaces
|no need for + repeat everywhere
|should 4 and 2 become some short of constants? You use these numbers a lot, I assume for a reason.
|What kind of exception? Do you want to catch it and raise your own? like no tester found?
|2 newlines
|2 new lines
|refactor into a method where you call it twice, once with zeroes, once with ones? Just a suggestion.
|I assume you verified the file was still there?
|Done
|changed to unittests
|Done
|Done
|Done
|actually not needed anymore.
|Done - set_up_logging now returns email_handler which is passed to the frontend_server.
|Done
|Done
|Done
|ahh good catch I had added more here for testing purposes (didn't clean it up all the way)
|CLONE_RETRY_INTERVAL_MINS
|should be 4 spaces, fix everywhere. and single quotes.
|single quotes and 4 spaces.
|single quotes.
|Done
|2 new lines
|logging? not print?
|logging?
|I assume this prints out stuff, maybe capture and log.
|logging?
|Done
|is there a mailing list for your team? In case you leave, etc?
|This work is large enough to merit a bug. Please go to crbug.com file one and reference here by BUG=chromium:[BUG_NUMBER]
|can end a video. ?
|This is technically correct, it just looks cleaner if you do:

job.run_test('video_YouTubePage', arg1, arg2, arg3, ....
             argN)

i.e. argN is directly under the '
Mostly because job.run_test is short. Up to you to change these but it would be nicer :)
|new line
|new line
|new line
|just 1 space
|name='youtube_page' I know this works but we generally put it here anyways.
|new line
|why is this not in the class and what calls it? If its not needed, delete.
|Maybe name this as YoutubeInteractor or something that describes what exactly this does.
|2 new lines here
|these seems like it belongs more in the test class than in the helper.
|K umm at first glance I thought this was the constructor... Please rename to initialize or something that's less confusing.
|these 2 alignments mixed up make reading this confusing. Separate the os.path.join to its own line and save the result and use it here.
|save playing as a constant and replace everywhere.
|save paused as a constant, do this for all these states: seeking, seeked, etc.
|constant
|are these 2 variables likely to change? if not make the page constant. If we want different pages tested with this same test then make them arguments of run_once.
|Please file a bug to track this work on crbug.com
|The order of imports should be as follows:

Standard python modules
Non-standard python modules
Autotest modules

Please move telemetry imports before autotest.
|2 new lines between imports and code.
|2 new lines
|2 new lines between functions. Repeat everywhere.

4 space indents, repeat everywhere.
|@returns repeat everywhere.
|newline between end of docstring and closing &quot;&quot;&quot;. Repeat everywhere.
|no new line.
|8 spaces not 2 or align with the A
|file bugs on TODO and put the bug in the comment.
|style guide says if you do double indent, all args must go on new line. repeat everywhere.
|alpha order
|is large guaranteed to be an avaliable video quality?
|align with '
|You only change the year if its a new file.
|The order of imports should be as follows:

Standard python modules

Non-standard python modules

Autotest modules

So move the telemetry import above the autotest imports with a new line separating them.

Also alpha order. browser_finder then browser_options
|2 new lines
|2 new lines
|2 new lines
|2 new lines between functions. fix everywhere.
|1 blank line at the end of the docstring. Please fix everywhere.
|logging uses , not %
|The order of imports should be as follows:
Standard python modules

Non-standard python modules

Autotest modules

So move the telemetry import above the autotest imports with a new line separating them.

also alpha order
|2 new lines
|2 new lines
|2 new lines and between all functions so fix everywhere please
|blank line before closing docstring. fix everywhere please.
|if you can't align this do an 8 space indent.
|8 space indent
|this alignment looks funny. Align with process or 8 space indent.
|save this as a global variable FLASH_PROCESS_NAME or _TYPE
|@parm time_to_wait
|fix this alignment.
|+1 and please repeat this on your youtube CL.

Thanks Achuith, I was starting to think about how we should refactor this for all the tests. Did not know we already have a chrome module :)
|change this to be time_to_wait_secs or mins? Its not clear what units this is.
|Correct hence why I copied over the required folders in the TEST= line.

But both CL's are required here.

https://codereview.chromium.org/18991012/
|Nit space before '
|Maybe add a link or command so the sheriff knows how to preform this deploy step?
|the alignment for the TEST= line is inconsistent. I suggest with the way you're using it, indent this second line.
|I'm not sure if you can do this but try DEFAULT TRUE, it would be a bit more clearer.
|whatever catches this error tends to suppress it so I kept the logging.error
|Adding 2 timeouts here is also acceptable, question is do we want to add this protection to just the initialization process or every call.

Waiting for Richard to respond.
|Done
|Done
|No we want it to be a tuple. ('pwr_button') == 'pwr_button', which ('pwr_button', ) is an iterable of 1 element.
|Done
|This was removed.
|2 new lines between functions, repeat below as well
|Make this string constant, ditto for 'system-guest'
|Please inform Chester (dunno@) and Rohit (Rohitbm) of this change. Rohit is about to commit code that uses chrome.py
|Should we have a check to ensure we are logged in? I.E. /var/run/state/logged-in exists?
|I believe the with statement can work without the as _

Please try this and if it works fix everywhere.
|ahhh gotcha
|Declare it once at the top of the file so you don't have to declare it again below.

Or now that you defaulted it just remove all the changes from this file :)
|Is this only called in one place? If not or if its possible to have other callers than below, I'd recommend making it a keyword arg with a default value.
|if you don't default the arg for run_job, make this a constant like ID_DIGITS. Looking at this its hard to figure out what that 1 is or doing.
|this is a big enough change it should have a bug to track this work.
|manual as in did you run the logintest?
|Why not keep the api the same and pass in the extensions_path here?

That way you won't break any existing implementations/or other work people are working on...
|NIT period
|if you do a double indent on the next line, all args must be on the next line.
|4 spaces
|4 spaces
|so this is the only code I see that merits the API change. However is there no way that to get the extension with just the browser object?
|or put on the previous line
|No spaces around =
|no spaces around =
|switch %s with %r and remove repr.

%r should call repr
|Richard and mine train of thought was if anything goes wrong in trying to talk to the servo, don't use it. Catches problems like connection refused, etc.
|Ya the message gets wrapped:
'Connection to servo failed. Failure: Timed out getting value for pwr_button.' but any other error will be wrapped the same way making it clear the connection failed.

I can do it your way but then I feel like the code would be a bit redundant as I would repeat the logging and the connection failed lines. (the exception gets caught but not logged but the caller)
|What happens here exactly?
|no 2 lines between functions/classes in this file?
|docstring?
|global constant?
|NIT: swap a with _
|nit period
|swap 'a' with _ ?
|you don't want to list the files? also period
|nit period.
|os.path.dirname()?
|period
|' '.join(command)
|Trybot run.
|if these are the telemetry based tests, they should be autotest-chrome (for building reasons)
|ya you're fine, thanks to the xmlrpc bridge.
|2 lines ;) - apply everywhere
|make a constant? you use this multiple times. repeat with the rest of the properties.
|should 4 be a constant?
|I thought these files auto-incremented?
|Done
|Done
|Done
|Done
|Done
|put a comment about the difference between here and just control. i.e. this uses the interactive mode
|a little easter egg :) if you want it gone though let me know.
|for consistency sake stick to ssh or SSH for all your comments. It's an acronym not a word ;)
|can this be after the rest of the imports? kinda funny like this.
|alignment looks off, could be gerrit.
|is this simply to get rid of the logging format?
|supposed to be commented out? shouldn't there be a wait if theres no communicate?
|Do we not want to error out or delete the folder if it already exists? What happens if I run 2 tests with the same results_dir?
|add a comment as to why you're having to shutdown logging?
|should be in the above imports but because of your weirdness i'll let it pass
|since you can't fix this add a comment why above.
|alpha order
|this should align the quotes. same with whitelist and and any other args you did incorrect.... I know you hate me ;)
|8 spaces
|% not ,
|ditto
|interesting trick, didn't know you could create a tuple without parens.
|I know you're just cleaning this up but make the comment clearer. Its the pidfiles after the refresh occurs. Something like that.
|could be gerrit but check alignment and single quotes.
|why drop the first element? Maybe a comment to explain why would be good.
|Umm not sure about wild-cards... I just played with tar --no-recursion it copied the folder but nothing inside... you could get rid of the --no-recursion but I suggest running that by Richard.

As for the tar size thats limited by the size of /tmp which after a quick check is different on my lumpy vs link (both are close to 2 gbs)
|Richard had me make powerwash so you can't supply a directory for security reasons. Each file in it needs to be specified.

If you look below you'll see the tar command runs with --no-recursion
|new line
|2 new lines
|8 spaces, repeat everywhere.
|lets just use communicate
|splitlines
|no need for wait with communicate
|no p.wait()?
|It comes up as generic flash device rather than a known chip.

Found Generic flash chip &quot;unknown SPI chip (REMS)&quot; (0 kB, SPI) on linux_spi.
|--force did not work...

$ sudo flashrom -V -p linux_spi -f -c SST25VF040
flashrom v0.9.4 git.chromium.org/git/chromiumos/third_party/flashrom : 6a1618f :  on Linux 3.2.42-psp27+ (armv7l), built with libpci 3.1.8, GCC 4.6.3, little endian
Acquiring lock (timeout=30 sec)...
Lock acquired.
Initializing linux_spi programmer
read(/sys/bus/spi/devices/spi0.0/modalias) &lt; 0, try next.
read(/sys/bus/spi/devices/spi1.0/modalias) &lt; 0, try next.
Detected linux_spi:dev=/dev/spidev2.0
Using device /dev/spidev2.0
Probing for SST SST25VF040, 512 kB: id1 0xbf, id2 0xdb
No EEPROM/flash device found.
restore_power_management(): Power management enabled
|So looking at the schematics https://docs.google.com/a/google.com/file/d/0B3p_T-4I-2yWaUE1OFhPTWFUQU9XY3lVWXp6WkJjZw/edit?authkey=COqTwe0M&amp;authkey=COqTwe0M the I/O expander is at 0x21.

The v2 file pointed to 0x25 but I didn't see any devices at that address if I did i2c-detect so I checked with David:

&quot;ok its suppose to be 0x21 
on the flex test board 
for the tca9555 
so it looks like you were looking at the wrong address which could explain why you werent seeing it &quot;
|Done
|comment deleted.
|created a v3_kbd test function.
|David is on vacation till 9/3, Steve might know
|Run and add after ./site_utils/suite_scheduler/suite_scheduler.py --sanity
|Done
|% not ,
|can you not just do 'if servo_args:' same with the following if statement
|please add a comment on what is happening here. or an example of out.
|why get rid of this? Automatically determining servo is useful and can we really assume all host files will call get_servo_args??
|call this dut_hostname it'll be clearer
|PWR_BUTTON_CMD_TIMEOUT_SECS, do this to all time values so we know its secs and not mins
|log the cmd error
|+1 move to ServoHost
|you do this multiple times, best to refactor it.

some sort of run(command):
if self.is_localhost():
  etc
else:
  etc
|ya your default here is localhost
|new line before closing &quot;&quot;&quot;

repeat everywhere
|why did you have to override it? why do you need the extra options. just add a comment if need be explaining why.
|@ returns?
|@returns
|use single quotes
|alpha order
|s/calss/class
|alignment
|alignment Note this could be new chromium-review showing me this wrong
|So the servod process can go up, try to launch and can fail. How about checking twice or making sure its still up 20 seconds later?
|single quotes
|maybe just 'Time out' your final message seems very repetitive:

Servo health check failed: Servo host health check timed out
|can we not make this a blanket exception?
|2 new lines not 3
|reset implies it actually resets. But this verifies and resets if verify fails
|ServoVerifyFailure?
|do you want a check for this?
|if you can leave this on the previous line
|is there anyway to make these numbers constants?
|does this need a todo to remove later?
|If its not a number, you could get a null pointer exception here. Is that a worry?

isNumber() &quot;a reference to a JSONString if this JSONValue is a JSONString or null otherwise.&quot;
|ditto my null pointer exception question.
|all args start on the double indent or they align with the first arg
|We don't really have a style enforced for Java in autotest but ya if you want you could split this.
|this is no longer a param
|If there is work to be done to get profilers working properly please file a bug and add a TODO here
|1 more new line
|Well if it does not exist you won't be able to run this. I sent Caroline instructions on how to open the chroot and have it exist: cros_sdk --chrome_root=$HOME/chromium-cros --chrome_root_mount=/tmp/chrome_root FEATURES=&quot;-usersandbox&quot; CHROME_ROOT=/tmp/chrome_root
|raise error.TestError or something autotest-related
|/tmp/chrome_root should probably be retrieved from the enviornment variable $CHROME_ROOT, if possible
|that looks fine to me
|also put a mailing list for toolchain
|would you ever run profiler without profiler_args?
|agreed this should go after, this could be why you're not getting the right results.
|move common to right before the from autotest_lib imports
|Does this not need ./tools/perf/page_sets?
|s/tyo/to
|use single quotes whenever possible.
|change this to if not os.path.exists, then raise an exception if the file is missing.
|just put your the string generation in the following line
|raise TestFail?
|Match this file's style as described in the style guide please
|PTAL at http://git.chromium.org/gitweb/?p=chromiumos/third_party/autotest.git;a=blob;f=CODING_STYLE;hb=HEAD and adjust all your docstrings to match the correct style.
|what do you do with this?
|Do we want to keep the rest of the code if we're just erroring out each time?
|Done
|:( modifying ssh_host causes soooooo many complaints but will do.
|Fine, removing. and replacing errors with AutoservError.
|Done
|Done
|I think I will remove it as utils.run doesn't need it. and the call to super.run will collect the environment stuff as needed.
|Done
|Deleted env. handled by the super call to ssh_host
|Was in the next patch
|Done
|Done
|Done but now uses exceptions as control flow.
|Done
|Refactored to instead pipe it into utils. Wiley only covered the ssh host timeout which calls utils.run.
|Done
|Done
|Done
|Added a raise exception here.
|Done
|Done
|Done
|Changed it to be echo ADB_CMD_OUTPUT:$? and will use regex to split the command.
|Yup
|Done
|So I think we need to keep adb_host always refers to the machine that talks to the android device.

And yes I agree with what you think I mean to say, will clairfy.
|Done
|I did but the basic functionality is there, I prefer that in general we avoid it and stick to ssh+adb over usb. If the other use case really becomes necessary we can flesh it out more.

Mentioned USB is more stable.
|Done I went with \w in case serial lengths change by device type/manufacturer/etc

It will be a new line word tab 'device'
|Done
|hmm.... if this connect fails the host object would be hosed... which is why we need to come up with a good verify/repair flow.

For now I will raise ADBHostException on that case, and the caller should react accordingly - most likely the test fails as this method is called when a new ADBHost is created or reboots
|I added 'if timeout and' to make sure it only does that check if its valid.
|Done
|will be fixed in next cl
|Done
|Done
|Done
|Done
|Done
|augh will delete require_root in next patch.
|except RemotePowerException? that could be used to indicate the power_cycle failed
|use has_power()
|move this into the loop?
|I say do the first power cycle in the loop then increment this.
|is this if case needed, can just say Powercycling was successful after 0 failures
|why is this needed? Add a comment to explain.
|can you make this Exception more specific?
|Done
|Good point Fang about downed hosts, i'll make sure I catch timeouts, run errors, etc.

The follow up on which host to use is a lot tougher. For now I will stick to CrosHost. When we do the full lab integration we may have to adjust this later on.
|renamed to connectivity_class
|good call
|ahh thanks, just updated it.
|Done
|Done
|Done
|Done
|nit period
|why do you need the nested, try's?
|dir_list.insert(0, os.environ['CHROME_ROOT'])
|use for... else and in the else raise the exception it couldn't find the chrome-root.
|I'm a bit confused from what you're trying to do here. But it looks like you're trying to find chrome source tree from either the environment chrome_root, /var/cache/distfiles/target/chrome-src-internal, &amp; /var/cache/distfiles/target/chrome-src.

If thats the case why not just put these 3 elements in a list and loop over them and use the first one that exists? And if none exists then throw the exception.
|use os.path.join to join your chromeroot to the script. and don't do the cd.
|what happens when this fails? I'm just a bit concerned about cd-ing in the middle of a test.
|multi-line this
|should you maybe set this to None if autotest_ext is False?
|Maybe put this eariler in the code.

self._autotest_ext_path = None
if autotest_ext:
  self._autotest_ext_path=os.path....
  extension_paths.append...
|how does this happen?
|raise?
|well sadly their code actually uses some stuff in /build/android (mostly when it probes the dut to see what kind of device telemetry is talking to).

I'm testing a new change to move this call to install_telemetry_dep_resources so we don't break any other deps and we just do this for telemetry only.
|Well this function is copying stuff from Chrome into a Chrome-OS test package. So they would know nothing about what is on the actual device?

The thing I'm trying to fix is the telemetry team has a script that outputs the list of directories it needs from Chrome to run telemetry. One of those directories is {chrome}/src/build/android but seems like theres symlinks to the compilers in {chrome}/src/third_party.... that we don't copy or need for telemetry. Then if you try to install this dep, autotest complains those files aren't there and the current workaround is to delete the symlinks from your build directory.

Is there a better place to put this command to clean up the directory? I can also move it to the end of install_telemetry_dep_resources to limit it to just my use case as well.
|Can you elaborate on this? From my understanding install_test_resources copy up a portion of chrome and tars it up to create a dep. So anything needed for that dep should be in the test_dir.
|do you want the newline on purpose?
|can you align this with document? repeat in the next function.
|hmm maybe password should be a keyword arg set to '' by default
|possible comment that the current correct password is ''
|you shouldn't need '' here.
|Ahh good catch, what should the default be? None?

Your code was trying to run:
perf perf_options='what ever you passed in'

Which would result in perf failing to run.
|Its a bit of a pain and your code looks good to me but to test it https://sites.google.com/a/chromium.org/dev/chromium-os/testing/autotest-design-patterns#TOC-Locally-Testing-a-Wrapped-Telemetry-Test:
|please add a comment here to elaborate.
|in status
|Wouldn't this leave the HQE stuck as STARTING?
|why the check to filter out the ones that are done?
|single quotes
|ditto
|Done
|It does but I'm fine with the current version of the code double checking it just in case we somehow get here from a caller that does not pass in timeout.
|Well then we might as well delete this whole if-statement then, shouldnt we?
|isn't this already set to false by the __init__ now?
|You can start a sentence with Because but i'll reword it anyways.
|getting rid of this method.
|going to keep it as it overloads a method from LoggingConfig. I'll add a doc string to explain.
|Done
|Done
|I prefer 1 file for all the levels but if you guys want we can have it be different file per log level.
|Done - was confused by the BackgroundTaskRunner but figured it out.
|Done - I changed the return format of is_special_task_complete to be a tuple as well now.
|Done
|Because the method is called is_special_task_complete, otherwise this is more of a get_special_task then. I can rename it if thats what you feel like.
|Since this is a big change can you please test via our workflow of setting up a local lab setup?

https://sites.google.com/a/chromium.org/dev/chromium-os/testing/autotest-design-patterns#TOC-Locally-Testing-a-Wrapped-Telemetry-Test:
|are page_sets completely deprecated?
|Tried but the ports aren't changing. Discussed with Fang IRL.
|Done
|please add a todo referencing bug crbug.com/324964 or feel free to solve it here :)
|Also
|we have switched everything to timeout_mins now
|I said this on the last patch but throw all this into a _get_devserver_telemetry_path
|double indent
|just use extend?
|there really should be a bug to track this work.
|might be worth breaking the logic in this if else into 2 methods. setup_local() and setup_devserver()
|docstring?
|put these constants at the top of the file
|just do:
telemetry_args = []
if self._devserver:
  ...
  telemetry_args.extend([ssh...
|double indent
|double indent
|bug #'s with todo's please
|is this is lumpy specific maybe lumpy_profiler_args
|put this on the previous line
|double indent
|+1 what is going on here? I think we need more context... You have sudo rm -rf, which in the lab runs on our actual drones.... This looks to me a non-lab test
|double indent
|It should be the connectivity_class which can be ssh or paramiko.

This whole process will need a rework once we have the RDB because for now if we can't reach the device we just decide its a CrosHost. But if a eureka host  or adb host is down we'll end up using the wrong host object type to try and bring it back up.
|hmmm ya good point, this is the expected logic flow when adb is missing. Nevermind then.
|can we log the error? ditto elsewhere
|do you have a team mailing list you can add here as well?
|double indent
|double indent
|you'll need a space here
|Too short... I dont remember how long parrot took to powerwash but i think it was close to 10 mins (which feels long)
|Ignore this. Powerwash was optimized to use fast wipe so it actually isn't as slow as I remember when it was originally rewritten.
|origin='_repair_full'?

well I guess it could be called by elsewhere but you don't have an easy way to pass in _repair_full below.

I saw your comments on the previous patch but I don't really see the point of the origin value. You still won't see any difference in Stats and you could just add a logging line after Powerwash that says if it succeeded or not before kicking this off.

If the purpose is to collect stats for _install_repair failures after powerwash, you'll still need something else to get this information.


I added a comment on patch set 1 right when you marked it 'Done' ptal.
|Well the stats code will know the failure occurred in _install_repair_with_powerwash as to whether or not it was before or after the powerwash, the current code wouldn't know.

You could add a new stat in this method that says whether or not powerwash_in_repair succeeded or not. So we can track how often powerwashing on a repair failed dut fails or succeeds.
|yup, makes me sad but okay.
|Wrap this with paren's and get rid of the \'s
|should be a double indent but the only other instance of this kind of wrappining the file uses single...
|suite job will exit
|umm why not just use options.no_wait and options.file_bugs?

I know wait is the opposite of no_wait but you can use not. And file_bugs is the same as options.file_bugs
|Then we should change the opt parser to set them as flags?

http://docs.python.org/2.7/library/optparse.html

action=&quot;store_true&quot;
|Done
|Done - should have both.
|Hmm not sure where I got the 4032 from... changing
|do we need this for the cq scheduler as well?
|do you need to redo all 3 lines or just Start?
|why not just
if not num_retries:
  raise
|So this line leaves me feeling not happy... kinda strange to be counting down.

At the very least lets change it to use range(1,-1,-1)

That way it'll be cleaner if we want to increase the number of retries.

OR

But it would nice to count up which you can do with a global MAX_RETRIES variable set and count up until you hit that.
|There should be a TODO with a bug number here
|include an example of what the output line should like as a comment.
|Done
|Done
|Add 318565 here too
|No, but the bug would be enable log collection via logcat for android for adb_host
|thanks for throwing my name here.... lol
|I reallllllly like having 2 lines between methods, its a lot easier to follow and read...
|all the host objects have a check_host method now.

@Beeps can probably explain why its static
|can you create a regular cros_host and make sure that still works. Just to be safe.
|For all of these methods why are we using a string for press_secs? and not an int? I'd prefer press_secs was just defaulted to 0 and we used numbers not strings.

Is this an issue due to xml-rpc-lib?
|sadly hdctools style is different than autotest, look at other files in this folder to see. Namely 2 spaces instead of 4 and 1 line between methods instead of 2.
|alignment
|alignment
|you can just get rid of this init can't you?
|ditto about this init
|Done
|why get rid of the ${MNTS}?
|Done
|Done
|Done
|A method called get_timeout_mins() that returns timeout/60?
|Done
|I'm still pretty new to cbuildbot, where do we take and set this timeout for cbuildbot to kill the process?
|Awesome thanks!
|new line in between
|Please convert all the double quotes to single quotes in the actual code. Thanks
|alignment
|Does this break for the CQ server?
|all args on next line
|log which error occured?
|You are right, the comment is wrong.
|Ahh checking for /proc/device-tree might be a much better solution.

Looking at our Kernel 3.2 beaglebones that directory exists but is empty, while the newer Kernel has stuff in that directory.

How about if I check if its empty or not? I'm familiar enough with Kernel specifics to know if this is a valid assumption or not.
|So the reason for set_muxfile is that some muxes in the sysfs were incorrectly labelled and we supply the info via the servo config files and servo_interfaces. Otherwise we would stick to set_pin_mode.

This flow is similar in bb_uart for one uart that has mislabeled pins in the sysfs so I would like to not change bb_mux_controller too much.

If you want me to make the change still, let me know.
|Done
|indent spacing should be 4 spaces before the raise and 8 before 'target
|wrong indent spacing.
|You still need to delete this line right?
|this ebuild no longer exists. RDEPEND on chromeos-base/openssh-server-init
|shouldn't this file be called chromeos-bsp-beaglebone-servo-0.0.1.ebuild?
|2013?
|sadly yes, does that apply to the ebuilds as well?
|Done
|Done
|Done
|Done
|Done
|Done - title is kinda long now tho.
|Done
|@Gaurav, does it matter? Its just putting that script in that directory correct? I can verify with a normal build as well.
|Done https://chromium-review.googlesource.com/#/c/181403/
|Done
|Done - no period though
|I had this question on a previous patchset but reasking just in case:

Do I need a RDEPEND=&quot;&gt;chromeos-init-0.0.2-r744&quot; here or something to avoid a file collision? Last time I refactored ebuilds around it worked in my chroot and trybot run but failed in the CQ.
|Done
|I have a feeling Jay's follow on work will move shill to its own package (in a couple days) but for the moment can I get a decision on how to proceed?
|It builds either way so I'm willing to do either. Richard, thoughts?
|So I discussed with Richard and because these upstart jobs now depend on shill and they are installed by chromeos-init this does indeed now depend on chromeos-init.
|Richard says this sentence is no longer true in the world of Chrome-OS today and should be removed.
|Done
|Done
|Done
|Done
|no longer a cros_workon package so I kept the symlink
|just fyi I made this no longer a cros_workon package
|Its not a cros workon package. It won't build at 4 only 2.
|Done
|Do I need a RDEPEND=&quot;&gt;chromeos-init-0.0.2-r744&quot; here or something to avoid a file collision? Last time I refactored ebuilds around it worked in my chroot and trybot run but failed in the CQ.
|Done
|removed from here and moved to the chromeos ebuild.
|Done
|repo would not let me upload without this symlink, please let me know if I do not need it.
|Done
|Done
|Done
|Done
|Leave this 2012
|update the metadata.xml file please
|I'm not sure if this is the best ebuild for this code to go in... Vapier thoughts?
|I personally think its slower. If it doesnt work it takes 6 minutes to run as it tries rebooting it 6 times.
|what was your test to make sure its faster to preform a power cycle?
|Done
|repo would not let me upload without this file, let me know if its not needed.
|Done
|Done
|See comment on other CL
|Done
|Done
|So the Autotest ebuilds that currently exist provide the client-side dependencies required by client side tests. I.E. telemetry tests need the telemetry deps installed.

Currently those ebuilds include nothing about what the lab servers require to run Autotest. I.E. these are the server-side dependencies. Hence there are not already in other ebuilds and there is no duplication here. Also why I had to update portage-stable because many of these were not already in our tree.

The goal here is to add the stuff required to run the Autotest server code on a Chromium OS Image rather than run an Autotest test on a Chromium OS Image. Does that make more sense now?
|K that sounds like a good idea. After I have got an image with all these deps working, the next step is for me to add an ebuild to install the autotest-server code.

So for now chromeos-bsp-moblab -&gt; autotest-server-deps

Then once we have the new autotest-server ebuild it'll change to
chromeos-bsp-moblab -&gt; autotest-server -&gt; autotest-server-deps

Sound fair?

I could also do the same thing for the devserver dependencies below as well.
|Done
|Done - i am paid to code not to spell

;)
|For now I'll throw them in with autotest-server-deps.
|Done
|any good place we can refactor this code to so its available to both sources?
|Luis, 1 solution is to move the parse logic into common_lib/site_utils as parse_chrome_version and then have here and in site_sysinfo call the command to get the chrome version and pass the stdout to the parse_chrome_version command.

That way the code is refactored as much as possible.
|I assume if I build with *-release and go to the output directory and then check its not on chromiumos_base_image.tar.xz then I am checking the correct image right?
|Make this a global and I suggest renaming this function _install_sonic_extension, or add optional param extension='sonic_extension' that way the name highlights what its doing exactly.
|update docstring
|alpha order
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Or just call get_board, looks like it does some clean up of the output of /etc/lsb-release
|log it instead?
|I rebased this. So the current -r is -r743 so I set this to be !&lt;=

Please let me know if this is incorrect.
|Done
|should I delete or move this over to the new ebuild or leave as is?
|Done
|Done
|Done - but its 92 characters long now.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|sam_instances?
|K I agree its not human readable, how about a comment above saying to make sure if someone changes either dev_server_hosts or dev_server they must update both lines?
|How about just parsing the dev_server line below and using IP addresses?
|thats fine, I just like to avoid nested if's like that so I refactored out the xbuddy_config.read to the bottom and just used these if's to set the config file. But yes your way has less join's so I'll change it.
|Done
|Did you run this past the telemetry dev's to make sure this will work for profiling?
|from multiprocessing import pool?
|Done
|Done
|curious src_install step of which ebuild?
|So I'm pretty sure I need to do this file rename. However I blew away my /build/stumpy_moblab and ran into an error emerging dev-db/mariadb because it said it couldn't find mariadb/mariadb-5.5.32-r1.ebuild

However after I emerged it with -r1 and then unemerged it, moved from -r1 to -r2, I was successfully able to emerge the -r2 version.

Vapier, thoughts?
|The only changes to this file are here.
|Done
|Well the new location is still a system install just installed via portage in a different location.
|Done
|Its special cased because as the docstring describes 'site-packages is favored'.

If you want me to include it in the loop I guess I can make &quot;gwt_dirs = [site_gwt] + _DEFAULT_GWT_DIRS&quot; and loop over that?
|Done
|Done
|A lot of them are init scripts in chromeos-bsp-moblab in the overlays folder. These currently (for V1) run as root. But even though the daemons run as root we have a bunch of useful scripts we want to be able to run as chronos:

cli/atest for example is a big one. So is run_suite.py. If chronos can't execute or write in these directories (mainly results/logs) we run into all sorts of problems. There's likely other tools I have yet to think about that we might need.
|doins changes the permissions when installing the files. This command was given to me by Vapier, I can try it without the quotes around the !.

We have a number of python and bash scripts scattered in our repo I want to make sure are executable. And the problem is we don't put the extension on all our files:

Big example: server/autoserv has no file extension but is a python script that is kicked off directly.

I'm worried that if I start white-listing stuff, the odds increase of me missing something important.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Hmmm the more I work without 755, the more I think I need it.

I want to be able to execute the python scripts in this directory as shell commands i.e. ./run_suite.py

Is there a better setting than 755?
|Assume you mean 1. Done
|I pulled it from https://github.com/Bapabooiee/bapa_overlay/blob/master/dev-util/google-web-toolkit/google-web-toolkit-2.2.0.ebuild

but I'll throw our license header on it.
|Done
|Done
|Done
|Done
|I can put this pretty much anywhere in the rootfs, this is just what I've been working with. Suggestions?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I kept this in dev-libs, let me know if I should move it.
|Since most these bits are copied/modified from dev-libs/protobuf I was not sure what to do about the license.
|Done
|Done
|Done
|augh my bad. Done
|Done
|Done
|Done
|Done
|The find causes access violations.... wouldn't it be better to not install it to begin with like I was doing before?

Example:
F: unlinkat
S: deny
P: cros_mark_chrome_as_stable_unittest.py
A: /build/stumpy_moblab/usr/lib64/python2.7/site-packages/chromite/scripts/cros_mark_chrome_as_stable_unittest.py
R: /build/stumpy_moblab/usr/lib64/python2.7/site-packages/chromite/scripts/cros_mark_chrome_as_stable_unittest.py
C: find ( -name *.pyc -o -name *unittest.py ) -delete


I also changed the 'cd' to cd &quot;${SYSROOT}$(python_get_sitedir)/chromite&quot;
|Should I just rename the keys in the files/ directory or do the rename here in the ebuild?
|Done
|Done
|Done
|I'm just going to delete the logging.
|Disabled the logging.
|Done
|Done
|Done
|I rebooted and the database and all the data are still there. It could be because a password is set that the command isn't actually working if the database is now up.

If you want I can try to find some command to see if its setup or do what I do below in post-start by trying to log into mysql.
|Done
|Done
|Done
|Done
|Done
|Done
|Utility
|alignment
|My understanding is that its either aligned with the previous argument or all the args are on the new line with 8 space indentation.

&quot;For hanging indentation, use 8 spaces plus all args should be on the new line.&quot;

So in this case theres 2 args.

Rather than bring the entire string down I would say align crbug_crawler under the ' however I no longer see this in the style guide but I assumed that was our style for multiple args....
|alignment
|alignment - i.e. fix everywhere below...
|Done
|Have it say the amount of time it waited please. i.e. no usb ethernet dongle found on eth0 and eth1 within 5 minutes.
|need to convert to tabs, will do next patch.
|Done
|Commented below
|Added this line.
|Added this
|Done
|I needed all 4 of these lines.
|Done
|Reverify that this works please.
|it should look for &quot;moblab&quot; not stumpy_moblab.
|Its running chrome so that if they want they can go to http://localhost and see the results right on the machine. A future (but punted feature) is that moblab will skip OOBE and log right in as guest and go straight to that page.

When the AFE goes live thats also a sign that all the components are initialized.


As for Demo mode, download any ToT image now and let it sit. The UI Team recently add this ~a week ago.
|Please test RPM and POE
|So chromeos1 machines are very slow (40-60 seconds to connect sometimes) and so is chromeos3. Could we maybe do 90 seconds?
|either bring both args down to the next line or align this if possible.
|is this timeout long enough for chromeos1/3?
|Now that we have multiple timeouts please add some more clarity to this message.
|state '
|docstring?
|all args on newline
|are these extra parenthesizes really required?
|get float? also it might be better to refine this to seconds.
|just use double quotes around everything here and get rid of the escape.
|Will do, though the instructions are quite ugly and would make Alex cry. We need to convert the process to involve an init script.
|What happens if shutdown_pending is True and the dispatcher has a new request?
|Hmm we should throw this into another lock to protect it.

I.E. another with statement here.

Thoughts?
|so is the problem with this call right here?
|Did you run the hwtest step on these trybot runs?
|just make this a new line
|Yeah I was thinking we should clean this up somehow.
|Done
|Done
|Done
|I thought sleep is seconds. This is meant to run daily. 24 hours * 60 *60 = 86400
|removed respawn
|Done
|Done
|gs_offloader does not exit and has a built in sleep as it loops over the results directory.
|removed
|removed
|gs_offloader does not exit and has a built in sleep as it loops over the results directory.
|Ben Chan said the best thing to do here was wait for the mount directory to exist.
|Done
|Done
|Done
|crbug.com/351510
|Yes this user needs a real home directory (stores ssh keys, boto file). Init Job in chromeos-bsp-moblab creates and chowns it should it get wiped.
https://chromium-review.googlesource.com/#/c/189523/7/overlay-variant-stumpy-moblab/chromeos-base/chromeos-bsp-moblab/files/init/moblab-homedir-init.conf
|I am creating the moblab user in chromeos-bsp-moblab which depends on this ebuild.

I'm halfway tempted for good software engineering practices to move this file to that ebuild's files directory. Or I can leave it here.

Please let me know your thoughts.
|So this is the only thing outside bsp that requires the moblab user.

For the moment I'd like to commit this as is (due to immediate time constraints) and clean it up by moving this file back to the bsp OR adding new chowns to run after this in the bsp.
|Theres a bug listing the outage point to it here please.
|We have a bug right? Can you point to it here.
|lets move this to global_config please.
|OFFLOAD_TIMEOUT_SECS?
|REPORT_INTERVAL_SECS?
|is the \ necessary?
|Hmm can't you test by setting your email in the shadow_config, removing your .boto file (so gsutil cp fails), run locally and seeing what your emails look like?

That way you can do a full integration test and ensure it doesn't send emails unless the time limit expires.

And if you want to make sure offloading still works, create a test bucket and point to there?
|Please put an example of what this should look like, either here or down below where you use it.
|Looks like you got rid of all the rsync code. please update the doc string.
|remove rsync
|add a comment about what this file is and how its related to gs_offloader.
|_SECS?
|this function doesn't really offload it queues it for offloading.
|queue for processing by the designated offload function/thread.
|why the &quot;self._offload_count &gt; 0 and&quot;? shouldn't it be completed if the path does not exist?
|No more than 80 characters per line, break the comment into multiple lines.
|Above each of these lines:

# TODO (jimishs) - crbug.com/354547 Uncomment the suite line below once the test can be properly ran in the lab.
|As long as you can kick this test off against a Chrome OS device via telemetry, you should be good. The telemetry_benchmarks test essentially pipes kicking off the benchmarks through our infrastructure.
|Done
|Done
|Done
|Wrapped it in a try/except catching IOError.
|Done
|You don't need to, I verified that if I create a job right after a fresh install I can create jobs in the afe etc and it works fine. And i checked the database and it created the user. Seems like the AFE handles this step.
|good point, trying that.
|fair enough.
|hmm yeah here is not the user name, which could change say if we decide to use a different user to run the services. This is more tied to the board name. For now I am going to leave this as is unless I search for moblab boards elsewhere in the code later.
|For example pool gets passed to create_job_page_handler. Create_job doesn't need/won't need it but create_suite_job will consume it.

The alternative is I list every possible arg in create_job_page_handler and only pass the ones required to either create_suite_job or create_job. But that needlessly blows up the definition/docstring of create_job_page_handler. This way I can take in **kwargs and just pass them along.
|Done
|Nevermind, we can't delete it because we require an apache interface from which to get to rpc_utils.create_job_common.
|K I switched it to this flow, but create_job is pretty empty now...

Thoughts on deleting it completely?
|Done
|I ran the suite_scheduler unittests not sure how to test the suite_scheduler end to end. and added a new unittest for this.
|I'll change is to return the result then.
|Done
|Regardless we need to still need to stage the artifacts, so I'll move that logic into a helper to keep things cleaner.
|Done
|True. I shall add anchoring then!
|if you do the double indent, all the args go on the next line.
|Done
|I'm just going to stick with chromium:362776 as the TODO bug.
|Done
|Done
|We have a testing plan for Moblab which is to get automated testing running on it which would do a complete suite run (including DUT reimaging). If we have this test run with the latest &quot;good&quot; image then we can establish we have (or access to) the required  artifacts for running tests with Moblab.
|I always forget, but this is a -9999 ebuild and I am only editting a file in the FILES_DIR. Do I need to do anything to the ebuild/reving?
|Yeah :/, let me make this vm_test_results_* and see what happens
|So the whole rest of this function is exactly the same as in host_create.execute(). Correct me if I'm wrong though...

Refactor to its own method and have both functions call that.
|@return?
|@return? What happens if you don't go into the if? Should there be a default return value?

If so do:

if not label_names:
  return default
Rest of your code here.
|Should be a double indent, i.e. 8 spaces.
|get rid of this newline.
|Can't this just be the __init__ with a super call at the start?

Try it and respond here if that doesn't work (the site class logic can be weird sometimes).
|Double indent, i.e. 8 spaces
|We generally keep the first sentence in 1 line description then a long description following.
|Return
|'that renders'

The wording is confusing, what do you mean by 'the labels filed in a comma....' the 'filed' word doesn't make sense.

I think you want: 'A widget that renders the labels in a comman separated text field.'

Note you misspelled seperated.
|should value not be plural? You seem to use it as a list.

A docstring would be good here.
|except what?
|docstring please
|double indent.
|double indent.
|only 1 newline.
|Can you fit this all on 1 line?
|No whitespace at the end of lines. Still run the pylint checks before uploading. Only use --no-verify if the only issue if something unrelated.
|Captiol F and a period.

s/parse/parsing from the command line.
|Put these all in sentence format.

s/specify/specifying.

Explain why the web_server is used looking below you create self.afe but why do you need that?
|as strings.
|Captiol s and period.
|you don't need this check, platform defaults to None.
|alpha order.
|no new line.
|alpha order, i.e. autotest_lib.cli goes before autotest_lib.frontend
|nit period.
|clean up comments. Capital Override and period. do everywhere.
|needed is misspelled. I think submitted info might sound better too.
|delete spaces. No spaces at the end of a line.
|extra space.
|Don't blanket catch, specify the Exception you're looking for.
|extra space.
|align with request. Don't use \, just end it with ' and python will auto-concat the 2 strings.
|Can we move this function and changes to site_host? We prefer to edit site_* files rather than the base file.
|from autotest_lib.cli import site_host
|Change this flow:

If not form.cleaned_data['labels_autodetection']:
  return super(.....

Then rest of the code here.
|site_host.site_host_create
|So this flow seems off to me as you're creating the object then passing in all its attributes after. Maybe add to site_host a constructor that takes in these values and calls the super constructor after.

And then just never call the parse method.
|sucess = None
try:

then remove the following 2 success=None
|Should be:
BUG=\n
TEST=\n
no new line in between.
|What is host_info.platform if it was unable to retrieve it? None?

If none then why not just make this an else and remove the else clause below?
|Add a comment about why you are checking that platform is not in labels.
|Are we no longer worried about duplicates like you were before?
|nit period.
|# Check platform is not None and that platform is not in labels to avoid duplicates.

Wrap around 80 chars though.
Essentially capital the first letter and period at the end of your comment.
|Moved it to be staged in preform_reimage_and run like you suggested.

However I decided against resolving the devserver again as its injected into the control file that you see in the AFE. Otherwise it will be misleading if the AFE shows a devserver URL that is different than the one we ended up using.
|Can we put the 30 in a constant called process_timeout_buffer or something then?
|some spaces around the %
|Umm what if I do:
s/artifact_path/args

Is that clearer?
|Done
|Done
|Revised kwargs.
|Well not true. If args requests local its still build_id/artifact. I'll expand this out though.
|Done
|Done
|Done
|Done
|Done
|Done - thanks!
|Done
|Done
|Done
|I'll pipe it into LookupChannel as well then.
|Done
|Done
|Done
|Done
|Done
|Done
|I posted on the bug, can you ask the hydra if it has this rpm?
|Why do we need the row check if it doesn't matter?

It's all based off of racks right?
|since self is not yet instantiated completely would it be better to pull get_hydra_name out of the class rather than make it a static method?
|Done
|Correction not remove, set image = self.translate(image)
|Done
|Done
|You mean get the match in the caller, if so call translate here, redo the regex and now if it fails return an error?
|Going with Alex's suggestion.
|Done and good idea, that essentially means no changes to this file :). Though some callers will still need to know, i.e. dynamic suites.
|no point adding this newline if you're not changing the file.
|To clarify and explain this:

First we import regular python modules.

Then we import common which allows us to import the autotest modules. It may be worth looking at common.py to understand how it works. Theres copies of it in all our directories.

Then we import our autotest modules.
|Yeah that check_lab_status starts with:
test_server_name = global_config.global_config.get_config_value(
              'SERVER', 'hostname')
    if not test_server_name.startswith('cautotest'):
        return

Maybe pull that into its only utils function and use that.
|Maybe just check if server starts with cautotest? We have a utils function that does that already right for the lab check?
|No, they just say 'sudo servod' as normal.
|Sorry slipped my memory and was just doing these for convenience. Will just remove them.
|Done
|This syntax looks wrong to me... Isn't this all commented out?
|Child Jobs:

Also what does it look like if there are no child jobs? i.e. the sub-job's page?
|Hmm I kind of feel we should but the Childs Job table below the Hosts table.

Thoughts? Or could you generate a screenshot of that so we can compare?
|incompleteCountFiled? should it be incompleteCountField?
|What is the user experience like for the Create Job page? Or if I am looking/searching for a host via its labels on the Hosts Page?

If I am filling out a form does it interfere with the experience? Or is it in the background?
|Is autorefreshTimer not null right now?
|Sounds like a race condition. Can you add autorefresh != null to the if statement.
|I feel this may go unused if its it is default unchecked? How is the experience if we leave it checked?
|spelling: separate

I would said: Separate multiple args with commas.
|You made these changes for your old approach right? If so get rid of these changes for now then.
|anyway to retrieve this from the shadow/global config?
|should be spaces?
|no newline.
|move the &amp;&amp; up here and align testType and testName
|align this please.
|I think for readability's sake you should align the HasText and HasKeyPressHandlers.

Make that change please and then we can submit this.
|The log links still work as intended right?
|Why do we need factory_install?
|Wouldn't this mean we would get chrome bugs that the pfq may have protected us from? I.E. this version of chrome has yet to rev for Chrome-OS.
|No one will know their Host's ID, lets not break this functionality...
|Can we somehow have this take hostname, translate that to id then fetch the jobs?
|I'll put up a different CL for that.
|Done
|Will do.

My only concern is that while we are the only user of this ebuild currently, we're putting settings we care for Moblab in this my.cnf for any Chrome-OS image that requires MariaDB.

This is the second such change https://chromium-review.googlesource.com/#/c/202318/ being the first. Do we care that we are making this file tailored for Moblab? Or should we be throwing a copy of this ebuild into the overlay?

But like I said we're the only users that care so for now it might not matter.
|alignment.
|align set with set?
|the EAPI=&quot;3&quot; sorry I posted this comment 1 line off.
|repo upload complained about this but its from gentoo so I did --no-verify.
|can you elaborate what is happening here? or add a comment.
|alignment
|does this work if i abort jobs and special tasks at the same time?
|why no follow the same convention as the previous if?
|what does this result in? should it not reset page?
|with a parent job.
|with no child or parent jobs?
|A test to catch the assertionerror.
|add some tests to catch the failure cases associated with extra_job_type_filters having more than 1 filter true.
|no need to add this new line.
|alignment.
|did you write this file or find it somewhere?
|did you test running gsutil on a moblab build as well?
|wmatrix_url
|no need for this.
|put http:// in the config?
|need this white space?
|we want this in the prod shadow_config on the servers not the global config of everyone's checkout.

https://sites.google.com/a/google.com/chromeos/for-team-members/lab/autotest-server-admin#TOC-Making-Changes-to-the-shadow_config.ini
|my only issue here is some of these suites looks like they need to know if they're in dev or normal mode.

It's as if this is really 3 suites:
faft_lv2_normal
faft_lv2_dev
faft_lv2 (complete)

Not sure what the right answer is here.
|the tests have the necessary SUITE=&quot;faft_lv1&quot; in their control file right?
|this should be a comment in the code.
|should this not be in the tooltip change?
|Did you build a moblab image and test it?
|if not servo_args
|get_servo_host_attribute
|follow proper docstring format.

@returns ....
|no new line.
|move constants to top of file
|={}

whatever checks servo_args should be fine.

if you do if an empty dict that counts as false.
|delete.
|use spaces not tabs.
|no \'s in autotest code.
|send directly to create_servo_host, it'll be cleaner that way.
|alignment is all wrong here....

either align with the 'd' or move all args to new line and double indent.
|change this to take in servo_host and servo_port and in the higher level pipe those values in correctly.

Then edit the bottom below to act accordingly if servo_host is not None
|You need 2 new lines here.
|Create*
|drop more.
|align the quotes and move the + to the above line.
|ditto.
|align this better, plus above and the &quot;s aligned.
|Where do you suggest? /usr/local?
|Done
|move this to create_job_page_handler. That is what the web interface hits.
|what is the behavior is I try to create a job without selecting a control file?
|did you try creating a job without selecting the control file?
|If I select image and hostless your check is skipped.
|thats if the suite_name is passed in (via run_suite) but via the afe it requires the control file to know which suite to run.
|move to the top of this function.
|2 newlines.
|Does this work if start_time and end_time is None?
|alignment
|double indent.
|double indent
|this code looks identical to what you added above, refactor it to a helper method.
|maybe have your rpc_utils function take in the base filter and call the copy in there.
|We don't allow \ in our python code. Try parentheses?
|ditto
|rename this cause you're injecting into filters

inject_times_to_filters
|can you take &quot;rpc.utils. to the next line?
|ditto
|you can make both these function names shorter if you just say inject_times_to....
|Done
|Done
|O I thought we said its best for me to put it back the way it was before I deleted it?

I can go either way.
|Done
|Done
|Yeah its looks like its not bringing in the devserver ebuild in at all anymore :(....
|Gaurav, did I do this right?

http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/stumpy_moblab-release/builds/24/steps/Archive/logs/stdio

It failed as it could not find /usr/lib/devserver/strip_package.py
|So I put this back as I removed it in https://chromium-review.googlesource.com/#/c/184976/12/chromeos-base/cros-devutils/cros-devutils-9999.ebuild
|Done
|Done
|I thought I needed this change when working but I really don't it seems like.
|undoing changes to this file.
|Done - Refactored it out to Moblab Host.
|Ehh I could but the prompt specifically says if you push submit it will reboot. So the reboot is expected when hitting this rpc.
|That's going to take a bit of work to get that right and I wanted to do it in a future CL. So I'll file a bug and add a TODO Here.
|Done.
|No it works as expected.
wb+ = &quot;Truncate to zero length or create file for update.&quot;
|Done
|Done
|Done
|switching to error.TestError. There was none for args, Wiley suggested this one.
|I see I mistakenly wrapped &quot;HOME&quot; with quotes but the only other instance i see it is below in the sed command which has a single quote in it.

I can just escape those single quotes though.
|Done
|Done
|Done
|This is the host class and not running on the Moblab... So it needs to ssh in and run the command, how would I call shutil.rmtree here?
|Done
|Done
|Done
|I believe afe is only for java changes that need to be compiled.
|2014?
|Its moblab specific for the most part.

192.168.231.* is the testing subnet.

Saying .255 on a subnet is the Broadcast address. I don't think this will be used in any other cases, for moblab or outside in the rest of autotest.
|I needed to add a whitespace change so this CL will take effect. Any workaround to this?
|Done
|Done
|add space before '
|this would be cleaner as a factory method or constructor in utils to return the PowerUnitInfo given a device_hostname &amp; host object.
|separate
|should this inherit from RPMInfrastructureException?
|I wrapped or It wraps?
|@params?
|use logging?
|@params?
|I would do an os.path.exists check prior to trying to open the file.
|Move POWERUNIT_KEYS to new line and double indent.
|no check that there is 1 arg only? If you use argsparser we could get --help info too.
|NIT: reverse the order of these lines so it matches the parameter order of the function.
|2 newlines
|Wouldn't this throw away the most recently used data? I thought LRU wants to throw away the least recently used item.
|receive
|separate
|Just realized these 2 sections is exactly the same. Do we ever expect hydra's to have different credentials? Might be works having 1 [hydra_credentials] section.
|double indent
|+1
|Fair enough.
|why not just add outlet as an arg and have that extracted from powerunit_info when calling this method. It would be cleaner and easier to understand that way.
|Done
|I updated it to grab non-aborted hqe's and if there are none use the created_on time like before.
|Done
|Done
|Done
|Done
|Done
|Done
|O whoops, you're right Fang. I had mixed it up when fixing the unit tests and assumed we wanted the earlier one.
|My problem with that solution is we have stumpy_moblab. Soon like within a month we'll have panther_moblab. We're moving to a target system so any {board}_moblab is possible.
|So theres several other tests that also have similar baseline issues. I filed crbug.com/406013 so that we can discuss offloading the baseline files to the overlay there if that becomes the solution we want to go with.
|So what I wanted to do originally was make it so different boards can specify their baseline with different files. But then that seemed bad cause right now is stumpy_moblab, soon there will be a panther_moblab and potentially {anything}_moblab so that didn't seem like a good long term approach either. Unless I did it so it was like base.*_moblab but still that seemed ugly.

Yeah I'm perfectly fine doing the USE flag approach if you think that will be a much more scalable approach.

So for now we would need to do:
!moblab? (
  +tests_security_Firewall
)

And should something else not need this test as well it would be come:
!moblab? (
  !new_feature?(
     +tests_security_Firewall
  )
)
correct?
|Well the other CL fixes this bug.

I wasn't sure if we want to do a revert then rebase that CL and submit that.

Or not do this revert and just submit that.

Thoughts?
|Done
|Done
|Ha Dan, good point.
|Done
|Done
|Done
|I cleaned it up but just a loop around self.run('pgrep....')

I don't think I want to catch AutoservSSHTimeout as that implies something went wrong talking to the Moblab, not an issue with the process not running.
|code removed.
|Good point, I changed it to be:
while self.afe.run('get_special_tasks', is_complete=False):
            time.sleep(5)
|To grab their status following the verify (and possible repair) job(s), this does a fresh DB query.
|Good call, simplified it for the good case and kept some logging for the bad case.
|Good catch.
|Done
|Added one to the loop constraints. No error will be raised it will just go on to check the hosts status.
|script
|Is there not a way to make parser require this arg?
|Not seeing anything similar. There is the opposite, a format string.

I made this one based off of VERSION_RE in devserver_constants, I'll have mine be made off that one and put in devserver_constants, should someone else need something similar in the future.
|Done
|Done
|Kk let me explain this:
* Moblab has server code installed in /usr/local/autotest.
* Autotest normally installs client/ code in /usr/local/autotest on normal DUTs but on Moblab installs in /usr/local/autodir.
* The old code here deleted ['/usr/local/autotest', '/usr/local/autodir'] always. Therefore on Moblab, it breaks the running scheduler and etc processes.
* We want it here to delete only the correct installed autotest client directory, therefore the autotest.Autotest.get_installed_autodir will find this directory out of the list of ['/usr/local/autotest', '/usr/local/autodir'].
* Therefore on Moblab only /usr/local/autodir is deleted not /usr/local/autotest
|Done
|Done
|Hmm yes apache is running. I could move this to a new process and have apache depend on that instead.

Currently the mounting process is handled by moblab-devserver-init. I think I'll move all the code related to the external storage to its own init script and have anything that depends on it to wait till that job is done. Thoughts?
|Agree with Richard.
|Done
|Well the devserver-init would not be started if it failed to mount /mnt/moblab.

I also think the pre-start would fail if any of these commands don't exit 0. Richard, is that right?
|special
|I'm not sure how Decorators work in regards to nested functions... this happened when rebasing against Jakob's change.
|Done.
|Done, I did a double indent on 'CROS' let me know what you think about how it looks now.
|Done
|let me know if there is a better way to get this information.
|Switched to mac address
|Discussed in real life, sticking with nested function in order to avoid recalculating the gs_uri on each offload.
|Ran locally uploading to gs://sbasi-test bucket
|switched to mac.
|Done - added test.
|Done
|Done
|Done
|Done
|Done
|Done
|Filed crbug.com/415384
|Ahh yes if we did database cleaning on Moblab (not yet enabled), that would likely either break gs_offloader or the result folder would never be removed.

Sounds like a bug we should file to be fixed in gs_offloader.
|moblab-scheduler-init:

start on (stopped moblab-apache-init and
          stopped moblab-external-storage-init RESULT=ok)
|For more context:

Moblab is a server we give to our Partners (like Intel/Dell/etc) that runs the Autotest server.

So a Partner takes this server puts it on their corp network, and use other machines on their network to access the web interface. So will their non corp.google.com machines be able to still access the web interface?
|Whats the purpose behind this change?

I'm worried it will break the AFE running on Moblabs not on our corp network.
|Done
|Done
|Done
|Done
|I'm fine with that approach. Just wanted to protect against powerwashes.
|s/Either/If
|I restricted this to results just in case there's a use case I don't know about.
|Done
|Done
|should this not be aligned with the above line?
|Please test that Moblab functionality still works.
|Why the -*?
|independently
|kk it just looks weird on chromium-review but could be the new interface.
|can you wrap this line?
|Can you do me a favor and disable security_StatefulPermissions as well? Since you're moving this anyways.
|1) Why are we doing the blocker here on the old name?
2) The old name is misspelled...
|Alternatively I could have it set options.delete_only true if not GS_OFFLOADING_ENABLED.

Originally I was thinking of having 4 instances of gs_offloader running, 2 for jobs and 2 for hosts, where delete_only has 1 extra day to run in case offloading failed, but now I think sticking to 2 might be best and do delete_only if offloading is not on.
|Richard, is there any good way to add a unittest for the main() stuff?
|I thought we agreed to put this in project-moblab?
|2014 no (c)
|is this bug right?
|hmm yes Moblab is a cros system and a drone... /usr/local/autotest/server/autoserv would exist on both a Moblab running tests and a Moblab dut as well.

So in this situation you'll get the screenshot of the Moblab server as well but we are looking at removing Chrome and X so that would also be a problem :/...

I think you need may need a different solution here to detect if you are running in the server vs the client.
|chromeos-test@destiny5:~$ pgrep -o ^autoserv
20150

Autoserv is running on the drones too....
|ahh you're right.
|4 minutes.... I'm going to update the bug with some changes to my approach so we don't have to take this hit.
|I want to reuse them for when I go back to this CL:
https://chromium-review.googlesource.com/#/c/221329/2/cbuildbot/commands.py

I could refactor them to reduce the duplicity here but then you reintroduce the duplicity when its called the same way in multiple places.
|This is the old autotest.tar ball creation.

I decided to just remove it completely.
|As I said in on a different comment I am planning to use these methods for:
https://chromium-review.googlesource.com/#/c/221329/

Hence why I refactored it out. That way I can say here is my build_root, cwd, tempdir give me the tarball I need.
|I tested it, it actually grew bigger 435-&gt;437MB's. Sosa says its cause this tarball is a bunch of already compressed tarballs so all you're doing by compressing it again is adding more metadata.
|We were not compressing the original autotest.tar tarball, I assume this was meant for speed more than anything. So I kept the same arguments we used for the original.

Not compressing control_files.tar should be fine as it is pretty small anyways. As for compressing packages:

Pro: Smaller builder artifact, quicker to pull down from Google Storage.

Con: More time to extract.

I can do a trybot runs with both compressed or not and time that staging of the artifact locally to try to weigh the pro and con against each other.
|Done
|Done
|Done
|I don't actually think we need this, just changing it to be consistent.

Leaving as is.
|Will do. I don't think we can even really plug (you mean remove?) this code though. Otherwise we will forever break old builds from being compatible with our system.
|Done
|Done
|Done
|AU tests only stage 'test_image'.

Where is paygen used in autotest? Don does not think the paygen process requires it.

I grepped through all the stage_artifacts callers so we should be good.
|uhh how about just using host.get_board()? It comes from /etc/lsb-release however.

Take a look at server/host/cros_host.py
|_get_temp_path singular?
|path?
|something like?

This method should always return the same thing for a given input.
|Look at my comment below. I was confused as to what this was returning. Just return a normal path here.
|This is not very readable. Like I had to go up to the method to figure out what is element 1. Just have get_temp_paths return the full path rather than a tuple and use os.path to get the filename.
|2 new lines between description and the first method. Same for other classes.
|make Mario a constant, also the capitalization should probably be removed. Just use lower_case on board.
|make this tuple a constant.
|Can you file bugs if you haven't for all of these and reference the bug numbers below.
|So this method is close to 80 lines long. Generally we like to stick around a max of ~30.

Just to make this more readable I suggest breaking it into a few methods. Easy ways to do this is have a create/initialize method that returns the tools initialized.

Take the massive for loop's internals and make it a method that you pass a tool to to test it.

And optionally the in try/except in the finally for loop could be its own method but I'll leave that to you to decide.
|I would throw this at the top of the file.
|2 newlines
|2 new lines
|Move all these classes out of the test class. Or probably better put them in a module somewhere in server/cros/ and import the module.
|class(object):
|Why not /tmp?
|2 new lines
|2 new lines between methods.
|Raise an exception indicating it is not yet implemented, ditto elsewhere.
|Instead have this return self._name that each subclass will set in initialization.
|newline between @param and @return. Ditto everywhere.
|align with the previous lines '
|I feel like this would be better as keyword args. Or atleast save=, cause as I was reading your callers below I wasn't sure what the boolean True/False was doing.
|Why this strange format? Just path in the path of paths and save yourself from having to parse/put it back together.
|No Disable?
|You should check for this and raise your own Exception.
|I would just use full paths, I know its a bit repetitive but the current format is unique to just this test.
|can we make enable raise a specific exception that we can specifically catch here?
|These are more debugging statements IMO.
|Now that I'm down here why not just replace the name() method with:
def __str__(self):

and then you don't have to go .name()
|Just go with disabling.
|disable
|Your cleanup doesn't seem to do anything for any tool?
|Put these on separate lines and import common before from autotest_lib
|put import common between import logging and from autotest_lib...
|Alpha order.
|Is debugd going to work on every board? Or will some boards have -debugd in their overlays.
|a or the server database?
|This whole sentence is confusing and I am lost as to what is going on.....

From what I can guess:

These functions only update the database records, {and, for, but}? there is no logic to determine how to add and/or delete a server or its {how}? its role with impact the Autotest instance.

Even with those guesses I'm lost.....
|with {a} given...

Ditto for all the other functions.
|repair_required might be clearer.
|Just a shot in the dark but what about a Django Model class? Similar to Hosts
|Or say look at _ROLE_LIST above
|I feel like there should be already a class or code that does most of these things already?

Inserting into a database, updating, selecting, deleting is all pretty standard.

Also non of this has to do with the Server table. It should be in its own module somewhere.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|modules
|Is it? Most these files look owned by mobbuild after the checkout.

I'll remove the -R anyways.
|Done
|AssertionError: Expected to find call(['cros_sdk']) in any of:
call(['/tmp/chromite.test3P33xt/buildroot/chromite/bin/cros_sdk', '--buildbot-log-version', '--create', '--replace'], extra_env={}, cwd='/tmp/chromite.test3P33xt/buildroot')
call(['sudo', '--', 'rm', '--', '/tmp/chromite.test3P33xt/buildroot/chroot/etc/shared_user_passwd.txt'], redirect_stderr=True, print_cmd=False)



So I tried to update the reference in the unittest to be os.path.join(constants.CHROMITE_BUILD_DIR, 'cros_sdk') but looks like the chromite path is auto-generated:
AssertionError: Expected to find call(['/mnt/host/source/chromite/bin/cros_sdk']) in any of:
call(['/tmp/chromite.test3P33xt/buildroot/chromite/bin/cros_sdk', '--buildbot-log-version', '--create', '--replace'], extra_env={}, cwd='/tmp/chromite.test3P33xt/buildroot')
call(['sudo', '--', 'rm', '--', '/tmp/chromite.test3P33xt/buildroot/chroot/etc/shared_user_passwd.txt'], redirect_stderr=True, print_cmd=False)
|Ping Mike.

Should I go with the basename suggestion or move this check elsewhere?
|Augh yeah I don't know what happened here....
|Yes and No.

The chroot is correctly created but then other callers like the Uprev stage fails.

I could find all the relevant callers and update them to be correct. WDYT? Or go with my path hack in PS2.
|Done
|No it should work. You need to also patch in the ebuild change as well.

When you run the dynamic suite it will find the control files packaged by the build artifacts.
|Make a trybot image with this change, then test that image on your moblab with these changes as well.
|Does this suite exist?
|Should we remove this?
|Maybe a go link?
|s/rout/route

I would remove the word several
|frontend 1 word.
|adds anouther route for all calls to the server database, `server`.
|Current if that was what you were going for. currect is not a word.
|I don't really get the point of this method if its just wrapping around config.get_config_value?
|This looks wrong.

Where is @param getter?
|I've been noticing people dropping the (c), vapier makes me get rid of it now when I write new files.
|double indent.
|Capitol P.
|hostname
|I was confused by this:

`server` topic can only manipulate 1 server at a time. Use -h....
|Capitol E. repeat on all docstrings.
|BUG?
|new line. repeat everwhere.
|weird alignment.
|Wouldn't this fail because hostname_required=True is the default?
|No need for parens.
|I am confused by the &quot;supports queries like all&quot;?
|Action or A action
|Can you use 430976?
|Could we try to fix it here instead?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done - let me know if this matches.
|Done
|Done
|+1,

I was actually gonna ask in the last CL why you weren't using classes but I didn't want to force you to do a big refactor. But now I am inclined to agree with Fang.
|Hmm thats a good idea and forever prevents many copies of these logs from growing too big overtime.
|Cause this file's spacing makes no sense -_-.

The normal indent is 2 spaces so I made this a double indent instead of a quadruple indent.

The if above uses 2 spaces, the if below uses 4...
|Done
|Done
|Done
|Done
|Done
|K so if I follow all your comments, the code works as is - Yay!

BUT if I try to use this new API:
File &quot;/home/mobbuild/buildtools/chromite/cbuildbot/stages/sync_stages.py&quot;, line 242, in BootstrapStage
    @osutils.TempDirDecorator(base_dir='/home/mobbuild/lumpy-paladin')
TypeError: TempDirDecorator() takes at least 1 argument (1 given)


Boo :(

This require us adding another wrapper layer to the decorators to support passing in the arg. I'd have to update all the callers but they're mostly all in unittests.

I'm going to follow that path for now unless someone objects?
|Done
|Done
|Done
|Done
|:/

I was about to comment until you posted this comment. Having 2 formats feels bad to me... but then your explanation makes sense on why we want that support.

But I think longterm this may be confusing to have 2 formats in the database.

Will the zako_freon DUTs be used for regular zako testing as well? The answer could be you get no DUTs in the lab till you have 1 good build.
|Then lets just stick to the Rx-yyyy.0.0 format for everything?
|new line
|proceeding.
|@returns?
|@returns?
|I don't understand this comment or see its necessity.
|I don't understand why we want a tuple? I just told you the board I need a stable_version for, do I care if its the Default value or not?

I think you should just return the version, the callers would look cleaner too that way.
|Returns the global_config value
|afe_stable_versions
|Move this up in the commit message. You have an example above it right now.
|Maybe say &quot;User did not confirm. Aborting...&quot;
|You keep repeating this basic flow:
if self.prompt_confirmation(message):
  return do_something
print 'aborting'

Maybe make it a decorator instead?
|How about we don't make board an optional argument and require it to be set here.

Any callers that want all stable versions should use get_all_stable_versions()
|Get rid of the ability to get all and just return a string.
|The whole '[1]' makes me feel this API is not very clear...
|No we still need it. To support older builds and branches should we ever need to reimage or try a test on one.
|Done
|Done
|Added that flow.
|Done
|Done
|Done
|Done
|Followed your comments below.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This actually is not necessary. The reason I did it in &quot;canocialize_local_path&quot; was to make sure its a subdir of the static directory and not anywhere on the filesystem.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think that would involve an ugly:
sys.path.insert(0, os.path.abspath('%s/../../chromite' % os.path.dirname(__file__))) before the imports.
|remove #
|Can we keep it as a list rather than joining but ',' then splitting it by ','?
|I guess I could do it there but sync_chrome has no knowledge of the build_root. I could do os.path.join(__file__, '..', 'chromium', 'tools', 'depot_tools', 'gclient') but if sync_chrome moves this breaks.
|Got it. Yeah lets just error out to be on the safe side then.
|I guess you're right. But I have no idea why the user would want to run all these commands with gclient set to '', it would just error out terribly. Doesn't seem like  a usecase we should support and on the plus side now the script would run should someone mess up like that.
|Silly me. Possibly something we want our linter to catch :)
|Right suite jobs require an Image.

Regular tests its optional.
|get rid of the trailing S
|Nice, can you do something similar when they hit submit job.

Namely when they submit and don't specify an image to use, alert the user so they can correct it.
|+1 to the --all-boards flag.
|I feel like we should just call this sequence.py not sequence_helper.
|Hey Gwendal please take a look at line 136 of the CODING_SYTLE File and update all these docstrings please.
|Class so name this SequenceJob
|Don't put Arguments on the first line. also @params
|Indent these.
|test
|Returns:
|Get the child job timeout in minutes.
|Maybe save the default as a constant above.
|Please use sing quotes whereever possible.
|Alignment
|delete newline.
|SERVER_SEQUENCES
|80 chars max.
|DEPLOY=afe
|Hmm k I think cause we are only staging the control files this is fine.
|Shouldn't you translate prior to resolving?
|This all looks a lot cleaner now, thanks for fixing this up :)
|_parse_controlfile_attributes might be a better name.
|why do you need 2 strings per attribute? just use the first element and lowercase it when you use it as the test_dict key.
|this is really confusing...
|Why use named groups if you don't fetch by the name?
|period.
|Shouldn't the translate be above the resolve?
|Include e in your error message.
|use os.path for these types of operations.
|os.path.splitext
|':'.join
|change to match the button text.

FetchImageTestsButton.

Also update the tag.
|rename.
|update to fetch.
|Do we always know this is the active interface? Or odds are it is?
|units? seconds/minutes?
|Single quotes in autotest.

Use `with open(....) as link_file:
|why not `reboot`?
|capitalize Clean
|Is this a new file?

If so no (c).

2015
|is builds.values()[0] supposed to default to the cros-version build? I feel like this default should be done a bit differently/cleaner OR error out if there is no providsion.CROS_VERSION_PREFIX key in builds.
|Do we still need this argument? You have builds below and test_source_build as well.

I get why we need it in dynamic_suite for backwards compatibility but we should get rid of it here.
|space after =
|same thing I said in a different comment, do we expect provision.CROS_VERSION_PREFIX to be missing ever?
|ditto.
|Please attach a bug #
|Get rid of the else and shift the next line left.
|Wait I thought my tests come from the ssp_build?? This should be consistent across client, server and suites.

Otherwise as a user I am going to be confused to as where my tests are coming from.
|This is a bit confusing... Can it be a value that is not --build or --firmware_build? Is this the build that client side tests come from? Say if I set it to the same setting as --firmware_build, could my client and server tests come from different locations?

Maybe make this a flag instead to specify test from firmware build and the default is to test from the --build?
|Feel free to use arg_dict now.
|Just update this control file to use arg_dict. Charlene can give you more information.
|typo.
|Generally add a unit to constants like these. I am assuming these are seconds so RPC_RETRY_SECS if they are minutes RPC_RETRY_MINS, amount can be dropped.
|align this under the A
|Stop using + to concatenate your strings.
|Generally TODOs go in the code not the docstring. I would put these types of TODOs right above the function declaration.
|Why this empty line?
|I would just make this a 1 liner.
|add an optional arg host and port and set those to localhost and 9999 respectively and use them here.
|kwargs?

Return?
|Add a comment describing what is happening here and an example.
|To hammer in this point: No \ in code. EVER.

Use parens.

Alsoe just make this string a constant and throw it at the top of the file (URLLIB_CALL_FORMAT_STR)
|make the 5/2 constants at the top of the file.
|I am assuming these are all dummy placeholders for now. File bug(s) and leave todos to flesh them all out properly.
|NO \
|Add a parser and allow the caller to set the port.
|Should these all be made top level constants?
FREON_SUFFIX
X86_PREFIX
BOARD_PLATFORM_MAP
|Do a trybot run too to verify this fixes the builder.
|Delete (c)
|This is a HUGE function, can we break it up?
|no space. use % to pipe in args, repeat on all raise error lines.
|Please use single quotes whereever possible.
|no space
|no space.
|Can these be instance variables?
|Is this supposed to return an int or a double? If double maybe make STATS_INTERVAL = 10.0
|Do we have to do this as a thread?

How slow is refresh_io_stats()?

What if you just track how long its been since you last calculated the stats and divide by that? I would wrap the call to refresh_io_stats with a lock still though.
|This decorator isn't really required.... BUT I can see someone trying to call this later on without a check so I'm 50/50 on keeping it.
|Maybe add a decorator that does nothing if not psutil.

Then take the insides of the 2 if psutil sections, put them in their own methods and decorate them with the decorator?
|I think you should add the package here.
|This is moblab specific or not? Can you put a comment above if yes.
|That does not seem like the correct CL?

Is there a bug to support module 2.2.1? Can we delete this work once that is done?
|Can we do this for both is_moblab and not is_moblab? Just to maintain consistency in the lab and moblab?
|can you clean up this commit message please.
|I would suggest just install everyting in ${FILESDIR}/init/* here.
|Then maybe but them in subfolders based on the relations.
|We expect an external drive on all our systems?

How does this work with GCE?
|Isn't there already an init script that does most of this? Shouldn't that be deleted?
|nit: new line.
|Get rid of these newlines.
|We might want to take a look at Moblab's normal CPU Load.

A better question is what happens if all devservers are under load? Do we revert to the old hashing function?

Or if there is only 1 localhost devserver (like for Moblab) maybe just return that always.
|timeout_secs?
|To be clearer maybe name the args: devserver1, devserver2?
|This was confusing till I read the code below.

I would make the description:

Comparator function to compare load between two devservers.
|make 2 a constant.
|Shouldn't we default to hashing if we can't receive any load information?
|Are you sure this is what you want?
&gt;&gt;&gt; args = ['a','b','c','d']
&gt;&gt;&gt; ':'.join(str(a) for a in args)
'a:b:c:d'

It may be easier if you say if there are args, the first element is treated as a subname?
|So make all these /proc/* and other filesystem reads constants. Then in your unittests make those call the constants from this file. If you need to change a path in the future that will handle it for both the actual code and the tests.
|Pretty much most of that comment you posted should go in here :)
|Add a comment showing what the output you're parsing looks like.
|memtotal can ==0? comment would be good.
|K I'm seeing a pattern of:

if not self.NeedToUpdate(blah):
  return self.data.get(blah)
.... function gets blah_value....
self.Update(blah,blah_value)
return blah_value

So this looks like a great opportunity to write and use a Decorator!

@&lt;decorator_name&gt;(DATANAME_DISKPARTITIONS)
def DiskParititons
  ...code...
  return blah_value
|In general if you parse anything add a comment explaining/example of what you're looking for.
|comment.
|Should these be at the top of the file?

ditto elsewhere
|Lets just put this in chromiumos-overlay.
|cherrypy
|initialization
|Do stdout and stderr still go to /var/log/messages?

I find doing grep mobbuild /var/log/messages useful
|use -e I found that -n was incorrect.
|You can't do that here, tried it.
|Done
|Done
|Done
|I'm fine with that. Generally we debug by doing grep moblab /var/log/messages
|Don't we start we -r1?
|You mean buildbot deps? Why aren't these part of cbuildbot-deps?
|Is there some way we can share this amongst all the different upstart scripts?
|alpha order.
|Umm, is there no better way to solve this? Why can't autoserv detect the current user and pipe that into the container call?
|I would make simple constants called null_description and empty_actions.
|+1
|with logging use commas not %
|why is actions here a named arg and not in the above 2 instances?
|Always attach units for timed intervals. Its hard to know if we are talking seconds or minutes here.
|firmware_rw_build
|for consistency make this firmware_rw_build
|firmwareRWBuild

ditto everywhere
|The image/build from which the tests will be fetched and ran from. It can be one of the specified Build Image, Firmware RW Build or the Firmware RO Build.
|A servo may be required to be attached to the Test Device in order to have firmware updated.
|unittests.

I would list those trybot test examples/results here.
|This looks wrong.

1) There is no parens after the %
2) You shouldn't use % with logging.
|Ditto, just swap the % with a comma.

Logging works: (string, paren1, paren2,...) What you're doing is (string % paren1, paren2) Which first brings in paren1 then uses the normal logging comma separation.

Fix everywhere you use logging.
|comma
|Done
|SiteConfig
|should rw be here?
|ditto
|typo
|clean up all trailing whitespace.
|I would swap all your &quot;may&quot;s with &quot;should&quot;
|repair_actions.py
|Args should be supported somehow.
|A comment with an example please.
|independent
|Yes I think that would be best.
|This is confusing me a bit. Cause you're verifying that a the check is good and for a service you're verifying that the whole service is good?
|Just to be clear theres 1 CheckFileManager for all Services correct?
|add a comment. Clear out service states or something.
|So is this unhealthychecks?
|So can we name the variable to indicate that?
|Do these always happen 1 after the other? I see this duplication below.

Part of me is wondering why self.service_check_results is an instance variable? Are there users outside execute and consolidate?

If not: why not have a function that wraps those 2, makes  service_check_results and passes it between those 2 methods.
|This seems like it should be defined in the same file as the HEALTHCHECK_STATUS object.
|Scratch what I said, misread the CL for a second.
|Not true anymore right?
|I think apt-get install can take in a list of packages, right?
|Any chance you can run pip only once?
|Mike, it would be my preference if we could just use the CROS_WORKON_SUBDIR_BLACKLIST but CROS_WORKON_OUTOFTREE_BUILD=1 breaks that. Any thoughts?
|We use tabs in ebuilds.
|If the folder we store the code is mobmonitor maybe the ebuild's name should align. i.e. no -
|CROS_WORKON_SUBDIRS_TO_COPY=&quot;mobmonitor&quot;

Then below you can just do &quot;${S}&quot; and not &quot;${S}/mobmonitor&quot;
|Use tabs in ebuild, repeat everywhere.

Also I have a feeling you need a blocker in the chromite ebuild.
|You can exist outside of chromite right?
|local is stateful, powerwash will wipe your tools.
|just make sure you have the right version when you commit.
|Launch.
|Tabs
|could be improved? maybe reword or elaborate more. Unhealthy might be better.
|Can't you just do args=[], kwargs={} in the function definition?


Note: I don't know if that works or not, just wondering.
|You might want to do a sanity regex on inputs to make sure its in the right format.

What if I do:
1,,,3,4,5=6,,,

or something similar.
|Why? Add a bit of explanation in the comment.
|I would just add an explanation why this decorator is useful.
|Generally we do &lt;Inteval_name&gt;_&lt;units&gt; so if you can make these UPDATE_DEFAULT_SEC, etc that would be best.
|ditto
|Shouldn't this also update if update_sec seconds has passed?
|Ahh got it, this makes more sense to me now.
|add a todo/comment (with a bug) that we can remove this in the future.
|Please file a bug, especially if this is DOG worthy.
|Please comment on why parent_job_id is no longer needed.
|o hmm... So they're talking about renaming that stuff eventually. Since brillo is already mentioned I'll let you make a call.
|Lets not say its a brillo board.

Brillo is now Android and this code is open source so lets avoid mentioning it here. Lakitu is really Chrome OS
|Maybe your commit message should mention we're moving away from optparse to argparse.
|arguments
|and if the test
|What should they do instead?
|Will we ever use mobmonitor with a different staticdir? I guess I don't see the point of having this be an argument to mobmonitor in general.
|This whitespace necessary? Repeat elsewhere.
|I respect that.
|Shouldn't this be moblab_id_rsa?
|You don't need the tabs.
|Hey lets just use /dev/null
|Use an ssh config file to make this unnecessary
|This TODO is simple and I would rather you did it now then leave it as a TODO.
|If you handle the TODO you can remove this line.
|you don't need this anymore with the fperms right?
|why is this necessary? Can't you just use logging?
|I would remove this and the following newline to keep this function compact and easy to read.
|delete this as well.
|Hmm this import order looks wrong.

Should be regular python packages first then common then our stuff.
|Do you use this?

You override this variable below at line 82.
|Hmm can this file be more unique than just actions.py?

Maybe common_moblab_actions or moblab_actions
|As per Gediminas's feedback, lets not do a format. I am fine with supporting a mount in case they insert the usb stick and then want to mount it (note there would only be 1 MOBLAB-STORAGE device to mount so no need for an arg).
|Very kool. Have you tested this?
|CHECK_INTERVAL_SEC?
|Can you use positive numbers? That would be closer to the concept of exit codes (0-255) with 0 being all good and a number tied to an failure.
|Uhh why minus 2? Just adjust your error codes appropriately.
|Root partition should not be an issue ever. It can't change unless we auto update :)
|Well this is not the root partition...

Also you are just checking the stateful mountpoint. What if the USB stick is full?
|USB Ethernet device?
|New health check to verify there is a USB ethernet device connected.

Very common error our users hit is forgetting to connect one.
|Quicker to just check the file exists.
|whitespace.
|It would be really cool if you could pass the service name here.

so in the action.py file something like:

def LaunchUpstartService(service):
  def func():
     cmd = ['start', service]
     cros_build_lib.SudoRunCommand(cmd)
  return func

You would have to split up the multiple service checks below.
|lets just go with is_moblab
|do len(machines) == 1
|automatically
|Mark this as true in the Moblab config.

Or only put it in the moblab config and when you get the value if it's missing default to False.
|if not utils.is_moblab():
  return


I know this is only called right now if it is on a moblab but add that just in case someone tries to call it somewhere else in the future.
|Adding this line to the logs might cause some confusion. Only log when autostarting servod.
|should there be a return here?
|default=False
|The builds will exist but the DUTS won't.

Is that what you mean?
|I overrode the test definitions just for guado.
|actually make this more explicit and say /etc/mobmonitor/checkfiles/devserver

That is where you want them to go, right?

Ditto with the other ebuild.
|No this value is only good for users at Google. Just get rid of this sentence. Or link them to https://www.chromium.org/chromium-os/testing/moblab/setup#TOC-Setting-up-the-boto-key-for-partners
|Isn't this the same file in your other CL? I don't think you need this duplication and just move it to the moblab overlay as a boto file is required for moblab to work and it is the common ground that both these services run on.
|s/gsutil/Google Storage. It would be awesome if this could list the current bucket name.

Then point them to the moblab setup page to fix.
|Use netifaces https://pypi.python.org/pypi/netifaces

Essentially iterate over the interfaces that start with 'eth' call netifaces.ifaddresses(interface)

and it should be a dict with a key of netifaces.AF_INET that holds the correct address.
|I would just align this previous '
|ditto
|Read this was confusing, let me clean it up:

To repair a DUT connected to a moblab, try to create a servo object if it was failed to be created earlier as there may be a servo_host host attribute for this host. Setting servo_args to {} will force it to create the servo_host object if possible.
|Lets just move this logic out of this function for now and do:

if utils.is_moblab():
  setup_servo()
if not self.servo:
....

then in setup_servo() you can put this logic if not self.servo
|You can get rid of the if since its in a try/except.
|Done
|Done
|Done
|Done
|Done
|Yup don't be a moblab_host if this file flag exists. This is similar logic to what is in cros_host.
|Very clean, I like it :)
|this file is not exactly the most readable in its current format.
|good use of using existing libraries!
|I don't see anywhere else in the code using +=

usb_passthrough=&quot;${usb_passthrough}hostaddr=${FLAGS_usb_dev_id}&quot; might be best.

Confirm with Richard (hes our pseudo resident bash expert).
|Done
|Done
|Done
|Done
|Done
|I raise an exception now in _find_all_gtestsuites
|Done
|Done
|Already cleaned up in the next PS.
|Autotest style
|Done
|Done
|Autotest style.

gtestSuites is the object I wanted to return but I can see how that is weird with the style, will adjust.
|Done
|already deleted.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Good catch!
|Hmm how about _get_adb_host_tmpdir

_setup_adb_host doesn't exactly represent what is happening.
|new line between @params and @raises
|Shouldn't this pass shell=True
|new line
|Repetitive code generally means a good opportunity to refactor into a method :)
|No this runs on the android device.
|Yeah I kind of prefer is_brillo becoming 'os_type' and being a string, that way when this is used in other locations its clearer what is happening versus just a True/False
|Enums work too
|Wouldn't this be better if it was more expandable in the future besides just brillo/cros by using a String instead?

For now possible values could just be 'cros' or 'brillo' and just ensure that the value past in is in our list of supported values.
|updating
|Add bug?
|docstring
|A comment here would be nice explaining what is happening.
|A comment with an example stdout being parsed would be nice.
|Why is this function needed?
|So you are looking for this script on the Drone and then are trying to send it to the Brillo DUT, correct?


On MobLab we have the script somewhere else:
$ which stateful_update
/usr/local/bin/stateful_update


I don't know if this is the script you want though.
|nit period.
|Did you test this with the old send_file?

Kevin is currently implementing this so it will do something different that it does now soon:
https://chromium-review.googlesource.com/#/c/301143/2/server/hosts/adb_host.py
|Could be an ADB error.
|8 spaces
|this can fit on 1 line right?
|Might be worth setting up a moblab and running the au suite against a Cros DUT to ensure nothing broke.
|s/and/an
|See my comment on your other CL, anyway we can make this clearer and pass in 'Cros' or 'Chrome OS'

https://chromium-review.googlesource.com/#/c/301147
|Can you wrap these lines at 80 chars max please?
|put this as a constant at the top of the file.
|use commas for logging not %
|can't you just do self.board?
|just make these constants at the top of the file.
|Can you run cros stage to ensure local staging still works?
|Expand out and to android please, 'and' took me a minute to decipher.
|Suite jobs will just fail.

Want me to say:

&quot;but Test Suites won't run properly and will likely fail.&quot;?
|Done
|Done
|Done
|Done
|If there is only 1 key why not just destroy this loop?
|What do we return if nothing matches? probably should be a return None or return ''
|I suggest reordering this to make it cleaner and easier to read:

m = re.findall(job_pattern, result_dir)
if m:
        return int(m[-1])
m = re.match(special_task_pattern, result_dir)
if m:
  return int(....)
m = re.match(ssp_job_pattern, result_dir)
if m and utils.is_in_container()....
|If we are not expecting much Brillo specific code:

I suggest we do

if self.run_output('getprop ro.product.brand', shell=True) == 'Brillo':
  return 'brillo'
return 'android'
|These are all extremely similar.

Is there no clean way to refactor this or use a decorator?
|I believe atest allows you to add multiple hosts with a single command.

In this case you should error out if they supply serials cause they can only apply to 1 host.
|Add a todo to update this once multiple device support is working.
|specify that this is for adb based devices as Chrome OS devices also have serials.
|I would just delete this and update adb_run to use self._serials[0] with a TODO to support multiple serials later.
|change this to serials and have it take in a list.

I would update the docstring and say only 1 device is supported currently though. (Cause we still need to design the interaction/manipulation of multiple devices per host).
|self._serials now
|The setting of the serials should go into the atest cli code.
|Ahh yeah, I see your problem now. This might be a bit tricky. Moving some of this logic outside of the object and into utils might resolve the issue but I'm not 100% sure.
|Hey we need to expose the devserver too. It's 8080 on the device.
|I'm fine either way. The environment is significantly different than normal so might be worth it.

Also board is not required so this would help for people who get confused.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Shouldn't this just be 'port' with the default value being 80? Saying 'default_port' but being an arg is weird.
|This is pretty slow right?

Are there optimizations we can do prior? Like to vet out cases where it is likely not too large? Easy case: is it less than N MBs? Then maybe its not gonna have 500 files.
|this regex is also in job_directories.py, please use that or refactor.
|Done
|Done
|say boolean or True/False here please.
|Shouldn't this just be source_release=None in the definition then?

Ditto below.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Can you elaborate? I don't understand your comment.
|Done
|Done
|Done
|Done
|Done
|It is done twice because if you restart shill, the forwarding rules are lost.
|Elaborate please.
|Has to be done again if shill restarted. Also those are 2 different files.
|I am fine moving this to before set_up_forwarding.
|For guado &amp; panther dhcpd_iface is static as lxcbr0. But for stumpy, it is not known till the usb ethernet dongle is detected.

Take a look at moblab-network-init for stumpy's script. We decide which to install based off of the lxc useflag.
|This is here for if there is no usb ethernet. The network bridge requires the forwarding.

By restarting shill below we have to reset the forwarding.
|Done
|Done
|We already checked with pstew before, there is no way to add blacklisted devices without restarting shill and I don't want to blacklist the usb ethernet until I've confirmed it exists and which interface it is.
|Done
|ahh now i get why you wanted that other change below.
|Line 131 in the kickoff script ;)
|Done
|Just ensuring the sequence kicks off multiple test runs, we will be adding the au test in between these two runs.
|Done
|Done
|Done
|2) No because I plan to add later logic that will fetch our VM image from Google Storage and kick it off and then this script will interact with the VM instead.
|Done
|Done
|Done
|Actually I'm going to put it higher up in CrosHost so that any CrosHost can convert to this.
|moblab.add_dut
|Done
|Just gonna raise the exception for now, no need to handle it yet.
|Done
|Missing the actual return value, will add.
|Done
|Done
|Done
|Done
|I'll stick with logging.
|Well get_jobs is technically broken as right now setting finished=False in the get_jobs call returns finished jobs, and I would rather fix the bug than work around it.
|Good call, I expect the dut to not be easily repairable without human intervention at this point to be honest.

But I will abort the remaining jobs.
|Done
|Done
|Done
|Done
|sorry there is a bug here, cleaning up for my next patch.
|Done
|Mind filing a bug for this?
|just align this with isinstance.
|This will only apply to brillo/android correct?
|2 new lines.
|I take it you don't care about exit codes with this correct?
|Done
|The port for the VM is the forwarded port. Matthew put the Virtual Machine forwarded port as 7777, I figured that it was probably best to stay away from what might be already running on the host system anyways.

If we wanted to, we could change the VM's port forwarding.
|Done
|Done
|It does not, we could assume if no --moblab_host, try the VM, and fail if not.
|Done
|web_addr (127.0.0.1) will not work with ssh.
|Done
|Done
|O kool, thanks for the add_mutually_exclusive_group tip :)
|the period is on the next line?
|Line 53 above says action='store_true' so it should be a boolean.
|I tried this, and no we can't :/

Took me a while to figure this out. Above in check_host the object is just of type abstract_sshhost. It's ssh_ping and run are the normal methods there.

Down here the object is of type adb_host, and ssh_ping calls run when doesn't work cause the serial is not yet set.

I could update ssh_ping in here to call host_run, but that breaks is_up and wait_up, etc as now they only tell you if the host is up not the adb DUT.

The whole create_host logic is overly complicated making it difficult to refactor this.
|Hey it was a good suggestion just didn't work out do to the weirdness of the create_host process!
|this could be deleted though.
|Done
|I'll break it out.
|Done
|Done
|Yes currently the finding of the control file logic is a bit weird.

By default you give it a test name it finds just &quot;control&quot; in that folder. But we support multiple control files per test so in this case if you want one of those you need to give it the filename of the specific control file. &quot;control.brillo_GtestsWhitelist&quot;.

I was hoping it would just grep the NAME= line from the control files but that is not the case right now.
|Done
|Sequences are an autotest concept.

A suite runs a suite of tests in any order and against any device.

A sequence runs a sequence of tests in a specific order against a single device.

You'll find these in server/site_tests/sequences/

The Brillo PTS will be a sequence.

I will clean up this output tho.
|Done
|This will conflict with https://chromium-review.googlesource.com/#/c/305505/6/site_utils/brillo_test_launcher.py which I just sent into the CQ.
|This is not the right check. If the devserver outputs an error message curl will still give return code 0.
|Delete this.
|Add a TODO on mkryu above this to remove this and pipe in args directly below.

Cite bug crbug.com/545572
|Change test_args to {'args': test_args}

This will allow it work for all tests now.
|I don't have a good reason why this happens but if site-packages only contains chromite, the log level is stuck at WARN

My guess is something optional used to call basicConfig beforehand with logging.DEBUG as the level and when I searched online you can't call basicConfig twice.
|Nope doesn't work.
|Still can't call this function directly :/
|What are you doing with this information?
|What are you doing with this information?
|if not dargs.get('retain_image_storage', False):

Either way is fine I just think this might be a bit clearer.
|@param do_quote
|Maybe MoblabInitializationError

or BrilloTestError from brillo_test_launcher.

You can move it into client/common_lib/error if you want.
|See if your script works if you do the following:

files$ rm -rf site-packages
files$ &lt;run your script&gt;

You might need to do something similar to this:
https://chromium-review.googlesource.com/#/c/307238/
|pull this from moblab_host?
|Yeah lets make -R the default if the other 2 are not ran.
|We should require atleast one of these, right?
|from autotest_lib.server import utils

utils.run?
|import common
|passing 2 values is probably the best option. I just don't think we need a whole another class to wrap these 2 values.
|Why not just save the external devserver port into the Moblab host object rather than wrap it with a whole new object?
|Done
|Done
|Does adb push preserve_symlinks or do we need more here?
|all the required tests.
|Is this not used?
|Is this supposed to be percent_required_to_pass?
|docstring?
|use commas for logging.
|I feel like I need to agree with Ang, that we might want a better android vs chrome os identifier than branch. Chrome OS has branches we just don't use them like Android.
|s/will/with
|Check with Zeuthen but I think fastboot normally requires sudo to work.
|Probably should make adb and fastboot constants.
|default value?
|Use the retry decorator?
|Docstring.
|remove (c) no longer part of the license.
|separate lines per import is what we're pushing for these days.
|do a trybot run:
cbuildbot --remote -g 309577 whirlwind-paladin
|You didn't really respond to my earlier comment but is it worth make '0' &amp; '1' constants for what they represent? Which I am guessing A/B?
|@raises?
|@raises?
|2 new lines
|Only 1 underscore please. repeat to the folder name.
|commas with logging, repeat everywhere.
|Any chance you want to make these commands constants? Might be worth it.
|This 0 represent something that should be a constant? Ditto with the '1'?
|Looks like something that should be added to adb_host.
|look at:
from autotest_lib.client.common_lib.cros import retry
and the retry.retry decorator
|maybe add to adb_host a run_fastboot_cmd function or something?
|Looks like something we should move to adb_host.
|Add a comment of an example line.
|continue and remove the else?
|Does this make sense to add to PTS if there might not be an SSID to join?
|no (c) and s/2012/2015
|GCI Team?
|Hmm this was to allow this to run via test_that... let me see what I can do here.

Maybe its worth adding remote support into test_droid first and use that to run these tests instead.
|Lets leave it empty here and put it in the shadow.

That way people can adjust this locally and it doesn't need to be hardcoded in the code.
|This is the location I was planning to have puppet pull the comms framework into.

We could just put it in the shadow_config for the lab servers.
|I'm fine with that change.
|Fine with this change as well.
|put this on kevcheng
|Put kevcheng here.
|newline this somehow?
|Yeah this is just determining if the drone is running on a moblab or not. /mnt/moblab is usually an external drive or a much larger partition.
|This name confused me for a minute, lets try something else.

Maybe ANDROID_EXTERNAL_IMAGES or ANDROID_EXTRA_IMAGES?
|Could we use a regex instead?
|Wouldn't this work too:

if self.hostname is 'localhost' and utils.is_moblab()
|make this a constant.
|I would just update the moblab init scripts to ensure this directory exists.
|Actually I thought about it, just leave this as is for backwards compatibility support of current moblab images.
|If None, what?
|This implies only AndroidInstallError is the only possible thing that gets raised.

However in that try block, you call host_run a number of times so an AutoservRunError could get raised.

You might want to catch all exceptions and wrap them with AndroidInstallError.
|Shouldn't this go after the finally? What if it can't switch to adb mode properly, i.e. the image did not boot.
|Why is this ever necessary?
|GCE?
|metadata?
|Lets find a different location for this file.

Are there common utilities somewhere already? If not maybe create a server/gce folder?
|GCE_Error?
|2 docstring between methods in an object.
|8 spaces repeat everywhere that's the same.
|docstring.
|docstring
|use commas with logging. Also you never imported logging.
|License?
|import common
|We're pushing for separate lines these days.
|2 new lines
|docstring
|8 spaces
|8 spaces. Also use SSH_KEYS_METADATA_KEY?
|The implementation of this and add_ssh_key are verrrrry similar, can you refactor somehow?
|8 spaces
|8 spaces. Also use SSH_KEYS_METADATA_KEY?
|Use a regex?
|import common
|docstring.
|This function is ~90 lines, any chance you can break it up a bit?
|Lets refactor this, its also in brillo_aue2e_test_setup
|Maybe add get_tmp_dir to MoblabHost?
|import common
|@raises
|Please delete this at the end.
|That makes no sense because then all the run calls are piped over adb.
|I don't think you need this line anymore.
|We support the testing of ADB devices locally by connecting the device directly to your workstation or MobLab (aka Drone).

We still want the test station object to represent a host so that test writers don't have to distinguish between the case of testing against a remote or local adb device.

client/bin/local_host.py lacks necessary methods like get_file,send_file, get_tmp_dir, etc.
|Correct, kevin you need to do a full grep through the codebase and clean up all callers of host_run.
|Part of me feels like this code path should go through the test station host now right?

Dan, thoughts?
|8 spaces
|Yeah exactly.

The point here is that we're trying to make it so the test writer does not need to know if the adb device is local to the MobLab/Drone or remote (like an actual teststation). Regardless the test should still go through the same flow.
|For Brillo, when they connect the brillo board directly to the workstation/moblab.
|Essentially a test might require putting a file in a specific location on the test station.

I.E. copying over the ACTS config files.

This abstraction ensures the test writer does not need to know whether or not the test server is the same as the test station.
|the cros url comes from global_config, maybe do the same here?
|CrosImageServer?
|Got it. Add a comment saying we would rename it but can't do to backwards compatibility issues.
|QUERY_TIMEOUT_MINS
|+1
|platform, still misspelt :P
|I would swap test_that with autotest
|Might be worth breaking this huge try up.
|This already errors if there is a reboot issue.
|8 spaces
|logging should use commas anyways.
|You don't use this...
|This is only defined in cros_host right? I think adb_host does not have this currently...
|Yeah a utility would be nice, but it would be good if it can check if the right version of the apk is already installed, and if so don't install it.
|Wait, not all android tests require sl4a.apk correct?

APKs should only be installed by the tests that require them IMO.
|Is most this code you're deleting just code rot and unused?
|Yeah you are right, the instances I see are Autotest objects.
|Are you 100% we don't need this?

Server tests kick off client side tests all the time and I think it goes through this code path.
|If there is a test that calls host.run_test and it still works then yes.
|how are you planning to test this?
|Are these all necessary?
|Whats the import error?
|2 newlines
|I think taking in a list of serials is also a usecase.
|connected to the duts.
|use commas with logging
|I feel like this should maybe be a map of serial to adb_host
|First check if the serials are in the host attributes table and use those if possible.
|Since you have the 2 methods below, this might be better to return a list.

Use case: Verify

Verify calls get_all_hosts and just iterates over making sure they're all in a good state.
|If this is going here, it should be relative to the autotest root directory, but I would suggest moving this constant to where it is being used.
|Why do all this passing of &quot;autotest_dir&quot;? Just go relative to the current file.

I think __file__ should be the path to wifi_client.py and from there you know the relative path to the android_xmlrpc_server.py

Also use a constant for the relative path.
|Chromium
|else:
  class.append(ssh_host.SSHHost)?

Otherwise it won't be able to run if its a remote host.
|single quotes
|Maybe pull this into its own method.
|Move this to factory and look at what I am doing here with the connectivity classes of create_host:

https://chromium-review.googlesource.com/#/c/314870/5/server/hosts/factory.py

Feel free to steal that and finish it if you want.

Pretty much create a tuple of classes then use type() to form the class you actually want.
|thats fine.
|Make this a regular class and just inherit from Abstract_SSHHost.
|I would recommend putting this file in the ARC-specific testing repo. https://chrome-internal-review.googlesource.com/#/c/239586/
|So what happens is that, it tries to ssh as root. If that fails it changes the user to adb and then tries the test command (which will fail if adb does not have access either). If that fails or its not an adb host, it then restores the original user.

I'm going to leave this wording as is and we can adjust later if my explanation is still confusing.
|Fix TEST= line
|Done
|repr
|Done
|Done
|delete.
|test_runner_utils.py
|Done
|Done
|Done
|Done
|Played with this, can't have 2 nargs='+' in a row, it won't know which argument the multiple args belong to. 

Also there is no string arithmetic because CSV is the expected format of serials when they come from the database as well.
|Done
|Done
|Done
|Done
|Done
|No, because currently adb_host will skip this step and we can enable it at the host level again once its valid.
|Willing to move Quickmerge but will leave the keys here for now as I want to use that later with test_droid.
|Added a TODO to fix that once we bring in remote support for test_droid.
|Fair enough.
|Disagree this one belongs here.
|Done
|Done
|Done
|No host_class can be defined by passing it into create_host and it defaults to None.

But I did make it cleaner now:
host_attributes = args.get('host_attributes', {})
host_class = host_class or OS_HOST_DICT.get(host_attributes.get('os_type'))
|Done
|I think I can undo, this. Will double check.
|It could, I was just following the import pattern below.
|Yeah we can remove for now.
|Fair, I was going to add serial support next but my endgoal was that it could work for directly connected hosts and remote hosts.
|Done
|Lets come back and clean this up later. This is purely for the suite logic to work in this fake AFE environment for kicking off tests and have no real impact on the actual test run.
|Done
|Done
|REFACTOR
|Done
|Aviv: Make copy here.
|Done
|Use utils.hostname_from_machine here.
|Done
|doh
|Doesn't work...
&gt;&gt;&gt; d = {'a', 'b'}
&gt;&gt;&gt; isinstance(d, dict)
False
|Done
|Done
|Done
|Done
|Its still available to the callers as its part of the parent abstract class now.
|Done
|Discussed online, adjusting to do a type check.
|Done
|Done
|Done
|Done
|Done
|Aviv/Wiley requested isinstance.
|Thats fine for now. Thanks :)
|a bit more text here would be nice
|This should be a property or something so that we don't need to pass is_brillo around in between methods of this class.
|This looks like it should be in the test station class.
|See my comment at this method definition.
|I feel this arg is unnecessary, this is a private function and this instance should know if it is running brillo or not.
|You depend on unzip as well.
|Is the logs folder directly relative to this file or do they have to go up a layer?
|I'm confused as to why this section got added here and below?

Don/Aviv?
|Not sure what is the correct indentation here. Normally for this I would align the nots.
|this one I would do 8 spaces.
|I would bring the [ down a line, and then it should be a double indent of 8, to be consistent.
|double indent
|double indent
|double indent
|doule indent
|Double indent. Okay you get it by now, repeat everywhere applicable.
|I would put the string above if possible.
|Sigh that means we need to get our server's access to this repo as well...
|Awesome, thanks Dan!
|Where are the vendor keys located and where do they need to be on the host?
|Can a job and special task both be active at the same time?
|Please try to refactor these 2 functions.
|close the get.
|Cut this down into 3 lines:
if server_utils.machine_is_testbed(machine):
        return create_testbed(machine, **kwargs)
return create_host(machine, **kwargs)
|Shouldn't you check the teststation host as well?
|Do cbuildbot --remote -g 318500 &lt;board&gt;-paladin
|from multiprocessing import pool?
|I would shift this a bit
|Want to make these 3 keys constants?
|Legacy code? I'd rather move up above and match our style guide.
|Yeah I felt it was odd too, k let me refactor.
|Is this true for both ubuntu and chromeos?
|I think we're going to always want to call build_externals on chromiterepo in order to ensure we have the newest changes :/
|This is where the magic of having a chroot comes in useful. These packages are part of the chroot/host environment.

From Vapier: &quot;the first thing setup_board/build_packages does is run update_chroot which makes sure all sdk packages are updated&quot;
|yeah according to Dan the build_externals in the lab for chromite has been broken... (crbug.com/570716) they fact we never realized says its probably not that big an issue for now.
|Every time we do a push to the lab, it calls build_externals to ensure we have the latest chromite/etc.

My concern is user runs this once. Gets chromite.

Down the line repo sync: new autotest changes requires newer chromite.

They run this script again, stale chromite, weird errors, user has no idea wtf went wrong.
|newline
|newline
|Can you check if its already closed?
|return or raise?

Ditto below.
|Don't call this common.py as thats an Autotest thing, look at other directory's common.py files for more info but if you ever need to use other autotest libraries this will need to be renamed.
|kwarg name?
|K lets just leave it here for now then.
|curious any reason why we don't want to just put these in the host object?
|See my previous comment on PS4
|I believe you said you were going to move this file.
|kwarg the True
|kwarg the True, repeat for all the get/send_files
|Might be worth making a new folder: client/common_lib/brillo?
|Nothing here is really Brillo specific, might be worth just adding to the regular client/common_lib/site_utils.py
|Could we abstract the host.remount() call so that write_cmd_to_script is not Brillo specific? Or have it no-op in the default host object.
|The fact there is a host object suggests this should be in the server/ subfolder as a server utility.
|SG
|Not sure if this works but how about:

with wave.open(filename, 'r') as chk_file:

That way you ensure the file gets closed right (which I don't see you doing)?
|import common before autotest imports.
|This needs to be under server/ if you are manipulating a host object.
|so we don't ever want to lower it?
|use parens not \
|Really? Sigh... I would suggest 2 nested blocked as we actively push for no \ to continue a line in Autotest.
|Is this a kwarg? if so please specify the kwarg.
|stick with single quotes.
|You are right, I missed the apostrophe, ignore me.
|put the kwarg in front of True
|_REC_DURATION_SECS? MINS?
|kwarg name?
|import common
|You can set host and dut_tmpdir as self.host and self.dut_tmpdir and not need to pass them as args.
|Args should be explained in the DOC= area.
|import common
|Can you put a little bit in the docstring about why you need this function?
|You can set host as self.host and not need to pass it.
|Add feedback arg.
|Refactor this into utils somewhere?
|CQ-DEPENDS? Since you need closed_loop_audio_client.py
|Done
|Done, I'm not so sure about downloading it just yet so lets leave it as is for now.
|Done
|Done
|simplify this please.
|devservers = cls.servers()
|logging.debug('The host %s (%s) is in a restricted subnet. Try to '
                          'locate a devserver inside subnet %s:%d.',
                          hostname, host_ip, restricted_subnet[0],
                          restricted_subnet[1])
devservers = cls.get_devserver_in_same_subnet(
                    restricted_subnet[0], restricted_subnet[1])
|This code is almost exactly the same as 445-451, lets clean up.

I would delete all the lines here and then put line 444 after an else: clause and then this should work fine.
|Change this to be: &quot;unit tests &amp; trybot run&quot;
|Good catch, I cp-ed a suite control file and editted it.
|Just sets the max runtime for each sub test to 20 mins.

Is there something you want here? This is pretty standard.
|Is this required?
|get_all_hosts()?
|If you run just true, that should work on the test station host as well.

What if in the future we want to have a testbed made up of a test_station, cros_host and adb_host, then get_all_hosts() will make sense.
|How about the true command?
|why not just run?
|localhost host does not have the user attribute as everything is done locally, its not ssh'ing anywhere.
|WIll do.
|Hmm shouldn't this go above import re?
|@returns?
|maybe do this check in machine_install
|Maybe do a regex check to ensure the image_string is in the correct format.

Also please add a comment showing an example.
|^Yup
|File a bug please.
|You were right, it has to be relative to the def, sorry.
|What if server_ip_map does not have server as a key?

I would do something like default server_ip_map to {}

Then here do:
server_ip = server_ip_map.get(server) or get_ip_address(server)
|Can server_ip be None here?
|lets double indent this.
|Hmm so if we have multiple hosts in a single test job, does autotest always use the same drone for all of them?
|do

subnet, maskbits =

Your code below will easier to read that way.
|Maybe a check that checks if there were filtered_drones_for_host but it did not intersect with filter_drones.
|You don't need to double indent here, I think?
|If you need to explain it as a comment on the CL, it should be a comment in the code.
|host_ip

also @param servers
|one period
|Hmm the fact host_ids is a list is worrying me.

Couldn't I launch a single test against 2 hosts in separate subnets?

What happens then? Is there 2 separate agent tasks (and this code is valid) or is there a single one?
|Do we really need to re-calculate this for every agent task, lets just save a list of unrestricted drones somewhere?
|2016 :)
|so why did you add all this?
|Link so I can take a quick look at the UI?
|restricted
|I still think a regex would be best :P but I'll leave it up to you.
|this should be in the normal python imports section above.
|What if someone puts a comment at the end of a line? Like

testa,yes # THIS TEST IS HARD AND NEEDS ROOT.

I think using a regex for this whole function would be the best here.
|Single quotes.
|Is this if backwards?

I thought we do su shell when we want to run as root...
|Why do we need to add this as an option? I don't see the harm in adding it to the stage API in general.
|align under the A
|Make this an autotest_campaign below constants please.
|use commas with logging.
|double indent here.
|this should move up a line
|Can you make this logging message more meaningful? If someone sees File: &lt;&gt; they won't really know the point of that message.

Or just delete it?
|CAMPAIGN

Also I think you can drop the _NAME on both of these variables.
|attempt
|instead do:

if os.path.exists(input_path):
  return
&lt;rest of the code&gt;
|Remote generally means off the machine.

I would update the docstring to say If the file does not exist, attempt to fetch it from the ACTS config folder if it exists.
|Don't you want to do this if input_path exists?
|2 new lines between methods.
|I would explain in the docstring that test_file is only used if test_case is not provided.
|Supply them as comma separated values.

Yes we will need both.
|Can you refactor this code and the code for config_file into a helper method. A good portion of this looks identical.
|Lets do act_cmd = 'act.py -c %s -tb %s' % (
                    os.path.join(ts_tempfolder, os.path.basename(config_file)),
                    testbed_name)

Then in the if cases appen the -tc or -tf part.
|This looks wrong....
|single quotes in autotest.
|2016
|needs to be unique.
|update docstring.
|get rid of all these.
|Maybe we name your new function get_board and this becomes get_board_label?
|Example here please.
|not have a serial specified in it.
|install the given images.
|is images a list of tuples? The example I asked for in the docstring will help.
|Installing build %s on DUT with serial %s
|actually autotest style is:

normal python imports
&lt;new line&gt;
import common
autotest imports.
|Single quotes please
|Please describe these args in the DOC= section above.
|why did I delete this?
|fix
|Still working on that. I want to make sure I don't break anything.
|So builds contains the build we still want to test and the way run_suite is written is it sets test_source_build to the build we want to test so the way the code currently is, this won't work. I think for now lets leave it as is since we should get packaging up and going pretty soon.
|Done
|Done
|Done
|What about host_in_lab_env so it's could be our lab, a MobLab or any autotest instance.
|Done
|Done
|Richard asked me to not use decorators
|Done
|I actually wanted this function to be in site_utils, but due to a circular import problem it can't.
site_utils -&gt; afe_utils -&gt; frontend_wrappers -&gt; site_utils
|Done
|Done
|still need to put a comment here
|I stole this comment from provision_AutoUpdate, but I think its fine. Its saying that it would make sense to raise TestNA but it cant.
|Was gonna use it, didn't need it.
|Check the next PS, but we need this arg as all our current Infra relies on the fact we have test packaging which we don't have for Android/Brillo builds yet.
|Done
|Android Build.

I'll rename it provision_AndroidBuildUpdate
|Done
|adding a new utility called afe_utils
|Done
|Pretty sure there is autotest magic here that value is a local variable but not set here. Doing what you said would break it.
|Done
|I'll update the docstring, pretty sure we need to stick with value as the name.
|Done
|Done
|Done
|Done
|K here do:

self.staged_image_name = self.options.staged_image_name
self.board = self.options.board

And then undo all the setting of self.options.*
|self.staged_image_name
|self.staged_image_name
|self.staged_image_name
|self.staged_image_name
|self.board
|self.staged_image_name
|self.board everywhere
|self.board
|self.board
|self.staged_image_name

Repeat everywhere below.
|Style guide is for functions to be roughly ~30 line, while we're generally relaxed on that this is still pretty big so can you break it up?
|single quotes for strings in autotest (unless a string contains a single quote), repeat everywhere
|import common
|class Client inherits from class client.Client?

Is there a better name? Maybe not cause its the Client side Client....
|docstring
|+1
|+1
|+1
|alpha order
|bugs for all your todos please
|nit single quotes
|use autotest's import format
|For your TODOs can you file bugs in case theres a reason you might not complete/do it.
|Nit: put this in a helper function please.

Also if this can be employed by Chrome OS maybe it should go into test_runner_utils
|Have a comment explaining what is going on here?
|insert newline
|process
|2 new lines between methods
|2 new lines between methods
|2 new lines between methods
|Might want to change this to be Brillo/Android and repeat that everywhere.
|Done
|Done
|Done
|Done
|Done
|Done
|Flipped the logic.
|So if anything we can change this to be:

if not (host.job and host.job.in_lab):
    return False

but I think that's harder to read.

Any utilities for lab deployments will have to call site_utils instead.
|No that would never return the build.

I can't find the magic that sets up host.job but it does work somehow :/
|BUG=b:25368607
|as are

is cleaner syntax.
|Does this test run on the Brillo emulators &amp; you want to include this in the VMTest stage that runs here? https://uberchromegw.corp.google.com/i/internal.client.brillo/waterfall

If so add it to suite:brillo-smoke as well.
|I think the host has a get_tmp_dir function
|Do the same order as the args are passed in.
|should be indented by 8 spaces.
|These names look wrong. Also you missed spelt array.
|Would you want this to run against the emulator on here? https://uberchromegw.corp.google.com/i/internal.client.brillo/waterfall

If yes add it to the brillo-smoke suite as well.
|use the with statement so you make sure you close this file.
|use the with statement.
|this arg name looks wrong.
|this arg name looks wrong.
|Example? Is this a URL? Should it be?
|New license has removed the (c)
|@param?
|@param
|2016
|For docstrings, use double quotes. Fix everywhere.
|This docstring is confusing. I have no idea what it means...
|nit newline
|You're returning 2 different things here...

First return statement you return the location of the input_path relative to the Drone (where the test is running). On the second return statement you're returning where the file lives on the test station after you send it over.


Note the test doesn't run on the teststation it runs on your workstation or the lab drone.


Workstation ----(ssh)---&gt; TestStation -----(adb)-----&gt; Android DUT

This python code runs on workstation.
|self.test_station.send_file sends a file from the workstation to the test_station.

get_file is from the test_station to the workstation.

self.ts_tempfolder is a temporary folder on the test station, not the workstation. So that folder is not local to this python code.
|return actual_path
|Delete lines 89-92
|Why do you need to copy it back? Did it change?
|Try just config_file again after you folow my other comments.
|Maybe have the host returning the attribute? and then have a default in the base and override it in adb_host to include the serial
|Ditto what I said above, hide this in the host object.

host.generate_repo_url(devserver_url,...&lt;whatever else you need&gt;)
|I don't think we should have afe_utils in test_bed, just like how we don't want afe_utils in adb_host.
|Try my idea of adding a generate_repo_url,

This is just trickier for test_bed because you have to count for the multiple repo_urls
|Make sure test_droid still works as it does piping of the serial number as a host attribute.
|We might want to put here:
if not host_in_lab(host):
    host.host_attributes.get(attribute)
|Correction it might want to be:

First grab the local value, then if its not in lab return.

Then grab the afe value. If it is none return the local. If there are both values, return afe.
|Correction we might want here:

host.host_attributes[attribute] = value
if not host_in_lab(host):
    return
|We might want to put here:
if not host_in_lab(host):
    host.host_attributes[attribute] = value
|This piece of code looks exactly like line 1296, please refactor.
|Comment here please.
|Why android? Couldn't this be Brillo?
|Highlight these only work in the lab.
|Default should be false.

Example (ACTS wrapper test):
At my desk I install everything, use test_droid to run. Test goes in here (force_reinstall=False) sees its already installed, returns.

In the lab, device is provisioned (no sl4a), the test is kicked off, goes in here, sees the APK is not installed (and force_reinstall still False), goes through the process of installing it.
|There should be a check at the top of this function that if the APK is already installed and not force_reinstall, return right away.
|tabs?
|tabs?
|We should also have it so that test_droid can still run the test and just assume that sl4a is already properly installed.

So Ang what do we want here exactly?
|Did you mean to put tabs here?
|More I want test_droid to follow the codepath that the lab uses (which always supplies the serial), just incase some developer hits a case it works at their desk cause they didn't supply the serial but in the lab it fails for some random reason.
|Can you do this :

if not serials:
  output = &lt;run adb devices&gt;
  devices = adb_host.parse_device_serials(output) # Static Method
  if not len(devices) == 1:
    # Error out
  serials = devices[0] # update line 100 below.
|I'd rather the user didn't need to know to use '' magic for this.
|Sounds good, it should just return a random devserver.
|do not
|os_type = config.getstring(section, 'os_type') or OS_TYPE_CROS

then delete the next 2 lines.
|why 8 spaces?
|Can you refactor this with lines 823-836
|I would put this function in TimedEvent, use a class level constant and override it the constant in each subclass with 1 or 7 for nightly or weekly.

That way you get rid of this duplicate code.
|I would put this in a submethod and in the docstring explain out the logic as that if-statement is pretty convoluted.
|We don't want this in the lock anymore?
|why pop and not get?
|Lets simplify the logic. Remove these lines then below do:

if not default_timeout:
  respdata = urllib2.urlopen(request).read()
else:
  respdata = urllib2.urlopen(request, timeout=max(min_rpc_timeout, default)timeout)).read()
|why did these have to be different?

Couldn't we just have updated the other regex to support android as well?
|2 new lines
|init_frontend_rpcs?
|why is this required?
|This is turning out to be a big bug. My suggestion is to write smaller bugs that block this larger bug.

I.E. 1 bug for SSH Communication to Moblab via ssh tunnel.
Then block 582646 on that new bug.

Easier to track work, especially when you're new.
|moblab host
|+1 &quot;host_used&quot; is a very unclear variable name.
|+1 to refactoring.
|test station right?
|Please remove this as well
|I would remove this blocking as well.
|Create a whitelist list as a constant and use that here.
|Done
|The host object is adb_host. Theres a number of areas getprop is executed, so moving this into there and refactoring those callers would be great.
|Nit 2 new lines
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(7 comments)
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2

Inheriting +2 will submit once other CLs land.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Trybot-Ready+1
|Patch Set 4:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5: Verified+1 Trybot-Ready+1
|Patch Set 5: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review
|Patch Set 1: Verified+1 Trybot-Ready+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 2:

Got rid of the redirections.
|Patch Set 3: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 1: -Code-Review

Whoops, just replace that one area with a regex and then I'll +2
|Patch Set 2: Code-Review+2

Thanks that part is much more readable now :)
|Patch Set 3:

(9 comments)

Couple of comments.

1) A number of things in lxc_utils look like duplication of code we already have. Why do we need path_exists or the run method?
2) I think you can use Python's built in tempfile functions for your tempdirectory needs. That way you ensure it is deleted when the process dies. Is there a reason you're not using it? I would understand if the answer is after this process is done, the container is still up running a test and deleting a folder from the main system might mess with it. Not sure that is correct but a comment or something explaining why would be good.
3) Add a simple unittest to make sure the config file is in a good format. We can prevent bad changes from landing that way :)
|Patch Set 4:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(10 comments)
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2

(1 comment)
|Patch Set 1:

(5 comments)
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2

(1 comment)

Send this through the moblab trybots before committing.
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2

This looks okay now but we may want to move to a model of using a dict or an object that stores the host system settings.

I'll let you decide if you want to do that now or in the future if we need it.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Slightly restructured to appease unittests.
|Patch Set 1:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 3: Reverted

This patchset was reverted in change: If24f79c79aeae41ff39371469e41e7dfaab2a614
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

I thought we wanted this to be added to chromite/lib/gs and from there use that module to offload instead?
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 3: Reverted

This patchset was reverted in change: Id0cba900edc28d0beab255f8059606b6dabc741e
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)

I have a second cl to update the controlfiles after this is pushed to prod.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue -Verified
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Verified-1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)

Mike, any issues with this USE flag change?
|Patch Set 1:

Hes applying it specifically for pyshark (as it will be required by server side testing).

If you think its better to apply to everything, I'll defer to your judgement.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(8 comments)

Sorry for the delay here. But updating this CL. We plan to start testing SSP next week so Chris, lets test this approach for private tests for jetstream.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue Trybot-Ready+1

Strange failure, retrying
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 2:

(2 comments)

I'm assuming https://chromium-review.googlesource.com/#/c/262457/9/chromeos-base/autotest-server-deps/autotest-server-deps-0.0.1.ebuild properly pulls in all the dependencies as well correct?
|Patch Set 3: Code-Review+2
|Patch Set 3: -Code-Review

Found a nit, 1 second.
|Patch Set 3: Code-Review+2

(1 comment)

Fix this NIT then inherit my +2
|Patch Set 4: Code-Review-2 Verified-1

No, it should be a TEST= line and a DEPLOY= line
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

I am confused as to why we are making this change to check for the folder path.

Can I get more context?
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)

Take a look at PS3 and for a simpler solution that will likely work PS1.
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Trybot-Ready+1
|Patch Set 4: Commit-Queue+1
|Patch Set 1:

I'm confused, why is beaglebone not correctly getting its users from third_party/eclass-overlay/profiles/base/accounts/user? Your root user is the same as the one in that directory and chronos is the same except it uses /home/chronos/user as its homedir.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Reverted

This patchset was reverted in change: I7456dc5c920e31f9cc6e019943ea879c1c9e7c28
|Patch Set 2:

(6 comments)

Curious what is our story for SSP and Special Tasks?
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 3:

We're going to have to do a trybot job and then verify on a beaglebone that servo still works as expected. 

Just launched the build:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/beaglebone_servo-release/builds/14
|Patch Set 3:

The only real feedback I have is the white space you've introduced probably should be deleted.
|Patch Set 3: Verified-1

Doesn't work, will explain in offline email.
|Patch Set 7:

Does this still impact Beaglebone white or no? i.e. do you need any verification from me or not?
|Patch Set 7:

Kicked off a build https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/beaglebone_servo-release/builds/16
|Patch Set 8: Code-Review+2

My trybot build worked fine.
|Patch Set 1:

(25 comments)
|Patch Set 3:

(4 comments)
|Patch Set 4: Code-Review+2

(3 comments)

Few nit's.
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue Verified-1
|Patch Set 1: Commit-Queue+1 Verified+1

Restructured the moblab pools.
|Patch Set 1: Verified-1

I'm worried the timeout may not be longer enough for most cases. will revisit over the weekend.
|Patch Set 1: -Commit-Queue
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Same CL but up-ed the timeout from 30 mins to 120, matching the other paladin timeouts.
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)

Few Questions:

1) How does a drone know if it supports SSP?
     a) For moblab/drones with no SSP support it should just check for the existance of a lxc-* binary. stumpy_moblab won't have it.
2) What if no drones support SSP? We should still run the test normally right?
|Patch Set 1:

(1 comment)
|Patch Set 2:

(5 comments)
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

This is the same change without the db migration.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Trybot-Ready+1
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Fixed unittests.
|Patch Set 7: Reverted

This patchset was reverted in change: I0c6875ec17f9362b7e646471b6ae5d06c70b770d
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

That was an accident, anyways Gwendal has a better cl he's putting together.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2 Commit-Queue+1

Inheriting +2 from https://chromium-review.googlesource.com/#/c/249870/, I split this out into 2 CL's for proper pre-cq coverage.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1

Whoever can take a look today, that would be great so I can land this before the weekend. Otherwise stumpy_moblab-canary will keep turning the tree red.
|Uploaded patch set 3.
|Patch Set 3:

Updated via pprabhu's suggestion.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed USE= line to include ${USE}
|Patch Set 4: Verified-1

Imma split this into 2 CL's to get pre-cq coverage.
|Uploaded patch set 5.
|Uploaded patch set 6: Commit message was updated.
|Uploaded patch set 7: Commit message was updated.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified-1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

I'm confused, why do we need to update the afe_jobs table?
|Patch Set 3: Code-Review+2
|Patch Set 4: Reverted

This patchset was reverted in change: I3300de55bfe3e0266095a3e43094f9ba0fb0f79d
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified-1
|Patch Set 2:

(5 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

I did a trybot job with this change last week and it seemed to work fine. I think Stefan's work involves beaglebone black.
|Patch Set 3: Code-Review+2
|Patch Set 1:

That test does run on canary.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

inheriting +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Beeps is out and he seems to be the only one with the knowledge on how to run/test this properly. But my change looks innocent enough and passes unittests.
|Uploaded patch set 2.
|Patch Set 2:

Please take one more look, Don's comment got me to take a closer look. The code is the same just made to look more like how the rest of the links are created.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 3: Reverted

This patchset was reverted in change: Id375929a6e8ee6ac98aae7ca174ff688c6cdac65
|Patch Set 1:

Awesome, thanks Dan.

Can you also commit an empty moblab_config.ini file?
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review-1
|Patch Set 2:

(1 comment)

Thought of an issue.
|Patch Set 4:

(2 comments)
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

I added/put them in the README, do you want them in the commit message as well.
|Abandoned

Kool thanks, I'll put up the corresponding CL for that.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(29 comments)

Sorry for the delay. PTAL at the new PS and https://chromium-review.googlesource.com/#/c/239321/
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

(11 comments)
|Uploaded patch set 5.
|Patch Set 5:

(4 comments)
|Uploaded patch set 6.
|Patch Set 6:

(8 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Verified+1

Sorry for the PS spam, Mike want to take a final look?
|Uploaded patch set 10.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

That was to keep max_runtime_mins backwards compatible with tests that did not supply it.

The 2 parameters are technically different. Timeout is from when the test is created. runtime is from once it starts.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)

I made your suggested change.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Code review for device-apt.txt change completed.
|Patch Set 1: (10 inline comments)

PTAL:
Wasn't sure if I should return a value if the permissions did not match as that would change the functionality if the directory exists and has different permissions. Darren said to log it but I wasn't sure if it should exit.

Please double check that I am outputting as octal correctly.
|Uploaded patch set 2.
|Patch Set 2: (16 inline comments)

PTAL:

I added uid &amp; gid checks. As well as mock_crypto.h and 2 more unit tests to check uid and gid logic.

I also changed the return type to bool.
|Uploaded patch set 3.
|Patch Set 3: (9 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (14 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (9 inline comments)

PTAL:

For the gmock setting valid output values in mock_platform I simply set the returned uid, gid to be 0. If there is a different default value or if i did not do this in the manner you wanted/expected please let me know.

For mock_crypto I'm not too sure how to set the valid output's if the input is an object passed in to be manipulated. if you can please elaborate I would appreciate that. Thanks.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (4 inline comments)


|Patch Set 7: (19 inline comments)


|Uploaded patch set 8.
|Patch Set 8: (2 inline comments)


|Uploaded patch set 9.
|Patch Set 9: Verified; Ready


|Uploaded patch set 10.
|Patch Set 10: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (32 inline comments)


|Patch Set 3: (20 inline comments)

@Tbroch Currently we are utilizing this codein some changes to autotest. https://gerrit.chromium.org/gerrit/#change,23049

I added the test sample code you suggested to the commit message. We can make the dut-control changes now or do it later if you want to expose this functionality through it. Let me know what you think.

-Simran
|Uploaded patch set 4.
|Patch Set 4: (3 inline comments)

Applied Tbroch's nits.
|Uploaded patch set 5.
|Patch Set 4: (8 inline comments)


|Uploaded patch set 6.
|Patch Set 6: (7 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready

Rebased and using LGTM from previous patch.
|Patch Set 1: (14 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (9 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: (20 inline comments)

Completed Scottz's suggestions except to use pxssh. Investigated it and looked at the source for pxssh and I don't believe it will work well with the Sentry CDU's prompt.
|Uploaded patch set 3.
|Patch Set 3: (11 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 4: (5 inline comments)


|Uploaded patch set 6.
|Patch Set 6: (2 inline comments)

Made the change from condition variable to a blocking Queue and pointed out how I handle the race condition.
|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: (9 inline comments)

Handled all but 2 of Richard's Comments. Will get to them momentarily.
|Patch Set 2: (2 inline comments)

Fixed everything but pushing off a response to Richard's comment about looping forever with potentially slow processes until I get a chance to discuss the issue with Scottz. If we don't expect the processes to generally take close to the Timeout time of 3 hours or hang often then the algorithm is most likely okay. However if this is a commonly occuring issue than we may want to try something different.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (6 inline comments)


|Uploaded patch set 6.
|Patch Set 6: (4 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Patch Set 7: Not Ready


|Patch Set 7: Ready


|Uploaded patch set 8.
|Patch Set 8:

Sosa or Masone can one of you take a last look at this?

Thanks,
Simran
|Patch Set 8: (10 inline comments)

Addressed or replied to Sosa's comments.
|Uploaded patch set 9.
|Patch Set 9: (2 inline comments)


|Uploaded patch set 10.
|Patch Set 10: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

Realized this morning there would be an issue if the dispatch server shuts down and does not unregister properly. Fixing and will release patch set 3 in a bit. Please hold off till patch 3.

Thanks,
Simran
|Uploaded patch set 3.
|Patch Set 3:

Ensured that if the dispatch server is unreachable the frontend server reacts appropriately.

Also fixed a bug in the unit tests where the mock objects were not being called properly and expanded the testing for increased coverage.

Feel free to review whenever possible.

Thanks,
Simran
|Patch Set 3:

Hmm good point, sorry about that. There's 2 key pieces and that's the frontend and the dispatcher + tests.

And the rest is pretty small shared sections.

How about:
Sosa/Masone - rpm_dispatcher, rpm_dispatcher_unittest, MultithreadedXMLRPCServer and rpm_config.

Scottz/Richard - frontend_server, frontend_server_unittest, test_client.

Thats about 50/50. Also nearly half the lines are my comments/docstrings so it looks bigger than it really is.

Let me know what you think about that division.
-Simran
|Patch Set 3: (3 inline comments)

Addressed Sosa's initial comments.
|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (39 inline comments)

Hey Sosa/Masone,

So I addressed or commented on all of Scottz's Comments. He asked me to follow up with you guys while he's OOO.

I know this CL is getting kinda of big now but you've already looked at half last week. Worse case I could break it up into multiple CL's if need be so let me know.

The files you didn't look at last week were frontend_server, rpm_config &amp; rpm_emailer (both small), frontend_server_unittests &amp; test_client.

About to post the next patch.

Thanks,
Simran
|Uploaded patch set 6.
|Patch Set 6: (15 inline comments)

Handled Masone's comments. However for his comment about the recursing calls to try different dispatchers I handled slightly differently than Masone suggested.

Before recursing I now ensure that there does exist a dispatch server, that is indeep up, within the heap. In the situation we can't talk to any dispatch servers we instead raise an exception up to the caller like Masone suggested.
|Uploaded patch set 7.
|Patch Set 7: (6 inline comments)

Addressed all of scottz's nits except the try/except one as I believe it is cleaner as is. Please take a look at the comment I put there in response.
|Uploaded patch set 8.
|Patch Set 7: (1 inline comment)

Changed the logging email subject line to use socket.hostname() and refactored out the set_up_logging code so it can be shared by frontend and dispatcher.
|Uploaded patch set 9.
|Patch Set 9: (1 inline comment)


|Uploaded patch set 10.
|Patch Set 10: Verified; Ready


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)


|Patch Set 5: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Gonna wait for Scott to take a look before I set commit ready.

Before is_job_complete had its return values swapped but all the callers (the main function and gs_offloader - I grepped for more but didn't find any) used the actual values.

I changed it so that it returns True when a job is completed. Just want to make sure there wasn't any special reason for the swapped values.
|Patch Set 3: (2 inline comments)

Added the logging but did not change it to return the results of _AFE.run since it returns a list not a True/False response.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 4:

K SGTM
|Patch Set 4: No score; Not Ready


|Patch Set 4: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: (4 inline comments)

Turns out the bug I was chasing that started Monday is just the old tests failing due to the power outage over the weekend. The rpms need to be reset to get an ip address and they have to be statically assigned for the cnames to work.

Aka I was chasing a false bug.
|Patch Set 2:

O whoops I was just adding that comment about the delay/issue I was chasing and I didn't mean to post all those comments yet. I need to go through and reapply them to the code and upload.
|Patch Set 2: (1 inline comment)

So Scott, I addressed everything but the only thing for now i default init to take in 'hydra1' and it looks up the information from the config. I think we need to decide how we're going to do naming semantics for the hydras.

Also I discovered an error in pycurl that would rarely cause the web interacting code to crash the python interpreter. In order to avoid this I subclassed dli to use urllib to get the webpage. I added more info to the commit message. So take a look.
|Uploaded patch set 3.
|Patch Set 3:

Augh sry I missed that comment and handled just ur inline comments. But yes its a good point, I guess the solution will have to be some sort of another abstract class above rpm_controller to handle hydra specific devices. ill get on that asap
|Patch Set 3: (2 inline comments)

So I moved all the hydra code into the abstract RPMController class, as an optional pathway. This way any type of RPM that inherits from RPMController has the option of being accessed directly or through a hydra device. This will work well for devices like the Sentry that are setup in both configurations, and devices like the WebControlled devices can opt out of this pathway completely.
|Uploaded patch set 4.
|Patch Set 4: (8 inline comments)

Added the kill previous connection code.
|Uploaded patch set 5.
|Patch Set 5: (7 inline comments)

Handled scottz's comments.

Now SentryRPMController is very simplistic and all it does is set Sentry Specific variables.

RPMController handles login/logout for all ssh devices including tunneling through a hydra.

Any expect calls that can have varying responses (i.e. the connection is held) now are expect_list calls and will determine whether or not the connection or CLI is held and if so disconnect the previous connection. This way we may not be killing connections incorrectly as we check for the specific case and we get error logging if this occurs.
|Uploaded patch set 6.
|Patch Set 6: (21 inline comments)

Addressed all but 2 of your comments that I was confused about which we can talk about at 15:00.
|Uploaded patch set 7.
|Patch Set 7: (1 inline comment)


|Patch Set 7:

Added a flag admin_override to authenticate_with_hydra to reuse the pexpect.spawn code to create an ssh connection.
|Uploaded patch set 8.
|Patch Set 8: (2 inline comments)


|Uploaded patch set 9.
|Patch Set 9: Verified; Ready


|Patch Set 1: Looks good to me, approved

Used the wrong acct before.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 4: (3 inline comments)

Handled scott's nits and pushed a new cl:
https://gerrit.chromium.org/gerrit/#/c/31032/
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)

Added the lookup, tested it on chromeos-autotest.cbf (it has that login but as user id 3 which it found correctly).
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2:

I know there's a bunch of discussion going on about how enterprise devices should act with this process, but Nirav wanted me to push out this CL and start getting it reviewed. So please take a look when you get a chance. Thanks
|Patch Set 2: (3 inline comments)

So we're changing the scope of this change to just preserve attestation.epb since we will not be having this feature on enterprise devices in the immediate future but we need attestation preserved at the moment.

I added the for loop where mattias asked for it. As well as reduced the scope to only allow us to preserve files in /mnt/stateful_partition/unencrypted/preserve/

Nirav has expressed a need for this to be in ASAP so please take a look again.
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)

Completed Richard's comments and just moved all the changes to clobber-state
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (2 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Patch Set 1: (2 inline comments)

Added the optional config debug variable.
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Im running this in python:
import db
db = db.db()
db.delete_jobs_before_date('2012-02-01')

I will soon add another python file that takes in 1 arg that will do all from the command line.
|Patch Set 1: (1 inline comment)


|Patch Set 1:

Its still iterating over all the values in numerical order however when I look at the db, I still see some entries that should have been deleted in test_iteration_result, so that is giving me some doubt that it is working unless the transactions did not complete right away or maybe I am overwhelming the system. I will keep it running and it may take a day or 2 to complete and we can check the results.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

So I ran about half of this last night and then it hit the 'View' tables which it can't really delete from so I got rid of those lines and also rewent through the list of tables to try to make sure I get what matters. Right now its running again but it'll take a couple hours till it completes or fails.

If it works now its more of a question of is this all the tables which I believe so. Theres are 5 afe_parameterized_job tables, which I'm not sure whats a parameterized job but those can easily be included if we want them to be.
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)

Current version, its on the second to last query so barring any foreign keys on the last query that I may have missed, this should complete successfully.
|Uploaded patch set 5.
|Patch Set 5: (7 inline comments)

Addressed your nits but added a 6 more queries to clean up afe_jobs more thoroughly so take another look.
|Uploaded patch set 6.
|Patch Set 6: (2 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready

Handled your nits and carrying on the LGTM from before. Feel free to execute when you're ready.
|Patch Set 1: (8 inline comments)


|Uploaded patch set 2.
|Patch Set 2:

Umm ya didn't know about the '-' as the destination being just a cat... and I'll defer about the location to Sosa but ya this may be pointless now that we know about '-'...
|Uploaded patch set 3.
|Patch Set 3:

Changed the scope of this to just be a new command inside cbuildbot_commands and there is no downloading to the temp directory anymore, it just calls gsutil cp with the destination being '-'
|Uploaded patch set 4.
|Patch Set 4:

Brian/Chris please take a look at these changes as they will provide the functionality we desire without adding a wrapper script.
|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 6: Looks good to me, approved

So I checked all the files that use gs.py and none actually called CopyInto and I double checked in the interpreter that this worked as we want it to. I'm marking it as LGTM but I'll wait for Brians approval before committing.
|Patch Set 6: Verified; No score; Ready


|Patch Set 6: Not Ready

Updating the commit message
|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready

Carrying over the +2 from Brian earlier before I updated the commit message.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved

(1 inline comment)

Just 1 more Nit/question
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 79bd368a18830af1ad6b55ab969c24c636b625f8
|Patch Set 2: Looks good to me, approved


|Patch Set 2: No score

(1 inline comment)


|Patch Set 2: Looks good to me, approved

k, then this CL looks good.
|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 2: (1 inline comment)


|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1:

So I had mixed up the Sentry cycle command which is actually 'REBOOT' but in an effort to make this work for any ssh-based devices I just changed it to turn the outlet off, sleep, then on.
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Just going to +2 and commit this since its a minor change.
|Patch Set 1:

While I have tested these changes we may not want to commit till we have ensured all the RPM's and DUT's are correctly named in the lab.
|Patch Set 1: (2 inline comments)

Fixed comments.

I filed crosbug.com/34726 yesterday, if that's not clear enough I can add another comment or create the audit bug.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Uploaded patch set 3.
|Patch Set 3:

Yes this is still blocked on the cname audit and RPM updating, I was just fixing that NIT you left me last week. I'll refactor the client calling code to site_host though.

As for hard_reset and the power warnings, I was going to do another CL for hardreset. I can wrap it in the same way they already do to disable power failure warnings. Or in site_host I can do the warning disabling/enabling in power off/on/cycle.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Patch Set 5: (1 inline comment)


|Patch Set 5: (1 inline comment)

Completed testing of hardreset.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

So I removed site_remote_power like you said.

However there were a couple of checks to see if calling RemotePower returned anything at all and then make the calls.

So I put a couple of checks for '.cros' in the hostname to make sure it is a lab machine. But I think it may be better to either add a new function is_labmachine() to site_host or keep  the remotepower function and have that do the determination if its a lab machine or not.

Ideas I have it check for '.labmachine' on the DUT or have the function look for .cros.

Let me know which idea you like better (if we even need to do it) and I'll wrap this up this weekend. I think on Monday I will just start filling in the remaining RPM outlets so we can unblock this as well and get John to handle the incorrect cnames.
|Patch Set 7:

Actually I'm going to refactor the way I check if we can use the RPM so don't look at the above patch right away, I'm going to adjust it in the morning.
|Uploaded patch set 8.
|Patch Set 8: (1 inline comment)


|Patch Set 8: (3 inline comments)

Came up with a solution to whether or not to determine if its on an RPM using regexes and hostnames. Haven't trouble testing but once I test it I'll push the next patch.
|Uploaded patch set 9.
|Patch Set 9:

ping
|Patch Set 9:

Which patch? I don't see the questions you are referring to
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: (1 inline comment)


|Patch Set 11: (1 inline comment)


|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14: Verified; Looks good to me, approved; Ready


|Patch Set 1: (1 inline comment)

So I need to update the RPM Infrastructure and find a stumpy (with the setpci cl I committed yesterday) or a kiev that is actually repair failed to make sure this whole process works from start to finish but I tested the different parts of it and it should be good.

At the same time we don't want to push this live until we have completed the lab cname audit. A lot of stumpy's and kiev's in sterling bay have not been configured with their RPM's yet.
|Uploaded patch set 2.
|Patch Set 2:

Hey Scott, sorry I was working on this in parallel with something else yesterday and I accidentally repo uploaded this project yesterday instead of the other project (and didn't realize what happened till I saw it now in gerrit) so it wasn't clean and ready for review. Hence the commented code and extra logging that was for helping me figure out the flow.

I did look through your comments though and I'll use those to help me wrap this up. Thanks.
|Uploaded patch set 3.
|Patch Set 3:

Not ready for review, just posting so we can look at it together in the sync up. I have a few questions
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

K, this should be good now. Feel free to take another look Scott. Thanks.
|Patch Set 6: (5 inline comments)


|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: (10 inline comments)

Handled all of Sosa's comments except not injecting the control file. I will look into that one tomorrow morning.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11:

Please don't look at this new patch right away, only uploaded it so I can test using a trybot, I'll message here when it is again ready to be looked at.
|Uploaded patch set 12.
|Patch Set 12:

Again not ready yet for more review.
|Patch Set 12: (1 inline comment)


|Uploaded patch set 13.
|Patch Set 13:

Ready for review again. Please take a look. I moved the todo with the gs_upload re factoring.
|Uploaded patch set 14.
|Patch Set 14: (2 inline comments)


|Patch Set 14: (1 inline comment)


|Patch Set 14: (6 inline comments)

The newest patch follows Scottz's latest comments however if Peter and him agree on a different solution I'll update it again.
|Uploaded patch set 15.
|Patch Set 15: (2 inline comments)


|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 17: Verified; Looks good to me, approved; Ready

Handled Scott's Nits and inheriting LGTM.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Patch Set 5: Ready


|Patch Set 2: Looks good to me, approved

(1 inline comment)

Looks straight forward to me, one nit that I'm not sure about, mostly a suggestion to keep it looking clean.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: (4 inline comments)

A few Nits.
|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Handled Richard's Nits and verified nothing broke.
|Patch Set 5: (2 inline comments)


|Patch Set 5: (1 inline comment)


|Patch Set 5: (1 inline comment)


|Patch Set 5: (3 inline comments)

Handled Richard's NITS and reverified the process works as expected.

Permissions are the same before and after. As to whether or not to do the loop to generate the full arguments to tar or to hardcode in the paths, I am impartial but this new patch keeps in the loop arg generation.
|Uploaded patch set 6.
|Patch Set 6: (2 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2:

Well the preserve directory was set aside to be the location where anything that has to be preserved would exist.

If accessing anything inside the encrypted directory will unencrypted it for the consumer then yes maybe we can move the preserve inside encrypted.

Essentially power wash moves (tars) the files we want to encrypt to /tmp, calls the wipe, and then moves (un-tar) the files back to the preserve directory.

As to whether or not moving files from encrypted to /tmp, wiping, moving the files back to encrypted will make a difference, I'm not sure but I'll follow up on Monday to see if this is something we can do/ is required.
|Patch Set 2: Abandoned

We will not be moving the lockbox.
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (7 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved; Ready

Inheriting LGTM
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Inheriting LGTM
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: (8 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Pinging the CL, since I pushed a patch over the weekend and we all just underwent a flood of emails about bugs/nagios.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (4 inline comments)


|Uploaded patch set 6.
|Patch Set 6:

Removed the forked signal_pid and added the try/except block to attempt to kill the pid into nuke_pid's for loop.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 378ed62071ec896a7eba57e55c1a0f17294902b4
|Patch Set 3: Looks good to me, approved


|Patch Set 1: (3 inline comments)

So I noticed you only test this with unittests, we implemented  the gs to stdio a little differently than you originally visioned due to there already being a google storage library. Please refer to that bug and update the code slightly.

Essentially stdio is captured but the RunCommand in cbuildbot and if you actually want it to go to stdio from this code, you would need to capture the result object and print result.output
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified

So this should fix the scheduler issue we saw this morning. My solution was to instead of just raising an error and crashing, instead change the state of the hqe or host to a state that it is looking for.

Alternate ideas:
* Abort this HQE/host job.
* And/Or create a cleanup/verifying/repair job for the host.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

So instead of reassigning the job state, we now instead tell the job to request an abort and on the next scheduler tick it will be killed.
|Patch Set 2: (1 inline comment)

Its pretty much the same as aborting the job through the AFE. It kicks off a cleanup job, and the host ends in 'Ready' once the abort completes.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: (8 inline comments)

Handled all of Alex's comments except the Decorator one, will figure that out tomorrow.
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)


|Patch Set 3: (9 inline comments)

@Scottz: Handled all of your comments, except the overall comment of using a dict. Let's discuss this a bit as I get the overall idea but the label can vary for a given method. I.e. in your example you used 'bluetooth' with has_bluetooth function however get_board will not always return the same board name.

I did making the naming more general and I used a decorator to automatically generate the list of functions. However I did need to use a nested decorator to make it work. Alex is going to take a look at that in case theres a cleaner way of making it work.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Patch Set 5: (9 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready


|Patch Set 7: Not Ready


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready

Renamed the decorator to something more general. Re-inheriting LGTM
|Uploaded patch set 9.
|Patch Set 9: Verified; Looks good to me, approved; Ready

Rebased
|Patch Set 1: Looks good to me, approved


|Patch Set 1:

This was what I was worried about, and did occur today for an RPM that was not properly set up. Those cleanup tasks ended in failure luckily we got the email notifications right away and John updated the RPM.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Chumping in.
|Change has been successfully cherry-picked as 154f558580c473b4cb24d55ee2ddd1223dbf0aa2
|Patch Set 1: Abandoned
|Patch Set 1:

My Trybot run is still running but if you look at the logs currently you can see that the benchmarks are running.

Job: http://cautotest/afe/#tab_id=view_job&amp;object_id=857770

Log File showing benchmarks running:
http://atlantis4.mtv.corp.google.com/results/857770-chromeos-test/chromeos1-rack7-host3/desktopui_PyAutoPerf/debug/client.0.log
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2:

Hey Scott, so I added some arguments in gs_offloader so we can launch two instances of it to handle hosts and/or all of results.

Alex is suggesting instead we should make the program launch multiple threads and have many different threads offloading different subdirectories.

Let's discuss in our sync-up tomorrow.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved

(1 inline comment)

One comment but I doubt it will be a real problem.
|Patch Set 1: Looks good to me, approved

(1 inline comment)

1 NIT no need for round trip
|Patch Set 1: Looks good to me, approved

(1 inline comment)

1 Nit
|Patch Set 1: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1:

Ya I was about to repo upload but I noticed something weird occurred after I tested it. So I want to verify that I didn't cause that. I'll post the patch once I verify it's good. Sorry about that.
|Uploaded patch set 2.
|Patch Set 2:

Sorry for the delay- repo syncing fixed that flake. Thanks
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 3: (2 inline comments)


|Patch Set 4: (3 inline comments)

Did a quick look but you did the logging messages incorrectly. This will error out.
|Patch Set 1: (3 inline comments)

Hmm yes it seems that other control file uses host_attributes to lookup the board. I'm not sure how the attributes are generated or where they are retrieved from but we may want to centralize that code. Currently host.get_board() will ssh to the machine and retrieve that info; however, if the machine is down that pathway will not work.

As not messing with the repair control segment, we can overload repair_with_protection in site_host and move all this repair logic there as a try/except around the super call. and then revert the repair file back to its original state.
|Patch Set 3: (1 inline comment)


|Patch Set 7: (37 inline comments)

K so I was Nit-picky and may have gone overboard but a lot of your alignment doesn't match the autotest standards.

In general: Align with the previous line, fit as many args as you can to 80 characters and wrap to the last open paren, etc.

Only when thats not possible then wrap using double indent (which is what you used mostly).

For strings that are too long just end at 80 chars or the last word and then continue on the next line. Python will automatically join the strings. And if they're not in an open paren just put it inside paren's.

I did point out a lot of violations about alignment but I may have missed some. But please take your time to go through and address this. Thanks!
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (8 inline comments)


|Uploaded patch set 5.
|Patch Set 5:

K sg, once the other one goes through the CQ i'll push it prod and run the sync command.
|Patch Set 5: Verified; Ready


|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified

This is the same code that was previously approved. The previous issue that caused this to be reverted was addressed in https://gerrit.chromium.org/gerrit/#/c/37760/
|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 1: Ready

Hmm not sure why this failed in the CQ, retrying since I don't believe autotest changes have any impact or testing done by the CQ (and the fact that I previously committed this code before successfully)
|Patch Set 1: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Patch Set 4: Verified; Looks good to me, approved

Chumping in.
|Change has been successfully cherry-picked as 94d9bd0eb3dc70f7261a39c3ba97b98aacb4acc0
|Patch Set 1: (2 inline comments)


|Patch Set 3: (2 inline comments)

2 quick nits
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 9b78ee13bc2fbb590ee11454ad649856e9ec064d
|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Ya I'm just going to abandon it since we changed a lot of this logic in that other cl of mine.
|Patch Set 1: Abandoned

Changes here no longer apply due to similar work I did in https://gerrit.chromium.org/gerrit/#/c/39125/
|Patch Set 1: Looks good to me, approved


|Patch Set 3: (1 inline comment)


|Patch Set 4: (6 inline comments)


|Patch Set 6: (1 inline comment)


|Patch Set 6: (1 inline comment)


|Patch Set 4: (10 inline comments)


|Patch Set 6: (1 inline comment)


|Patch Set 9: Looks good to me, approved

(2 inline comments)

2 Nit's besides that its good so no need for the roundtrip.
|Patch Set 12: Looks good to me, but someone else must approve

Scottz can you take a look at the difference between patch sets 11 and 12. Specifically how Richard is importing models.
|Patch Set 1:

So I tested this with changes to control.BVT locally.

I want to merge this code first and separately from that change so we can then push another cl for changes to the suite control files and then use a trybot to ensure that changing control.BVT won't timeout in the normal case on the actual lab-infrastructure.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved


|Patch Set 1: Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Try-bot hwtest was sucessful. Committing.
|Uploaded patch set 2.
|Patch Set 2:

I have another CL already in flight https://gerrit.chromium.org/gerrit/#/c/38419/

But once thats merged I'll rebase this one but I moved set_power with those changes in mind.
|Uploaded patch set 3.
|Patch Set 4: Verified; Looks good to me, approved; Ready

Inheriting previous LGTM
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 4:

ping
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 7f2da60ebcd9e18ef8a50bace9eb2d82bfc45295
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 7366305fb7ca0948cf5e5d94f476a052856deedc
|Patch Set 1: Abandoned

After discussion we have decided to no longer backport this to R21.
|Patch Set 1: Abandoned

After discussion we have decided to no longer backport this to R21.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as c9e6b0c65b7fbae187eda95fa13cd12e4b8811a4
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Patch Set 4: (1 inline comment)


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 5: (10 inline comments)


|Uploaded patch set 3.
|Patch Set 3:

So I just realized this would not Timeout if All the Jobs are Locked and Running.

That would be easy to add (add the check to wait_for_jobs_to_finish), but this matters in the situation we get a Try-Job HQE that starts Running and never finishes, does this occur?
|Patch Set 3:

Before I go through handling the comments, my thoughts on reworking the flow then would be only do a timeout/check for an abort if 2 conditions are met:

* There is only One Job in Jobs.
* It is a try-job

If those conditions are met, then check for the timeout and aborts. Does that sound better/more special-cased?
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3: (15 inline comments)

Simplified the Logic:
* Now we don't determine or special case this process for Try-Jobs.
* If a timeout is provided and we run overtime, job_status will abort all jobs in jobs for wait_for_jobs_to_start and wait_for_and_lock_job_hosts.
* If in *_start there is a timeout, this is considered a failure.
* If in *_jobs_to_start there is a timeout, the locked hosts are returned and then reimager will use a new public method in job_status: check_job_abort_status to determine if this any jobs in jobs had too high a % of their HQE's aborted and if so the reimager job will abort as well.
|Uploaded patch set 6.
|Patch Set 6: (1 inline comment)


|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved; Ready

Removed those extra characters, inheriting previous LGTM.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 1: (10 inline comments)


|Patch Set 2: (5 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (5 inline comments)


|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved; Ready; Verified


|Patch Set 6: Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3:

Waiting on scottz's take before submitting.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: (7 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (2 inline comments)

Augh sorry, I mis removed the wrong set of quotes.

So for the UMA side what I remember reading when I looked into it: you add the client side code and that will send it to the UMA server.

Now for the server I'll have to do a different CL to add this histogram to the XML file that lists out the histograms but I don't believe that is Chrome Version specific.
|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved; Ready; Verified


|Patch Set 5: (2 inline comments)


|Patch Set 7: (2 inline comments)


|Patch Set 8: Looks good to me, approved


|Patch Set 2:

For testing: I log into chromeos-autotest.cbf using become chromeos-test

I usually scp in my new changes and do small script modifications before running gs_offloader:
* change it to offload to gs://sbasi-test instead of the actual folder
* Comment out the os.rmtree line.

This should then just loop over the results folder and keep offloading (without deleting) the test results.

*Alternative is backup those dummy test results in /usr/local/autotest, offload them all and when done testing put back the dummy results.
|Patch Set 2:

changes look okay to me- just ping the cl once its been tested.
|Patch Set 2: Looks good to me, approved

Looks good, hopefully this will end our offloader woes.
|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3:

Sorry for the delay in responding to this but testing wise I just ensured the scheduler works as expected still as this is simply adding a new exception catching case.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: (3 inline comments)

Code looks fine but some of the naming and docstrings aren't entirely correct.
|Patch Set 4: Looks good to me, approved


|Patch Set 2: Ready

Failed CQ, assuming not this CL's fault and re committing it.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved

Dan, talk to me tomorrow about how to test your change so we can make sure this doesn't break the system again.
|Patch Set 2: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

One NIT: Which was my fault for suggesting it in the last patch.

LGTM: No need for the round trip so once you make the change just CR it.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

(9 inline comments)

+1 in the sense that it worked on my system.

I do have a couple of stylistic comments that should be looked at before Alex +2's
|Patch Set 10: (2 inline comments)

A couple nits.

+1 Alex's comment of a unittest.
|Patch Set 13: (2 inline comments)


|Patch Set 1: Ready; Verified


|Patch Set 2: (2 inline comments)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved

LGTM: I doubt anyone else will object.
|Patch Set 6: (3 inline comments)


|Patch Set 9: Looks good to me, but someone else must approve

(1 inline comment)

One NIT: but I'd prefer Alex gives the +2 since he was involved in most the review for the logic.
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: (4 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

LGTM, though I wouldn't be surprised if you somehow break the offloader again :)
|Patch Set 1: Fails


|Uploaded patch set 2.
|Patch Set 2: Verified

I couldn't get a message at the very end but this should be enough to help us know what is happening.
|Patch Set 2:

I couldn't get a message at the very end but this should be enough to help us know what is happening.
|Patch Set 2:

Ya sounds good, i'll file that and add the TODO and tomorrow we can push this and keep our eyes open for problems.
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 3: Not Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2:

If you want to see the resulting tar ball take a look at autotest.tar under https://storage.cloud.google.com/?arg=chromeos-image-archive/trybot-lumpy-release/R26-3601.0.0-b700

and you will see the dep-telemetry_dep.tar.bz2 under packages.

Note if you want to run it you have to extract both that tar and dep-page_cycler_dep.tar.bz2 in order to have all the necessary files.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)

Per Sosa's comment I discovered I actually was packaging too much as chrome_test packages some of the files I need.

@DTU - can you double check the folders I have packaged for telemetry to make sure I have what I need.
|Patch Set 3: (1 inline comment)


|Patch Set 3:

So I talked to Sosa and what I'm going to do it submit this as is with a TODO to make it more dynamic once the bootstrap script is in and works as we need it to.

That way we can start working on the autotest infrastructure side of things at the same time and update this once thats ready.

I'd add wiltzius but seems I can't, he probably doesn't have a gerrit account, so I'll just add what I need to his review there.

Let me know if you have any problems with this plan.
|Uploaded patch set 4.
|Patch Set 4: Fails

Please don't take a look yet, will mark as Verified when ready for review.

Need to do some more testing with trybots before confirming this works.
|Patch Set 4: Verified

This is indeed working. Please take a look when you all get a chance, this works now through the use of the bootstrap script that exists withing the chrome source folder.
|Uploaded patch set 5.
|Patch Set 4: (9 inline comments)


|Uploaded patch set 6.
|Patch Set 5: (2 inline comments)


|Patch Set 6: Looks good to me, approved; Ready; Verified

This work is now complete and whatever is listed by the telemetry_bootstrap script will be packaged into chromeos's autotest tarball.
|Patch Set 1: (3 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 4: Reverted

This patchset was reverted in change: I8a19d30651ba2380a5f1e4af4f47ff343e76a066
|Patch Set 1: (4 inline comments)


|Patch Set 4: (1 inline comment)

Did you test this with and without the option?
|Patch Set 5: Looks good to me, approved

(1 inline comment)

One NIT, no need for the roundtrip.
|Patch Set 3: Reverted

This patchset was reverted in change: I6a6f0c170d5410de79ad0d2b96c7b9c95046cae4
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 285b5338b83d873abc7afec8b0ddf99d56e1b6b6
|Patch Set 1: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Patch Set 3: Looks good to me, approved

(3 inline comments)

LGTM a few NITS, but I like this much better.

No need for the roundtrip after you fix these.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Verified


|Change has been successfully cherry-picked as eb3c33199082030e1a6e8ccb8b3db7a052bfe381
|Patch Set 1:

Please prepare and test the CL that will use this first
|Patch Set 7: Looks good to me, approved


|Patch Set 2: (4 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 1:

Hmm this might cause issues as the importing of the global config requires common to work...

A better solution would be to copy common.py from the other other test directories (you'll find copies of it everywhere).
|Patch Set 1:

autotest* directories I meant
|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Just kicked off a try job, going to ensure that the try-bot image works completely with my devserver changes before committing.
|Uploaded patch set 2.
|Patch Set 2:

Glenn asked me to preserve one more file, kicking off a try-job to verify. If this all works and I hear no objections I will commit this later tonight.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Wrapper scripts successfully packaged, committing.
|Patch Set 2: (7 inline comments)

a couple nites
|Patch Set 2: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 2: (1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Please file the bug and put the TODO at the top of this file before committing.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2:

Please ignore my refactoring that will have to be fixed once sosa's changes land. Otherwise please focus at the RPC call and telemetry_runner.py as those will likely not be affected and reviewing now will speed things up later :).

Thanks!
|Uploaded patch set 3.
|Patch Set 3:

Changed so now the dev_server just sets up telemetry and returns where it is installed.
|Uploaded patch set 4.
|Patch Set 4:

@Chris:

So I changed it to rebase your new extraction code to common_util, and also added the lines to stage autotest automatically in stage_telemetry.

However because the telemetry files are inside of the autotest tarball I didn't make it into an artifact, instead I added the locking code here.

The reason for this is I didn't see a clear way to utilize the artifact locking code as it technically does not need to download anything from google storage at this point. And the locking code for artifacts seems to be inside BuildArtifact.Process which goes through the process of downloading then staging the files.

So just let me know if you don't agree with the solution I went with.
|Patch Set 4: Fails

I think the locking logic may be a bit off, hold off on review . :/
|Uploaded patch set 5.
|Patch Set 5: Verified

(1 inline comment)

This should be good. PTAL at my previous message too.
|Uploaded patch set 6.
|Patch Set 5: (7 inline comments)


|Patch Set 6: Looks good to me, approved; Ready; Verified

\o/ woot all unittests passed, submitting.
|Patch Set 3: (6 inline comments)

Please refactor the changes to site_host so that it is not redundant and will look cleaner.
|Patch Set 4: (15 inline comments)

lots of style inconsistencies involving quotes and spacing
|Patch Set 6: (2 inline comments)

Question why do we need to pass in power_control as an arg?

You may have been trying to get this point through to me the other day but it may be better to automate this:

if in the lab: use rpm/servo (whichever it is expected) - and if something is wrong with this, ensure the test fails and doesn't use manual.

else if servo is connected: use servo.
else: use manual.

I think this is what you were trying to tell me the other day Yusuf but it just clicked.

However it would be very good if its using Manual that it yells about it loud enough that we know if there are any debugging problems.

Anyways the code is close, but I have a feeling we may not need the new arg anyways. (also work for replacing run_remote_tests may remove --args)
|Patch Set 8: (8 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 3: Looks good to me, approved

(1 inline comment)

LGTM: One Nit, no need for roundtrip
|Patch Set 1: (1 inline comment)


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 2: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 22: Reverted

This patchset was reverted in change: I8aaf6394491592f18880808df801bc8c5200d5b6
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

Please take another look.

Luckily my TODO's were rendered no longer necessary and as some new telemetry changes (currently in review in chrome but the patches work) fix those problems.
|Patch Set 4: (1 inline comment)

Heh... I actually did remove the old debugging early on in fixing comments but in later debugging put it back. Good catch.
|Uploaded patch set 5.
|Patch Set 3: (14 inline comments)

Oo... Sorry I thought I had published all these...
|Patch Set 5: (1 inline comment)


|Patch Set 5: (2 inline comments)


|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 6:

So drumroll please: here is a new major patch.

Changes:
* Fixed previous comments.
* Allow the use of Tests as well as benchmarks.
* Added a test to test Tests.
* Added the concept of a TelemetryResultObject to hold result output plus statuses to allow us to differentiate between Warnings and Failures and Success.
* Added parsing of the Telemetry output to generate the TelemetryResultObject and grab the perf key val's we want to upload.

Rather than looking at the whole thing again I suggest diff-ing between patches.

Thanks!
|Patch Set 6: (10 inline comments)


|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: (2 inline comments)

Addressed last set of comments and added parsing unittests please take a look.
|Uploaded patch set 9.
|Patch Set 8: (6 inline comments)


|Patch Set 9: (1 inline comment)

Ran ./site_utils/run_suite.py --build=stumpy-release/R27-3806.0.0 --board=stumpy --suite=telemetry_benchmarks

Successfully
|Uploaded patch set 10.
|Patch Set 10: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

One nit, no real jarring issues but it would be good for a second look before committing
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Guess there was a reason we had the other exception to begin with.
|Patch Set 1:

So seems like theres some contention on whether or not to actually make this change.

I kinda just hopped on the bug as it was something I knew how to handle pretty easily, we can decide here if we want to do this change, make it a third button instead or just straight up abandon it....
|Uploaded patch set 2.
|Patch Set 2:

After talking to Scott, this change now just adds a third button rather than replace reinstall.
|Patch Set 2: (1 inline comment)

Added a unittest for repair_hosts
|Uploaded patch set 3.
|Patch Set 3:

ping
|Patch Set 3: Looks good to me, approved


|Patch Set 3: Ready; Verified

(1 inline comment)

Thought I had committed this already, marking as ready.
|Patch Set 1: Looks good to me, approved


|Patch Set 2:

Best lab sheriff ever
|Patch Set 3: (3 inline comments)

Looks good, have a few questions as to why you do some stuff in control.repair, seems unnecessary.
|Patch Set 4: (3 inline comments)

2 NIT's and a suggestion.
|Patch Set 5: Looks good to me, approved

(1 inline comment)

Then this all looks fine to me, +2-ing unless someone else wants to chime in.
|Patch Set 1: Looks good to me, but someone else must approve

Code looks clean enough to me but leaving to Todd to double check the effect of running those commands.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 4d7bca2b124b10ae1cee9a0ca711dea10bfab1a6
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 37eeff11d8f22eba0464746f8f0d03216fc9e6ab
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 899f9fe5de55df0b7e96f732cef99b8c9a372c5e
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved

K sounds good
|Patch Set 1: Looks good to me, approved

(1 inline comment)

1 Nit no need for round trip
|Patch Set 2: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Patch Set 5: (4 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (2 inline comments)


|Patch Set 7: Ready; Verified


|Patch Set 1:

Nope it fixes it as now the .labmachine file is dropped (eariler in the machine_install script) and we just need to rerun this upstart job for it to take affect.

This was the solution Richard and I discussed and compared to the others figured it was the best way to go.

https://gerrit.chromium.org/gerrit/#/c/44537/ adds comments to this upstart script so that any modifiers know it will be ran twice.
|Patch Set 2: (2 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Ready; Verified


|Patch Set 1: (1 inline comment)


|Patch Set 1: (2 inline comments)


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (8 inline comments)

I feel like there is a less hacky way to do this without so much 'currying' maybe subclass socket.socket and replace the udp_sock and override send_to?

probably would look cleaner.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 4: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Patch Set 1: (3 inline comments)


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)


|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 1:

Looks like when I renamed interfaces_common.py to servo_interfaces.py I forgot to git add...

Same changes though.
|Patch Set 1: Looks good to me, approved; Ready; Verified

I'll patch in those changes in my next patch.
|Patch Set 4: (5 inline comments)

couple comments and questions
|Patch Set 5: Looks good to me, approved

(1 inline comment)

One Nit (that applies to 3 places) about Java style - but I don't think we really have one (that I know of).

Otherwise this looks fine.
|Patch Set 7: Reverted

This patchset was reverted in change: I00185888d74d1f70f0284a04633f923ae019e804
|Patch Set 5: (1 inline comment)


|Patch Set 6: Looks good to me, but someone else must approve

(3 inline comments)

+1 with NITS
|Patch Set 1: (2 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved

Ya this looks better now.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1:

Fixed Aviv's comments but I removed memory benchmark as a bug chrome side was found with it. Will add back in future CL.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified

Inheriting +2
|Patch Set 3: Not Ready


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified


|Patch Set 4: Ready


|Patch Set 4: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 3: Verified


|Patch Set 3:

Thanks Aviv, will wait till the morning before committing to give Scott or whoever a chance to look at it.

Or forever hold their peace.
|Patch Set 3: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 3: (2 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (2 inline comments)


|Patch Set 5: Looks good to me, approved; Ready; Verified

Handled last 2 NIT's Inheriting LGTM.
|Patch Set 1:

Feel free to debate away if any of you are not happy with this solution.
|Patch Set 1: Abandoned

WontFix
|Patch Set 3: (2 inline comments)


|Patch Set 4: Looks good to me, approved

Thanks for refactoring it, looks a lot cleaner this way :)
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2:

PING +sosa...
|Uploaded patch set 3.
|Patch Set 3:

patch set 3 is just a rebase
|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified

inheriting lgtm
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved

It looks fine to me but like you said this is the first Eagle Eye thing I'm reviewing. Feel free to take the LGTM or ask someone else to take a second look if you want.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Do not submit

looking over this we should never change common.py, I'm working on finding a way for you to import telemetry.

Changing common.py in this way would break all of autotest as most DUT's will not have that directory installed.

I get this is an example but just -2'ing to ensure this does not get checked in.
|Patch Set 1:

ignore this, just for a trybot.
|Patch Set 1:

ya i know, i forgot till after :/
|Patch Set 1: Abandoned

change is not necessary.

but now i know for sure the left side of my keyboard works.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (3 inline comments)


|Patch Set 3: Fails

We discussed this and we are going to change the flow such that telemetry is installed in the test image/python path and can be imported directly.
|Uploaded patch set 4.
|Patch Set 4: Fails

Do not look at this yet, asking scottz a question about this code.
|Patch Set 3: (5 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Verified

PTAL, this is now a cleaned up version that can import telemetry directly since it is now part of a test image's python path.
|Patch Set 5: (1 inline comment)


|Patch Set 5: (2 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Verified


|Patch Set 6: Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved; Verified


|Change has been successfully cherry-picked as 40836b21dd61fb48a6528ec83238975aa63708b0
|Patch Set 1:

Spit out an error when -A is missing
|Patch Set 2: Looks good to me, approved

(2 inline comments)

2 NITS no need for round trip
|Patch Set 1: (7 inline comments)


|Uploaded patch set 2.
|Patch Set 2:

Reworked this via Scottz's suggestion. So all except Dromaeo all share the same python file.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Patch Set 5:

Actually decided to rework this one more time so that the general case supports running a list of page_sets.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Uploaded patch set 8.
|Patch Set 8: Verified


|Patch Set 8:

ping
|Patch Set 8: Looks good to me, approved; Ready


|Patch Set 8: Ready


|Patch Set 8: Ready


|Patch Set 1: Verified


|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as a1211b9d81e3e04321ecd70af74287007deff8d0
|Uploaded patch set 2.
|Patch Set 2: Fails


|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3:

Skip patch set 3, Richard posted comments right as I pushed, patch set 4 will be arriving imminently
|Patch Set 2: (4 inline comments)


|Patch Set 3: (2 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified

Tested via try-bot, works.
|Patch Set 4: (6 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

Fixed previous set of comments.

David James/Vapier can you take another look?

Also I added a new ebuild similar to autotest-chrome called autotest-telemetry to hold telemetry related tests.
|Patch Set 6: (14 inline comments)


|Uploaded patch set 7.
|Patch Set 7: Verified


|Uploaded patch set 8.
|Patch Set 7: (1 inline comment)


|Patch Set 8: Looks good to me, approved; Ready; Verified

Rev-ed the autotest-all ebuild and inheriting lgtm
|Patch Set 8: Ready


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 3: (4 inline comments)


|Patch Set 1: (9 inline comments)

So I started reviewing with autotest style in mind, compared to a couple files in cbuildbot but a few of my style remarks may not be correct.

Also would like someone more well versed in regexes to look over your regexes.
|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)

1 more NIT, +1'ing as I would like a more regex experienced person to review those 2 lines.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 4: (1 inline comment)


|Patch Set 3: (1 inline comment)

This code looks similar to stuff in the afe/rpc code. Would be good to do a refactor or to use that.
|Patch Set 7: (5 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved

Thanks for handling this Dennis!
|Patch Set 1: Fails

Not ready for review, simply posting so Todd can test.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 3: (6 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified

Addressed your previous comments PTAL
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified

@tbroch, tested and reworked the read logic. PTAL
|Patch Set 7: Ready


|Uploaded patch set 8.
|Patch Set 8: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: (3 inline comments)


|Patch Set 3: (1 inline comment)

Please follow autotest/files/CODING_STYLE

UNLESS this is a very old autotest file which has a different style to begin with. Since Chaos lab is relatively new I suggest you follow the style guide.
|Patch Set 3: (6 inline comments)

Did a quick pass through and found some style problems with these 2 files.
|Patch Set 4: Looks good to me, but someone else must approve

Still-wise I approve
|Patch Set 4:

style*-wise
|Patch Set 1: Looks good to me, approved

(1 inline comment)

One NIT that gerrit is showing.

I downloaded and tested it with my changes, no errors/warnings and able to interact with the elements listed by dut-control.

+2'ing not sure if you want another opinion or not from someone else tho.
|Patch Set 1: No score

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

Added bus_num to parems
|Patch Set 3: Looks good to me, approved


|Patch Set 3: Ready; Verified


|Patch Set 1: (1 inline comment)


|Patch Set 1: (19 inline comments)


|Patch Set 2: (2 inline comments)


|Patch Set 3: Looks good to me, approved

Thanks adding the examples, a lot easier to understand this way :)
|Patch Set 1: Looks good to me, but someone else must approve

(3 inline comments)

A couple NIT's.

Alex if you can take a look today too that'd be great - besides my Nits this looks okay to me and Pramod would like us to get this out at some point today.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified

Patched in your changes and tested on V2 &amp; V3
|Patch Set 1: Ready


|Patch Set 1:

Hey Todd,

So I took the gpio's listed in servo_v3_setup.sh and added them to this XML.

I talked to David and seems like most of these are output controls, except he said the _ocs lines are inputs when stuff goes wrong.

And I looked through the V2 xml and I couldn't find any of these signals with od=&quot;PU&quot; in the old version (though it is possible I missed it)

How is the best way for me to test the inputs via dut-control?
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2:

Ping!

@Tbroch, anyone else I should put on this review to help get it moving?
|Patch Set 2: (17 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Fails


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified


|Patch Set 5: (2 inline comments)


|Patch Set 5: (7 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Uploaded patch set 8.
|Patch Set 8: Verified


|Patch Set 8: (8 inline comments)


|Uploaded patch set 9.
|Patch Set 9: Verified


|Patch Set 9:

I purposely changed it when I realized the old ftdi interfaces were double quotes instead. Figured I should go that way for consistency but I can change it back.
|Uploaded patch set 10.
|Patch Set 10: Looks good to me, approved; Ready; Verified

Inheriting LGTM :)
|Uploaded patch set 11.
|Patch Set 11: Looks good to me, approved; Ready; Verified

Rebased and retrying.
|Patch Set 11: Ready


|Patch Set 4: (1 inline comment)


|Patch Set 6: (2 inline comments)


|Patch Set 8: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3:

ping
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

inheriting previous lgtm
|Patch Set 1:

So this change assumes we're going to stick to this folder for chrome-os specific tests.

The alternative is update the deps for telemetry. But I have a feeling Nat might not like that as this isn't exactly a dependency to run telemetry. Thoughts?
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 3: Looks good to me, approved; Ready


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified


|Patch Set 4: Ready


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Patch Set 6: (2 inline comments)


|Patch Set 7:

NVM looks like you fixed my comment right as I posted it.

Dennis just to double check you did a full build from scratch with these changes correct?
|Patch Set 8: (1 inline comment)


|Patch Set 8: (1 inline comment)


|Patch Set 9:

That sounds to me like telemetry was built-in and running; but the checkout you have is broken.
|Patch Set 10: (2 inline comments)


|Patch Set 5: (16 inline comments)

A couple of NITS but besides that I don't see any glaring issues.
|Patch Set 7: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 2: (22 inline comments)


|Patch Set 3: (2 inline comments)


|Patch Set 4: (12 inline comments)


|Patch Set 5: (13 inline comments)

Mostly NIT's.
|Patch Set 9: (1 inline comment)


|Patch Set 10: (8 inline comments)

mostly just nits at this point.

So its almost all periods. My suggestion:
* '#' comments should end with a .
* Most logging messages that don't end in %s should end in period. if it does in %s I'll leave it to your judgement.
|Patch Set 12: Looks good to me, approved

Sorry for the delay Fang, but good job - this turned into one pretty huge CL in the end :)
|Patch Set 1: Looks good to me, approved

(2 inline comments)

LGTM with a few nits
|Patch Set 1: (2 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: Ready; Verified


|Patch Set 1: (6 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 2: Ready


|Patch Set 1: (10 inline comments)

NITS, i disagree with some of Thieu's style comments tho.
|Patch Set 1: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 6: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)

I'm crowd sourcing this review.

If anyone has things they would like added/changed/removed from the Style Guide please comment in your requests and I'll make the fixes.

I think most the information is correct, people just weren't seeing it clearly so made a few changes to help with that.
|Patch Set 2: (1 inline comment)


|Patch Set 2: (11 inline comments)


|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Patch Set 4: Ready


|Uploaded patch set 2.
|Patch Set 2:

I'll be adding unit tests for bbuart.py but the rest is ready for review. In case you get bored in your hotel room Scott :) or up super early on Monday.
|Patch Set 2: (1 inline comment)


|Patch Set 2: (1 inline comment)

Replying to Todd.
|Patch Set 2: (21 inline comments)


|Uploaded patch set 3.
|Patch Set 3: (7 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (3 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 3: Looks good to me, but someone else must approve

I don't see anything glaring wrong but reserving the +2 for whoever did your previous provisioning reviews.
|Patch Set 2: (1 inline comment)


|Patch Set 7: Looks good to me, approved

(2 inline comments)

Fix those 2 comments then inherit the lgtm
|Patch Set 3: (4 inline comments)


|Patch Set 4: Looks good to me, approved


|Patch Set 2: (1 inline comment)


|Patch Set 2: (2 inline comments)


|Patch Set 5:

(1 comment)
|Patch Set 2: (1 inline comment)

Not sure why I did not do iteration_result but yes thats a good catch. I followed the diagram at https://github.com/autotest/autotest/wiki/TkoDatabase and yes its on there so I must have missed it.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 2: (13 inline comments)


|Patch Set 3: Looks good to me, approved

(1 inline comment)

1 last nit
|Patch Set 1: Verified


|Patch Set 1: No score

I'll find a way to run at my desk then mark verify.
|Patch Set 1: Verified

platform_InstallTestImage worked with the lab infrastructure!
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Patch Set 2: (1 inline comment)


|Patch Set 1: Verified


|Patch Set 1:

Well this code change only impacts Servo V3 code. All the V3's we setup in the lab have an image with my new kernel.

I doubt we'd want to launch/setup a V3 without my image or kernel. Though it will be a requirement for Richard's CrOS image to have support for I2C-2.

Let me know your thoughts before I CR this.
|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved

Nice - looks like we'll be able to powerwash enrolled devices soon.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (5 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 6: (4 inline comments)


|Patch Set 7: (1 inline comment)


|Patch Set 9: Looks good to me, approved


|Patch Set 6:

I'm confused on where test_suites/control.test_that_wrapper gets found/used/called. Please elaborate
|Patch Set 6:

(1 comment)
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: No score

(1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

(5 inline comments)


|Patch Set 5: (1 inline comment)


|Patch Set 6: (1 inline comment)


|Patch Set 7: (1 inline comment)


|Patch Set 8: (2 inline comments)


|Patch Set 10: Looks good to me, approved


|Patch Set 2: (7 inline comments)


|Patch Set 7: (10 inline comments)


|Patch Set 8: Looks good to me, approved


|Patch Set 1: (6 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 7: (1 inline comment)


|Patch Set 8: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

LGTM w/ 1 NIT
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 4: (6 inline comments)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

Can't you just do
MAPPING_FILE = os.path.join(os.path.realpath(__file__), rpm_config.get('CiscoPOE', 'servo_interface_mapping_file'))

where you use the file. I don't like the idea of hardcoding in this full path.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved

(1 inline comment)

Looks good, just added a comment to your TEST line of what I do after I powerwash to verify functionality.
|Patch Set 2: Looks good to me, approved


|Patch Set 2:

Hmm, so dli.py was provided by the manufacturer of the Web Powered RPM's. We actually have no modifications to it so it'd be good if somehow we can do this without modifying this file.

Could we do this around the import of dli.py instead?
|Patch Set 3:

Hmm but do we need these unit tests to run in the chroot at all? This is all code that never runs in the chroot.
|Patch Set 3: Looks good to me, approved

K well if this is the best idea we got for the moment I think I'm fine with this change then.
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 3: Not Ready


|Patch Set 3: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 2: (4 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1:

Pretty sure, akeshet hunted down that failure to be a different CL https://code.google.com/p/chromium/issues/detail?id=255170
|Patch Set 1:

No the CL that turns on the new testing was in that CQ run https://gerrit.chromium.org/gerrit/#/c/59942/

That can't land until ToT is fixed. So as long as thats not +1 Ready, we'll be good.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready; Verified

Uhh that looks like the tool-chain folks got something else going on... I'll ping Ahmed and let him know use run_measurement.
|Patch Set 1: Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: (5 inline comments)

A couple of NIT's.

Mostly why are you using prints instead of logging?
|Patch Set 3: Looks good to me, approved


|Patch Set 1: (1 inline comment)

When I was working on UART and creating servo_v3_r0.xml I was running into the issue that I needed those empty signals in the xml file. If you look at the &lt;params&gt; section it's empty.

At the moment I was more busy with getting UART up and when I asked Todd, he said mark it with a TODO for the moment. So this is me cleaning up that TODO with an actual fix rather than a workaround.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: (10 inline comments)

+1 Alex's comment on reading and fixing the style. I gave you some initial style comments to help get that moving in the right direction.

Once you've done that it'll be much easier to look at the actual code and figure out what is going on.
|Patch Set 3: (11 inline comments)


|Patch Set 4:

Hey Chester, how important is it that these tests run together in the same test?

If not, it may be better for you to refactor a bunch of logic, and make a bunch of small tests that share the refactored module. Then you can test easier if playing, paused, resumed, seeking, ending break individually. And you can run all the tests by using a suite as per Alex suggested in the email thread.

http://www.chromium.org/chromium-os/testing/test-code-labs/dynamic-suite-codelab


Note this would require a bunch of smaller files but would give you a much better suite and granularity in testing.

And you would kick all the tests off by using run_remote_tests suite=[whatever you name the suite].
|Patch Set 8: (8 inline comments)

Looking a lot better Chester, almost there!
|Patch Set 10: Looks good to me, approved

(1 inline comment)

Good job Chester this looks great.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, approved

(1 inline comment)

1 Nit, apply everywhere in that file.
|Patch Set 1:

Rohit can you sync up with Chester (dunno@) and make sure theres no duplication of work. He's saying he's working on base html5 implementation of youtube and you're using the iframe version.

We may want to swap the naming/clarify the differences between the 2. Bonus points if you two can refactor and share some code for manipulating the player. Though his javascript works on the window object and your's uses the player object.
|Patch Set 1: (17 inline comments)


|Patch Set 3: Looks good to me, approved

Hey Rohit,

This change looks good to me. But I think we need a better resolution on this player.set().return business.

At the very least if you feel this should be resolved in telemetry: file a bug against them, add a TODO to remove the '.return's once that bug is resolved and a comment explaining why you needed to add it.

Besides that this LGTM.
|Patch Set 6: (3 inline comments)

Almost there, glad we got rid of the '.return' as well.
|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 7: Looks good to me, approved


|Patch Set 1: (2 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 1:

Achuith has a good point, please make this an experimental test and we can verify if its flakey or not.
|Patch Set 3: Looks good to me, approved

(1 inline comment)

1 Nit
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(1 inline comment)

Doing this review as Alex will be OOO tomorrow and Beeps and I would like this to land in tomorrow's devserver push.

One nit.
|Uploaded patch set 2.
|Patch Set 2:

Hmm ya Dan has a good point, please hold off until review let me see why exactly I have to do that trick to make this work.
|Patch Set 2:

K Alex explained the hack is required due to requiring a scheduler tick to take the HQE from Queued -&gt; Aborted.

This hack may be acceptable due to a lot of this code getting dropped soon.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 2: Not Ready


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 1: (3 inline comments)


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Patch Set 2: (4 inline comments)


|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Patch Set 5: Reverted

This patchset was reverted in change: I8ae4b5009d0a79fead9120062947e3d4c77a071a
|Patch Set 3: (3 inline comments)


|Patch Set 5: Looks good to me, approved

(2 inline comments)

2 Nits, no need for a round trip after that.
|Patch Set 1: (2 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: (9 inline comments)

So this your second API change this week... is there no way to do this without changing the API again?

I see that the only code that really merits the change is the extention support you added in chrome.py but couldn't the caller use the browser object to get its extensions?
|Patch Set 4:

K then once again please inform Chester (dunno@) and Rohit
|Patch Set 4: (2 inline comments)


|Patch Set 6: (1 inline comment)


|Patch Set 7: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 1cbc5f206a0e3372daf9a110da0e36d5d29ab0c4
|Patch Set 1: (1 inline comment)


|Patch Set 1: Ready; Verified


|Patch Set 2: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: (3 inline comments)


|Patch Set 4: Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 3: Abandoned
|Patch Set 1: (6 inline comments)


|Patch Set 2: Looks good to me, approved

(1 inline comment)

1 NIT
|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

NIT: Style is wrong... Aviv will fix in future CL.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

Trybot run succeeded! Please just update the TEST= line and commit :)
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: (3 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved; Ready; Verified

Updated the docstring as per Scottz's NIT. This change now only has the piping of servo board version.

Inheriting +2, and moving the version specific code to a new CL.
|Patch Set 1: Verified

This is the second half of the previous CL. This contains the actual fix we need to support these controls on V3.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

I don't see anything glaring wrong but as I don't know the bt spec, I'll wait for other reviewers to chime in before +2-ing.
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

A little hackish but after our discussions this is definitely the easiest way to accomplish this.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Ready

If Scottz says its okay, committing.

Sorry Alex lol
|Patch Set 1: Verified


|Patch Set 1: Looks good to me, approved

(1 inline comment)

Just fix the comments to be consistent and you're good to go.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 5: (6 inline comments)


|Patch Set 6: (5 inline comments)


|Patch Set 7: Looks good to me, approved

(2 inline comments)

Found 2 actual bugs but they're minor. Fix and then feel free to commit.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: (4 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 3: Looks good to me, approved

(3 inline comments)

a few nits, otherwise lgtm
|Patch Set 1: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 4: (1 inline comment)


|Patch Set 4: Verified

(1 inline comment)


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Fails

Found a bug, be back with a new patch later tonight or in the morning.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 1: (1 inline comment)

Steve, can you answer Todd's Question?

And Todd, is there a way we can have this also program in the MAC addresses for us. We need to do that to all the existing V3's as well.
|Patch Set 1: Looks good to me, approved

I guess I can just LGTM, though the GCN question is still unanswered.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Looks good to me, approved; Ready; Verified


|Patch Set 4:

(11 comments)
|Patch Set 6:

(8 comments)
|Patch Set 8:

(5 comments)

I'm worried about not automatically using servo for lab machines and expecting all tests that use servo to specify they are.

Whats the reasoning behind this change? 

And have you guaranteed repair via servo still works?
|Patch Set 11:

(2 comments)

Few Nits
|Patch Set 1:

(1 comment)

Looks good, just one question.
|Patch Set 1: Looks good to me, approved


|Patch Set 6: Code-Review+2

Looks good to me. Feel free to land or wait for Scott but seems like he was satisfied last time he looked.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4:

(5 comments)

I just see a lot of potential for NullPointerExceptions in your java code. May be worth looking at. Not sure what happens if this code errors out. Or if bad input is ever possible, so just worth pointing out.

When you do isNumber().getValue() or anything like that if the first command is False it will return Null and that will error out as it calls getValue().
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(12 comments)
|Patch Set 1:

(2 comments)
|Patch Set 4:

(4 comments)
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+1

LGTM will let Aviv take a final pass.
|Patch Set 8:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(15 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

PTAL at my comments.

Alex, I thought about the whole local vs remote thing and ya I agree. I'm going to push that back till we get the autodetect working first. Once that is in then I will refactor this all into 3 classes:

*AbstractADBHost - stores all adb functions that dont require knowledge of local vs remote.

Then a local/remote class that inherits from that. Any code that is dependent on this will go here. I.E. the lowest level of run, send_file, get_file, etc.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

Wiley give this patch a try.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Wiley has been using this patch to run his tests and his changes are ready to commit but dependent on this CL.
|Uploaded patch set 6.
|Patch Set 6: Verified-1

DO NOT REVIEW. This patch is meant for Wiley.

Wiley, please cherry pick and try this patch. Exit codes are now implemented.

NOTE: I found an extra level of escaping, so previously working commands may be slightly different now.
|Uploaded patch set 7.
|Patch Set 7: Verified-1

(2 comments)

Alex you are my actual reviewer.

New patch is imminent don't look at the most up to date one.
|Patch Set 5:

(14 comments)
|Uploaded patch set 8.
|Patch Set 8: Verified+1

Ready for review. PTAL so we can land this soon.
|Patch Set 8:

(7 comments)
|Uploaded patch set 9.
|Patch Set 9: Verified+1

Addressed Fang's comments. PTAL
|Patch Set 9: Code-Review+2 Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: Ife222321bc7a826a9eda71b897facfa238a6a297
|Patch Set 2: Reverted

This patchset was reverted in change: Ifcb241ccf44107f1fdf7b1b4dde12944fddae2ba
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2:

(6 comments)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3:

(3 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Partially. So the hostname the vm's used included the port. I.E. '127.0.0.1:9234' so it would try to ssh to that address and get a gai error.

Now I let the normal process go throw as expected and you would end up with a sshhost or paramiko host at the front of the class list. Then it parses the args as normal (including pulling the port out of the hostname and into an arg) and then it is able to reach the VM.

I tested this on a try-bot. just updated the TEST= string to imply this.
|Uploaded patch set 8.
|Patch Set 5:

(1 comment)

It is now closer to the old way, PTAL
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Ping
|Patch Set 1:

Hmm so in that bug are you saying this change didn't work as expected?

We have this change sitting in prod, figured it would be best to actually commit it.
|Patch Set 1: Commit-Queue+1 Verified+1

Sounds good, will commit this for now since it's running on prod.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as cd6aed26b5325a7011d6ba0e47987f6e2d17ee34
|Patch Set 2: Reverted

This patchset was reverted in change: If4caf1676e2bc3073e16e226b46b26c96ace405b
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 68e4a4e91a627fdf10c86ef5096cd5692293f651
|Patch Set 1:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1

I'm happy with this now, but since Vapier had comments earlier, I would like him to take one last look.
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 5:

(5 comments)

I'm concerned about the use-case of non-googlers who want to run chrome.py and telemetry_LoginTest. Thoughts on this?
|Patch Set 6:

Hmm the naming autotest-private-ext implies its private to Googlers. Maybe I'm miss understanding where that file comes from.
|Patch Set 6: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

Vapier, I adjusted this so it only impacts our Telemetry Dep and nothing else.
|Uploaded patch set 4.
|Patch Set 4:

ping
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4:

(3 comments)
|Patch Set 6:

(2 comments)
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Had to update the unit test so it can pass CQ. Re-trying commit.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: -Code-Review
|Patch Set 1: Code-Review+2

I ran ./run_measurement --browser=cros-chrome --remote=172.22.75.140 media page_sets/tough_video_cases.json and it worked so this should be good.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 9d9b7294346752a5668d4f61c95d3888a9fec33c
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 49e21e6f66df4cca76824a9e10dec55c4e94cf0d
|Patch Set 4:

(4 comments)
|Patch Set 5: Code-Review+2

(2 comments)

2 NIT's but good to go, sorry for the delay.
|Patch Set 7: Code-Review+1

Beeps should give final +2 now
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Verified-1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

This is the first change that needs to go in for the timeout granularity increase.
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6: Verified+1

Alex, if you makes you feel better, I did this change separately and came up with the same CL essentially. I just didn't have the extra options stuff but added that after looking at yours.
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Updated the rpc_test file so the unit-test will pass.
|Uploaded patch set 11.
|Patch Set 11: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 11: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: Commit-Queue+1
|Patch Set 11: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: Commit-Queue+1
|Patch Set 11: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: Commit-Queue+1
|Patch Set 11: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: Commit-Queue+1

I hate the cq....
|Patch Set 1:

feel free to abandon this
|Patch Set 1:

feel free to abandon this
|Patch Set 1:

feel free to abandon this
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

I have no other issues/questions about this cl
|Patch Set 1:

Umm how about we fix this at a higher level? This just solves the problem for custom_perf but theres other profilers people may want to use in the future....
|Patch Set 2:

This is less about the move to test_that, rather than  profilers on server-side tests haven't really worked in a lonnnnngg time. I doubt anyone has gone through this exact workflow in a while.

And desktop_PyAutoPerf tests kicked off profilers on the client side tests rather than server-side like these.
|Patch Set 2:

Caroline, this CL was +2 and Cr-ed before I got a chance to look but if you can come up with a way this will work for all profilers that would be better.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified-1

Please wait before reviewing, want to verify a few things first.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

(1 comment)

PTAL
|Patch Set 4:

(5 comments)
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Rebased and retrying
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Strange CQ Failure, retrying
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(2 comments)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

I already left the office but I'll cherry-pick and verify tomorrow morning.

If you can please rebase this against the change Fang referenced and re-upload the patch set. Thanks.
|Patch Set 1:

lets rebase this and get it committed.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

*Updated the unit tests*
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

code wise it looks fine to me but wait for richard's approval first.
|Patch Set 1: Code-Review+2
|Patch Set 6:

(13 comments)
|Patch Set 7:

(3 comments)

the pylint check does not enforce autotest style
|Patch Set 8: Code-Review+1

(3 comments)

Let me know if you need help testing this locally at your desk from end to end.
|Patch Set 12: Code-Review+2
|Patch Set 5:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6: Code-Review+2

(1 comment)
|Patch Set 5:

(3 comments)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)

1 nit but if the testing succeeds I think it should be good.
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 4:

(4 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified-1

No ready, forgot to --draft
|Uploaded patch set 3.
|Patch Set 3: Verified-1
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Ready for review but can't commit till the other cl is committed and deployed.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

PING, not sure why it doesn't show https://chromium-review.googlesource.com/#/c/177413/ as depending on this but thats ready as well.
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Patch Set 6:

ping
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Fixed 1 unittest I missed.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

Kool, ya I like the way this feels a lot more. Thanks!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as f4ea9b54fac2efeea8cbc2a7c75b5bffbd07897d
|Patch Set 1: Code-Review-1

Please wait on submitting this till Fang Deng approves. I believe she changed the output so we can get performance data on the new chrome perf dashboard and we don't want this to break as its how we track performance regressions in chrome-os.
|Patch Set 1:

(2 comments)
|Patch Set 1:

I know you can change the output format (and csv is an option) but for the lab needs I believe we do it the same way the chrome bots do by parsing the block format output.

We could make have telemetry_CrosPerf request csv output and Caroline could manipulate it to be the format she needs.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

ping
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased
|Patch Set 1:

Can you also do a draft CL of the corresponding changes of HDCTools for me?
|Patch Set 2:

Sadly git was not as smart as I was hoping
|Patch Set 2:

(2 comments)
|Patch Set 2:

I don't think anything real is missing or broken here. Just add the bug for adb_host log collection and then put that in the comment as a todo.
|Patch Set 3: Code-Review+2

(1 comment)

Update the BUG= and commit
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

I'd say let's commit this to fix trunk for now.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)

Why is press_secs using Strings?
|Patch Set 2:

(5 comments)
|Uploaded patch set 1.
|Patch Set 1:

Fair enough, the old control files would still work but I see the useful-ness of back porting to the older branches.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Good catch 2 files did not use timeouts to begin with, adding that in.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1:

I assume this is not yet ready for review considering the CL it depends on is marked -1 by you.
|Patch Set 2:

(1 comment)

1 question
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

PING
|Patch Set 5:

(3 comments)
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Running a trybot run to verify but PTAL
|Patch Set 7: Verified+1

Trybot Successful
|Patch Set 7:

ping
|Patch Set 7: Code-Review+2 Commit-Queue+1
|Patch Set 7: -Commit-Queue

fixing david jame's nit first
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

inheriting
|Patch Set 4: Code-Review+2

(1 comment)

1 nit from the old code
|Patch Set 11:

taking a look
|Patch Set 11:

(4 comments)
|Patch Set 13: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

We utilize that too but you first need to set the pin muxes that you are using the GPIO's. Then you can do the export, set direction and value.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified

PING
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified+1

got rid of bb_utils and just have bbmux_controller check for the existence of the omap_mux directory.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

For reference on why I had to do this: http://elinux.org/BeagleBone_Black_Enable_SPIDEV
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Rebased and retrying.
|Patch Set 1:

Don how old is the image you're testing on?
|Patch Set 1:

That explains a lot :)
|Patch Set 2:

(2 comments)

style nits but overall fine with me
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 5:

(1 comment)
|Patch Set 6:

(1 comment)

LGTM but I deleted and replaced one of these ebuilds...
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2

LGTM just do a complete build before CR-ing please.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

augh I went with encrypted_mounts....
|Uploaded patch set 4.
|Patch Set 2:

(1 comment)
|Patch Set 4:

switched to encrypted_stateful PTAL
|Patch Set 4:

(1 comment)
|Patch Set 4:

(5 comments)
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8:

(2 comments)
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Patch Set 10:

Added line wrap. Waiting on Richard/Security for +2
|Patch Set 10: Commit-Queue+1 Verified+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Waiting on +2 here as well.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

Mukesh, so I didn't see your comment on &quot;setting the FORWARDing policy to DROP&quot; till after I reworked this. Is that something that still applies and you want me to address?
|Uploaded patch set 3.
|Patch Set 3:

+Scottz, if he has any input to this discussion.
|Patch Set 3:

Discussed with Richard/Gaurav on how to proceed here:

Current thought is to move the default iptables.conf and ip6tables.conf to their own subdirectory of init. Create a new ebuild responsible for installing these into /etc/init and have Chrome-OS depend on this ebuild.

Then have the beaglebone-servo and moblab variant not depend on this ebuild so that these upstart jobs do not get copied into /etc/init.

If need be they can install alternative upstart jobs via a virtual ebuild in the overlay. This alternative upstart job would block forwarding. Please let me know whether you all feel having no upstart job vs forwarding disabled job is desired.

Thus we have no new USE Flag and any overlay that requires no firewall can disable it this way.

Thoughts on this approach? Waiting on an okay before I complete this work.
|Patch Set 3:

Okay first off I was a bit confused by the workings of virtual packages so here’s a retry:

1) Create a new virtual package: chromiumos-overlay/virtual/chromeos-firewall

2) chromeos-base/chromeos-init RDEPENDS on virtual/chromeos-firewall

3) Move the default ip*tables.conf to their own directory. As well as add empty set of rules that include disabling forwarding. (As requested by Mukesh)

4) Create new ebuild chromeos-base/chromeos-firewall-init. chromiumos-overlay/virutal/chromeos-firewall will REDEPND on this new ebuild. This ebuild installs the default ip*tables.conf to /etc/init

5) In overlays/overlay-variant-stumpy-moblab create virtual/chromeos-firewall that REDEPENDS on overlays/overlay-variant-stumpy-moblab/chromeos-base/chromeos-firewall-init-moblab. This new ebuild installs the empty rules that include disabling forwarding.

Please let me know if I am missing something here.

Also adding Masone as I was told by Keybuk he has expressed interest in this.
|Uploaded patch set 4.
|Patch Set 4:

Kicking off a trybot with --board=stumpy to verify nothing breaks.
|Patch Set 4: Verified-1
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified+1

Ping. +2 anyone??
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

Kicking off a trybot with --board=stumpy to verify nothing breaks.
|Patch Set 4: Verified-1
|Uploaded patch set 5.
|Patch Set 5:

(3 comments)
|Patch Set 5:

(6 comments)
|Uploaded patch set 6.
|Patch Set 6:

So to remove the circular dependency that Richard was worried about:

* Reworked the upstart dependencies. So now the iptables job depends on the shill upstart job but guaranteed to run before shill if they exist.

* Chromeos -&gt; virtual/chromeos-firewall -&gt; chromeos-base/chromeos-firewall -&gt; chromeos-init. This is because the ip[6]table upstart jobs depend on shill supplied by chromeos-init.
|Patch Set 6:

(1 comment)
|Patch Set 6:

(3 comments)
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 7:

Ping. +2 anyone??
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Added the chromeos_version file as Vapier suggested. Rebased and inheriting +2.
|Patch Set 9: Verified-1
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 9:

(2 comments)
|Uploaded patch set 10.
|Patch Set 10:

Rebased this, removed the iptables installation from cros_embedded, and did the proper blocker modifications to make sure this goes in properly, please take another look.
|Patch Set 10: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: I90575ea8a1003e3146c79aa66bb56d86ad3aa499
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: I80b37cf7ab881e1eb4ce27402167d30b418e01e9
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: I75d5fc4bdc715ea618c81685c3113290718c0f03
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

rebased, and kicking off tryjob before CR-ing
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2 prior to rebase
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

I added:

RDEPEND=&quot;!chromeos-base/chromeos-dev-init&quot;

to fix the conflict in the CQ. I would like it if someone took a look and gave me another +2 before I send it to the CQ.

Thanks
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Abandoned
|Patch Set 1: Code-Review+2
|Abandoned
|Abandoned
|Patch Set 2: Code-Review+2
|Patch Set 2:

(3 comments)
|Patch Set 1:

In atlantis1 its pretty slow but in atlantis2 its a lot faster... but I think this should only be supported on Stumpy as thats the only device that will turn off/on by killing power.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)

Yeah we should have that whitelist. And I think thats the reasoning we have it at the bottom of the list I believe. Like 1 last effort.

This is supposed to work by rebooting the device 6 times and if it fails it will revert to the last good install. If it comes back after rebooting once it'll end successfully. Maybe a better option is to reboot once and if its still not up, try servo.

I think servo install takes a couple of minutes, not sure exact timing.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

Kicking off a trybot with --board=stumpy to verify nothing breaks.
|Patch Set 1: Verified-1

UPREV failed :(
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(4 comments)
|Uploaded patch set 4.
|Patch Set 4:

ping
|Patch Set 4:

Ping. +2 anyone??
|Uploaded patch set 5.
|Patch Set 5:

fixed
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 3.
|Patch Set 3:

Heres the updated commit message.

Some of these are used by other boards. Like numpy for example.

I kicked off trybots on all the architecture's with hwtest. I did stumpy, x86-mario, daisy, lumpy, link. Let me know if there are any other boards you want tested.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4:

Ping. Mike let me know if you still have more questions about our use case here.
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Rebased and inheriting +2
|Patch Set 4:

I'm confused by the ebuild naming schema, shouldn't it got to R3 rather than 0.0.1-R2 -&gt; 0.0.2-R1? Note this could be just be me trying to learn more about portage than a real problem...
|Patch Set 7: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1

Verified with Trybot run. Ensured no git/svn existed on chromiumos_base_image
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Currently we use mysql in the lab and we're copying the lab components as close as possible for moblab. I read up a bit on MariaDB and it does seem to be a drop in replacement.

Lab scripts use both command line calls (mysql) and  from django.db import connection &amp; MySQLdb modules.

If its really as replaceable as it claims to be then it may be easier to utilize it if the cost of building/using MariaDB is less than the cost of building Mysql on Chromium-OS.

Thoughts?
|Abandoned

Went with MariaDB Not Mysql
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

Leaving it to Vapier to give full approval. Any problems of having a virtual being in CROS_RDEPEND?
|Patch Set 2:

We could get rid of the RDEPEND of chromeos-firewall-init on chromeos-init, but Richard was insistently we add it as iptables.conf depends on shill.conf...
|Patch Set 2:

(3 comments)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

To get mariadb to build properly:

* I copied the ebuild out of portage-stable to chromiumos-overlay.

* Added RDEPEND on dev-libs/libaio &amp; sys-devel/binutils (NOTE: It emerges without libaio but build_image fails without it)

* Added src_configure to properly setup LDFLAGS

* Added symlink mariadb-5.5.32-r1.ebuild -&gt; mariadb-5.5.32.ebuild
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3:

I added them as RDEPENDS in my chromeos-bsp-moblab ebuild, did I forget a step?
|Patch Set 3:

If by sdk mean the autotest-server ebuild I'll be writing soon and then I'll make chromeos-bsp-moblab RDEPEND on autotest-server and the devserver ebuilds which will RDEPEND on their deps instead.

I can wait on submitting this if you want me to write those first however.
|Patch Set 3:

I see what you mean about the duplication between this and hard-host-depends.

Except I don't know if we want hard-host-depends to have everything from autotest-server-deps. I was planning to add mariadb and apache to autotest-server-deps once those are ready... and I don't see them being necessary for hard-host-depends.

Looking at the ebuild hard-host-depends is what the builders need but I'm adding stuff my image needs, does the duplication matter? Like we don't need the chroot to have django installed in order to build chrome-os...
|Patch Set 3:

So when we say Server here we mean the actual Host Machines in the lab that run say the web frontend, the database, DHCP, etc. It crosses over with what is needed in the chroot as we also run the tests from these machines as well.

But running tests from the chroot does not require everything the Autotest Servers does. I guess you could say the Server requirements encompasses the autotest requirements in hard-host-depends but neither fully encompasses the other.

I guess one option is to take the stuff that belongs to both and put them in their own ebuild and have both hard-host-depends and autotest-server-deps both RDEPEND on that?
|Uploaded patch set 4.
|Patch Set 4:

ping
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 2: Code-Review+2

Please land this after you've applied the label to the coo responding machines.
|Patch Set 1: Code-Review+1

(1 comment)

Heh guess it came down to this in the end. If theres no clean way to fix it, killing the spam is probably a good call.
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Ahh yes sorry forgot about that.

Here's the list:
/usr/bin/devserver
/usr/bin/devserver-2.7
/usr/lib64/python2.7/site-packages/host/lib/update_payload/common.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/__init__.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/checker_unittest.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/applier.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/checker.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/block_tracer.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/payload.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/error.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/test_utils.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/format_utils_unittest.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/update_metadata_pb2.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/histogram.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/format_utils.py
/usr/lib64/python2.7/site-packages/host/lib/update_payload/histogram_unittest.py
/usr/lib64/python2.7/site-packages/autoupdate_lib.py
/usr/lib64/python2.7/site-packages/xbuddy.py
/usr/lib64/python2.7/site-packages/autoupdate_unittest.py
/usr/lib64/python2.7/site-packages/gmerge_test.py
/usr/lib64/python2.7/site-packages/downloader.py
/usr/lib64/python2.7/site-packages/devserver-0.0.1-py2.7.egg-info/dependency_links.txt
/usr/lib64/python2.7/site-packages/devserver-0.0.1-py2.7.egg-info/PKG-INFO
/usr/lib64/python2.7/site-packages/devserver-0.0.1-py2.7.egg-info/top_level.txt
/usr/lib64/python2.7/site-packages/devserver-0.0.1-py2.7.egg-info/entry_points.txt
/usr/lib64/python2.7/site-packages/devserver-0.0.1-py2.7.egg-info/SOURCES.txt
/usr/lib64/python2.7/site-packages/devserver_constants.py
/usr/lib64/python2.7/site-packages/builder_test.py
/usr/lib64/python2.7/site-packages/shadow_xbuddy_config.ini
/usr/lib64/python2.7/site-packages/__init__.py
/usr/lib64/python2.7/site-packages/common_util_unittest.py
/usr/lib64/python2.7/site-packages/gsutil_util.py
/usr/lib64/python2.7/site-packages/update_test.py
/usr/lib64/python2.7/site-packages/builder.py
/usr/lib64/python2.7/site-packages/devserver_integration_test.py
/usr/lib64/python2.7/site-packages/autoupdate.py
/usr/lib64/python2.7/site-packages/downloader_unittest.py
/usr/lib64/python2.7/site-packages/build_util.py
/usr/lib64/python2.7/site-packages/log_util.py
/usr/lib64/python2.7/site-packages/xbuddy_config.ini
/usr/lib64/python2.7/site-packages/devserver.py
/usr/lib64/python2.7/site-packages/build_artifact_unittest.py
/usr/lib64/python2.7/site-packages/artifact_info.py
/usr/lib64/python2.7/site-packages/build_artifact.py
/usr/lib64/python2.7/site-packages/strip_package.py
/usr/lib64/python2.7/site-packages/common_util.py
/usr/lib64/python2.7/site-packages/gsutil_util_unittest.py
/usr/lib64/python2.7/site-packages/xbuddy_unittest.py
/usr/lib64/python2.7/site-packages/update_firmware_image.py
|Patch Set 3:

That didn't come out very pretty... so I posted it on crbug.com/339915
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4:

Following Sosa's advice I am going to update the cros-devutil ebuild in the following way:

* Rework the dependencies so that it does not try to bring in blocked packages into a board's sysroot.

* Rework it to take advantage of distutils to build the devserver.

* Update start_devserver to look for /usr/bin/devserver. (Note: I tested this change and it requires sudo to launch start_devserver, not sure if thats a problem or not).


Please let me know if anyone has an opposition to this approach or other suggestions. Or if you want me to move this into a bug for discussion.
|Patch Set 4:

I actually like Vapier's suggestion but how do you deal with both ebuilds having the same LocalName

CROS_WORKON_LOCALNAME=&quot;dev&quot;

Sosa said you can't have 2 ebuilds with the same name. And cros-devutil installs a bunch of other tools from this directory i.e. gmerge, cros_workon, etc
|Patch Set 4:

Sosa you lost me with the typo comment?

And is it fine that start_devserver with require sudo to run now? Without sudo and building the devserver in this way I get:
IOError: [Errno 13] Permission denied: '/usr/lib64/python2.7/site-packages/devserver-0.0.1-py2.7.egg-info/entry_points.txt' but with sudo it works fine.
|Patch Set 4:

O i get the typo comment now, you mean in my new ebuild.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)

Sosa/Mike PTAL at my current set of changes.

Note that my devserver ebuild still installs:

/usr/lib64/python2.7/site-packages/__init__.py

While I disabled cros-devutils from installing it as well. If its a problem that devserver.ebuild still installs it let me know and I'll see if I can find a way for distutils and setup.py to not package it...

Mike mentioned that it should install {sitedir}/{module} but when I looked into setup.py it seemed like to get that to happen I would need the platform/dev structure to looks like:
dev/
&#124;
setup.py
&#124;
devserver/
\
 \
  move everything into here

Which seems like a big change with the potential to break a lot...
|Patch Set 6: Verified-1

Marking as unverified till I fix a permissions issue here.
|Uploaded patch set 7.
|Patch Set 7:

So I kept running into issues with the setup.py approach (and it was becoming overly complicated) and realized I could (&amp; should) simply utilize the Makefile approach we had before. (Likely I should have started with this approach anyways).

So I pulled the installation of the devserver code to its own ebuild, added a blocked against the current version of cros-devutils and made cros-devutils RDEPEND on the new ebuild instead.

This also means the other CL I had for changes in platform/dev are no longer required as well.
|Patch Set 7:

(2 comments)
|Uploaded patch set 8.
|Patch Set 8:

(4 comments)
|Uploaded patch set 9.
|Patch Set 9:

/usr/bin/start_devserver
/usr/bin/stateful_update
/usr/lib/devserver/autoupdate_lib.py
/usr/lib/devserver/xbuddy.py
/usr/lib/devserver/downloader.py
/usr/lib/devserver/devserver_constants.py
/usr/lib/devserver/gsutil_util.py
/usr/lib/devserver/builder.py
/usr/lib/devserver/autoupdate.py
/usr/lib/devserver/build_util.py
/usr/lib/devserver/log_util.py
/usr/lib/devserver/xbuddy_config.ini
/usr/lib/devserver/devserver.py
/usr/lib/devserver/artifact_info.py
/usr/lib/devserver/build_artifact.py
/usr/lib/devserver/strip_package.py
/usr/lib/devserver/common_util.py
/usr/lib64/python2.7/site-packages/write_firmware.py
/usr/lib64/python2.7/site-packages/common.py
/usr/lib64/python2.7/site-packages/update_payload/common.py
/usr/lib64/python2.7/site-packages/update_payload/__init__.py
/usr/lib64/python2.7/site-packages/update_payload/applier.py
/usr/lib64/python2.7/site-packages/update_payload/checker.py
/usr/lib64/python2.7/site-packages/update_payload/block_tracer.py
/usr/lib64/python2.7/site-packages/update_payload/payload.py
/usr/lib64/python2.7/site-packages/update_payload/error.py
/usr/lib64/python2.7/site-packages/update_payload/test_utils.py
/usr/lib64/python2.7/site-packages/update_payload/update-payload-key.pub.pem
/usr/lib64/python2.7/site-packages/update_payload/update_metadata_pb2.py
/usr/lib64/python2.7/site-packages/update_payload/histogram.py
/usr/lib64/python2.7/site-packages/update_payload/format_utils.py
/usr/lib64/python2.7/site-packages/cros_output.py
/usr/lib64/python2.7/site-packages/tools.py
/usr/lib64/python2.7/site-packages/fdt.py
/usr/lib64/python2.7/site-packages/checker_unittest.py
/usr/lib64/python2.7/site-packages/applier.py
/usr/lib64/python2.7/site-packages/checker.py
/usr/lib64/python2.7/site-packages/block_tracer.py
/usr/lib64/python2.7/site-packages/pack_firmware.py
/usr/lib64/python2.7/site-packages/payload.py
/usr/lib64/python2.7/site-packages/error.py
/usr/lib64/python2.7/site-packages/test_utils.py
/usr/lib64/python2.7/site-packages/bundle_firmware.py
/usr/lib64/python2.7/site-packages/format_utils_unittest.py
/usr/lib64/python2.7/site-packages/update_metadata_pb2.py
/usr/lib64/python2.7/site-packages/histogram.py
/usr/lib64/python2.7/site-packages/format_utils.py
/usr/lib64/python2.7/site-packages/exynos.py
/usr/lib64/python2.7/site-packages/histogram_unittest.py
|Uploaded patch set 10.
|Patch Set 10:

(1 comment)
|Patch Set 10:

(1 comment)
|Uploaded patch set 11.
|Patch Set 11: Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Verified-1

I changed my approach and likely no longer need these changes.
|Abandoned

No longer required, a different approach was taken.
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Just passed Trybot runs with hwtest for Daisy, Lumpy and x86-mario. Please let me know if you want me to test on other platforms as well.
|Patch Set 1: -Verified

Unmodified pulled in via portage stable.

I cp-ed in the 2 apache eclass changes (I pulled in apache* which included apache-module.eclass if you want me to remove that lmk).

I'll remark this as verified once that passes. Just for my own information what exactly is the chromiumos-sdk bot and when should I test changes against it?
|Patch Set 1:

Yeah I launched the trybot that way just was curious what kinds of changes should I be testing against that bot in the future?
|Patch Set 1: Verified+1

Try Success for Chromiumos SDK, i'll wait till the morning to mark it ready though.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

I am assuming the &quot;No package 'libftdi' found&quot; error is not my fault.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Ran successfully on chromiumos-sdk. Inheriting +2.
|Patch Set 2:

(1 comment)
|Patch Set 1:

Wouldnt it better to somehow fix the ebuild to not even request an non existant file from installing?
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

I blew everything away and did build_packages, no issues.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified-1

I'll be updating this CL so hold off on review.
|Patch Set 2:

(14 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4:

(2 comments)

PTAL at my new permission settings.
|Patch Set 6:

Ping
|Uploaded patch set 7.
|Patch Set 7:

(2 comments)
|Uploaded patch set 8.
|Patch Set 7:

(2 comments)
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

Per IRL discussion with Richard, converting the upstart scripts to run as chronos. Inheriting +2.
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Changed autotest-server-9999 keywords to be ~*
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

(24 comments)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

Kicked off trybots will mark verified when completed.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

Able to import from google.protobuf on test images now. Verifying with trybot runs, if successful will inherit previous +2.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Passed Try-Bot runs with hwtest. Inheriting +2.
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 11.
|Patch Set 11: Code-Review+2 Commit-Queue+1 Verified+1

Rebased and retrying.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

Since we both +1'ed.
|Uploaded patch set 1.
|Abandoned

Accidentally created a new cl
|Uploaded patch set 1.
|Abandoned

Not needed.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(7 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified-1

Something broke here :(
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 4:

(4 comments)

Was just taking a quick look because of the spelling error and noticed your alignment is incorrect in a lot of places.
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

For the moment this is the quick fix for moblab, I can add a TODO for this bug and get back to it for V2. Scottz gave me the okay to go with this for now.
|Uploaded patch set 2.
|Patch Set 2:

Added a TODO comment PTAL.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2:

(1 comment)
|Patch Set 6:

You need to rebase b/c https://chromium-review.googlesource.com/#/c/188271/ landed.
|Patch Set 7: Code-Review+1
|Patch Set 7:

I'll +2 this but you need to rebase again.
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(4 comments)

Commented the lines I added in moblab-httpd.conf from the regular httpd.conf.
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Sorry for the flood of patches -_-....
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 6: Reverted

This patchset was reverted in change: If36f2212c738cf2948071e6c70acdcb5d7ef535d
|Patch Set 1:

(1 comment)
|Patch Set 1:

Whats the best way to disable OOBE?
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+1

I want to make sure cmasone is happy before landing. He'll be back midway next week.
|Patch Set 1:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5:

(8 comments)
|Patch Set 6:

(2 comments)
|Patch Set 7:

(1 comment)
|Patch Set 7: Code-Review+1

I'm good with this, leaving to Alex to +2.
|Patch Set 9: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Verified-1

Hitting a bug here.... will update as soon as possible.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(8 comments)
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Ready for review. Fixed the outstanding bug.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7:

(2 comments)
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1

Failure was due to &quot;Gerrit Code Review requires Java 7 or later&quot;

Retrying....
|Patch Set 1: Code-Review+2

(1 comment)

Please update the bug line and test it before submitting.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

apparently this has a merge conflict, vapier should I not have rev-ed the ebuild if this is a 9999 ebuild?
|Uploaded patch set 2.
|Patch Set 2:

The manual rev bump fails trybot runs... Not changing the symlink causes repo upload's verify hook to fail...

Waiting for a reply from Vapier, if I don't hear anything soon might go with the whitespace hack temporarily.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Added a new line to make sure this uprev's properly.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(12 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2

I've got no issues here.
|Patch Set 5: Code-Review+1

+1, leaving final approval to Alex.
|Patch Set 8: Code-Review+1

Alex had the last set of comments so again +1
|Patch Set 8: -Code-Review

Richard, since you did not land this before you went on vacation odds are I will be modifying gs_offloader for moblab this next week. So you'll likely need to rebase this once you're back.

Sorry for the inconvenience.
|Patch Set 15: Code-Review+1

I spent some time re-reading this twice and I don't see any issues to this approach. But again leaving +2 to Alex.
|Patch Set 15:

Pinging too as I want to make some gs_offloader changes for moblab on top of this.
|Uploaded patch set 1.
|Patch Set 1:

Trybot run in progress: https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/stumpy_moblab-release/builds/2
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Try-bot run was successful.
|Change has been successfully cherry-picked as 932ee5bf1af5178c3404e25ca1e40cfadfb9142a
|Uploaded patch set 1.
|Patch Set 1:

Still need to test this, will look into utilizing the test server to verify.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned

Beeps already fixed in a different CL
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2

Inheriting +2 (Dan had put it on patch set 2)
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/rambi-release/builds/21/steps/BuildImage/logs/stdio

Looks like we have a bug in your lambda logic.
|Patch Set 2:

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/rambi-release/builds/22

build_image finished.

Doesn't seem to be working:

Its in chromeos-image-archive
https://console.developers.google.com/storage/chromeos-image-archive/trybot-rambi-release/R35-5702.0.0-b22/

but not in our other bucket:
$ gsutil ls gs://chromeos-moblab-rambi/rambi-release
gs://chromeos-moblab-rambi/rambi-release/R35-5623.0.0/
gs://chromeos-moblab-rambi/rambi-release/R35-5624.0.0/
gs://chromeos-moblab-rambi/rambi-release/R35-5625.0.0/


if you look at the build image logs gs://chromeos-moblab-rambi is nowhere to be seen but you can clearly see the commands for gsutil sending files to gs://chromeos-image-archive
|Patch Set 3:

Still hitting issues, guess it didn't build the recovery image?
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/rambi-release/builds/26
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review-1

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 6: Code-Review+2

Has this not yet landed?
|Patch Set 1: Code-Review+2

(1 comment)

Update the TEST= line and verify you can kick it off via telemetry's run_benchmark script.

You shouldn't need to make any changes to the ebuilds here.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as ae73fe6fcebc37229ab903e04b4c441ba11f13e2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 7ff849012a37996d79484f7a66080f75197975d8
|Patch Set 4:

K so this is now kind of working... We are getting artifacts in our other bucket! Yay!

But lots of files are missing...
$ gsutil ls gs://chromeos-moblab-rambi/trybot-rambi-release/R36-5723.0.0-b48/
gs://chromeos-moblab-rambi/trybot-rambi-release/R36-5723.0.0-b48/UPLOADED
gs://chromeos-moblab-rambi/trybot-rambi-release/R36-5723.0.0-b48/chromiumos_base_image.tar.xz
gs://chromeos-moblab-rambi/trybot-rambi-release/R36-5723.0.0-b48/chromiumos_test_image.tar.xz
gs://chromeos-moblab-rambi/trybot-rambi-release/R36-5723.0.0-b48/recovery_image.tar.xz

where is the autotest tarball etc? There should be a lot more files...
|Patch Set 4:

http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/rambi-release/builds/48/steps/Archive/logs/stdio

If you search for 'moblab' you will see near by lots of other artifacts not being sent to this bucket.
|Patch Set 4:

Though I'm still not sure where the autotest tar ball gets uploaded...
|Patch Set 4:

K so the autotest tarball and other artifacts are uploaded at the start of build_image. Lets make sure they all get uploaded. And the missing files from the archive stage as well.
|Patch Set 6: Code-Review+2 Verified+1

This is now working! Lets commit this asap.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(2 comments)
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4:

(5 comments)
|Patch Set 6:

PTAL
|Patch Set 6:

(2 comments)
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Just launched a trybot to verify it builds correctly.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified-1

This change only gives us the UPLOADED file in 1 bucket not both, going to just rework the complete plumbing for multiple buckets.
|Abandoned
|Patch Set 2: Code-Review+1

(1 comment)
|Uploaded patch set 8.
|Patch Set 8: Verified+1

Reworked how we are going to do this.

NOTE: Multiple buckets is still broken since Friday, Intel was asking me where are their images and we need this back up ASAP and I'm going on vacation after tomorrow so asking for a quick review.
|Patch Set 8:

(2 comments)
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Fixed comments, inheriting +2.
|Patch Set 4:

Hey Puthikorn, try landing this CL on its own. Then the one that adds it to the BVT after.

I don't think landing both at the same time is going to work. Also when you update the control file and the python file, the control file change will be picked up right away but the python change requires a lab push to prod.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

Hmm our current instructions to our users is to ssh in via user moblab for kicking off their suite tests, etc.

SSH works by using the testing_rsa keys we pre-installed in the moblab homedir.

Will that still work with this change?
|Patch Set 1:

Yes the plan is to fix up the Web UI so that no command line interaction is necessary (except for troubleshooting, etc). I'm currently working on serveral UI upgrades and will have an Intern working on cleaning up/updating the current web UI this summer.

Until that work is done I would like us to hold off on landing this.
|Patch Set 1: Code-Review+2
|Uploaded patch set 7.
|Patch Set 7:

For the moment I consider that thread us discussing the long term plan. Scott and I don't want to give them access to gs://chromeos-image-archive even if the ACL's are managed.

Currently we had to disable the extra archives due to us leaking the Manifest.xml file. We need to whitelist or blacklist it ASAP so we can get images to the current group of Moblab users (who have not received any since Friday).

An alternative to this change is instead of filtering buckets based off a white/black list, we can filter the ACL settings instead.

Either way we need this back running again.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 7:

(2 comments)
|Patch Set 8:

I have yet to hear back from Vapier on his thoughts of Whitelist vs Blacklist but I went ahead and implemented/tested this as I discussed with David James eariler today.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Updated commit message, inheriting +2.
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 9: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

Hmm I don't think there is any reason difference besides calling convention.

Timelimit was already being invoked by the autoupdateEndToEnd test but was missing from Moblab, maybe switching the test over to timeout is the cleaner solution.

I'll move this discussion to the bug.
|Uploaded patch set 3.
|Patch Set 3:

timelimit will be changed to timeout by the AU Team.

Note I had to post this with --no-verify. Am I supposed to manually rev the -rX.ebuild for this -9999 ebuild?

Errors:
            * Changelist probably needs a revbump of an ebuild
            or a -r1.ebuild symlink if this is a new ebuild
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting previous +2.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Sigh, rebased again...
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Just kicked off a trybot run to verify.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2,

Ensured that vm_test_results tarball and directory are not available.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified-1

Will look at a different approach as per Milleral's comments on the Bug.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

blank=True is necessary for it accept 0 as an acceptable value and pass the validation checks before saving to the DB. (If you look at control_type above it has a comment that it has blank=True to allow for 0)

With my change a suite job passes in None for synch_count when creating the DB entry and we get the correct value of 0 in the DB.

05-08-2014 [10:35:07] Created suite job: http://localhost/afe/#tab_id=view_job&amp;object_id=177

mysql&gt; select synch_count from afe_jobs where id=177;
+-------------+
&#124; synch_count &#124;
+-------------+
&#124;           0 &#124;
+-------------+
1 row in set (0.00 sec)


I did just realize however having (blank=True, null=True, default=0) works as well, and that likely is the better answer as we don't change the null logic but allow it to support 0.

I can change it to that if that SG?
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Ping.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Updated default value in the unittests. Inheriting +2.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+1

Added pstew/quiche so they can take a look.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified-1

Still working on corresponding autotest change.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 6f46fd768fc4764b791cb42a7891ca539455fcb3
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 023d1ef52d5e25e42587c6424ebe46cb9c894ff4
|Patch Set 1:

Why not just delete db_clean.py?
|Patch Set 1: Code-Review+2

Fair enough. If you don't mind put in the commit message something like:

* Deleted db_clean.py
* Renamed db_cleanup_by_date.py to db_clean.py
|Patch Set 4:

(17 comments)
|Patch Set 6:

Shouldn't there be an html change to add the checkbox?
|Patch Set 6:

(6 comments)
|Patch Set 8:

This has a merge conflict, please rebase, if you need help with this I can help you once I am in.
|Patch Set 9:

(12 comments)
|Patch Set 12:

(3 comments)

This is close. A few more changes.
|Patch Set 13: Code-Review+2

(2 comments)

2 Nits.

Fix them, and feel free to inherit the +2.
|Patch Set 14: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 5:

(2 comments)
|Patch Set 7: Code-Review+2
|Patch Set 8:

(1 comment)
|Patch Set 8: Code-Review+1

Gonna give Beeps a chance to take one last look.
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Verified-1

Realized unit tests fail.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Updated unittests.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 8:

(1 comment)
|Patch Set 8: Code-Review+2

(1 comment)

my comments are nits
|Patch Set 1: Code-Review+2

+2'ing this as it is the same. Please commit all of them together.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 4.
|Uploaded patch set 7.
|Patch Set 7:

PTAL. I just kicked off sandybridge-ivybridge-release-group run to make sure it still works with the grouped builders. Will mark as Verified once that finishes.
|Patch Set 7: Verified+1

Trybot was successful.
|Patch Set 7:

Explained to Don IRL, that the markers display what is the most recent completed build. The point of this CL is so that extra buckets like gs://chromeos-moblab-rambi/ also have the extra markers. This way Moblab's devserver can determine what is the most recent build for a project.
|Patch Set 7: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

So when I run the integration test (even without my changes) it always gets stuck at this line....:
INFO    : Making request using http://127.0.0.1:45980/xbuddy/x86-generic/R32-9999.0.0-a1/test?for_update=True

Something I am doing wrong here?
|Patch Set 3:

(20 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Verified+1

Will commit in a bit, I'm modifying and testing against the corresponding autotest changes.
|Patch Set 7: Commit-Queue+1
|Patch Set 2:

+1 to Beeps' suggestion. Already discussed with Jiaxi IRL, but a doc and being able to show before/after impact will help a lot with this conversion process and end of internship presentation.
|Patch Set 2:

Have the stats collection been deployed yet for this? or is that https://chromium-review.googlesource.com/#/c/201381/ ?

If so land that and wait a few days then land this.
|Patch Set 2:

(1 comment)

A little late to the convo... The issue I have is what are we going to do with destiny. Are we going to have the same exact layout?
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2

Sorry thought I already did +2 this.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Ping, some feedback would be nice.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1

Handled your comments. PTAL today as we want to cut our shipping image tomorrow morning and fully test it by the end of the week.

Thanks in advance!
|Patch Set 3:

(3 comments)

Thanks for the regex help :)!
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

Beeps got any last comments?
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Is there a boardless builder I can use in a trybot run to completely verify this change?
|Patch Set 1: Verified+1

Worked on Pre-CQ trybot
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Rebased. Ping.
|Patch Set 2:

Ping.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2

We're trying to cut a Moblab update tomorrow, so we'll have to take this fix as is.
|Patch Set 1: Code-Review+2

Thanks for the quick fix :)
|Patch Set 1:

(1 comment)
|Patch Set 1: -Code-Review

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Verified-1

https://chromium-review.googlesource.com/#/c/201425 will fix this.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 2: -Commit-Queue
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3:

Addressed Vapier's comments and actually added a small other change here as well to setup apache's ssh directory.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

If someone can +2, its old code being put back into place.
|Patch Set 1:

Jay made a good point earlier that Moblab users may want to say just run 1 test (not a suite) on multiple machines with a specific image. This makes it easy and possible to do this from the AFE. I know its cruft but apparently its cruft that worked before we deleted it so shrug...
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

I just kicked off the trybot runs.
|Patch Set 1: Verified-1

:/ name came up as trybot-sandybridge-ivybridge-release-group
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

This now works as expected.
|Patch Set 5: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

I would like to chump this ASAP.
|Patch Set 1:

My bad I meant to put you on the other CL and Alex on this one.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 742b81d29617aab913cf512dbeeccd8606049a57
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 24747199929955effb1edee3a32b8f4cb4145e41
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 0b26ecf22d6805b5bc92c1d9fa285469719a0840
|Patch Set 1: Code-Review+2

This change sounds fine to me.
|Patch Set 2:

Because this is a UI change can you please attach/link screenshots so we can get a sense of how this looks?
|Patch Set 3:

(2 comments)
|Patch Set 3:

Looking at the screenshots what does the select checkbox do?
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2
|Patch Set 9: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

For the moment this looks good to me, we can take a look at the default settings more once I'm back.

I don't want to block you too much :)
|Patch Set 8:

Hmm as long as dev-python/mysql-python still ends up on the stumpy_moblab image I am happy.

Can you build_packages and ensure those files are still in /build/stumpy_moblab
|Patch Set 2: Code-Review-1

So the code here looks good but while some people like the Test team (not our team) have requested it, others who believe in more test purity and not allowing args (so that the tests are 100% automated and should not require args) have expressed that they are against this change to me offline.

When I am back, I'll talk to the different groups and Scottz and see if we can reach a proper conclusion.
|Patch Set 2:

(1 comment)

From my understanding of this change, you are updating the control file as the user types into the display box. Why not pass the args into the create_job_page_handler RPC like we do for max_runtime, etc?

Also args should not matter for suite jobs at all, just single tests. So pipe it to create_job_page_handler which would send it to create_job at which point you can do the injection to the control file. This way you're not hitting the rpc for every character typed.
|Patch Set 2:

No they should be able to see the control file and modify it as they want they just won't see how the args get injected.

Like for build/image name. That gets piped in and later injected by the RPC's later. Just seems like a cleaner approach to me.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

Yeah I know contrib does not require code review. Just nice to not have paths in our configs hardcoded in other places.

Thanks Richard!
|Patch Set 1:

Can you align the beginning of the select box for client/server with the text box?
|Patch Set 1:

(3 comments)
|Patch Set 2:

(1 comment)

1 more NIT
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

What is going to use this? Does it need to be added to the autotest-server deps?
|Patch Set 1:

Looks like you need this for gsutil, if gsutil can't run without psutil can you add dev-python/psutil to the overlays and add a dep on it please? Or file a bug so I remember to handle this once I'm back.
|Patch Set 1:

I mean gs_offloader.
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2

Looks like you need to rebase.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

I'm excited to see this speed improvement.
|Patch Set 4: Code-Review+2
|Patch Set 6: Reverted

This patchset was reverted in change: Id5629d6fe0569e403438ee71bdf21348fb518383
|Uploaded patch set 1.
|Patch Set 1:

Mike, I added the new google-web-toolkit ebuild and used sudo emerge to test it and make sure it fixed things. Its pulled in by hard-host-depends, do I need to do anything to make sure the builder uses the new -2.3.0 ebuild? I.E. do I need to rev something?
|Patch Set 1:

I'll check but I added it myself for Moblab February-ish so I doubt it.
|Patch Set 1:

IRL, told Sosa that the builder needs google-web-toolkit not the resulting image.

Checked with Ricky Liang from Factory Team and he does not believe they use this ebuild.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Verified that my image has the AFE working. Inheriting +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

This will require a rebase after https://chromium-review.googlesource.com/#/c/204500/ lands.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

PTAL at the README.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Rebased inheriting +2.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Verified+1
|Patch Set 6: Code-Review+2

(2 comments)
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(4 comments)

I am confused by the oid stuff can you expand out why you did that?
|Patch Set 1:

Fix the alignment comment and rebase this change (merge conflict).
|Patch Set 3: Code-Review+2
|Patch Set 2:

Can we get some screenshots of what this looks like?
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(6 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(4 comments)
|Patch Set 3: Code-Review-1

(1 comment)

Make the corresponding change for the shadow_config as per the comment and remove the global_config change.
|Patch Set 4: Code-Review+2
|Patch Set 1:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2:

This is a very large CL that has 3 distinct changes, if any of which are broken the whole thing requires a complete revert.

I suggest breaking into 3 changes.
* UI look
* Tooltip
* The view job and view host reorganization into tables.
|Patch Set 4:

(2 comments)

You comments on this CL should be comments in the code.
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)

What is the end result of this? Is there another server running on Moblab? If so which on which ports as we are already running Apache and the Devserver so I want to make sure there is no conflict.

Or is this just installing the bits but not launching the server?
|Patch Set 3:

A few more questions:

I assume this installs all the bits in the rootfs. If not, how are you handling powerwashes (i.e. wiping stateful? If yes, how much space is used up in the rootfs?
|Patch Set 1:

(7 comments)
|Patch Set 2:

I dropped comments in patch set 1 that were not addressed in ps2.
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(2 comments)
|Patch Set 1:

If I select an element, it goes to enabled correct? and then if I unclick it should go to unenabled right?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

rebased
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

I agree with both of you but that won't fix support for older images. This binary is not installed by autotest rather its built directly into the test image.

I set ownership of the bug to the owner of this binary but I would still like to fix this for test images we already have and run on DUTs.
|Patch Set 1:

I can file a TODO to eventually remove this but it would have to be some time after we want to support the older releases we are supporting now.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Discussed with Richard, he's fine with this fix because the bug is built into the test images. Added a TODO to eventually remove.
|Patch Set 1: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1:

(5 comments)

align all the tooltip strings better like i suggested.
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed nit, inheriting +2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(4 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

+1, I would like milleral to take a quick look at this though.
|Patch Set 1:

(1 comment)

Who will be watching results of this test?

Should these results be uploaded somewhere?
|Patch Set 2:

(5 comments)
|Patch Set 4:

(4 comments)
|Patch Set 5:

(3 comments)
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

I successfully used the devserver on moblab minus the host/lib files to preform provisioning, so I don't believe we need the files. Sosa, correct me if I am wrong or missed something.

I just kicked off trybots to verify this will build as expected since we're moving files between ebuilds.
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

re-kicking off trybots
|Patch Set 2:

(1 comment)
|Uploaded patch set 4: Commit message was updated.
|Patch Set 2:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Successfully built using trybots.
|Patch Set 5:

(1 comment)
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+2 Verified+1

Addressed nits and restored logic to not copy __init__.py.

Inheriting +2
|Patch Set 1: Code-Review+2
|Uploaded patch set 6.
|Patch Set 6: Verified+1

So I took over this CL from Jiaxi and just posted PS6, even though I am listed as a reviewer consider me the owner.
|Patch Set 6: Verified-1

making a slight change, new PS incoming.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified+1

PTAL now.
|Patch Set 8:

(7 comments)
|Uploaded patch set 9.
|Patch Set 9: Verified+1

Addressed some of Dan's comments replied to others.

You take a look at my moblab: http://100.96.48.99/
|Patch Set 9:

Gentle ping.
|Patch Set 9: Code-Review+2 Commit-Queue+1

Thanks!
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Unittests failed on VM due to the shadow_file.ini not being part of the git checkout, so adjusted the unittest to account for this.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(10 comments)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

cros_workon is for my local builds right?

I don't think the builders will pick up on this by themselves. I remember I changed an files/ init script before in a -9999 ebuild and it didn't work. But the autotest source updates pretty often so it will likely be picked up by that being updated too.

I'll see what Vapier says.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+1

I'm good with this. Let Dan do once last quick look first.
|Patch Set 2:

(2 comments)

I know you delete the test code in different CL but I feel like the deletion should be part of this CL.
|Patch Set 3:

Yeah just move the deletion here and this should be good to go.
|Patch Set 4: Code-Review+2
|Patch Set 3:

(10 comments)
|Patch Set 5: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 4:

(4 comments)

A couple of NITS and 1 real comment.
|Patch Set 5: Code-Review+2

Hail Hydra
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Augh so I kinda went through the process of doing this (with https://chromium-review.googlesource.com/#/c/212670/ ) and then realized I could just instead use the moblab useflag and in the autotest-client ebuild do the if logic to determine the install directory.

I'm fine trashing this and going the other route, let me know which you guys think is more correct however.
|Patch Set 2: Verified-1

You know what ignore this CL and the corresponding CL. I'm going to use the useflag approach instead.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified-1
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: I558753dc0a9aa2d7d15791cf9dc1a9b9f43b6d31
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified-1

Ignore PS2, found a better/cleaner solution to fang's comment.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Going to update DEPLOY
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

Failure does not look related.
|Patch Set 4: -Commit-Queue
|Uploaded patch set 5.
|Patch Set 4:

(6 comments)

Thanks for the comments Richard.
|Patch Set 5: Verified-1

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Abandoned

No need for this once overlay test baselines are implemented.
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Just kicked off trybots for nyan_blaze-release, peppy-release, stumpy-release.
|Patch Set 1: Verified+1
|Patch Set 1:

Mike, Aviv and I were curious if you have an opinion about the order of ReadOverlayFiles (or ListOverlays) goes through the overlays.

Right now its parent-&gt;child order, but what if we reversed it?
|Patch Set 1:

Maybe the normal situation is parent-&gt;child,

But for the case of my bug/issue we only care about reading an overlay file for this board specifically not the parents. In which case my CL adds the ability to request that.
|Patch Set 1:

Just saw David's last comment, I'll update accordingly.
|Uploaded patch set 2.
|Patch Set 2:

Fixed it as David suggested. Updated Doc strings, unittests already existed but was wrong.

Kicking off trybots to verify.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified-1

Thanks for the comments guys but I found a good way to test this and I'm finding some issues so I'll have to do some more work here first.
|Patch Set 1:

(11 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

K so the big difference between PS1 and PS2 is that I moved the cleanup logic into check_device.

Mostly so its not rebooting the moblab between every test but now just when it needs to restore stuff (like after repair).
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified-1
|Patch Set 3: Verified+1

Whoops meant Verified +1!
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

Retrying to get pre-cq failure.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit message was updated
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

I don't need this anymore.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

I reworked this so we have a new job in charge of mounting the external drive and setting it up.

Following scripts only execute after that one completes successfully and properly receive the exported env variables.
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Code-Review+2 Verified+1
|Patch Set 4: -Code-Review Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)

1 nit.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Makes sense and looks like this while loop was introduced to just find -rpm2.

I assume with the new host attributes system we don't need to search for the second rpm anymore, correct?
|Patch Set 1:

Hmmm this change makes me hesitant. The most basic test would be to flash the SPI chip on link via Servo V3: https://sites.google.com/a/google.com/chromeos-partner/hardware-control-and-debug/servo#TOC-How-do-I-re-flash-firmware-stored-on-an-SPI-flash-device-

And I have a feeling that might break with this change.
|Patch Set 1:

Try to flash the SPI chip on link and if it doesn't work we should look at your usecase:

Is this a 1-off for debugging ensemble or do you need other people to do the same thing you're trying. If so then we likely need to refactor this change and maybe create a new overlay for your usecase.
|Patch Set 1: Code-Review+2

Then I guess you found a legit bug. Looking at https://chromium-review.googlesource.com/#/c/179893/ it seems I only checked that the chip was detectable via flashrom.

FAFT in the lab has been broken for a while so I don't believe this is actually getting exercised in the lab currently so I don't think we need to worry about breaking anything over there. Mostly we just use the I2C and GPIOs in the lab for reimaging devices mostly.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: -Code-Review Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

Die CL Die
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Actually I may fix this on the Moblab side, holding off on committing.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

Just kicked off a trybot let me know if I did this wrong.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

It worked and I discovered I forgot a test.

Inheriting +2.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

Failure looks like crbug.com/411693
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(5 comments)
|Patch Set 4: Verified+1
|Patch Set 4:

ping
|Patch Set 4:

Ahh I had fixed that slight bug (the double //) when testing on the live system AFTER I had tested with unittests.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Sorry should have re-ran the unittests even after making a small change.
|Patch Set 5:

(6 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified-1

Hey Richard, I know we're almost done with reviewing this but I want to make a slight change to prepare for a future change. I'm going to move the figuring out the offload URI logic to its own function in utils, this will also be used in the log redirection for the afe change I have planned next.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10: Verified+1

Moved gs_uri generation to utils and rebased.
|Patch Set 10:

(3 comments)
|Uploaded patch set 11.
|Patch Set 11: Verified+1
|Patch Set 11: Verified-1

Going to add a random ID to moblab's result path.
|Uploaded patch set 12.
|Patch Set 12: Verified-1

Augh Jacob's changes will make me have to do a rebase...
|Uploaded patch set 13.
|Patch Set 13: Verified+1

(1 comment)

Minus the nested decorator this should be verified.
|Uploaded patch set 14.
|Patch Set 14: Verified+1
|Uploaded patch set 15.
|Patch Set 15: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 15: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 15: Commit-Queue+1
|Patch Set 15: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 16.
|Patch Set 16: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Just kicked off the trybots but want to try and land this once that passes.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased
|Uploaded patch set 1.
|Patch Set 1: Verified-1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

PS2: Made this cleaner as it now checks the count of afe_jobs, so we're protected if we do database pruning in the future.
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(1 comment)
|Patch Set 2:

Note the CQ-DEPEND= line if you need more info.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2

Still waiting on a +2 for CL:217822
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

Looks good overall. Added Prathmesh as he was going to do this work.

1 major comment. How about calling the new overlay project-mobbase? We plan to enable lab and/or build features via useflags in the child overlays.
|Patch Set 1:

Lets go with mobbase as thats what we planned to name it initially.

Unless Sosa/Prathmesh have other suggestions?
|Patch Set 4:

(2 comments)
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)

1 Nit
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 10: Commit-Queue+1

(2 comments)
|Patch Set 10: Code-Review+1 -Commit-Queue

whoops
|Patch Set 10:

(1 comment)
|Patch Set 11: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Thanks Dan, I hit this issue yesterday actually but was too busy to investigate.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

ping
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

ping
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

ping
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3:

TBH I've never looked at portage_util, you should add reviewers who work on this utility.
|Patch Set 2: Code-Review+2
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Abandoned

ppraphu's cl takes care of this.
|Patch Set 3: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 3:

Can you go through requesting a builder etc for this as well, you may have to do that after this lands.
|Patch Set 5: Code-Review+2
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

pause on this for a second
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue
|Patch Set 3: Commit-Queue+1

This is good to go, the weird issues I was seeing was related to Jakob's fix getting reverted and the latest builds I was using to test with were affected.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

ping
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 3: Commit-Queue+2 Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

(1 comment)
|Patch Set 4:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5:

So the main difference between ps4/5:

* I removed the creation of the original autotest.tar artifact completely.

I did not refactor the way Beeps wanted. I want to keep these methods available for this to CL to leverage: https://chromium-review.googlesource.com/#/c/221329

While I can reduce duplicity but refactoring to a single method and calling it over a loop, then I reintroduce duplicity when adding a new caller.

Alternatively I could collapse the 2 new command methods into a single method that places both tarballs the tempdir. I am open to that.
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(2 comments)
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

The problem with that is once I land the chromite changes (after this change lands) the old autotest.tar ball will no longer exist. https://chromium-review.googlesource.com/#/c/225060/ The reason I am not making the old and new is that I don't want to add 4 minutes to all builds including CQ.

Therefore I wanted to leave support for both types of tarballs.

I can centralize the logic in devserver so that if its asked to stage autotest.tar, try the new tarballs first.

I don't see an easy way to avoid 2 roundtrips without me knowing exactly what the buildname will be when my chromite changes land...
|Patch Set 1:

&quot;When I say I can centralize the logic in devserver&quot; I mean the autotest client dev_server.py code.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Beeps, see if you can look at this by tomorrow as we need this change to be in the next MobLab release before landing the chromite changes.
|Patch Set 2:

(6 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 6:

(22 comments)

For coding style errors PTAL @ http://git.chromium.org/gitweb/?p=chromiumos/third_party/autotest.git;a=log

Main comment is to move those classes out to their own module. This would be cleaner for the test and allow other tests/tools to access them.
|Patch Set 8:

(3 comments)
|Patch Set 9:

(11 comments)

Gave a much closer look right now, still got some more comments.
|Patch Set 11: Code-Review+2

(1 comment)
|Patch Set 12: Code-Review+2
|Patch Set 1:

Is there a bug? Why are we making this change?

Control files are supposed to be mostly metadata anyways.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Jay for review. Preeyanka for fyi.

Once this lands new builds of moblab will automatically offload results after 1 day.
|Patch Set 1:

Yes offloading also deletes it locally.

I thought in the last meeting we thought about that problem, looked back at the past projects and saw no conflicts?
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 8:

(7 comments)

K so I started going through this but decided to take a step back and ask some questions:

Why are we not using Django models like the rest of autotest? I feel like theres a lot of stuff here that is reinventing the wheel. Do we really need to reimplement interacting with a mysql database via python?
|Patch Set 9:

K so I just talked with Beeps and we both agree that you should be using Django or some sort of ORM.

What you should do is take over the db_router work and finish it, and then use Django models to handle this.

We both agree we should not be reimplementing all this logic cause it won't be maintainable in the long run.
|Uploaded patch set 1.
|Patch Set 1:

(8 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue
|Uploaded patch set 5.
|Patch Set 6: Commit message was updated
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Forgot to revbump the ebuild. Inheriting +2.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

1 NIT
|Patch Set 1: Code-Review+2

&quot;No URLs matched&quot; is the correct string.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

The script kept sleeping when shill was stopped.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified-1

Still doing testing on this.
|Patch Set 2: Verified+1

Works locally. Still waiting on trybots.

Mike is there a different way you envisioned this or any other trybots you suggest me testing with?
|Patch Set 2:

@pprabhu on the bug, Mike says its likely best if we have it calling the correct cros_sdk in all cases. Comments #1&amp;3
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified-1

A bunch of unitttests failed. Mostly as they were looking for 'cros_sdk' not the full path.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Updated unittests. Trybots passed.
|Patch Set 5: -Commit-Queue
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 6:

(1 comment)

My bad for rushing.
|Patch Set 6: -Code-Review -Commit-Queue
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 8: Verified+1

K trying this again.

lumpy-paladin trybot build was successful.
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 5:

(7 comments)

Thanks for taking the time to redo this as Django models. Long term this is going to be much more maintainable.
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Relanding this so we can retry it tomorrow in the lab.
|Patch Set 1:

(9 comments)
|Patch Set 4:

(3 comments)
|Patch Set 6: Code-Review+2

(1 comment)

1 nit
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

ping.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(7 comments)
|Uploaded patch set 2.
|Patch Set 2:

Ping.
|Uploaded patch set 3.
|Patch Set 2:

(6 comments)
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Fixed final Nit. Inheriting +2
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

Hi Darren, this is to follow up on remounting /home for mobbuild like we discussed with you and wad@.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

The builder sets the timeout 220. I could lower that? I'd rather have 1 timeout then multiple.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

So PS1 and PS2 are 2 different approaches to this problem.

Let me know which one you guys prefer (if either).
|Patch Set 2:

Also a note: I don't think trybots can actually test it as they patch in this change when bootstrapping into /tmp
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(6 comments)
|Uploaded patch set 4.
|Patch Set 4:

PS4 is a rebase.
|Patch Set 4:

So if the implicit API is a bad idea should we just skip using the decorator and have this stage set the tempdir in the constructor? Essentially what PS1 did?
|Uploaded patch set 5.
|Patch Set 1:

(3 comments)
|Patch Set 5:

Reuploaded PS1 with fixes to Vapier's comments.
|Uploaded patch set 6.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

K I'll separate the safe stuff to their own CL momentarily.

As for the unsafe side heres an incremental build trybot run that passed Friday:
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/lumpy-incremental-paladin/builds/195
|Patch Set 2:

It failed unittests on lumpy-release but not paladin so splitting it out.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

K so this passed all 3 builders release, paladin, incremental-paladin.

It requires no unittest update as they all have cwd set to None, which following my logic will skip the path change.
|Uploaded patch set 5.
|Patch Set 5:

ping
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 6:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased off of Vapier's big whitespace cleanup.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Its not on a peppy test image, if thats good enough?
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Just kicked off a tryjob with Vapier's change and my change.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

So this lands when if I'm on vacation, someone please +2.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3:

Well as a string should I not be able to get the stable or dev build?

Whats their naming format??
|Patch Set 2:

(6 comments)
|Patch Set 5:

(8 comments)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3:

(14 comments)
|Uploaded patch set 4.
|Patch Set 4:

(5 comments)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 1:

David James pointed me towards a quick easy fix, I'll post that.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

I can do a local cbuildbot run with it to verify.
|Patch Set 1:

The unittests now pass with this CL. Thanks Derat!
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 4: -Commit-Queue

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: -Code-Review Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Published edit on patch set 2
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

rebased.
|Patch Set 4: -Commit-Queue Verified-1
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified+1 Trybot-Ready+1

This is ready for review/to land.
|Patch Set 6:

ping
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 1:

Looks good to me but you may need an autotest change as well for the drones.
|Patch Set 2:

Adding Preeyanka to review the UI on Matthew's box.
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)

I think you missed my comment in PS3
|Patch Set 5:

(1 comment)
|Patch Set 7: Code-Review+2

Double check with preeyanka then you can submit this
|Patch Set 10: Code-Review+2
|Patch Set 3: Code-Review+1

Let Richard also take a look.
|Patch Set 5: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 6:

(13 comments)

Sorry for the delay, was deputy last week.

Lots of style issues.
|Patch Set 9: Code-Review+2

(1 comment)

1 last comment, I kind of feel lets just call the main file sequence.py and then I think this is good to go.
|Patch Set 10: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Updated unittests.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Published edit on patch set 1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Going to chump to ensure it makes the next build.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

True run moblab trybot with --hwtest
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

the mario incremental builders appear to have vmtests enabled so up to you if you want more coverage by enabling it on yours as well.
|Patch Set 2: Code-Review+2

LGTM but please first do a trybot run to verify.
|Patch Set 2: Verified-1

I did a quick test and it doesn't work.

To test your change use image: storm-release/R45-7086.0.0 and there should be a server test named jetstream_Connect
|Patch Set 3:

Quick functionality comments:

1) Reset button at the buttom of the page does not clear out the tests.
2) storm-release/LATEST does not work but we support using that naming format to run suites. Look at client/common_lib/cros/dev_server.py:translate
3) Lets name the button. Fetch tests for build
4) Alert if they push the button with no image.
|Patch Set 4:

(13 comments)
|Patch Set 8:

(2 comments)
|Patch Set 8:

(1 comment)
|Patch Set 8: Code-Review+2
|Patch Set 8: -Code-Review
|Patch Set 8:

(1 comment)
|Patch Set 9: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3:

(5 comments)
|Patch Set 4:

(1 comment)
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review-1

(6 comments)

So I did a quick look and I want you to kind of do this slightly differently.

Here's my big issue: as a user I have no idea where my tests are coming from. The suite control files, client tests and server tests are coming from 2 places with this approach.

I think what you should do here is first change --ssp_build to either a flag that indicates that the tests come from the firmware build or the regular build. OR rename it to something like --testing_build.

Now all my testing should be done with this build. First it looks up suite control files from that build. Then it looks for all the tests that belong to that suite by looking at the same build. And update even the Client side code paths so that those tests come from the same place as the server side tests.
|Patch Set 2:

Be careful changing job_repo_url. My only worry there is that other tests that run after want to install the test_build might assume that the test_build is installed when it really isn't. This may or may not be the case though.
|Patch Set 5:

(5 comments)

You do self._builds.get(provision.CROS_VERSION_PREFIX,
                                 self._builds.values()[0]) a lot.

Why do we need the default? Maybe I am just missing something.
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 5:

(10 comments)
|Patch Set 7:

(4 comments)
|Patch Set 8: Code-Review+2

I'll bow in favor of Vapier's comments since he's touched chromite more than I have.
|Patch Set 9: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)

1 NIT Really
|Patch Set 5: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)

LGTM but please do a trybot build to verify.
|Patch Set 3:

(6 comments)
|Patch Set 1: Verified-1

This is failing the CQ:

Look at autoserv.DEBUG at https://pantheon.corp.google.com/storage/browser/chromeos-autotest-results/33414524-chromeos-test/chromeos4-row1-rack4-host11/ssp_logs/debug/
|Patch Set 1: Code-Review+2
|Patch Set 1:

(3 comments)
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+2

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2

(1 comment)

One last question/nit but regardless of the answer LGTM
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 7:

(3 comments)

What if I don't have an external drive but a massive internal drive? I should still be able to use mobbuild...
|Patch Set 7:

(1 comment)
|Patch Set 12: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 3:

(6 comments)
|Patch Set 4: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+1

LGTM but will leave +2 to Richard for his Bash expertise.
|Patch Set 2: Code-Review+2
|Patch Set 1:

(7 comments)

Overall good job.

No this is fine as 1 CL. If it was 700 line of non-unittests then yes break it up and yes unittests belong in the same commit.
|Patch Set 3:

(2 comments)
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

Sorry the title was wrong.

The dependency is that users of dut-control may be working with servo V3 and require screen to access the beaglebone and retrieve the IP of the Beaglebone device to feed into dut-control.

If you feel like this dependency is not proper I can revert this and put it elsewhere.
|Patch Set 5: Code-Review+1
|Patch Set 5:

Is this dead?
|Patch Set 1:

(1 comment)
|Patch Set 1:

cbuildbot-deps-0.0.1-r0 should also be a symlink, doesn't look like that from here.
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Your build failure looks like google storage flake.
|Patch Set 6:

(3 comments)
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 6:

(3 comments)
|Patch Set 1: Code-Review+2

(1 comment)

1 nit
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(5 comments)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review-1

PTAL at chromite/lib/cros_build_lib.py:RunCommand

Odds are most of what you want are there.
|Patch Set 3:

I guess my point was why do you need this CL at all? The callers of commandexecutor.py should just call RunCommand directly?

If that does not have support for pipes, feel free to update it to support pipes or whatever you need :).
|Patch Set 3:

K so your code needs to be packaged and installed on the system. This package can depend on the chromite package to ensure chromite is installed.

From a moblab system right now I can do:
$ python
Python 2.7.3 (default, May 28 2015, 15:05:43) 
[GCC 4.9.x-google 20150123 (prerelease)] on linux2
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; from chromite.lib import cros_build_lib
&gt;&gt;&gt; cros_build_lib.RunCommand
&lt;function RunCommand at 0x7f52cc502938&gt;

I didn't have to do anything special. So you can use assume chromite and it's libraries are on the system and available because you will list it as a dep of your project.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 3:

(5 comments)
|Patch Set 4: Code-Review+2

My only comment is I wish we had named provision.FW_VERSION_PREFIX provision.FW_RW_VERSION_PREFIX.... It's probably too late but it might be worth doing some retroactive cleanup later.
|Patch Set 11:

(3 comments)

This looks pretty close to me but you're using the logging module all wrong.
|Patch Set 44:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

It looks like it tested the wrong Patch Set. Retrying.
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

Hmm this file is already checked in under portage-stable/eclass, you should have access to it there.
|Patch Set 1: Code-Review+2

Got it.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

This is actually pretty clean, good job.

I did find 1 bug:

Select a server side test and a test_suite and you get a confusing error:
&quot;ValidationError: {'tests': 'You cannot run both server- and client-side tests together (tests test_suites:dummy and dummy_PassServer:sanity differ'}&quot;

Should be you can't select a test suite and a server side test together.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 3:

(1 comment)

I think you should add a dummy health check and action OR a README with an example of each.
|Patch Set 3:

A part of me is wondering why wouldn't the check just import the actions it requires and the manager imports the checks?
|Patch Set 5:

(4 comments)
|Patch Set 7: Code-Review+1

+1 to give Dan/Paul chance to take a final look.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

(6 comments)

It took me a bit of time to wrap my head around what is going on in manager.py, I think you can do a bit of refactoring/cleanup to make this clearer and I'm not sure you really need the self.service_check_results as an instance variable
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Patch Set 2:

Do you guys have a paladin builder? If not maybe we should set one up so lakitu is protected via the CQ.
|Patch Set 4: Code-Review+1

I'm okay with this but adding Davidjames for a second opinion.
|Patch Set 5: Code-Review+2
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2:

I'm assuming we need to update:
src/overlays/project-mobbase/chromeos-base/chromeos-firewall-init-mobbase/files/{iptables.conf&#124;ip6tables.conf} as well?
|Patch Set 2:

I guess I own them, they're just the open firewall for Moblab/Mobbuild. I'll update them after this lands.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(6 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)

Let Mike take a final look tonight.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: I441b86211d46a19ae0d38f92c47e16f942b01fc5
|Patch Set 1: Code-Review+2
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2 Commit-Queue+1
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 1:

Added Richard to review.

Is there not a better a way to handle this outside of gs_offloader?? Maybe in scheduler?
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+1

Just read through this, lgtm but since fang did most the review I'll leave the +2 to her.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

Since this is a UI, can you point us at one?

I would also suggest having a check in place so we can see what to expect.

The easiest would be the missing installation of a .boto file.
|Patch Set 2:

(2 comments)

Please ask around the team for someone who has JS experience to review. I honestly have done very little JS.
|Patch Set 7: Code-Review+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)

Install an SSH config file as well so that we can just use your new rsa keys off the bat.

I expect the ssh config file to look like:
Host 192.168.231.*
CheckHostIP no
StrictHostKeyChecking no
IdentityFile %d/.ssh/moblab_id_rsa
Protocol 2
|Patch Set 2:

For testing ignore the VMTest failures.

For testing I would go to cautotest and run a job with build=trybot-stumpy_moblab-paladin/R46-7349.0.0-b112

and run test_suites:moblab

I kicked off a job here for you http://cautotest.corp.google.com/afe/#tab_id=view_job&amp;object_id=38855754
|Patch Set 6:

So here's something I am worried about:

You had to do a chmod on the key in the init scripts.

If I make a non-test (aka a regular) image for Moblab. Can I still ssh as user root to the DUTS?

I think this might be not true.

1) I am not sure if id_rsa is still installed.
2) I am now worried about the permissions.

Someone needs to do a regular build and test this out at their desk. I can do that for you tomorrow or Friday likely.
|Patch Set 6:

He changed that exact line to point to the virtual now.

I just want to verify that normal ssh usage remains the same for base images. He also had a permissions issue with testing and had to adjust the key permissions so I am worried that might bleed over into the rootfs's key's permissions
|Patch Set 7:

(3 comments)

Talked with prabhu, we don't like the hacky moving of the key file.

Please handle the TODO now, it should be relatively simple.
|Patch Set 8:

Just add to the chromeos-base/chromeos-test-testauthkeys-moblab a files/ dir and put a config file it in, exactly as I said in PS2. Just install that under /root/.ssh and you don't need the changes you put in moblab-apache-init and moblab-homedir-init anymore.
|Patch Set 9:

(2 comments)
|Patch Set 11:

Hmm PS10 almost works:

moblab@localhost ~ $ ssh root@192.168.231.100
Failed to add the host to the list of known hosts (/home/chronos/user/.ssh/known_hosts).
Failed to add the host to the list of known hosts (/home/chronos/user/.ssh/known_hosts).
Last login: Wed Aug 12 16:34:05 PDT 2015 from 192.168.231.1 on pts/0
localhost ~ # 


Those &quot;Failed to add the host to the list of known hosts (/home/chronos/user/.ssh/known_hosts).&quot; messages shouldn't be there.
|Patch Set 11:

(1 comment)
|Patch Set 11:

Hmm so now this is getting tricky. Each user needs their own UserKnownHostsFile line.
|Patch Set 11:

I am going to test out:

Host *
        UserKnownHostsFile %d/.ssh/known_hosts
	CheckHostIP no
	StrictHostKeyChecking no
	IdentityFile %d/.ssh/moblab_id_rsa
	Protocol 2
|Patch Set 13:

:(

Still doesn't work:

$ ssh root@192.168.231.100
Failed to add the host to the list of known hosts (%d/.ssh/known_hosts).
Failed to add the host to the list of known hosts (%d/.ssh/known_hosts).
|Patch Set 14:

Sorry was busy yesterday, testing now.
|Patch Set 14:

(1 comment)

Lets not use a config file, point it to /dev/null

It works now but I ran a suite and reimaged the DUT and then ssh complained:
$ ssh root@192.168.231.100
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the RSA key sent by the remote host is
c8:14:a2:7c:1c:05:90:6a:3b:30:f5:a0:ed:a7:f1:ae. 
Please contact your system administrator.
Add correct host key in /home/moblab/.ssh/known_hosts to get rid of this message.
Offending RSA key in /home/moblab/.ssh/known_hosts:1
Password authentication is disabled to avoid man-in-the-middle attacks.
Keyboard-interactive authentication is disabled to avoid man-in-the-middle attacks.
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the RSA key sent by the remote host is
                                                          c8:14:a2:7c:1c:05:90:6a:3b:30:f5:a0:ed:a7:f1
:ae.
Please contact your system administrator.
Add correct host key in /home/moblab/.ssh/known_hosts to get rid of this message.
Offending RSA key in /home/moblab/.ssh/known_hosts:1


I don't want to clog our test logs with these messages. Just point the host file to /dev/null and we'll be good.
|Patch Set 15: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Patch Set 1: Verified+1
|Patch Set 1:

Guado_moblabs come with 128GB SSD while panther and stumpy mount a usb key to hold the containers.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1

If he speaks before it gets in sure, otherwise this will be deleted pretty soon anyways.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(12 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(5 comments)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 4: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 2: Verified-1

(1 comment)

kicking off tryjobs to verify.

Don if you see something glaring wrong feel free to point out.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

inheriting +2
|Patch Set 3: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+1

Please get someone to verify the js changes.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2

(1 comment)

One nit
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(2 comments)

couple of nits
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

(5 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(3 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

Hey Matthew, what if I want to passthrough more than 1 device?

It would be really cool if this supported up to N devices.
|Patch Set 2: Code-Review+2

Richards out but LGTM
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(23 comments)
|Uploaded patch set 3.
|Patch Set 3:

(6 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

(5 comments)
|Patch Set 3:

(1 comment)

1 Nit
|Patch Set 4: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 5: Code-Review+2
|Patch Set 5:

(12 comments)
|Patch Set 7: Code-Review+1

(1 comment)
|Patch Set 9:

(1 comment)
|Patch Set 10: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(5 comments)
|Patch Set 3: Code-Review+2
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)

1 NIT
|Patch Set 1:

I added Kevin, hmm how much Brillo specific code do you expect to add to adb_host?
|Patch Set 1:

(1 comment)

So really I'm wondering if we need to split adb_host and brillo and maybe a brillo descendant.

But then we would need to rethink the check_host logic.

It really depends on how much brillo specific code we expect here.

But my suggestion might be enough for now and we can rethink this problem down the line.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2
|Patch Set 4:

So you're missing the saving and retrieval of the serials as host attributes.

The host add process should take the serials you inputted and save them as a host attribute. Look at cros_host and cntl+f for host_attribute to see how it uses the AFE to get/save the values.

The creation of a new adb_host should be updated so that when no serial is passed in, it tries to look up the serials from the host attributes. If its not there, check if there is 1 device and use that. If there are multiple devices and they're not saved as host attributes, error out.
|Patch Set 5:

Yup Fang is right about the labels, but I don't think Kevin has gotten multiple device support going yet.
|Patch Set 6:

(2 comments)
|Patch Set 7:

(2 comments)
|Patch Set 7:

Does the label decorator code work now?
|Patch Set 8:

(1 comment)
|Patch Set 8:

(1 comment)
|Patch Set 10: Code-Review+2

(2 comments)

2 Nits otherwise LGTM
|Patch Set 2: Code-Review+2
|Patch Set 3:

Hey Don, using a template here would make sense right?
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3:

No the work here is not meant for Chromite, its meant to lower the entry bar for testing with MobLab (i.e. not having to acquire hardware).
|Patch Set 5: Code-Review+1

Boom this works, thanks Matthew, leaving final +2 on Vapier.
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Dshi/kev just for FYI
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Patch Set 2:

(11 comments)
|Uploaded patch set 4.
|Patch Set 2:

(7 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

Hey so this is the starting group for the PTS Kickoff.

Not completed yet but what I have so far will contact the moblab and launch PTS (does not include AU E2E yet).

I figured before this CL grows any bigger lets do a review and iterate.

Thanks.
|Patch Set 3:

(4 comments)
|Patch Set 3:

(15 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: Code-Review+2

Works!
|Patch Set 1:

I'm fine with supporting both options.

Just know that the device id on the bus is incremented by the kernel everytime a new device is connected or a device is restarted.
|Patch Set 1: Verified-1

./bin/cros_start_vm --moblab --image_path ../build/images/guado_moblab/latest/chromiumos_image.bin --usb_devices=13b1:0041

qemu-system-x86_64: -device usb-host,hostbus=13b1,hostaddr=0041: Invalid parameter type for 'hostbus', expected: integer
|Patch Set 3:

(1 comment)
|Patch Set 4:

I think you need to update this for the property change.
|Patch Set 5: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 1:

(4 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

So the problem here is:

SSH only works with &quot;localhost&quot;
The web interfaces: AFE and it's RPC's only work with &quot;127.0.0.1&quot;

Hence the differences :/
|Patch Set 4:

(3 comments)
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch set 5: Commit message was updated.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2:

Dan is out, I think we prefer property
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

Looks good minus the confliction with the CL I just put in the CQ
|Patch Set 3:

(1 comment)

I guess I'm okay with this change but you should take a look at your office's network settings to see if it can be addressed that way.

And there's still a bug in the code.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review-1

For this I was thinking of adding --test_args and those would just get piped into the rpc create_job call.

Does that align with what you were trying to do? The rpc_interface.create_job just calls tools.inject_vars but I would rather keep the code centralized there than have this 1 caller do it outside.
|Patch Set 2:

(3 comments)

The commented changes should make this work as expected for all tests using multiple -A for each arg passed in.

Gilad can you verify the e2e works still?
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Verified-1

found a slight bug.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Verified-1

(1 comment)
|Patch Set 1: Verified+1

I'm going to leave this as marked verified as it will fix the AFE problem for now but other callers are still broken.
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(5 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Abandoned
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

Can you remove the temp fixes as well?
|Patch Set 1:

Actually just remove the temp fix in create_job_page_handler
|Patch Set 1:

(5 comments)
|Patch Set 2: Code-Review+1
|Patch Set 2:

I'll let Aditya take one more pass, he can +2 if hes happy.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

I think after our discussion yesterday we are going to need a host to represent the test station.

With that done, we can just have the adb_host have a test_station attribute attribute that points to that host and the test writer can use that host's send/get to do file transfers.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 5:

(4 comments)
|Patch Set 9: Code-Review+2
|Patch Set 14:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(9 comments)
|Patch Set 3:

(3 comments)
|Patch Set 4:

(3 comments)
|Patch Set 3: Code-Review+2

(2 comments)

Minor nits
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

This is very close to kicking off ACTS properly but hits the following error:

test_that --debug --autotest_dir=../third_party/autotest/files/ android1758-wifi-test-station-2.cros ACTSSampleTest

....
....

17:19:13 INFO &#124; autoserv&#124; Running: act.py -c /tmp/autoserv-CAiXFM/sample_config.txt -tb SampleTestBed -tc SampleTest
17:19:13 INFO &#124; autoserv&#124; Running (ssh) 'act.py -c /tmp/autoserv-CAiXFM/sample_config.txt -tb SampleTestBed -tc SampleTest'
17:19:20 INFO &#124; autoserv&#124; [stdout] Exception when executing SampleTestBed, iteration 0. 
17:19:20 INFO &#124; autoserv&#124; [stdout] Traceback (most recent call last):
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;/home/test/acts-0.2/acts/bin/act.py&quot;, line 212, in _run_test
17:19:20 INFO &#124; autoserv&#124; [stdout]     test_runner.run()
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;/home/test/acts-0.2/acts/test_runner.py&quot;, line 203, in run
17:19:20 INFO &#124; autoserv&#124; [stdout]     self.run_test_class(test_cls_name, test_case_names)
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;/home/test/acts-0.2/acts/test_runner.py&quot;, line 177, in run_test_class
17:19:20 INFO &#124; autoserv&#124; [stdout]     importlib.import_module(test_cls_name)
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;/usr/lib/python3.4/importlib/__init__.py&quot;, line 109, in import_module
17:19:20 INFO &#124; autoserv&#124; [stdout]     return _bootstrap._gcd_import(name[level:], package, level)
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 2231, in _gcd_import
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 2214, in _find_and_load
17:19:20 INFO &#124; autoserv&#124; [stdout]   File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 2201, in _find_and_load_unlocked
17:19:20 INFO &#124; autoserv&#124; [stdout] ImportError: No module named 'SampleTest'
|Uploaded patch set 4.
|Patch Set 6:

the factory/testbed changes I landed in a new cl: https://chromium-review.googlesource.com/#/c/317918/
|Patch Set 6:

(3 comments)
|Patch Set 7:

(1 comment)
|Uploaded patch set 10.
|Patch Set 12:

(1 comment)
|Uploaded patch set 13.
|Patch Set 13: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 7: Code-Review+2

(1 comment)

Same nit lets put the removal of serials on kevin.
|Patch Set 7:

Just saw your reply, ignore me its fine.
|Patch Set 1:

(9 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(2 comments)
|Patch Set 4: Code-Review+2

(1 comment)

Sorry for the delay,

In the future I think you should cc-Andrey or someone on your team for quicker reviews too.
|Patch Set 1:

(18 comments)
|Patch Set 7: Code-Review+2
|Patch Set 3:

(3 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1

I'll let Dan take one more pass
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(3 comments)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 4:

(2 comments)

Hmm upon closer inspection I do get Richard's comments that the test station's deviation from ssh host might be non-existent, currently...

It might be worth just getting rid of the teststation_host object and instantiate an ssh_host, unless there is a compelling reason that we will need specialized logic here in the future (in which case lets introduce it then).
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 11:

(1 comment)
|Patch Set 8: Reverted

This patchset was reverted in change: I057df80e2208fbce020e878d677e8b1e5f9656d0
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3:

Talked to Dan, lets add a proper retry decorator to the devserver repo.

No need to depend on chromite, lets just add it somewhere here as a util
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 1:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)

Testing wise I would say add a non-DUT to a Moblab and ensure your code changes operates repair the same way as before.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(10 comments)

Agree with your statement on repair/verify should go in the next CL.
|Patch Set 4: Code-Review+1

This requires a rebase.
|Patch Set 4:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review-1

(2 comments)
|Patch Set 4:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: -Code-Review
|Patch Set 1:

Charlene does your attribute_whitelist operate at suite runtime right?

David, I believe it should still work fine, jetstream does this themselves in src/platform/ap-daemons/autotest/test_suites
|Patch Set 1:

David you will need a new ebuild like https://chrome-internal-review.googlesource.com/#/c/240167/ to install the test_suites.

Look at the autotest-toaster-libs ebuild example in go/autotest-per-project
|Patch Set 4: Code-Review+2
|Uploaded patch set 5.
|Patch Set 5:

(4 comments)

So I agree with your intuition about using the AFE/DB and that was going to be my original approach but it doesn't work the way we want.

The AFE/Fake DB created by test_utils now actually only exist for that process and is only available for scheduling/launching the tests. Now look at line 124 in test_utils:_run_autoserv. Its launching a new process so autoserv can't see these fakes.

Now if the test code tries to access the AFE it actually tries to access the AFE/DB configured in the autotest {global&#124;shadow}_config.

Sigh...

But I was going to have to address this for passing the serial info down, and I don't have a good solution yet either. The only idea I have so far is to add more arguments to autoserv and that somehow passes this extra info down to the control file and then to the host creation but its going to require a lot of piping and be pretty nasty :/...

LMK your thoughts on that or if you have any other ideas?
|Patch Set 5: Verified-1

Still WIP, just publishing so Dan/Kevin can see my host factory changes.
|Patch Set 5:

Aviv and I brainstormed a way around the no AFE/DB problem. We're going to expand the &quot;machine&quot; object (currently its just a string) out to include host information.
|Uploaded patch set 6.
|Patch Set 6:

(3 comments)

This is still a WIP, mainly cause I have yet to move generate_test_report but please take a look, definitely depends on https://chromium-review.googlesource.com/#/c/315230/ 

Wiley because of fix-it week for us, I may want to land this tomorrow (if it seems ready) without moving generate_test_report and if you can do that early next week, this can be wrapped up without losing a week.
|Patch Set 6:

(2 comments)
|Uploaded patch set 7.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10.
|Patch Set 10:

(4 comments)
|Patch Set 10:

(4 comments)
|Uploaded patch set 11.
|Patch Set 10: Verified+1 Trybot-Ready+1

Please review
|Patch Set 11:

(7 comments)
|Uploaded patch set 12.
|Patch Set 11:

(3 comments)
|Uploaded patch set 13.
|Patch Set 12:

(6 comments)
|Uploaded patch set 14.
|Patch Set 14: Verified+1 Trybot-Ready+1
|Uploaded patch set 15.
|Patch Set 15: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 3: Reverted

This patchset was reverted in change: I6fd508271d507d9c01ddea779b03cb0d4a01c250
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 1:

(7 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(4 comments)
|Uploaded patch set 7.
|Patch Set 7:

Dan is right that this will increase DB load but it is 1 extra DB lookup per test run so kind of hard for me to gauge the impact.


But the only other option is to then do the lookup when we need it in create_host logic, and that was a route Aviv was against.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: Verified+1

Sorry for the string of PS uploads but this is good now.
|Patch Set 11:

(3 comments)

Comments from aviv/mine joint review on friday:
|Patch Set 11:

(5 comments)
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting Aviv's +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Patch Set 1:

(6 comments)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review-1

I agree with Mike. Chromite is a dependency of autotest and we refactor common code into chromite. Just import it as a chromite_lib.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 5:

I think that check needs to be moved then as we should discourage talking to the AFE if provision_AutoUpdate is to be launched by test_that.
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 5: Code-Review+2

Than
|Patch Set 5:

Wow thanks for going above and beyond by fixing the style as well!
|Patch Set 7: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)

Successful paladin trybot run:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/paladin/builds/601
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1 Trybot-Ready+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1:

(7 comments)

You forgot to fix the double indents
|Patch Set 4: Code-Review+1

(2 comments)

One more person should give approval.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

Can you post some screenshots?
|Patch Set 1:

(2 comments)
|Patch Set 1:

Also hid the &lt;null&gt; links.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

ping this is blocking intel from running Brillo PTS
|Patch Set 1: Verified+1
|Patch Set 3:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1:

Richard how did we deal with *-freon before this?
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: -Code-Review
|Patch Set 3:

Did you do a trybot run?
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

Does test_that use the scheduler tasks?

How about a trybot run? That kicks off VMTest and that uses test_that.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue -Verified
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 3: -Commit-Queue
|Patch Set 3:

Gilad did not have paramiko installed and hit a problem, moving the import back south.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)

You're going to want to run trybots for guado_moblab and any other platform with --hwtest and make sure nothing breaks.
|Patch Set 2:

Yeah the CQ will suffice.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2:

Thanks for fixing this Dan
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review-1

(2 comments)
|Patch Set 4:

Looking at your following CLs, I think you should move this folder into server/

client/ is code that can run on both the client and server. However looking at https://chromium-review.googlesource.com/#/c/319198/4/client/common_lib/cros/feedback/closed_loop_audio_client.py You are manipulating host objects.

Hence it can only run on the server.
|Patch Set 4:

However if you think there will be client side tests using your Feedback API then you can leave it here but https://chromium-review.googlesource.com/#/c/319198/4 should be in server/
|Patch Set 5: Code-Review+2
|Patch Set 5: Verified+1
|Patch Set 5:

1 last optional comment:

Want to move this up a level client/common_lib/feedback? There's nothing Cros/Brillo specific here.
|Patch Set 5: -Verified
|Patch Set 5:

Can we put the &quot;feedback implementations that are absolutely Brillo specific&quot; in client/common_lib/brillo?
|Patch Set 7: Code-Review+2

Only comment I would have is maybe put periods in the exception strings but I'm impartial.
|Patch Set 4:

(11 comments)
|Patch Set 4:

(4 comments)
|Patch Set 5:

(4 comments)
|Patch Set 9:

(2 comments)
|Patch Set 9:

(1 comment)
|Patch Set 5:

(9 comments)
|Patch Set 9:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 2:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

For the lab we require root access, for some ACTS stations we could not get root so we are using user adb.

I can also add try the current user as well for external devs?
|Uploaded patch set 1.
|Patch Set 1:

Re Wiley: I don't believe we have proper documentation on sequences but they haven been an Autotest concept for at least a year now... As for removing code, I would like to hold off until we externally announce test_droid (I will start the Doc this week) as there could be external users of the brillo pts sequence who could suddenly have the old workflow break on them.


Re Aviv: Thanks for catching that. Pylint stopped/complained due to crbug.com/572719 for which I can't really work around so I had to do --no-verify. However the suite still ran so I'm guessing the attributes stuff only matter for the builders, etc.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(4 comments)
|Patch Set 1:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1:

(5 comments)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1:

(6 comments)
|Patch Set 2:

(7 comments)
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4:

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

Just override the job_start method in gce_host.py to do nothing

Look at adb_host for an example. https://chromium.googlesource.com/chromiumos/third_party/autotest/+/master/server/hosts/adb_host.py Line 342
|Patch Set 1: Code-Review+2

Adding Richard as he has been involved in cleaning up the host objects a lot recently and I am curious to his thoughts about this problem.
|Patch Set 1: -Code-Review
|Patch Set 2:

those messages are more of an annoyance than anything of impact, I think the run method allows you to pipe stderr to /dev/null so they disappear, which is an option
|Patch Set 2:

Thats a fair point, I'll leave the current code for Richard to +2 then
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(5 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(4 comments)
|Patch Set 2:

(4 comments)
|Patch Set 3:

(7 comments)
|Patch Set 4: Code-Review+2
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Please make sure you have enough devices to run the bvt-cq in a timely manner.
|Patch Set 2:

(6 comments)

Can I specify 1 serial and leave the rest as builds that just say the board name?
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: -Code-Review

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 5:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1

Unless someone on your guy's side wants to fix b/26742334 ASAP lets land this for now.
|Patch Set 1: Code-Review+2
|Patch Set 3:

Yes we need both.

Cbuildbot uses ATTRIBUTES and the rest of our tools use SUITE
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Verified-1

(10 comments)

Requesting no more comments until my next PS (tomorrow sometime), a lots changed.
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Trybot-Ready+1

(1 comment)

Alright folks, so I've only done basic testing involving a Chrome OS suite and a Brillo suite run, I still need to do more testing with test_that and launching a regular job with a reimage (not in a suite) to make sure I didn't break anything.

But in the meanwhile I would like it if I can still get comments as I iterate in case anyone has issues with how I rearchitected everything here.


Also I know a lot more stuff can be pulled out of cros_host into afe_utils, I only did the common stuff for adb_host/cros_host. I expect people to continue this cleanup process as they work on these objects in the future.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(2 comments)
|Patch Set 4:

(8 comments)
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Patch Set 6: Verified+1 Trybot-Ready+1
|Patch set 7: Commit message was updated.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Chatted with Fang IRL, we think this should be safe or the CQ should catch anything that could potentially occur.
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

Have you tried running a suite with that custom-named staged build? I have a feeling the machine_install step will fail with a custom name as it compares what the /etc/lsb-release on the build says to the name you use to run the suite.
|Patch Set 1:

(11 comments)

Lets not manipulate self.options.* the way you are and instead use local instance variables.
|Patch Set 4: Code-Review+2
|Patch Set 13: Code-Review+1

I don't have any real issues with this, letting one more person take a look.
|Patch Set 1:

(2 comments)

I added Wiley but probably worth adding other Brillo folks to verify your test's logic.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(3 comments)

minor nits
|Patch Set 2: Code-Review+2
|Patch Set 3:

(5 comments)
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 3: Code-Review+1

(1 comment)

leaving +2 to ralph
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 3:

I'm assuming there is going to be a followup CL to enable emailing to bruteus+buildpolice@google.com right?
|Patch Set 1:

(5 comments)
|Patch Set 1:

Can you do a trybot run with moblab
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 3:

Aviv I guess its on you to develop a strong AI so this does get meaningful CQ testing :P
|Patch Set 1: Code-Review+2

Neat.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

We likely still need the pth file change as well.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(7 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

test_push is still running fyi
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1:

if anyone can +2 tonight I would appreciate that.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)

Did you run pylint against these files?

Instructions are at the bottom of https://chromium.googlesource.com/chromiumos/third_party/autotest/+/master/docs/test-droid.md
|Patch Set 2: Code-Review+2
|Patch Set 3:

(4 comments)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(4 comments)
|Patch Set 1: Code-Review-1

No, the SL4A installation should not be part of android_install at at all.

It should be a utility function called by Ang's test that requests a specific apk to be installed.
|Patch Set 1:

I'll update the bug.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(1 comment)

Just make the return value a bit more defined in the docstring.
|Patch Set 2:

(4 comments)
|Patch Set 2: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

(4 comments)

I think I deduced the problem. Your code is still incorrect as you return 2 different things in the fetch_file function.

Try my suggestions and see if they work.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)

minor comments, undo
|Patch Set 3: Code-Review+2
|Patch Set 3:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(4 comments)
|Patch Set 4:

(2 comments)
|Patch Set 5: Code-Review+2

Thanks Dan, this looks really clean now :)
|Patch Set 2: Code-Review+1
|Patch Set 1:

(1 comment)

Brillo may need this support too, seems like you're only doing it for Android?
|Patch Set 1: Code-Review+2

(1 comment)

Discussed IRL
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 3:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch set 2: Published edit on patch set 1.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

If we are making serial optional, there should be a change in test_droid to look it up and pass it to the test if there is only one.

Let's have a convo on b/27301538
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(6 comments)
|Patch Set 2: Code-Review+1

I have no other comments beside the refactoring in task.py

Letting Kevin take a fine pass and +2
|Patch Set 2: Code-Review+2
|Patch Set 1:

Did you change the ebuild at all?

If not please put it in portage stable as per https://www.chromium.org/chromium-os/gentoo-package-upgrade-process
|Patch Set 1:

Couldn't we have both the old and the new version in Portage-stable?

Mike?
|Patch Set 1: Code-Review+2
|Patch Set 2:

Can I get the IP of the device that is running with these settings?
|Patch Set 1: Code-Review+2
|Patch Set 1:

if the test works against the emulator add it to brillo-smoke as well.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

No comments.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R50-7978.B as commit 1cd924ff8b793f1a66b6f090050d75701e4ecea4
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

This is for MobLab to be able to do repairs FYI
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 5: Cherry Picked

This patchset was cherry picked to branch release-R50-7978.B as commit b4c2abb726654325ed05443c5c278307fa633c7e
|Patch Set 1: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 4:

(3 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review-1

(1 comment)

I recommend cleaning up the sanity stuff before sending this into the CQ.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Please import xbuddy only before you use it (i.e., in TranslateImagePath())

Importing xbuddy here forces users to have the entire chroimum os source checkout. If you just want to use a local image, you don't need the xbuddy module.
|Please change the name to reflect the fact that xbuddy may also download/stage the image.
|How about adding a flag in the XBuddy constructor to change the logging configuration?
|Do you have to import cherrypy and set the config here? This seems out of place.
|collapse this with the previous line.
|Collapse this line to the previous line
|trailing space
|A one line comment explaining why we import xbuddy in this function would be nice.
|Like Mike suggested in the other CL, this should be log_screen=False)
|Just a nit. Only this line needs to be in the &quot;try except&quot; block as this is the only line that could raise XBuddyException
|Done
|Switched to using a loop based on your suggestion.
|Done
|It was in the cros_vm_test CL which was later reverted, so it's not in the tree anymore. I want to put it in a more common place so that I can reuse (it'll be used by cros_vm_test, at least). Do you have any suggestions?
|There are at least two right(?) ways to do this, if you're interested:
 1. Add support in devserver to stage a local image directly. This will achieve what you want and will also help get rid of all the strange symlinks required for cros flash to work.
 2. Bypass devserver completely. Call other scripts to generate the payloads.

As for factoring out the functions from `cros flash`, devserver_wrapper seems like a good place.
|We are enforcing this:
 from __future__ import print_function
|Don't think you mean that.
|Use os.path.join
|two &quot;be&quot;s

Maybe:

  Generate the name as which &#124;image&#124; will be staged onto Moblab.
|You would also want to mention what this &quot;image&quot; path looks like because you make a lot of assumptions in the function below. For example, the path typically looks like

  /buildroot/.../.../board/build/foo.bin
|whose? :\

May want to clarify that this is a path.
|No need to define the variable name here.
|You may want to use osutils.ExpandPath which also expands '~' if necessary
|lacking a space:
  % realpath
|Make it more readable:
  len('-a1')
|this is where the example in the docstring would help the reviewer :)
|This is a ChromiumOSDevice object...not the handler itself.
|This is a weird way of using RemoteDeviceUpdater. If all you need is the two methods, try and make those class methods.

If you want more, you can create a new base class and inherit from there.
|This is another example why using RemoteDeviceUpdater this way is weird...now you have to clean up its tempdir :\
|One line docstring
|Perform
|this is already the default.
|logging?

If you want to print, you need to use print() (see comment at line 6)
|Why did you change this? There is no RemoteSsh.
|I would still prefer moving most of the logic here to another helper function in dev_server_wrapper.py. The similar code appears in cros flash too.
|Is this check necessary? dev_server_wrapper.GetUpdatePayloads would raise an exception if anything goes wrong. Perhaps you should catch that and re-raise if you want.
|Maybe explain that the callers need to clean the temp directories themselves.
|You may want to mention that this needs to be a directory in the chroot.
|I am not sure whether this should be defined here. It is essentially a static directory that `cros flash` chooses to use and I am not sure whether other consumers of this module would agree.
|Add a new line.
|Add a new line.
|Add a new line.
|Add a new line.
|Add a new line.
|You may want to change this now that the function is no longer in cros flash.
|If you want to avoid returning image_tempdir and static_tempdir, you can pass the temp directories to ConvertLocalPathToXbuddyPath() using the with context.

This needs some more refactoring, but might be cleaner. For example, you can add a new function that uses the with context and calls ConvertLocalPathToXbuddyPath() and GetUpdatePayloads()
|Add a new line.
|It should be made clear that on failure, the devserver log will be copied to &#124;payload_dir&#124;.
|Add a new line.
|Just a minor suggestion. Could _build_all_calls() bypass the hashing step completely? This is to ensure it iterates through the _dev_servers list regardless how the hash function is implemented (which can be changed later if needed).
|Done
|Oops...sorry. Fixed.
|Done
|Done
|Done
|Exactly, we can either tell the file type by the filename, or make it an argument for the calling object to specify.
|I did that because it seemed that the subclass should implement its own _ExtratTarball().
|Yes. Ryan does clean up the try jobs periodically (30 days?). I used this because there was currently no 'autotest.tar' in the release archives. Maybe I can submit another CL later when the file is available somewhere?

(p.s. the downside of using a real autotest tarball is that the size is ~500 MB.)
|Sorry missed the comment. Fixed.
|Fixed the indent here too.
|Yes. Removed in patch 2.
|Done
|Done
|Done
|Done
|Removed
|To accommodate more versatile extensions which may include a '.' or not (e.g. tar.bz2, tgz, tar), I will use re.search('.tar.bz2$') instead.
|hmm...All autotest tarballs and test results log to &quot;Info&quot; when no file is found. Is there a general guideline for logging?
|This commands only copies the file to the local archive_dir, which is later used for hwqual image. To actually upload to Google Storage, the file would need to be put into an upload queue.
|I just rebased and buildroot is used in used in BuildTarball for pbzip2 path.
|Done
|Doesn't need the filename. Removed.
|Done
|if we dargs everything, shouldn't the user still need to look at the base implementation for the arguments?
|Done
|Done
|Sorry it should be defaulted to true. Fixed. Also dropped this from the argument list.
|Make it self.REBOOT_TIMEOUT.
|Done
|The fastsync only performs more sync before reboot. I don't think we need that.
|Agreed. I was trying to cleanup other parts of the function as well, but I don't think we can save much by doing that. Fixed in the next patch.
|Thanks for the clarification. Fixed.
|Done
|I thought about it, but then there would be smaller changes  all over the place and would be hard to maintain. Having our own reboot method is much cleaner.
|Done
|Done
|It is indeed correctly logged in the log file.
|This updates the status at a job level (Host.job).
|Thanks for the input. If it sleeps for 5 seconds, this CL will not save any time for us. Is there a way to determine what the minimum sleep time is? What if we do not sleep at all? Will that cause any problem (e.g. reboot after reimaging)?
|Arghh... got it. change to reboot in the next patch.
|Done
|Changed it in the new patch. This updates the job status to RUNNING_LOG_REBOOT and run job.run_reboot which logs the timestamp.
|Done
|Done
|Why does the function return values that contradict its name? I would expect is_job_complete to return &quot;True&quot; when the job is complete.
|Typo. Done.
|Thanks for pointing out that we have a library for this. I didn't know it existed.
|I think 512 bytes should be enough. If not, we should probably revise how we name the files, instead of locking the file for every append for now. To avoid this function being used for large strings, I explicitly states its limitation in the description to make sure people don't expect atomic updates. This is now a one-line function, but it'd be good to keep it in case we want to update later (e.g. add a lock).
|Done
|I added the code to remove the file if it exists in _SetupArchivePath().
|Done
|Done
|Done
|Done
|Done
|Good point. Python library caches the compiled compiled regexp internally, but it'd still be good to pre-compile if we know for sure that they are going to be reused.

Not breaking would only be good if we are returning a full list, so &quot;no&quot;. Added &quot;break&quot; after found.
|Indenting looks fine to me. Am I missing something?
|Ahh...I always seem to miss typos. Done!
|Yes. I moved it from GatherSymbolArtifactDownloads() to reuse it in this function.

Done!
|Done
|Done
|Ahh...it's my emacs setting. The indent should be 4 spaces instead of two. Fixed the indentation for this file.
|This script can be used as a wrapper to start mysql after system reboot/crash.
|Done
|I'll pass to avoid adding dependency.
|Yes. Done.
|Done
|Done
|Done
|Added message to tell the user that the cpuset does not exist.
|Done
|Done
|Done
|Done
|Done
|Added error message printing here.
|removed
|Done
|Done
|If there are existing root-owned cache directory, there is a chance that the build would fail because no one can access the cache, where we need to create the gsutil lock.
|Sorry I didn't explain that clearly. There is still a chance that a root may create the cache directory (although it doesn't happen often). I'd rather have the CQ-DEPEND here.
|David already has a CL for this.
https://chromium-review.googlesource.com/#/c/171989
|Done. I learned about the CL only this morning.
|That's an accident. Restore it.
|Agree. Will create a new CL.
|Done
|Done
|Done
|Done
|Done
|Done. Restored the umask.
|Done
|Done
|Done
|Oops. Missed that. Fixed.
|Done
|Done
|Done
|Changed to URI.
|Done
|it'd be url_tar_cache.Lookup(key).SetDefault(cls.GSUTIL_URL).

I removed the debug logging, but kept the &quot;ref&quot; as it's more clear.
|Done
|Done
|This changes in this file are no longer necessary. The unittests are not the culprit.
|Done
|Done
|Removed
|The plan is to not act as root when creating the directory, thus avoiding problem completely.

The &quot;chown&quot; is here in case some of the old directory out there are owned by the root. I will remove the chown code once the transition is completed.

Move this to osutils.SafeMakedirsNoRoot() because this could happen at multiple places.
|Done
|Done
|Done
|Use TarballCache instead.
|Good point. Merged to TarballCache().
|Done
|Done
|Good suggestion. Done.
|davidjames, could you comment on this? Thanks!
|Removed.
|Done. Updated those files to use GSContext.
|Added support of fetching in DiskCache
|Done
|Done
|Done
|It wasn't changed by this CL, but I corrected it anyway.
|Done
|The buildbot runs succeeded no matter what was set to gs_context_dir. If, instead, it used GSContext(), no one else could access entry_lock for gsutil key.

I am still figuring out why. I wanted to upload this patch first to get early feedback.
|This should've been gone. My mistake.
|Oops. Forgot to remove this. Sorry.
|UploadArtifact (which calls UploadArchivedFile) has a flag &quot;strict&quot; which determines whether a failure is fatal. By default strict is set to True. But since UploadArchivedFile never raises the timeout exception, upload failure has never been fatal.

Now that we raise the exception here when timeout, we can choose whether or not &quot;strict&quot; should be set.
|Done
|It will.

The CL breaks the unittest because the unittest assumes that a board is either public or private. Because x86-generic/amd64-generic now appears both as private and as public, unittest complains about it.

Cbuildbot, on the other hand, looks at the per-builder configs and will not make this simple assumption.

However, the unittest should be updated to reflect the changes. I will update cbuildbot_stages_unittests.py in the next patch.
|Mike (vapier)'s made a valid point on my other CL which attempted to use -cros-debug for internal paladin builders. Doing so would cause conflicts when developers use --withdebug and download binaries from the internal builders.

Revert to adding a new builder here.
|Removed this. Inherit from internal_paladin
|Done
|Inherit from internal paladin.
|Done
|Done
|Yes it does. But the test assumes that we do not have private amd64-generic and x86-generic boards, which is not the case anymore.
|Done
|Done
|Because the new builders which use x86-generic and amd64-generic boards are not public. The board_map assume that they are public.
|Done
|Done
|Perhaps we could have a separate function instead of looping through the arglist? The loop makes it harder to identify the failed assertion.

FYI, David posted the link below on one of my CLs. https://big.corp.google.com/~jmcmaster/testing/2007/01/episode-24-data-driven-traps.html
|Done
|Done
|Done
|Done
|Remove all trailing whitespace?
|I think what Marc meant was that he wanted to keep the old tree so that he can make sure his changes are valid (i.e. worked in the old tree). Once he's sure of that, he can then sync the tree and start a new round of work on licenses.py so that it can handle the new package changes. Syncing the tree now could complicate his work.

I don't think he meant that licenses.py should continue to work for everyone, since it does not work with the latest tree anyway.
|Done
|Done
|Done
|Done
|Done
|Done
|I think it's better to create the directory as non-root, rather than correcting it afterwards with chown.

Have a separate GetNonRootUser() is handy though. I will do that.
|If I delay the logic, and the directory does not exist at this time, it would just go ahead and create the directory as root. We'd have no valid &quot;user&quot; to correct this problem. Also, the fix below is supposed to be removed in the near future, so I'd rather leave the logic here.
|Don't we have self.name and self.version? Why can't we use them here?
|Done
|Hmm.. I thought we had some flexibility of using '+' for strings from reading the Google Python style guide. I will correct that.
|Done
|Just wanted to clarify this. The regexes was used in the gsutil source code. I kept it more or less the same so that if we ever want to upgrade, it'd be easier to spot the difference.

But I could fix this if consistency is more important.
|Done
|Same as above.
|Done
|Done
|Done
|It'd be cmd[1] in this case (cmd[0] is 'gsutil).

I thought about this and decided that it was highly unlikely to have false positives. To be on the safe side, I'll fix this.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|If gsutil fails to download a file after maxing out the built-in retries (6 by default), do we still care about resuming partial downloads? It might better to start a new download.
|I checked again and parallel upload was added in version 3.32. Without parallel upload, things are much easier.

Since we're running 3.25 for now (and we need to solve the ccrmod problem before any further upgrade), looks like the problem is worth solving after all.

I will upload a patch later for deleting a specific tracker file between retries.
|Ok, after some more digging, here is my conclusion.

I can locate the tracker file for a download.

Upload is much more complicated because gsutil splits a large file and does parallel upload. This results in many different tracker files. I don't think it's worth our efforts to figure out the naming/splitting logic.

In short, if it's considered useful to remove the tracker file for downloads, I can certainly implement that. If not, we should wait until GS team fixes this.

Any thoughts?
|Would removing the tracker files for only downloads help us? If so, I have most of the code written already. I just need to cleanup and run some tests.
|I agree that if we cannot locate the specific tracker file, we should not attempt to clear the directory.

According to gsutil, the filename of the tracker file is &quot;the combination of the SHA1 hash of the name of the bucket and object being transferred and the last 16 characters of the file name&quot;
|Sounds good. Done.
|GSContext.Copy() supports only fully qualified paths anyway. I will add more description here. Also, there are examples such as &quot;gsutil -m cp src dest&quot;, so I am reverting the change back to if 'cp' in e.result.cmd
|I checked osutil and somehow I missed it. Thanks for pointing that out.
|Done
|x86-mario-paladin, beaglebone-paladin, beaglebone-canary
|Removed this in the next patch.
|cros_sdk intercepts the exception and raises a SystemExit exception with a return code of one.

  raise SystemExit('Running %r failed with exit code %i'
                             % (cmd, ret.returncode))

If I change the code here to return another exit code, the error message'd be lost. It seems better to stick to the original exit code (one).
|Done
|If we simply want to archive chrome when it's available and don't care if it's not, couldn't we just catch the NothingToArchiveException here and continue?

Without an explicit knob in the configs (e.g. in my first patch), we have no idea whether chrome is supposed to be archived or not. Since we'd rely on the fact that whether chrome was installed (intentionally or not), getting an exit code from strip_package or simply looking at the stripped-packages directory (which SingleMatchGlob does) don't look too different.

I am not against adding an exit code, but would like to be convinced more :)
|I think these are two separate issues.

Chome may not have been produced due to an error, and we don't want to treat that as an acceptable reason to skip ArchiveStrippedChrome (otherwise, we could've just caught and buried the NothingToArchive exception).
|I don't love it either (as only beaglebone needs it), but this is a build-speficific config and it belongs here.

ArchiveStrippedChrome() has no ideas what packages have been built.
|No, they are run parallelly.
|strip_package.py does not set the exit code when there is no such a package installed. Uploading a patch as soon as my tryjob passes.
|Borrowed your words. Done.
|In the bug (crbug.com/314132), Richard said the builder would only produce the base image. Maybe I misunderstood the meaning.
|Yes. Will remove it.
|Ah...agree. but this CL is in CQ already. From what I've learned today, now is not a good time to upload another patch. I will fix this afterwards.
|I did a global code search. strip_package.py is used only in archive_stripped_chrome. This change should not affect other things.
|Changed to 2, and update the other CL correspondingly.
|Of course we can just return a specific exit code, but if chromite cannot catch it, this code here would be a bit misleading. If I were reading the code, I would assume the exit code would be used somewhere, which wouldn't be true.

As for cros_sdk, that's a separate issue that is beyond the scope of this CL :)
|Urghh...retract my previous comment.

cros_sdk intercepts the exception and raises a SystemExit exception with a return code of one. 

  raise SystemExit('Running %r failed with exit code %i'
                             % (cmd, ret.returncode))


If I change the code here to return another exit code, the error message'd be lost. It seems better to stick to the original exit code (one).
|Missing a period at the end of sentence?
|Add a period at the end to be consistent?
|Thanks for catching the typo.
|Added unit tests.
|I think 3 retries should be enough, unless we have examples where more retries would help.
|By default, gsutil retries 6 times. Our retry logic is only for some errors that we know could be flaky, so we should not retry if an error is none or 0 (in those cases we don't even know what the errors mean).
|Done
|Done
|The downside is that we wouldn't know if a new error is flaky because we don't retry them (assume the extra retries could help).
|Done. However, the code would only be properly tested when there are gsutil errors.
|Done.
|I don't have a real example of the error message since I've never seen one. Removed the 404 status for now.
|Done
|Sounds reasonable. Done.

The new patch throws an error whenever non-whitelisted chars are found. This should encourage/force(?) people to properly fix the license.

FYI, I ran this against M32, and did not catch any other illegal characters.
|Oops... I missed that. Need to have better presubmission check.
|The while file uses AssertionError, so I followed it. 

But I agree we should have different types of errors. Done in the new patch. May consider re-examine all assertion errors in the file.
|You're right. _GeneratePackageLicense was called after this and caused the double escaping. Fixed this.
|Done
|Done
|I thought about it, but didn't end up changing it because this path was used only in the PackageInfo class. There is no apparent reason to do it, but I will make it more consistent in the next patch.
|That'd make things easier. thanks!
|This is a valid point and a good suggestion. I think this should be implemented in licenses.py though.

After looking at how licenses.py process ebuilds, I have a question. Why does licenses.py use 'portageq metadata'? Some packages (e.g. sys-kernel/linux-headers) does not have LICENSE in the ebuild file, but 'portageq metadata' returns the license (GPL-2) correctly. I am not sure how portageq gets this information.
|Ideally, the presubmission check should be our first line of defense, keeping people from submitting ebuilds with obviously incorrect or missing licenses. It should work for most if not all cases, and has to be fast. We don't want to encourage people to disable the check.

As you said, I didn't want to enter chroot for a supposedly very fast presubmission check. But having two different logic (one using portageq and the other does not) in licenses.py is also a bit confusing.

Why did you say &quot;most cases&quot;? If I implement the inherit function, wouldn't the function work the same as portageq for our purposes (retrieving LICENSE) ?
|license FOO could not be found in /Work/full/src/third_party/portage/licenses
            /Work/full/src/third_party/portage-stable/licenses
            /Work/full/src/third_party/chromiumos-overlay/licenses
            If the license in the ebuild is correct,
            a) a stock license should be added to portage-stable/licenses :
            running `cros_portage_upgrade` inside of the chroot should clone this repo
            to /tmp/portage/:
            https://chromium.googlesource.com/chromiumos/overlays/portage/+/gentoo
            find the new licenses under licenses, and add them to portage-stable/licenses
            
            b) if it's a non gentoo package with a custom license, you can copy that license
            to third_party/chromiumos-overlay/licenses/
                * /Work/full/src/third_party/chromiumos-overlay/net-misc/iputils/iputils-20100418-r3.ebuild
|Redundant words &quot;the one&quot;.
|Done
|I do check for the right quote. At line 1497:

  line.rstrip()[-1] == in_quotes:

It has to match the quote stored in in_quotes.
|Added a new string for test here.
|Done
|Your concern is valid for having a general function in cros_build_lib, and I will work on that in the next patch.

In our particular use case, this is not a real concern. We source the ebuild first so &quot;moo&quot; should be read correctly before even entering this function. As for trailing backslash lines,  it wouldn't be set properly when sourcing the file.
|Done
|Done
|Done
|Addressed this in the next patch.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I don't think we want that as the old behavior could lead to hangs.
|Do we need to use this? TheContextManagerStack docstring says &quot;Python2.7 directly supports a with syntax&quot;.
|BSD == BSD-3. This is quite confusing. Thanks for pointing that out.

As a note for myself, below are the packages to fix.

./dev-python/python-evdev
./dev-python/btsocket
./chromeos-base/audiotest
|LGPL-2.1 is included in the source under the filename COPYING. I didn't see any BSD license files...
|I did, actually. That's how I found out it was LGPL-2.1.
|I'm slightly confused... seems like we are looking at different packages?

This is how I got the source, from which I read the COPYING file. It was LGPL-2.1.

  ebuild-x86-alex $EBUILD clean fetch unpack
|This package is not actually piglit, but rather the dependencies for piglit (see the descriptions above). If you unpack the source, there is a GPL license file.

But there is also an LGPL-3 license file too (I missed that)...I will correct this.
|Why is this test flaky now but was not before?
|I am not sure how this CL is related to this bug?
|Done
|Done
|I chose to do this because &quot;ArchivePayloads&quot; would run only when upload_hw_test_artifact is True. It is an implicit assumption that test image should be uploaded for testing, when it's available.

I can add an explicit option if that's the preferred way. Although a list of payloads would be misleading because we can only upload payloads for one and only one image. We would need to rename the payloads for different image if we were to upload for multiple images, and then to change that filenames to look for at the consumer side. I don't see the need for that yet.
|Oops...didn't notice the CL in CQ-DEPEND. Ignore me please.
|There is only timeout_util.WaitForCondition() in the module. I can't find WaifForSuccess().
|yes, lost track of that when doing bulk indent. Thanks!
|you're right. I need to train my eyes for these sort of things...
|Done
|Done
|Why should we? gsutil/boto does not use the env variable 'proxy'.

Do you mean that if 'proxy' is set in the boto config file, we should respect that rather than using http_proxy? I don't see any use case for that yet.
|Done
|Changed to use urlparse. This will be supported.
|Done
|Done
|use os.path.join() instead?
|Yes, that's a good trick to know. Thanks! :)
|I agree with you. I did that because the error message would be more clear. but wget a non-existing local file is not a big deal.
|Done
|Done
|Removed.
|I don't get it. wget is piped to tar directly so how can I share code with local payloads?
|Done
|I don't agree that a relative_path is more flexible, but I am not against it. I wanted to decouple the action of payload generation and the return value, and these two routes are not drastically different.

Changed to use relative_path.
|Done
|It's not a prompt, if that's what you meant?

I meant to use it as the path to user's depot_tools. I suppose I can just use 'gcl' directly.
|Done
|I think keeping the fallback as the last resort is fine, but we shouldn't do extra work to assert the version and/or try to support older version. (assertion wouldn't help much, as the command would fail anyway)

We simply can't properly support arbitrary gsutil versions. Unless we have a strong case where an older gsutil version should be supported, I see no obvious reason to do this.
|Out of curiosity, do we have any potential use case for this?
|One of the main points of having GSContext is to have a pinned gsutil version. We control the upgrade/downgrade and therefore there should be no problem modifying Exists (or any other method) to use the correct/compatible commands.

Unless you're talking about passing gsutil_bin to other scripts?
|Looks like gsutil performs update check every 30 days by default (configurable in the boto file). The update check is turned off when output is redirected (file, pipe, etc).

To make sure the update check is disabled, you can also run 'gsutil -q version'.

See https://developers.google.com/storage/docs/gsutil/commands/update
|Done
|Changed the order to match the signature. Also changed to use &quot;If set'.
|Done
|I've done a global code search and no caller specifies device.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done.
|Done
|Done
|Done
|Done
|Done
|No it shouldn't work. thanks.
|Done
|Since this CL is already in CQ. I filed a bug (crbug.com/333433) for this.

I'm not sure which module is better, maybe cros_build_lib?
 
ReinterpretPathForChroot, imo, should not be in git.py as well.
|Done
|Moved to buildbot/constants.py
|Fixed.
|Done.

I keep &quot;scope global&quot; when no device is specified.
|1. It does not check whether we are inside chroot or not.

2. It does not expand the path.

I modified ToChrootPath to do the above two things and then call git.ReinterpretPathForChroot.
|Done
|devserver doesn't write new line after the pid number. Adding rstrip() just in case if this changes in the future.
|That'd be more accurate. Done.
|Done and done. Moved this function to cros_build_lib.
|I didn't touch this function other than splitting all the one-line statements, but I'm happy to add more docstring.

done.
|apparently it did not. done.
|Done
|Done
|Done
|Done
|Done
|Yes. Done.
|Done
|In patch 3, sosa@ asked me to remove the space...
|Done
|Done
|This is a stupid mistake. Thanks for catching that.
|I think this is the third time I spelled this wrong in all of my CLs so far... Thanks..
|This CL depends on another CL which modifies dev_server_wrapper.py. Could you comment on that CL (CL:181302) and see if anything needs to be cleaned up more?
|Done
|Done
|Done
|Done
|Switched to cStringIO. Thanks.
|Yes it does look odd now that I read it myself. Thanks! Done.
|Done
|Done
|Done
|I just took a look.

1. It does not check whether we are inside chroot or not.
2. It does not expand the path.

If you prefer, I can modify ToChrootPath to do the above two things and then call git.ReinterpretPathForChroot.
|Done
|I chose this because we need to run devserver and /mnt/stateful_partition is mounted as noexec. 

An alternative is to remount it with noexec and then restore the permission after cros flash is done.

Yet another alternative is to store devserver package in /tmp while payloads in /mnt/stateful_partition, but then we need to clean up more places.

Both options require more cleanup work. Any preference?
|Oddly, I checked three devices, but none of them have /home mounted with noexec.

But your point is valid, so I will update CL:181361 to use 'python devserver.py'.

Done.
|Done
|Done.

The blank line is there in most of the unittest scripts. Do we have a policy against this?
|Done
|Done
|Done
|Done
|They are indeed evenly worse. Done.
|Ahh...no it's not worth another CL. Done.
|Done.
|Moved these inside the Command class.
|Done
|Done
|Done
|Add more example usage.
|Done
|Changed to 15 minutes, which was used by the dev_server_wrapper.
|Done.
|I am not sure if we want to default to always update the device because if we want to incorporate image_to_usb (or more) in cros flash v2, this would be weird assumption.
|Yeah it's not a good name. I'm pretty bad with names, and that's why I used the name that's burnt into my memory.

Changed to image_as_payload_dir.
|Done
|cros.py gets a parser from chromite.lib.commandline.ArgumentParser. '--debug' is defined in its parent class, BaseParser.
|yes....
|Done
|Switched to return CPV objects
|Done
|.....Done.
|Done
|I don't think so. options is a list of strings you want to display. It could have nothing to do with how you store the corresponding data. The caller would either have to find the index themselves or have to parse the string. that seems unnecessary to me.
|Done
|it's not a consistency issue but rather a correctness issue. thanks for catching that.
|Done
|No, cros_sdk needs to run outside the chroot

  ERROR: cros_sdk: please run outside the chroot

I will update the RunCommand to handle this case.
|changed to '/'. By default it should look in the chroot.
|changed to '/'. By default it should look in the chroot.
|Done
|changed to '/'. By default it should look in the chroot.
|We can probably do that, and it sounds like a good idea. There are some things that need to be ironed out though... If user has a default board setup in the configuration file, should that overrides the detected board? If so, user will have to use --board every time they want to switch a device. That doesn't sound right to me.

I would like to leave that to the next CL, when I will update both cros flash and cros deploy (http://crbug.com/334498).
|Done
|Done
|no, I actually wanted the default &quot;Do you want to continue?&quot; prompt...
|Done.

still logs here to preserve the information.
|Done. 

Also changed to return '/' if board is None.
|Done
|Maybe. I have just uploaded the next patch. If this is still far from submitting, I'll split the CL.
|Never mind. Moving GetSysroot to another CL. 

CL:182923
|Done
|Done.
|Done
|uh.......that was a mistake. thanks.
|I filed a bug (http://crbug.com/336871).
It should not block this CL though. Could you take a look of the CL, thanks!
|I don't have stats, but I did a quick test with cros deploy.

Emerging adhd, alsa-utils, and gsm on peppy: 14s
Unmerging above packages: 21s

Is qmerge installed in the device image? I didn't find qmerge on my peppy.
|We should definitely use qmerge in this case. I'm more than happy to replace `emerge --unmerge` with qmerge, but does this block this CL?
|Done
|Done
|Yes....strange typo i had. Done.
|Moved this function to portage_utilities. Also added a new function to return '/build/$board' in cros_build_lib.

I also did a quick scan and change most of code to use these two functions.
|Agree, but I did a grep and there was no other use case in chromite. Keeping this function here unless you have anything specific in mind.
|Switched to this order:

  dest, action, default, help
|Done
|Was planning to use it but changed my mind. Removed it.
|Sure.
|Moved the remount functions to lib/remote_access.py.

deploy_chrome should be able to reuse or add similar logic (for android devices) there. I don't plan to touch deploy_chrome in this CL.
|After discussing with davidjames@. 'cros build' is not directly usable in the current condition (although it does build packages...).

As the results, I decided to keep cros deploy focusing on one task: deploying the packages. I removed '--build' option and the Build function here.
|Based on your suggestion, in the new patch:

- If category is not given, search the list of installed packages and ask users to choose if multiple matches are found.

- If version is not given, find the best visible package.
|I inherited the code from cros_package_to_live. Is there a better way to do this?
|Done
|moved to cros/lib/common_util.py. Also updated cros flash to use this function.
|Yes. Done
|Done
|Done
|Done
|If you except socket.error here, shouldn't you except httplib.exception as well?
|My bad. You were right.
|In the CL, socket.timeout is caught and retried. Do we want to retry on other exceptions as well?
|Don't think we need to explain 'self' here.
|Just an alternative:

  pending_paths[:] = [x for x in pending_paths if not self.Exists(x)]
|Hmm...that's why I had [:], so that you wouldn't simply rebind the local context. Did that fail too?
|Done
|Should probably make it clear that this is either a path or an open file object.
|Done
|I thought it might be clearer if I had a new function, but I don't mind passing though this flag. Changed to your suggestion in the new patch.
|Done
|Done
|two &quot;with&quot; shere.
|an -&gt; and
|yes. it actually runs cros flash without the escape.
|Done
|Moved all --no-* flags to advanced.
|Done
|Done
|Done
|Because this could be shared among cros commands, but I am not sure whether other scripts would have the need to use this function.
|Moved to cros_build_lib.
|I'm inclined not to restructure the logic solely for this purpose. I'll leave the CL as it is for now.
|hmm.....cros flash uses the with statement:

  with remote_access.ChromiumOSDeviceHandler(...) as device:

It'd be weird to catch the exception here, unless we add an explicit function to connect the device and remove the assignment of self.board in __init__.

  device.connect()
|I like the second idea better. Switching to use a helper function.
|Why the new line here?
|I'm restructuring the beaglebone settings in CL:183541. This would conflict with that.

Also, we should probably factor out some common settings  between these configs and reuse them...
|Where do we usually save these types of settings?
|Yes. See bug (http://crbug.com/337533)
|Done
|Fixed.
|Not saying I have better ideas but the danger seems like a high price to pay, too. I have code that does network connections in the retry_check...
|......Done.
|It makes sense now, but cros flash would have to do the work anyway to figure out what device to use (if it starts to support usb drive, etc).

I prefer leaving it here, unless you insist.
|The ssh:// would surely make things easier, but a change like that to the interface may be too much?

Python 3.3 has the ipaddress module, but we are far behind that.
|Done.

The bug mentioned in upload_symbols_unittest is marked as fixed, which is confusing... http://crosbug.com/37517

plus I ran the unit tests and they all passed...
|I considered that as well. Actually, it might be more useful that way.

I'll add a str_ok=True to the arguments.
|Done
|Done
|no it didn't. I moved it.
|Done
|I copied the function here from crostestutils, and it was used mainly for finding a port for a local VM. That said, your point is valid, and I'll do the changes.
|Done
|Added socket.error and only close if s is valid.
|Done
|Done
|Done
|Done
|Yes. Done
|Done
|For the startup timeout, I could change that to simply raise the timeout exception, but I didn't think the caller would want to know if the vm failed to start or it was just a timedout failure.

I agree VMException is a generic name. I did want to use it as a base exception, but the code didn't demand me to create more exceptions.

I had VMCreationError because to me, creating a VM image seemed very different than starting/stoping a VM instance. The latter is also much more flakier than the former. That said, I don't mind having a base VMError here, and extend that. That would make the whole module more cohesive.

In short, I will change the code to use VMError as the base exception and then extend it to VMCreationError, VMStartupError, and VMStopError. I will also expose the timeout exception. Does that sound good to you?
|Why shouldn't it be thrown directly?
|Raised when VM failed to start/stop.
|Done
|Done
|No good reason. results of my poor efforts of cleaning up the code I borrowed.

Done.
|Done
|Added NormalizePort() to remote_access.

Changed the code to:
     self.port = (remote_access.GetUnusedPort() if port is None
                  else remote_access.Normalized(port))
|Done
|Changed to ignore error here.
|Done
|Done
|ok. I'll remove it from the changelist :)
|Done
|correction: add a Cleanup function. The caller will be responsible for the cleanup.
|Well...I thought we could rely on the sanity of the caller... Removed the cleanup function.
|The __del__ function of TempDir will eventually be called...for better clarity, the new patch delete this in Stop()
|Done
|No real impact here. In this class, this is used only to tail a log.

It may be worth trying to make devserver rely less on sudo commands, but that's another story...
|ok, i'll leave it to another CL.
|Done
|It's not off. There are two layers of parentheses.
|not related to this CL, but do we have tests that test submit to GoB?
|mock GerritPatch objects?
|Swap &#124;change&#124; and &#124;bot&#124; to be consistent.
|Why checking cache_key here? Would it be possible that cache_key is in CL_STATUS_CACHE already?
|I'm not sure why we need to copy here.
|I like 'latest_patchset_only=False' better than simply 'False'.
|The code only runs if it the default query is used, so it will not be tested by setting --cq-gerrit-query. That's why I didn't run the tests.

I will create a local patch which filters out draft changes regardless, and use that to test.
|Done. didn't notice the for loop. thanks
|Done
|Why are these version alias? Don't they belong to artifact/image_types?

And most of them are also defined in GS_ALIASES, which is a bit confusing...
|See my comment above about VERSION_ALIASES.

I'm not sure you are extracting version here...
|I'm fine with either dropping the board mismatch check completely or creating a RPC. I don't want cros flash to duplicate more xbuddy/devserver (e.g. cros flas already creates symlinks for devserver to consume...).

Creating a RPC is definitively bigger change. If we have to access the RPC through devserver, we need to launch devserver just for that.
|Do you think it's worth keeping the _CheckBoardMismatch? Your code bypass this anyway.

It seems hard to meaningfully check the board name since most components in an xbuddy path is optional.
|why the new line here?
|Is the docstring true? Seems like you only handle exception as warning if the exception is SignerResultsException.
|typo: chould -&gt; should
|Isn't &quot;finished&quot; the same as &quot;all channels are signed&quot;? or do you mean &quot;finished on error.&quot;
|Done
|Done
|Done
|Done
|Done
|Done
|Remove retries and sleep here?
|You're right. new patch is coming.
|When I use tab to indent, the editor couldn't tell the difference when there is an open parenthesis. I'll have to fix that.
|It has always been 15 seconds. We don't want to print too many information. but 10 seconds is probably enough.

Switched to 10 seconds.
|In most cases, update engine should become idle if there is anything wrong.

In rare cases, where update engine continues to update slowly, there is no real &quot;error&quot; as far as `cros flash` is concerned.

Most of our tests should have a timeout wrapper that would catch this error, and they (the wrappers) probably have a better idea what the timeout should be.

That said, I don't mind adding a some timeout, just in case, if build/lab team think it's necessary.
|The logic is simply here so that the patch can pass the filtering. Do you have any other suggestions? :)
|Done
|Done
|Agree. I didn't find anything that could let emerge ignore package.provided...
|I don't have strong preference on this. Done.
|Actually, if I do the fix in comment #3, we are back to square one since all chromeos-base packages will be blocked.
|cros deploy has to set PKGDIR anyway....so we don't actually have the problem mentioned in the bug.
|How fast is the dedup server? If it's reasonably fast (compared with symbol uploads), the adaptive algorithm may be unnecessary.
|I don't doubt the adaptive approach may offer better performance, but I do have reservation of how much it can improve and whether it's worth it. I guess we can see how this CL is doing when it's online and re-evaluate.
|I see. That makes sense.
|I got confused because the two functions, SymbolDeduplicatorNotify() and SymbolDeduplicator() accepts different arguments. The former accepts &#124;dedup_namespace&#124; while the latter accepts &#124;storage&#124;. In the end, you call isolateserver.get_storage_api() again in line 459.

Looks to me there is no reason why you should not pass &#124;storage&#124; to both functions, or &#124;dedupe_namespace&#124;, if you'd prefer.
|I meant between this and storage_proc in the next line
|blank line here
|Isn't this covered in the check at line 368?
|uh...I understand that but I was asking the opposite.

If the limit is 0, it will always break at the beginning of the loop.
|Yes, it should not affect the local artifacts. I'm not sure why  it's in GS_ALIAS since devserver does not support it. (and of course it messes up the ordering.)
|My CL does not fix the problem in sosa@'s comment because there are still no dev image in the image.zip.

Should we simply remove &quot;DEV&quot; from GS_ALIASES instead?
|This would affect where test-ap is displayed on the waterfall. Right now it's second to last on the try waterfall.
Since test-ap doesn't really belong to any other group, you can just keep it here.
|If you read GetDisplayPosition() at the end of this file, it will show you that it checks if the config name ends with 'test-ap'.

Given that you only want the builder for test-ap-group (not for the separate child configs), you should probably change this to 'test-ap-group'.
|I think 'images' defaults to 'test', so you don't need this. You can double-check that.
|Unfortunately no. Any of the settings below this line is NOT in stumpy-test-ap or panther-test-ap.

if you want some shared settings between the two configs, you'll have to create a new test-ap config and derive both of your configs from that (see beaglebone-release).

I know this is confusing...we should probably fix this.

Also, to see the settings of a config, you can use

  ./bin/cbuildbot_view_config -d --pretty config_name
|Filed crbug.com/342520.
|I do need to fix my editor...it always assumes 2 space even with an open parenthesis.

replace echo with touch in CL:186362
|also fix this in CL:186362
|I am testing if the user-given root (--root) is writable here. If not, try to remount and/or disable rootfs verification.

The assumptions are:
1. user may give something other than '/' or '/usr/local'
2. if the user-given root is not writable, remounting rootfs should solve the problem.
|See my comment above.
|switched to importing the module.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|done..sorry about that.
|Done
|Done
|Dropped.
|Done
|I figured that, but it's good to have the reason stated in the comment :)
|Agree with David, this should not happen now that paygen is run on the builders.
|s/generating/generate
|s/mean/means
|do you still need the except here? it just re-raises the exception.
|_WaitForArtifactToExist() has an side effect to change self.name (e.g. if you are waiting on &quot;factory*zip&quot;, it'd find the exact filename and then set it to &quot;factor_image.zip&quot;).

The actual download happens in self._Download() in line 306.

I guess the comments are a bit misleading. I'll change that.
|Done
|Done
|I could do that by we need the same &quot;except's&quot; for _Download(), _Setup(), etc below, so I'll be unnecessarily duplicating the code.

I thought the docstring (line 98) made it clear that we don't want to wait for a file that may not exist. I'll add more comment here. It seems a waste of time to wait for something that may not exist at all.
|I wanted to do that but it wasn't allowed in python 2.7. I can do that in python 3.
|Done
|Done
|removed it.
|Just saw this bug to get rid of bayleybay canary (http://crbug.com/315194). Is anyone still using this builder?
|I don't see clapper or glimmer paladin on the waterfall...
Am I missing something?
|Done
|Good point. currently we do not support running multiple instances of `cros deploy`. To avoid the potential thrashing problem, I set the work directory to be a temp directory under /usr/local/tmp/cros-deploy in the new patch
|Done
|Done
|Done
|Changed to updatable (also see CL:187066).
|Added more comment and switched to use &quot;updatable&quot;.

Don, you're right. I updated this line after firing a trybot run and messed it up. corrected it.
|I just tried it and it doesn't look any easier to parse a full partition table. The '-m' flag makes parsing with`parted` much better. Another downside of `cgpt` is that we'll have to enter the chroot to run this command and convert the image path to be used chroot path. 

We could consider switching to `cgpt` later just because it's in our chroot.
|only one blank line here.
|You don't have &quot;expected&quot; in this function.
|Wrong docstring here.
|You forgot to rewrite the docstring you copied from assertCommandContains.
|This should be filtered_changes (or matching_changes) since there is no reason to cache incorrect information.
|Done
|Done
|Because there is mixed use of both (e.g. GetDeviceInfo uses device name, ListBlockDevices returns device name).

I have to the conversion one way or the other.
|Done
|Done
|I want to log the original path here because usb_dev can be an empty string, which would be confusing.
|Done
|Because the relevant information may be anywhere in the path. E.g. /sys/block/sdc/device is actually a symlink to
/sys/devices/pci0000:00/0000:00:1c.7/0000:08:00.0/usb4/4-3/4-3:1.0/host18/target18:0:0/18:0:0:0

I ported this function from image_to_usb.sh (or the library it uses). I keep it here because:

1) It provides some information about the device to display to the user.

2) It would be easier to support a flag similar to &quot;--to_product&quot; in image_to_usb.sh, if we choose to support that later.
|Done
|Done
|Done
|oops...sorry about that.

I didn't intend to change the default behavior but discovered that'd be much easier for pre-cq half-way through finishing my CL.

I've looked at yours and modified mine to report the actual fail count.
|I don't see too much value in it but I'll do it.
|Done
|Done
|Sounds good to me. That means we'll add a little bit of overhead to update the counter in GS, but that shouldn't be much and we get more stats too.

Instead of using builder type, I'll just exclude all runs with options.remote_trybot

Do all builders have the ability to send out emails?
|SGTM.
|Why would that be a problem for pre-cq-launcher? We can exclude all runs with options.remote_trybot.
|I thought about doing that, but wasn't sure if it was more readable (it is to me). Done.
|osutils can't handle creating a tempdir in chroot, when we're running outside of the chroot..

Done (cleaning up tempdir on exception).

to make the code cleaner, I'll always create the tempdir in chroot and then move the image to the destination.
|Done
|Done
|Done
|Done
|Done
|changed to NotImplementedError
|Done
|Done
|Done
|did it by mistake. done.
|Done
|you're right.
|I'm not familiar with what should be put in the license file. Does this meet the requirements of all &quot;proprietary&quot; packages in our codebase?
|Why do we need to hard code chromeos-chrome? Isn't Mike's CL supposed to fix this?
|Isn't this message covered by the error messages above?
|Don't you still want to set the default value here?
|s/chromimum/chromium
|Do you have bugs for each of the above entries?
|Could you mark it as TODO so that we can remove it after all packages are fixed? It would be nice to have a bug number here as well.
|only one blank line here.
|Is this the only package with &quot;&#124;&#124;&quot; in the LICENSE line?
|Use comma here for logging:

  logging.error(&quot;%s: Can't parse &#124;&#124; in the middle of a license: %s&quot;,
                self.fullnamerev, join(self.ebuild_license_names))
|It'd be nice to give a meaningful message in the exception.
|only one blank line here.
|I think you should make equery (and emerge) a variable and reuse them now that you use them in more than one places.
|one blank line
|Is this the right bug?
|unnecessary blank line here.
|If I understand the CL correctly, instead of dying at BootstrapStage when pre-cq fails to apply a chromite/manifest CL, this handles the failure as a warning so that PreCQSync stage can run and remove the commit-ready bit.

This commit message doesn't say that. Seems like you're only adding a message here. :)
|When will a builder abort its own HW tests?

This message can also be more specific, e.g. &quot;HWTest was aborted because another commit queue builder failed.&quot;
|The should also be updated with potential reason behind aborts.

And, just to be consistent, they should all be cros_build_lib.Info or cros_build_lib.Warning.
|I checked the code and I think Aviv's right. We only check lab status *before* we launch the test suite.  We will not run the suite if lab is down. We don't check whether lab is down after running the test suite at all.
|Does this mean &quot;HWTest failed because lab was down&quot; or &quot;HWTest failed before lab was down, but we are going to ignore it since lab is down&quot;?
|Aviv's statement makes sense because whether the CL is submitted or not should be clear in CQ-master, rather in the slaves.

However, we can make it clear that why the tests were aborted.
|I'm not sure why this fixes the problem. Could you explain a bit more?
|Done.

yes, I tried a couple of methods and they didn't work. I'll fix that this weekend.
|Done
|Done
|Done
|This bug is closed. Do you mean 348226?
|Why did the CL slow down the group builders?
|Done
|Update the docstring.
|Update the docstring :)
|another one. update the docstring.
|I see. Adding a unittest would be good.
|The commit message says: It now treats an empty {} from PushImage as nothing signed, and None as receiving an error result.

I don't see any code handling &quot;{}&quot; here? Did I misunderstand the words?
|sounds good to me.
|Done
|Done
|Done
|yep. I removed that.
|Done
|Done
|Done
|Done
|Done
|Done
|s/payaloads/payloads
|s/build_run/builder_run
|Is it possible that board/version is not set at runtime?
|Are you just refactoring here? Are these changes necessary for this CL?

I'd prefer this in another CL if it's not related.
|Does this kick off the process in the &quot;background&quot;? It's not clear to me that they are run in parallel.
|seems like this group is ordered alphabetically. Maybe you can move --channels to the first?
|I am not sure what you mean here. We fall back to use &quot;cat&quot; if pv is not available. It does work outside of chroot.

When you say &quot;cros flash should work outside of chroot&quot;, does that include generating payloads as well?
|why did you remove the setup_board command?
|Is there a way to exclude source code files?

I'm asking this because I don't want people adding more exceptions in this script for their packages.
|would it be too much if we simply allow any text file with &quot;license&quot; in the filename? This way we won't have to list ipafonts as a separate case.
|I think it's worth a one-line comment. This could also break if a GPL file is named another way (e.g. *_GPL?)
|could you explain why &quot;GPL&quot; is excluded here in the comment?
|Full builders build all packages (except for chrome) from source, so the build time is longer.

Let's keep it this way for now. If this becomes a performance bottleneck, I'll make another arm builder full builder.
|good question. I should've.
|Done
|my bad. moved it to where it was.
|You're right. I misread the code.

I removed the function entirely and just use ALL_COLUMNS.
|s/Return/Returns
|What if  _build_dir does not exist?
|It's a rare case and it may not ever happen:  _build_dir exists, but it's not a directory.

You can block this case by:

  if not os.path.isdir(self._build_dir)

It really is a corner case, so I'll leave it up to you.
|This should be removed. I forgot to do that.
|We do not set the timezone when first recording the date &amp; time. UserFormatDateTime also does not set timezone in the datetime objects.

As the results, datetime.date or datetime.time does not carry enough information to be converted correctly. E.g., is the 03/14 really 03/14, or 03/15 EST?

We have a few options:
-  Use isoformat (this latest patch)
-  Set end_date and end_time to strings when creating them.
-  Set the timezone when first creating datetime.time/date/datetime. Use this information to convert them to the format we want (and don't use UserFormatDateTime).

As for the queries, I agree string matching is not the best. We don't support any of these as of now.
|Although the format in cros_build_lib.UserDateTimeFormat() looks good ('Mon, 17 Mar 2014 10:27:20 -0700 (PST)'), it may not be good for writing queries. For example, if user wants to select all stats with the same end date, this would be hard to work with. Also, we don't have the chromite module in the appengine, there'd be a bit of code duplication.

On the side note, converting a datetime.time or datetime.date object into a string with timezone info doesn't make sense as they have lost the original timezone information.

The new patch uses isoformat to serialize the datetime/date/time objects.
|Done
|Done.
|Done
|deleted.
|We currently use gsutil -e to skip symlinks anyway. It just hangs on the broken ones :)

The symlinks are in the test results are from the sysinfo directory. They don't provide any meaningful information.
|Yes it should be in CopyTest.
|good catch. I guess I subconsciously wish this is always true.
|But we don't return &quot;existing&quot; unless we enter &quot;if&quot;. If we use full change id, we will fail at query.isdigit() and will even enter this statement.

Yes, this should be corrected with using full change ID :)
|yes, cbuildbot accepts fulll change ID. In this case, it will not be cached, but we also won't return the existing wrong patch.
|I overlooked the fact that the same problem can also happen in _committed_cache.

I like the idea of using full change_id. It simplifies the code and we don't have to deal with all kinds of exceptions. The code here seems unnecessarily complicated with many assumptions. I'll do that in the next patch. Thanks.
|I find it confusing that we convert change-ID to &quot;*change-ID&quot; if it's an internal change. We often need to convert back if we are sending a query, etc.

If we use full change ID, I assume we don't have to use the prefix (*) anymore. Do we have the same project&amp;branch on both internal and external repo? Is it worth keeping this prefix here?
|s/non-unpickleable/unpickleable
|ah it was two lines. forgot to remove that. thanks
|yes, that makes sense. Will do that.

I am actually planning to consolidate/remove more code, that's why I didn't touch FormatChangeID yet.

I don't think we should be storing the &quot;internally-formated&quot; change-id/gerrit number in GerritPatch. This creates a lot of unnecessary conversions (calling FormatXXX functions with force_internal/external), leading to less-readable code.

 - We should convert them to the internal format only when querying the cache.
 - We should convert the internal to external format only when accepting user-input (-g or CQ-DEPEND).
|Done
|Done
|Yes, for the reason I stated below. I don't think we should be removing leading 0s. If we do that, we could convert a valid hash to gerrit number (it's rare, but it's possible).
|There are conflicts in the code as to what is considered a gerrit number.

For example, we have a unit test for 40 0s, which is supposed to be a sha1. If we remove the leading zeros then it becomes a valid gerrit number.

I think we should not remove leading zeros, and I actually don't know anyone/place uses leading zeros before the gerrit CL number.
|This test has been removed in the next patch :)
|Ah I assumed it's a GitRepoPatch object.  I'll use internal then. Thanks.
|Done
|yes, done.
|Yes. I thought about making it more scalable by actually using the dictionary (thus why I had this level of indirectness).

but we currently don't need the scalibility, so I'll just change this. :)
|Done
|Done
|Done
|why don't you just use self.build_names = ['x86-generic'] here?
|wrong indent.
|In most of the chromite code, we do not have a blank line after a multi-line docstring, and `cros lint` is ok with that.
|If that's the case, maybe add another blank line before this?
|Is there a reason not to set board and package_name in __init__()? It'd be easier to use if you create a PackageInfo instance with the information.
|change &quot;dirs&quot; to &quot;_dirs?&quot; cros lint should've complained about the unused variable when you uploaded...
|Done
|Done
|Done
|Args: ?
|reason='' ?
|What's the need to return self here?
|Would be nice to explain a little bit more here. For example, when/how is start_date used and when is starting_build_number used.
|docstring would be nice :) 
(since you touched the function).
|I tested with --buildbot --remote --debug. 
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/peppy-paladin/builds/167

I'll test again to see if it actually submits the changes
|The reason why I changed it was because that &quot;GetDepsForChange&quot; returns partial patch  information that are not suitable for checking whether the dependency was submitted in line 1864 (see the comment below).
|Done
|This is a bug existed before this CL. &quot;errors&quot; is a dictionary using GerritPatch as keys, so __hash__() will be used for lookup here. A &quot;dep&quot;, whether it being a string or a PatchQuery object, may not have the same id ad the actual change (GerritPatch).

The only solution I can think of is to retrieve all the changes (GerritPatch) and use them here.

I did that in the next patch, but it looks cumbersome (and we may send gerrit queries again).
|I like it. changed.
|Changed the wording. Thanks!
|Done
|removed.
|Done
|Done
|Done
|I actually did test it, and it passed the cleanup stage. Forgot to update the commit message :)
|No...:9
|Done
|Hm.... I did get confused about these two because there was no way to tell whether &quot;242728&quot; is a version or slot in &quot;chromeos-base/libchrome-242728-r8&quot;

That information seems to be lost here.
|If that's the case, I'd say that we use `equery-${board} list` to find out a list of packages and simply assume the binary package is available (skip using portageq to find the best visible binary package).

cros deploy shouldn't be parsing and guessing what these strings mean here.

What do you think about that?
|new patch supports libchrome:180609
|Done
|Thanks for fixing this.
|ok. I'll do the change. ignore the second patch for now.

(the same flag is used in devserver as well)
|I wanted to change the flag, but decided to do that in another CL. But this change will make the option clearer.

Also, image_to_live.sh also uses --src_image for delta payloads. Some users may be used to that already.
|What do we gain by doing that? I'll pass that to the devserver, start the devserver, and just to have devserver delete the directory?
|ok. changed to that.
|Why not just re-use self.launching and only pops when the change is neither in-flight nor launching?
|If there was a bug that could cause a change to flip from inflight to launching, we should catch that in the unittest or log that as a warning/error if we can.

Using inflight_or_launching could MASK this bug by allowing it to be perceived as re-launched, which doesn't sound right...
|Yes, done.
|I'm not quite sure how this function is used here. Will that affect the collecting of stats?
|I don't see any value of keeping _GetSlavesOfMaster(), so I'm ok if you want to remove this option.
|I'd add a comment or TODO here or in _GetSlavesOfMaster() to indicate that.
|Done
|Done
|The docstring of GSCommandError says &quot;Thrown when an error happened we couldn't decode.&quot;

For the errors we can decode, we should be raising specific GSContext exceptions (such as GSContextPreconditionFailed or GSNoSuchKey). I assume they don't happen during uploads?
|This is not right. GetGerritPatchInfo doesn't return the patch number. I'll fix that in the next patch.
|As far as I know, the order shouldn't matter here.

This function was used to only process the gerrit patches &quot;-g 12345&quot; when launching a trybot/buildbot. The actual dependencies will be processed later.
|That said, the order is not preserved across different remotes. I'm not sure whether honoring the order makes any difference here (as said in the comment). Maybe David knows more?
|The changes that depend on this change will still be submitted.

All the dependencies will be checked in _LookupUncommittedChanges(), and those which are already merged will be ignored.

Also, the unittest (testAlreadymerged) I added already tested this:

 * patch[1] depends on patches[0]
 * patch[0] was chumped
 * patch[1] still got submitted though. patch[0] was neither rejected or submitted.
|No related to this CL, but we should probably try reducing the number of variables here.
|It would just print None. I think that's pretty obvious, unless Aviv disagree.
|I was going to use cros_build_lib.GetBoard() for consistency, but probably an overkill here since that needs some tweaks too.
|I could fold this into xbuddy() as well, but this seems cleaner.
|haha a typo that I had always wanted to correct.
|ConvertTranslatedPath() may seem redundant, but it makes sure that we use the exact same build we reported to the user. For example,

  user given: remote/latest-canary
  translated: peppy-release/R36-5753.0.0/chromiumos_test_image.bin

We then convert the path to &quot;remote/peppy-release/R36-5753.0.0/test&quot; and use that in the request to get the image/payloads.

If, on the other hand, we use 'remote/latest-canary' in the update request, we may get a different build due to the race condition (a new canary build may have finished between the two requests).
|No. xbuddy only accepts image types, so we have to convert it back to type here.
|The error message is meant to remind user to check the image path they gave, so should not be at the debug level.
|I did this on purpose to make sure what's in the message gives the user enough information about the image. Logging twice would give the user more more details than necessary.
|Moved logging to before &quot;return&quot;.
|Because we use it in both USBImager and in RemoteUpdater. Unless we want to merge both classes, it's better not making it a member.
|devserver should be able to create the directory itself.

We don't start devserver with sudo anymore, should it should be safe to let it create the directory.
|Wait...we do start devserver with sudo. I was wrong. Moved the creation of folder to the beginning of the program.
|ok. done.
|I am not sure it's a good idea because even though they look similar, there are quite a few differences. Making a function and tweak it just to accommodate two difference cases does not look better.
|Same comment as above.
|haha you're right. I'll change that.
|I keep it here to remind people that this only happens on the master, but I can remove that.
|Yes, my unittest failed because of this.
|Done
|that's much shorter. thanks.
|Done
|I forgot to include the (latest) changes I made in this file. Updating that now.
|double quotes around the message?

  echo &quot;You have uncommitted changes to buildbot/config_dump.json&quot;
|Because you use `cros flash` in a very limited way. it would be more clear if you say &quot;run cros flash command to copy the image to  the USB device&quot; or something similar.
|cros commands are auto imported, so you can run it from anywhere &quot;within&quot; the source tree.

cros flash has many other features that require chroot, but simply copying an image to a usb stick is not one of them.

If this is all crosdl.py is using `cros flash` for , you do not need the chroot.
|The code above uses 0 and 1. Any reason why using the string '1' here?
|Done
|1. I thought we could fetch by sha1, but that's not the case. Added &quot;ref&quot; and &quot;project_url&quot; in the new patch. (project_url is not required, but will make things easier).

2. Good point. Although it's not clear here, but ApplyPoolIntoRepo() actually writes the list of changes back to validation_pool.changes in the *applied* order. The list of changes then is written to the manifest in the correct order. I also confirmed that by checking the changes in the manifest and compare it with the applied order in the CommitQueueSync stdio log.
|Done!
|I'll remove this comment since Gerrit team is maintaining the unit tests.
|comment removed.
|I moved this function from GerritPatch and did not change the content.
|Alternatively, you can do:

  constants.CHANGE_PREFIX[k.remote]

or simply

  k.PatchLink()
|In this case, it might be worth a comment here to explicitly state that, so that people understand the reason behind this. and if someone wants to fix this, they can.
|This is how we currently parse the owner_email received from gerrit to get the owner, so I don't expect any surprises :)
|Done
|Both ARCHIVE_ROOT and METADATA_URL_GLOB can pull variables from constants.py:
constants.METADATA_JSON
constatns.DEFAULT_ARCHIVE_BUCKET.

This is not really relevant to the CL though :)
|yes. done.
|Do we have to use the ContextManagerStack() here?
|Can we set retry to 0 when input is not available, so that we don't retry them? Hmm....but gsutil will retry and fail anyway.
|add a blank line
|typo: spreadsheet
|in -&gt; is

No need to specified CQMasterTable and PFQMasterTable here.
|I think we can keep this as a set, to avoid it being modified by accident.
|I find it a little bit confusing because CQMasterTable contains all SpreadSheetMasterTable.COLUMNS and the COLUMNS here.

Perhaps use another name such as CQ_COLUMNS here?
|Yes, it's in our manifest-versions repo (unser paladin/buildspecs)
|Yes. Done.
|Aren't you in the process of adding a boardless pfq master?
|Not related to this CL, but I find the PFQ comments in constants.py confusing. PFQ seems to be a more general term than CHROME_PFQ. plus, PFQ_TYPE is said to be deprecated in that file.
|Again, not sure if you should state CQMasterTable and PFQMasterTable here. We may add more in the future and it's better not having to update this docstring.
|You do not need to pass COLUMNS here since PFQ doesn't have any additional columns.
|Yes. An example:

  lumpy paladin: The HWTest [bvt] stage failed: ** HWTests failed with code 1 **
|Yes. I think it's safe to delete this.
|To answer your question, we use set() a lot in comparing GerritPatch objects, so __hash__() is used quite commonly in this code. The only purpose of that is to uniquely identify a CL.

In case where PatchQuery is used, we don't know the patch number and will only have access to that information after querying Gerrit.

I'm ok with changing the code to be more explicit, but that's going to be an extensive overhaul (speaking from the experiences of cleaning up the code last time) ;)
|Is there a reason not to explicitly use capture_output=True?
|That doesn't work because append() does not return the entire list :)
|If you remember the method, let me know :)
|I totally forgot about this :(

I'll fix it. thanks!
|Done.
|Done
|Done
|Because it's more code change. I'll do a stack then.
|Yes, that's the plan. I'll address in the next CL. My understanding is that this will only affect the inflight run because the lab sheriff should also close the tree when closing the lab.
|Done. https://chromium-review.googlesource.com/#/c/198882/
|Done
|1. I was told that experimental tests have all been removed.
2. I will file a bug to ask lab to give more explicitly distinction through different error codes. For now, I think it's safe to fail CQ.
|Lab is going to add more/clear error codes. See

https://code.google.com/p/chromium/issues/detail?id=371122
|wow......I had the same typo in all places and passed the unittest!

done.
|Done
|internal -&gt; internal_review?
|replace b_regex with bugnizer to be consistent with the variable names above.
|Instead of splitting the string into tokens, perhaps you can just use findall() or finditer()?
|Why don't you make patterns and urls_patterns a dictionary since you don't use them separately? It's harder to get the orders wrong this way.
|It's worth a comment so that people don't mess with the order later :)
|one line docstring
|another blank line here.
|We use CQ and paladin interchangeably in many places. I guess that's because of historical reasons?
|It seems to me that we can make this function more readable. This is my understanding (correct me if I am wrong):

For a change, we want to process the gerrit dependencies, then the paladin dependencies.

We should keep two &quot;seen&quot; lists. One is &quot;gerrit_deps_seen&quot; and the other is &quot;paladin_deps_seen&quot;. (The latter is a subset of the former).

The pseudo code would be:

  add &#124;change&#124; to gerrit_deps_seen
  process gerrit dependencies for &#124;change&#124;
  append &#124;change&#124; to plan
  add &#124;change&#124; to paladin_deps_seen
  process paladin dependencies for &#124;change&#124;
|Let's think about a simpler example. Suppose I have two chromite CLs A and B. B depends on A. I upload them to gerrit separately (not as a stack), and set CQ-DEPEND=CL:A in B.

From the code here, B will be added to the plan before A?
|We don't say that in the documentation, do we? It's not in http://www.chromium.org/developers/tree-sheriffs/sheriff-details-chromium-os/commit-queue-overview
|Maybe a graph would help?

  Gerrit dep: &lt;-
  Paladin dep: *--

  A0 &lt;- A1 &lt;- A2 &lt;- A3
   &#124;                 *
   &#124;                 &#124;
   &#124;                B0 &lt;- B1 &lt;- B2 &lt;- B3
   &#124;                                   *
   &#124;___________________________________&#124;
|How is that possible since we append the change to the plan only AFTER adding it to gerrit_deps? (line 706, 710)
|Hmm.......I was hoping we could drop the variable include_cq_deps. Now that I think about it more, we still need to strictly process all gerrit deps to avoid the cases where people specify cq-depends weirdly.
|s/rasied/raised

s/wanring/warning
|+1 for simpler code. I don't think the a few seconds matter here :)

Is it required to clear the column before writing?
|update the docstring?
|changed to logging.warning
|Done
|sanity_check_failed -&gt; sanity_slave_failed
|This is the same as line 3245. Should they be raising the same exception with the same message? or are both necessary?

Can you set instructions_per_channel to None?
|Haha I didn't notice this.
|I think David means that we should set qsize to zero (instead of unknown):

  qsize = '0'
|docstring is inaccurate.
|True. that was part of the testing and I forgot to remove it. thanks
|Done
|See patch #2. I forgot to add it.
|Done
|Done
|Hmm... this sounds good and I almost implemented it. After thinking about it more, I'm not sure we should allow raising a exception from a different category when using this decorator at all.

I'd rather leave this as it is, until we have more reason to allow this behavior :)
|Done
|I'd like to get this in to prevent any more PFQ failure. Is this slow down significant?
|s/dirction/direction
|Use tab to indent here.
|I'm ok with getting rid of it. I don't know about other use cases though.
|I believe this is not actually used anymore, at least when called from cbuildbot. 
See https://code.google.com/p/chromium/issues/detail?id=357961

In short, cbuildbot always set the correct PYTHONPATH when calling this script, thus eliminating the need to import the package.

I'm not sure about other use cases, when it's not run by cbuildbot.

Also, it doesn't always use TOT cbuildbot. If you have downloaded the chromite package once before, it will just reuse them. It's very likely that you have an an old copy of chromite lying in src/third_party/autotest/files/site-packages on your machine.
|How about printing a message when failing to import so that the developers/testers would know?

If download_and_import always guarantees the ToT chromite, I'd be fine keeping this. The fact is that people end up having an old checkout of chromite lying there and fail to run this script due to the version mismatch.
|I don't like that there is not a systematical method to change the timeouts. There is often some other timeout you're not aware of. Maybe we should have better unittest(?) to verify the changes.
|nit, this does not &quot;lower&quot; the timeout.
|What are the exceptions? Will they fail the stage?
|I guess it's too late but don't we want to turn off the upload on those builders?
|Ah I see. Thanks for the explanation.
|I knew it was config. but since now upload the test artifacts is the default options, can we allow exceptions?
|Yes, as in this message will be printed, and the cbuldbot will also comment on the CL with this information.
|Yes, you're right. I was torn between calling returns in the middle of the function or have more nested if-else statements.

I switched to use &quot;returns&quot; here. Also added more unit tests to verify this path.
|I'm not particularly fond of overloading &quot;options.channels&quot;...  since you'll verify whether the config is a payload config, I'm fine with it.
|SUITE_TIMEOUT could be caused by:
 - A devserver failure that manifests as a timeout
 - No DUTs available midway through a suite
 - Provision/reset/cleanup took 10 minutes longer for the new image
 - A regression in scheduler tick time

I'd say 90% of the cases are INFRA_FAILURE, but the rest of the 10% could be a bad image. I don't want CQ to take the chance and accept CLs.
|I don't like overloading flags as well, but in this case it's clear enough that you don't have the artifacts to run tests :)

I'm fine with either approach and at this point, there is no need to change this.
|Why don't we just check if upload_hw_test_artifacts is True, instead of adding a new variable for paygen testing?

You almost certainly can't test paygen if upload_hw_test_artifact is not False, and it's easy to see the correlation from the name.
|Nope, I'll do that in the next CL. Thanks for reminding me.

This CL only handles cases  where the whole stages can be wrapped with InfrastructureFailure.
|Yes. Done
|Done
|This is a docstring change, which should not fail any tests :)
|missing the closing parenthesis.
|uhh...what happened to &quot;and CQ dependencies&quot;?
|You're right.
|Yes, that's exactly what I am doing. See CL:201880. I will update this CL based on CL:201880
|s/Translation/translaton
|Please update the docstring. This is exposed to the user as docs. (http://devserver_ip:port/doc/xbuddy_translate).
|No need to capitalized &quot;Image Dir&quot;
|The second sentence should be moved to the Returns section.
|&#124;image_dir&#124; if &#124;image_dir&#124; is not None. Otherwise, returns devserver_constants.GS_IMAGE_DIR
|No need to capitalize &quot;Trailing Slash&quot;.
|Why using the '//' instead of '/'?
|My biggest problem here is that image_dir is not used everywhere (e.g., LookupChannel does not use it). It's misleading that the docstring assumes that it's used everywhere.
|Since you touched this function, it'd be nice to have &quot;args&quot; here :)
|You should also add unit tests for when image_dir is not None
|Well...for most of the exceptions we have in the codebase, but for ALL exceptions we actually use with this decorator :)
|It might be a good idea to inherit from StepFailure. It's not used everywhere, so I'm ok if you don't.
|change the docstring
|Maybe give a little bit more information in the message? This will be printed when handling the the exception as warning. E.g.,

  raise PaygenNoPaygenConfigForBoard('No paygen config was found for board %s' % board)

You could also log more to tell people that this is common for new boards and what needs to be done to add it to the config.
|This should be stage.PerformStage without the parenthese

By not naming the function with prefix &quot;test&quot;, this test is not actually run.
|It probably doesn't matter for your change. An easy no-brainer is to run buildbot/run_tests, which runs almost all unit tests in chromite.
|Should retry be a boolean and be set to False?
|I see. The test testRunHWTestSuiteMinimal is target to test this command without any optional arguments. I still prefer having a clear default, but this is beyond the scope of this CL.
|What is the default value of retry if &quot;--retry&quot; is not passed to run_suite?
|We should also send alerts for no_stat builders. I passed that to HandleFailure in CL:201209. We can add that afterwards since I did not split my CLs into separate ones for you to use.
|Done
|Having a more thorough test for the flow would be good, but I think most of the tests here are covered by the individual tests in validation_pool. The rebased patch includes testing for CL:201201
|This unittest was not testing anything at all. It appended &#124;messages&#124; to the actual comment and then checked whether they were in the comment, which was always true.
|Done
|I'm leaving it to a separate CL. That should be trivial (with an additional unit test).
|I see. That makes sense.
|I didn't see &quot;--debug&quot; used in upload_prebuilts.py anymore since you replaced them with dryrun. Shouldn't this then be: generated_args.append('--dry-run')?
|Isn't &quot;--debug&quot; replaced by &quot;--dry-run&quot; completely? Why passing it here?
|Why not just create the GSContext with the canned acl?
|The url to print should include 'index.html' at the end.
|Is toolchain_url always a fully qualified url? From the docstring in line 316 above, toolchain_url could be a relative path without any schemes.

In that case, urljoin() does not recognize the 'gs://' scheme and would simply ignore it. The result of this would simply be toolchain_url without any scheme.
|s/He/Her
|Hmm....this looks incorrect. Let's assume the slave needs to apply 3 patches to one repo, say the chromite repo. For each of the 3 patches, you will call ApplyAgainstManifest(), meaning the branch will be reset to the revision in the manifest. Isn't the result of this the same as applying only the last patch to the manifest?
|+1 for a unit test.
|IMO, the comments and the unit test should be included in this CL. The reverse of the if statement and can be done later, although there is no reason not to do it in this CL.
|Done
|This is optional, but if you want to test _HandleStageException as well, you can 

1. mock (patch) _HandleExceptionAsWarning' to return (results_lib.Results.FORGIVEN, 'description', 0)

2. stage.Run()

3. verify that the mock is called.


There might be better way to do it by looking at other *stages_unittest.py
|You're right. Done.
|The alternative is to set the GSUploadFailure type here, but I backed off from it because ArchiveFile is included in this function. It copies files to a local archive directory. Refactoring would be tricky because we run UploadArtifact in background processes.
|I'd suggest a unit test in cbuildbot_config_unittest :)
|From the config file, I don't see any suite running with async=True other than pgo. If you want to be sure, you can write a unittest for that.

What would happen if we use async and retry?
|We should not turn on retry for PFQ. If anything, we wanted the opposite -- running tests twice and fail if *any* of the tests fail (which is not relevant for this CL).

I don't know much about PGO.
|SGTM. 

qav has been failing a lot and is not critical (the stage passes with a warning). I'd say it's not worth turning on retries for them yet.
|Sounds good to me.
|Done
|Done
|Done
|Yes, I understand the value of having the check here. Nonetheless, performing an network operation when handling exceptions is not ideal :)
|Done
|Hmmm.....the downside treating &quot;unable to check&quot; as aborted is that the run may actually pass (if there are no other failures) and CLs will be submitted. I would err on the safer side and simply fail here.

I added a logging message when checking failed so that we'd know.
|We do, but we don't use it anywhere.

If only the sanity check builder failed, we ignore it and submit the changes.

If the sanity check builder and some other builders failed, we don't reject CLs at all.

In other cases, when we actually look at the failure messages, we want to analyze the failures.  NoneType failure message from the sanity check builder does not help at all.

I'd rather update the docstring of this function and those in the validation_pool to accept only ValidationFailedMessage objects.

What do you think?
|That behavior (manually dropping an empty status file) is not documented anywhere in this module. If that's the &quot;accepted&quot; behavior, could you document it somewhere?

In fact, we should reduce the need of manual intervention in these cases.  Why can't CQ just ignore the builders without statuses when there are other obvious failures?

None message here is ambiguous because theoretically I'd categorize them as infrastructure failures, but it could actually be created by a person.
|Moreover, this filters out None messages, so CQ will *not* fail.
|When I said &quot;CQ will not fail&quot;, I actually meant the CQ would not blow up....(pardon my inaccurate sentence).

Yes, None message appears in slaves other than the ToT slaves should indicate an infra failure.

Perhaps we should decouple failure messages from failure analysis in the validation pool. That way, all builders always construct a failure message, but it's up to whether we have a master to analyze them.

This will also help the PFQ builders which don't have a failure messages.
|I'll upload a CL to filter out None messages in GetInfraMessages for now, so that CQ doesn't blow up if ToT failed.

The root cause will be addressed by decoupling failure message from validation pool (http://crbug.com/371004) and making None messages infra failure (http://crbug.com/381297)
|Mocking RmDir would result in temporary directory not being removed in teardown, which I fixed in https://chromium-review.googlesource.com/#/c/202549/
|Of course we can always create another method to remove the test results and mock that out.
|Are you talking about the test results directory? We need to keep that until the archiving is done.
|Mocking RmDir while running the stage is fine, but patching it here will cause the temp directory leak.
|The return value was supposed to be False so that we run through the archiving paths. I corrected the mistake in CL:202588 (which is in CQ), but then you still need to mock RmDir when running the stage.
|Prefetching actually belongs to the same stage. The only reason I wanted to separate them was to make the failure more obvious on the waterfall. I wish there's a better way to display that so that we don't end up having so many stages.
|A bad ebuild can also trigger the failure in fetching(?)......I'm not sure how often it happens.
|Does this overlap with what you're doing on another CL (to fetch in cbuildbot)? If so, I'll just abandon this CL to not create unnecessary conflicts.

Otherwise, I could make it a separate stage, which I was considering doing anyway.
|As long as you use failures_lib.CreateExceptInfo to convert an exception to ExceptInfo objects, it will automatically detect any CompoundFailure and copy over the exc_infos list.
|When re-raising a CompoundFailure, it will simply copy all exc_infos from the old to the new exception.

Will upload a new patch with the suggested format.
|I see. I'll read cros_mark_as_stable.py and see if we can improve that. Thanks!
|Done. Thanks
|Done.

That's a good question. I just thought the helper function might be useful for debugging other things in the future.

If no one think it's useful, I'll delete it later.
|Done
|There are too many files in usr/lib/debug. Print only these two paths because they've caused previous failures.
|Done
|Done
|Switched to using the annotated bad CLs. Is there any reason to keep the bad CL candidates?

It's hard to infer a stack of bad CLs from a single bad CL. It seems unreasonable to ask the deputies to enter *all* CLs in the stack (e.g. the usually huge kernel stack). Perhaps CQ can store the &quot;disjointed transactions&quot; it uses in the metadata.json file (or the database we'll be using). That way we can use it to sort out stacks of CLs depending on each other? Anyway, I think it's ok to tolerate the inaccuracy for now.
|Done
|Done
|Neither is entirely accurate. We could have the bad &quot;patch&quot; picked up while CQ failed for other reasons (e.g. infra issues). Theoretically we should exclude them as well.

That said, I'll use the bad CL blames in the next patch, since it may be closer to the truth.
|It's a typo that was consistently copied everywhere. Fixed it.
|Use osutils.MountDir() and osutils.UMountDir()
|Rename this to something more meaningful. E.g., _IsPackageMerged().
|One line docstring to explain the test.
|I preferred this block of the comment remaining in the original place. It is an example of the output of 'parted', so that people know why we parse it this way. It is a little bit out of context here.
|If you really want to hardcode the paths here, I'd prefer only doing it when inside the chroot:

  parted_path = 'parted'

  If IsInsideChroot():
    # Inside chroot, parted is located in /usr/sbin, but is not included in $PATH.
    parted_path = '/usr/sbin/parted'
|I'd prefer listing the names for the keyword arguments so that it's not easily broken (e.g. key_selector='number')
|Even though 'chroot/tmp' is cleaned up at the beginning of every run, I think it's worth digging more because this is a bug. How can we be sure that the image is correctly unmounted if we can't clean the temp directory?
|s/image_dir/&#124;image_dir/
|Create another class that is forgiving by default. Let the test cases choose which one they want to inherit from.

  class ForgivingImageTestCase(ImageTestCase):
      ...
|I still prefer this to being added in the next CL instead, and potentially factor out a function to our library for other modules to use.
|Add a comment in ImageTestCase that all tests should use the prefix 'Test'
|Is there any reason to keep the test_results directory *after* the tests complete? Are you going to archive it afterwards?
|How about using a different name here. E.g., image_path

You can then set the image_dir and image_file separately below. This may be  a bit less confusing?
|Why changing the convention of using 'test'?
|This looks a little bit weird to me. Perhaps you can create a subclass called ForgivingImageTestCase for other tests to inherit from?

This should return an attribute self.forgiving
|Is this something that can be reused by other tests/scripts? If so, it should be factor out to chromite.lib. In that case, this may worth a standalone CL.
|We rarely use inline comments.
|ok...this file has grown too large with the main function in the middle. I think your original approach of having a separate file for the actual tests is better. Since we do not have a dedicated test directory, using cros/tests is fine for now. We'll move them when necessary. Sorry for the trouble.
|Hmm....is there any reason why the tests can't just live in test_image.py?
|So far only scripts that test cros/commands live in cros/tests. I'm not sure if this is the best place to put the tests.
|add docstring for the function.
|test_image lives in chromite/script, not CROSUTILS_DIR.

see RefreshPackageStatus() for example.

Also, the script should end with &quot;.py&quot; and you should create a symlink named test_image in &quot;chromite/bin&quot; to call our wrapper.
|Why not just inherit generic_stages.ForgivingBuilderStage and make the stage forgiving?

Do you gain anything by making &quot;forgiving&quot; dynamic?
|If you inherit from ForgivingBuilderStage, you won't need to override this method.
|You probably want to wrap the command with a timeout:

  with timeout_util.Timeout(IMAGE_TEST_TIMEOUT):
|You may want to follow the convention we use in chromite. For example,

  Args:
      image_dir: The image directory ...

  Returns:
      ...
|You can use osutils.ExpandPath(), which calls os.path.realpath() and os.path.expanduser()
|It's more clear to simply use ['chromiumos_image.bin', 'chromiumos_base_image.bin']

Or you can use constants.BASE_IMAGE_NAME
|It's in general discouraged to use '+' to concatenate strings.
|You look for both base and dev image above, but your error message only indicates that &quot;base image&quot; is missing.
|You didn't test if &#124;image_dir&#124; is actually a file here.

If image_dir is an invalid path, you'd assume that is a file.

It's also not mentioned that &#124;image_dir&#124; could be a path to the image file in the docstring.
|It might be good to include the name of the missing script to make the error clear.
|We have a wrapper for this: chromite.lib.cros_build_lib.RunCommand()

This allows you to set the working directory as well.
|Do you need to copy the image to another temporary directory? Is this going to affect other stages that run in parallel? Are you going to produce any results/artifacts in the directory?

I also don't see &quot;--test_results_root&quot; used anywhere in the code.
|It lets you know how many people are using this script to test locally. If you'd like to know, it's easy to add that.
|If you want to monitor the script usage, you can use chromite.lib.stats to upload stats to our appengine app.

You can see chromite/scripts/cros.py as an example of how to use it.
|I removed this function because it's not used at all.
|I'm torn between the two, but I'm ok as long as we stick with one style. Done.
|It's strange but apparently dryrun was used in validation_pool.PatchSeries.ApplyChange() *only* to decide whether to do trivial merge or not.
|Agreed.
|If I understand correctly, this code path is executed only when &quot;build is marked as successful&quot;. In that case, don't we want to know why there is an unhandled exception with full traceback?
|Ahh...I was a bit confused about the purpose of StepFailure, and had seen it used differently in the code. I'll update the docstring to reflect that.

And yes, I should've put this into the if statement below. The comment above (&quot;If the build is marked as  ...&quot;) confused me. I'll move the comment as well.
|The code here is executed only when the build has failed and we see a non-StepFailure exception. Are we assuming all failures should be StepFailures? Is that why we raise the exception here?
|Done. It may not be meaningful at times because it may have been raised via the decorator.
|It'd be nice to have &quot;acl&quot; as part of filename
|sgtm, too.
|I meant it's an extra burden for the user to call this function to parse the file before calling ChangeACL(). This has been resolved because you already fixed that in the next patch.
|I agree with Mike. It should be an argument and the caller can decide.
|Whether it's a custom format or not, it's something our own gs module will support until we switch to using json. By having the logic in this module, it's easier for us to maintain and for the callers to use.
|Since you moved this function from upload_prebuilts to here, shouldn't gs.py provide a method that uses this? Perhaps SetAcl() should automatically decide what to call.
|acl_args_file should be optional. There should still be an argument for the caller to directly pass the changes.
|Perhaps we can allow both to co-exist, but I don't think it's a big deal and I don't know the use cases.
|Done
|--remote --buildbot --debug pre-cq-launcher?
|Remove this line ;)
|This only prints the text on the waterfall. Shouldn't the build fail if the pre-patching failed?
|If the pre-patch fails for reasons outside of a bug in ToT, isn't this misleading because it does not actually test the &quot;incremental&quot;  part?

It's at least worth a warning here.
|I had the suspicion too but I checked the code.

The inheritance hierarchy: 

SyncStage-&gt;ManifestVersionedSyncStage-&gt;MasterSlaveSyncStage-&gt;CommitQueueSyncStage.

CommitQueueSyncStage.PerformStage() calls ManifestVersionedSyncStage.PerformStage() directly, which does not call SyncStage.PerformStage()
|Done
|Done
|This does not fix the root cause that ArchiveStage may emerge packages while DebugSymbol is creating the tarball. This is, however, the only config that will lead to the race condition today.

I'm not sure what the actual fix would look like because ArchiveStage does a bunch of random things and some of them may invoke emerge. I'm not familiar with the stage enough, but the worst case may be that DebugSymbolStage will have to wait until ArchiveStage finishes, but this will greatly increase the build runtime.

In short, this is a workaround while someone picks up the work to fix the ArchiveStage. But if &quot;packages&quot; will be used soon by other configs, I'll not submit this CL.
|1 and 2: I can add the unittest. The logic would look like if you build any image, you need to have 'installshim&quot; in packages or packages=[]. 

The fact that we have never seen DebugSymbols tar failures on builders other than beaglebone suggests that building the package is the main problem.

If we can remove the freshening code, that'd be the best.
|bad_patch_candidates is our best guess. The authors may just want to upload a new patch.

For CQ, we have spreadsheet to collect the actual bad CLs, so we don't have to use this set of candidates anymore.

For Pre-CQ, we don't have any other options, so I think this is acceptable. We should, however, add a comment to indicate that this is a best estimate.
|I like that we're presenting the metric for Pre-CQ and CQ separately. It's more meaningful and we'd be able to track the performance better :)
|We should settle on using &quot;rate&quot; or &quot;ratio&quot;, and make the names consistent.  I'm okay with both.  I remember Aviv was reluctant to use &quot;rate&quot; when I first added the metric (?).
|Done. We have various style in our code base, including &quot;Optional&quot;, &quot;Defaults to foo&quot;, and not specify at all. We should converge to one.
|Yes it uprevs chrome. I changed the name of the method to better reflect that.
|Done
|It could've been in the sync stage.

However, this method has been changed to get the chrome version from metadata only, and the actual chrome version built by this stage (SyncChrome) will be set by the end of the stage. In this case, it makes sense to keep it this way.
|Done
|I doubt that there might be a case where both run_attrs.chrome_version and options.chrome_version are set.

run.attrs.chrome_version isl only set when the config has chrome_rev = CHROME_REV_LATEST. On the other hand, run.options.chrome_version is expected to be used with CHROME_REV_SPEC (there is not a single config using this).

To err on the safe side, I switched back to writing the run attribute and *only* in _Finish(), and then updating the metadata there. That way, metadata dictionary will be updated to the chrome_version used in this stage. It should also make the usage clearer.
|See comment above.
|Uh....You are not using 'e' so just remove 'as e'
|Why not just catch 'GSContextException' instead?
|GSContextException is the base exception of all exceptions in gs.py. Catching GSContextException here should be more complete than simply catching the RunCommandError.
|Remove &quot;(c)&quot;. It's not used in new files anymore.
|s/library/Library
|What don't you capitalize the method names and the variable names?
|indent should be two-space less.
|Does fetchone return an integer or does it return a string?
If it's the latter then you should make it consistent and return '0'.
|Could you add an example of the filename in a one line comment? It's easier for me to parse/remeber that way :)
|s/Copyright (c) 2012/Copyright 2014
|Shouldn't this be class-level constant or attribute?
|If you are still interested in this, my CL:212883 just landed and it provides functions to get sheriff/deputy's emails.
|Yep. cbuildbot does not know who the sheriffs are atm. By the way, have we used this manual blame function at all since it landed?
|We currently don't email to sheriffs...
|Could you clarify what quirk that we are trying to work around, and whether this is fixed in the newer versions of gsutil?

I'm not sure how this would solve the problem.
|Done
|oops...done.
|Done
|Do we have a gerrit bug number to put here?
|Hm....I didn't realize that this was not used only by the cros commands.

On the other hand, it may still make sense for the wrapper itself to handle first argument, no?

I moved the logic to cros_flash itself for now.
|Could you elaborate a little bit (either in the bug or in this commit message) what caused the bug?
|Add a docstring for success_map.
|Can we change the variable name? 'pass_dir' sounds like the build has passed.
|In what case will success_map not exist?
|This seems to contradict the commit message because you still use BuildSucceededSoFar for boardless configs and configs with child configs. Perhaps you can clarify this in the commit message?
|I didn't want to rename the existing variable, but rather to ask you to use another variable. non_testable_builder is used everywhere else as a base to derive a config, not to add a config directly. You are adding a config here, so it's inconsistent with the common usage and is confusing.
|Should this be more descriptive? Such as non_testable_full?
|a space got in here.
|Agreed. This'd make the code more readable.
|Why changing iteritems() to items()?
|Shouldn't this have the parser.error() line as well?
|I'll keep lumpy and add parrot.
|The problem I had with keeping both daisy on both chrome and chromium was that it may stress the daisy DUTs in the lab. But I forgot that daisy-chromium-pfq does not run hwtest, so that was a non-problem. I'll switch it back daisy.
|I'm not familiar with the afdo support, and whether it'd work for parrot or not.
|Yes, I could. Although I'm not sure if it should be a type of StepFailure :)

Done.
|This line below would include the traceback of the CompoundFailure itself, which may not be included in the message of the CompoundFailure instance.

In the common case where the list of exceptions is not empty in CompoundFailure, the message would contain the type, string, and traceback of each exception in the list. This does not include the traceback of where the CompoundFailulre is raised.

In most cases, we don't care about where it's re-raised. However, it doesn't hurt to print this traceback because there are cases we may want to know it.
|Just a nit

s/return their paths/return their version and paths

This way I'd make sure I read the &quot;returns&quot; below more carefully.
|Done
|This makes the assumption about &#124;side_effect_func&#124; in general and involves changing the exiting callers. I am okay with it if most people prefer this.
|Done
|Yes, there's always that option. I thought that if this is used frequently than an arg to turn it off would be convenient. I can change the callers.
|Done
|It's not desired. As mentioned above, I'll change the callers to discard the exception.
|Yes, I'm sorry :(
|Done
|Done
|Also, I checked and only sandybridge-ivybridge is not important among all group configs.
|Done
|I agree. I reworded the docstring a little bit in the next patch.
|Yep. I need to fix my setting again after the trusty upgrade...
|Done.

samus, beaglebone-release-group, storm, and duck are now important.
|Done
|Done
|Removed this.
|Done
|Removed from cbuildbot_config.
|The port is not known until the devserver is launched and the port file is read, so no need to print this before running the command.
|Why not use `os.path.expanduser('~')`, which seems to be more universal?
|Might be worth adding a check to make sure it's not used incorrectly.
|kwargs can also contain &quot;blocking=True/False&quot;, can't it? This method doesn't actually &quot;override&quot; the optional arguments as the methods above do (using setdefault or update the dict).
|Yes, but is that the intended behavior? If so, the docstring above is not accurate.
|You're right, we can drop it.
|Canary master doesn't upload prebuilts, so it won't be using this method.

A more generic name might be PFQ, but I think this is a term that people now associate with &quot;Chrome PFQ&quot;, so I didn't want to use it.
|Just a nit. The first impression I got from HWTEST_CQ_SUITE/HWTEST_CANARY_SUITE is that CQ/canary runs only this suite.

Can we rename HWTEST_CANARY_SUITE as HWTEST_PER_BUILD_SUITE?
|The flag &quot;-R' should come before path for gsutil to recognize it.
|Do we not want CQ to run this? I actually don't know who uses it. If we don't need that, it'd be the best to get rid of it.
|Yep. You're right. Done.
|Done
|Done
|Arghh....I was wrong. I misunderstood the comment. brillo boards didn't checkout chrome but they also didn't need them.
|The first one returns two west coast sheriffs, and the second one returns the non-west-coast sheriff.

Each of them can return multiple sheriffs, so as long as we have only two &quot;kinds&quot; of sheriffs, we should be fine.
|Done.
|It is desired because I don't think the build should fail due to not being able to get the sheriff's name.

Updated the docstring.
|nope. you caught a real bug.
|I added that in the next patch, but canary master won't actually use it. I plan to move these methods to MasterSlaveSyncStage when other type of builders start using them.
|What would we want to include changes that will be submit by Pre-CQ in the CQ run? Shouldn't we ignore them? They will be recognized as chumps in the next CQ run.
|I suppose this tests that no trybots were launched for the &quot;STATUS_READY_TO_SUBMIT&quot; CLs. However, this would be the same for &quot;STATUS_PASSED&quot; CLs as well. It's be nice to verify that SubmitChanges are actually called in testSubmit() below.
|Are we enforcing the style for pylint comments?
|I understand but apparently this is the best solution without having to chnage the server end :)
|There is one that tests if there are any syntax errors by running it :-)

testAnnotateFailingBuilders
|Actually this wouldn't happen because we fall back to use the default board:

  self.board = board if board else cros_build_lib.GetDefaultBoard()
|If chromeos-install assumes itself running in the chroot, you may need to go with option two.
|cros flash can be run from inside or outside of the chroot.


You either have to convert the path of chromeos-install to be used outside of chroot when needed, or you need to run the command with enter_chroot=True. The latter would require converting payload_image path to a chroot path when needed.
|oops... I missed that part. I still think it'd be good to have this work outside of chroot as well (since all other features of cros flash work both inside and outside of chroot). I'll leave that up to you because I don't know how many people run this command outside the chroot.

Converting the payload_image path seems reasonable. There is only one caveat, which is that the image has to be in the source root. RemoteDeviceUpdater works around it by copying the image to a temporary location in the chroot.
|What does this not affect the speed? You may want to add a comment :-)
|Good catch. We did not set record_patch=False for pre-cq. I assume this affects the numer of CL pickup actions?
|This is no longer true and should've been deleted.
|This belongs to the gs module, but not here. This script does not do anything that it claims to do (delete the file between retries) :)
|wrong bug number?
|When would we not setup a board before running buildpackages?
|Done
|Ideally that should be true, but it's not. autotest_quickmerge.py uses it own parser, which relies on the fact that the logging.basicConfig is run.

The suggestion sounds good to me. I'll do that. Thanks!
|Like you said, checking space, etc doesn't seem to be less likely to break. If this js generation is changed, we'll have to change this no matter what.

I believe the js generation code is checked in somewhere in the crontab in a repository that I've never touched. Given that, the warning probably won't help much :-\
|There is other code that relies on this format (e.g. crosbot, etc). Not saying we shouldn't do that but I also don't know if this is priority....
|It'd be nice to mention that we do not know the exact names of the files and have to rely on &quot;gsutil ls&quot; where only eventual consistency is offered.
|Instead of always sleeping, can we just retry the &quot;discover payloads&quot; process in _DiscoverRequiredPayloads()?

You can catch the exception, sleep, and retry again. That way we don't have to unnecessarily increases the overall build time.

Let me know if the retry logic will be too complicated since I don't know much about this.
|Then add a TODO comment to point out that this is a temporary  solution until we know more about the failures.
|Which version are we using?
|Do the builders check the start/finish time in cidb for any purpose? If not, using the database's clock might be good. Having the start &amp; finish time matching the metadata.json doesn't seem like a huge benefit(?).

How about setting the value to NULL, as I suggested above?
|I'm a bit lost here. I thought the mysql bug was that only *one* column could use CURRENT_TIMESTAMP. Don, your suggestion seems to imply that both columns use CURRENT_TIMESTAMP? The manual says:

  &quot;It is not possible to have the current timestamp be the
default value for one column and the auto-update value for
another column.&quot;

Also, the manual says (which you two likely already know):

  &quot;In addition, you can initialize or update any TIMESTAMP
column to the current date and time by assigning it a NULL
value, unless it has been defined with the NULL attribute to
permit NULL values.&quot;


This seems to me that you can always set the column NULL and it will be updated to the current timestamp.
|Updated the comment to point out where this is used.
|I also trust you but I'd like to know what they mean....I'm not blocking the CL on this, but it'd be nice if you can add some documentation later :-)
|That'd be good :-)
|Could you point the user to some documentation so that they understand what the settings mean?
|Why not just use &quot;and&quot; for the two conditions?
|Done
|It's possible that the message could be a lot longer, when accumulated over a long weekend. Because other failures don't update the message when the tree is not open, the worst case would be the canary master updating itself.

How about this....we discard messages previously updated by ourselves? For example, canary master will discard any part of the message that was previously announced by itself. That way it could only occupy one line in the tree status, always. See the new patch for this.

Note: I am not saying this would scale as we have more and more masters updating the status message. However, the waterfall and tree status don't scale well themselves, so this seems like a good compromise until we can adopt a new waterfall :-)

p.s., appending sounds good to me. Done.
|Done
|Done
|This is done on purpose so the message composed from one builder (canary master) does not include the delimiter. On the other hand, the delimiter is used to separate messages from different sources.
|Yes, the scan order is random so it's best not to include 'closed' as well. Changed to &quot;under maintenance&quot;.
|Removed.
|Removed.
|single quotes?
|s/agsint/against
|Would retrying insert operation cause correctness problems? Even if it wouldn't, can we clean up these rows in the database?
|s/has/as

s/&#124;handler&#124;/handler because I can't really find &quot;handler&quot; in this function
|If it was a ServiceException, it meant that the download/upload hadn't even started yet. There is no reason to try removing the tracker file at all.
|You can just use:

  dict(zip(keys, values))

In that case, you may not even need a function.
|Add a meaning message for the assertion
|Do we have any plans to switch to using the database's time? :-)
|You're right. Done.
|Done
|I was told not to &quot;+&quot; strings, but that is simpler.

Done.
|Done
|Maybe we should use &quot;Unable to find the server&quot; instead? I'm not sure if there's other error messages that will have www.googleapis.com in it...
|This probably doesn't belong to RESUMABLE_ERROR_MESSAGE. It doesn't hurt but it will try to delete the non-existent tracker file.
|Why wasn't this needed before for the branch PFQ builders?
|Done
|Done
|Oops I did not set the default. Fixed in CL:216702
|Done
|Done
|I'm just concerned that people who see the namedtuple would assume the field always exists, which is not true.
|I am not sure what we can do with an optional field. I'd prefer not having this field at all. That said, I'm not strongly against this.
|I'd appreciate some high-level description of how the lock internals work. For example, the class uses an atomic compare-and-swap operation which compares the generation of the lock..., etc. This can also be described in separate methods below as well.
|+1 for a generic stat command.
|Done
|Done.
|Yes. See line 661. We only put the relevant slaves (i.e. slaves in the builders_array into the builders_completed set)
|Good point. Edited the docstring to add the description.
|This CL does not change the behavior. See the line 656 where the missing builders are logged.

We can't simply send an alert email unless we set a timeout for launching...Again, this CL does that change the current behavior :)
|For a unit test, I think mocking out this method is enough. It covers what I want to test (which is the logic of querying cidb in a loop) and is easy to read/use.
|Agree that this is slightly clumsy, but it's not without any upsides. We get to reuse the whole GetBuildersStatus function without having to add extra code path. I'll add a TODO/bug for this.
|Done
|This is all this function does -- throttle or close the tree (i.e. update the tree status). What do you want me to mention here?
|why did you change this?
|I have no idea if we need this or not :\
Who would know this?
|A comment here'd be appreciated, so that non-experts like me can have a faint idea of what's going on :)
|Done
|Done
|I see. That makes sense.
|Delete this line?
|You don't use e at all.
|yes, you're right.
|The canary master checks the pass/fail of the &quot;rambi-d-release-group&quot;, so this group has to be not important for now until it can run and pass.

I believe what we do today is to bring up an individual release config when adding a new board. After it has been stable for a while, merge them to the existing group config.
|By assumption, I meant that what you really wanted was to look at only the IOError exceptions and check their errno. This is not as clear in the new version, but both versions are functionally correct.

I guess this is down to personal preference. I prefer the older version, but I'm okay with the new one too. :)
|Why not just catch IOError here?
|When will the caller pass more than one signatures?
|This function doesn't return anything...I think you wanted to put this for _SignPayload() below.
|I have a suggestion which may make this function a bit more clear. Change this line to to

  payload_signatures, metadata_signatures = self._SignHashes([payload_hash, metadata_hash])

And simply return:

  return [payload_signatures, metadata_signatures]


I am not sure why the return value needs to be list (do other callers expect list?). It can just be a tuple.
|Remove one blank line
|No need to add &quot;pass&quot; when you already have a one-line docstring.
|No need to add &quot;pass&quot; when you already have a one-line docstring.
|Our retry_util.GenericRetry relies on catching exceptions and dispatching them to the handler/filter. Setting error_code_ok=True makes sure RunCommand does not raise any exception, so the retry layer is never run.
|The question is does `stat` returns all errors on stdout? I am talking about the known transient errors such as the internal server error or dns errors. If not, the original code which catches the exception and examines the output should work for most cases.
|You're right about the CQ breakage. My comment was irrelevant to that issue (even though still valid) :\
|In the case where CQ actually encounter this, it should be a failure.
|Done
|Originally I had it as TestLabFailure, same as SuiteTimedOut above. But from what Fang told me in her CL, this should not happen for any existing board (that is running test), so this is simply a &quot;new board has not been set up yet&quot; signal.

However, for CQ, if this does happen (even though I was told it wouldn't), it'd nice to categorize this as TestLabFailure.

I'll switch to that.
|I didn't change it. SuiteTimedOut is a subclass of InfrastructureFailure, which is covered already. I was just cleaning up the code. This is proved by all the &quot;untouched&quot; SuiteTimedout unittests.
|remove the blank line.
|remove one blank line.
|You are comparing the length of the same object..? How could they be different?

I think you mean to compare _PRECQ_STATUS_TO_ACTION and _PRECQ_ACTION_TO_STATUS
|Why do we want to return the actions of the last patch set if a user has already uploaded a new patch? We should not display the pass/fail count for the last patch set.
|Add a blank line.
|I'm debating about making this function directly accepts the args: (gerrit_number, internal)

This eliminates the need to accommodate all three classes.

This is not really central to this CL. It's just a thought.
|Doesn't the GetCLPreCQStatus below do that?
|I am okay with seeing this in action first before optimizing it :)
|beaglebone should derive from the non_testable_builder config:

  beaglebone = brillo.derive(non_testable_builder, rootfs_verification=False)
|You're right. I was thinking about _AddGroupConfig, which was used for adding per-chipset group configs.
|Just a nit. Use crbug.com/420798 to be consistent with other comments :)
|All group configs are defaulted to important=True. Remove this line.
|&quot;that exception passes BuilderStage._StringifyException&quot;

Not all exceptions are meant to be &quot;Stringifyable&quot;, so the docstring is a bit misleading.
|Remove this because you don't use it :)
|Here the code updates the CL status to either READY_TO_SUBMIT or PASSED, but your change below always mark it as PASSED. Are we getting rid of the READY_TO_SUBMIT status?
|We mark the CL both VERFIFIED and PASSED in a Pre-CQ run? I found this a bit confusing...

In constants.py:
  # Actions that a CQ run can take on a CL 
  CL_ACTION_VERIFIED = 'verified'           # CL was verified by the builder
|I see. Some comment here to clarify why we need two different actions will definitely help
|delete this.
|Done
|Not really. This is more related to how we handle the GCE images in GCE than the things that are needed for a chrome os bot.
|I changed constants to bot_constants, but forgot to fix the order. Done.
|This is here also as an FYI, and I may not act on it.
|Done
|Done
|Yes, the permission here is not important. There is also some limitation of `gcloud`'s copy functions. If we use the remote_access library, we will have more fine-grained control.

Thanks for the reminder.
|(1) Done.

(2) I am aware that there is a lot of output. I am hesitant to not dumping them at this moment because we have not run this command often enough to say if there is any hidden warnings. We can revisit this sometime in the future. In the meantime.
|We may want to bundle the things in chroot in the future. This is yet to be determined. And currently we don't even have a use case where you will have the chroot already built there.
|In fact, I've moved on to creating the image from the disk in the next patch, due to some technical reasons. This path of bundling the image on the instance will remain but will not be used officially.
|This is not the best, but not the worst for just copying a file. As I mentioned above, this path is temporarily disabled, so we can revisit this later.
|Done
|I use &quot;choices&quot; for now. I can switch to using sub-parsers, but I'd rather not doing that for the first draft.
|Already did that in the newer patch.
|I am keeping the option open because we may need to do more than that later.
|Already fixed in newer patches.
|Done
|In the newer patches, an exception is raised so the caller can handle it.
|These are for running ChromeSDKStage (testing the simple chrome flow):
http://www.chromium.org/chromium-os/how-tos-and-troubleshooting/building-chromium-browser
|It shouldn't. Thanks for catching it. Moved the command to a separate function.
|What do we want to error out at all times...?
|Can we remove this since the root cause is fixed?
|Uh this seems like a wrong bug.
|__init__ checks a couple of places to set self.boto_file:

1. os.environ.get('BOTO_CONFIG') (which can be set by the user)
2. you can directly pass boto_file to __init__().

Is this what you're asking?
|You're right. I uploaded a new patch.

By the way, init_boto=True is sometimes used on the builders. But I assume TestGSLs() should pass for builders with OAuth2.0 properly setup, so they will never reach this function.
|This method will only run if &quot;init_boto&quot; is set to True when creating the GSContext. Here is the docstring:

  init_boto: If set to True, GSContext will check during __init__ if a valid boto config is configured, and if not, will attempt to ask the user to interactively set up the boto config.

In this case, the user will need to have a boto config. I don't believe our builders use this.
|Done. I've also verified with trybots that CQ slaves do run this function (i.e., the timeout is actively used).
|Did you copy/paste the functions from other files or did you modify them as well (other than changing the names of the constants)?
|Remove the spaces.
|Add a new line
|Add a new line.
|You need the sys.path.insert(...) to run this file directly.
|Change the docstring.

This is just a place holder? :)
|wrong docstring.
|We'll have to rely on the stage timeout to kick in...I guess that's also okay.

I was thinking about either:
 *separate out `git gc` and run it only for the first time (not in the timeout loop)
 * Run _AttemptToGetLatestCandidate() once without timeout before starting the timeloop.

The downside of my approach is that if RefreshManifestCheckout actually hangs, it won't get a second change to retry. Yours takes care of that, so I think it's better.
|I was thinking about doing something similar, but I wasn't sure whether &quot;refresh mainfest&quot; simply took longer than 10 minutes or it just hung. If it had just hung, this means your last check here could also hang without an imposed timeout.
|Do we need such a long fallback_timeout (timeout can be 20 minutes).
|In that case, why don't we increase &#124;timeout&#124; instead?
|I see. I misunderstood how we use the fallback_timeout.
|;)
|Done
|LaunchTrybot already looks at self._run.options.debug and append the --debug flag if necessary. Isn't that enough?
|add a new line
|I assume the underscore was needed to output the default config at the top of the file. If so, it might worth a one line comment here to avoid people from changing this arbitrarily.
|Pre-CQ considers a pre-cq-group run timed out after PreCQLauncherStage.INFLIGHT_DELAY, which is currently set to 3 hours. You have two hours of wait time. We should increase PRE_CQ_TIMEOUT or reduce INFLIGHT_DELAY.
|s/instane/instance
|I almost wrote a CL doing that initially. But it was a bit clunky running build_packages twice and parsing the output for the specific pattern. I'd also need to skip a huge part of the script (running setup_board, etc) while doing that.

I had a second thought since we're migrating to `cros build`, and wrote this CL instead.

If you prefer calling build_packages to get it, I can switch to doing that.
|I also didn't like the duplicated logic, but this seems to be the cleaner way to do it.

The build_packages will still have a certain list of *default* packages so that the users can run build_packages directly. In that case, it's unlikely we can get rid of the duplication.

However, if we switch to `cros build`, I can see cros_build sharing the same logic with cbuildbot, eliminating the duplication problem.

I will add a TODO here.
|s/reject/rejected
|move the comma to the previous line
|I think it's fair to add a comment somewhere to indicate that marking REQUEUED is best effort and may be out-of-order.

Besides the case where CQ picks up before the Pre-CQ sees the change, there are cases where the developer unset the CQ ready bit *after* pre-CQ requeues the change.
|The assumption here is that &#124;change&#124; is marked ready, which is unclear from the docstring.

The function itself does not check whether &#124;change&#124; is ready, it only checks whether &#124;change&#124; was previously rejected and hasn't been marked re-queued since.
|Done
|minilayout includes the whole chromimos-overlay (which includes a ton of packages), soI would not want to use that. buildtools seems reasonable.

Those are not *packages* though, so they don't fit in here. I can handle that at the consumer side when we categorize the CLs.
|I think we should still extract the dependencies here. We don't know if we are going to add dependencies in chromite or not. Might as well keep this consistent.
|Sure. Done.
|This is the original docstring for MoxBase (which I didn't change)...
|Yes. I didn't git depend on it initially and then I changed my mind :)
|Done
|Done
|Done
|Done
|You can probably make this command into a variable since you are calling it twice.
|Not directly relevant to your CL, but why do we check the tree status in the previous line, and then set check_tree_open=False here? Seems to me that we can just set check_tree_open=True
|Specify the class of the &#124;change&#124; the method expects.
|Missing a digit in the bug number?
|constants.CL_STATUS_*
|either rename this to &quot;precq_config_progress_map&quot; or just explain this in one sentence here. I found it slightly confusing at first looking at both &#124;status_map&#124; and &#124;progress_map&#124; in this function.
|Probably not the best name if this method also returns &quot;passed&quot; CLs...
|Just a suggestion. It might be more readable if you rename &quot;passed&quot; to &quot;verified&quot;.
|If you mark the current config passed first, you could simplify the logic here because there will be no pending configs.
|This should be in line with the buildbot name to avoid confusion. I put it here in case we want to change later.
|Done
|Done
|Just a nit. This is a path to the directory, not just the name. The same applies to all other functions below.
|Just to be consistent with other functions, maybe change this to git_repo
|Just to be consistent with other functions, maybe change this to git_repo
|It'd be nice to modify other modules to use the new function. E.g. lib.patch.LocalPatch.Upload(). This doesn't have to be done in this CL though :)
|If autotest/test_suites is not going to be used, why don't you exclude the directory when tarring?
|I believe the default value of &#124;files_to_extract&#124; is None, so you can remove all &quot;files_to_extract=None&quot; args.
|I'm not sure if you mean &#124;inflight&#124; in line 662. If so, that's not inflight CLs, but builders that are inflight (which hasn't reported pass/fail status).

As suggested previously, you should just set tot_sanity to false.
|These two are mocked below in line 335 and line 337 already. They are also used in other tests. Please do not mock them again.
|This is mocked in VerifyStage() line 361.
|Please change the handle_failure_mock check in line 376 to check whether sanity is set correctly instead.
|tree_was_open is set here while initialized when creating the pool in line 1390.

Could you move the pool creation to after this line and just initialize the pool with the correct tree_was_open value?
|s/ValidationPool.THROTTLED_OK/self.THROTTLED_OK
|s/ValidationPool.THROTTLED_OK/self.THROTTLED_OK
|don't need this new line :)
|Remove the new line
|It seems like you could set tot_sanity=False and just let the code run through its course. Is there any case that you need to call HandleValidationFailure separately?
|I'm not sure that I follow. With tot_sanity set to false, no CLs will be rejected anyway. This makes your change cleaner as well.
|We are migrating all the tests from mox to mock (when we can). One side effect of my CL:228880 is that this class has been converted to using mock, so be prepared to rebase.. :)
|This changes the current CQ behavior, which allows changes to be submitted when tree is throttled. This is important because we want the pending CQ run to commit when the tree switches to the throttled status.
|Agreed. This should be a timeout (10 min) instead of a loop.

It may make sense to factor out the logic here to another function and use timeout_util. In that case, you don't need to store the queries into a list. Just do it one by one as it will be more readable (instead of checking the query again in the loop like line 1459
|remove 'q'
|We have the streak counter (using GS) in the ReportStage. Could you factor out this function and update that as well?
|Can we switch to using mock instead? I know this class is mixed with mock and mox, but it'd be great if we encourage new tests to use mock. :)
|Hm..this is not entirely accurate. MoxBase inherits from MockPatchBase and cros_test_lib.MoxTestCase, so it does use mock and mox at the same time. But you're right that the majority of the class uses mox.VerifyAll() to verify the calls.

Consistency shouldn't be a big issue since we want to deprecate mox, but I agree this is not the focus of the CL. On the bright side, if you write these tests in purely mock, it'll help people migrate other tests as they can use yours as a template.

Anyway, thanks for considering doing this.
|There are &quot;no&quot; unittests?
|This might be a stupid question: why do we need a while loop to kill the child?
|ExitAsStatus()?
|This method does not return the status of the child. It asserts that the child exits the same way as the grandchild does.
|Isn't this just _SpawnChild()? Why not reusing the code?
|should be ExitAsStatus()
|Done
|Done
|I'm unsure about how/why we are doing that. There are many interactions between validation pool and cidb. If you move everything to the stage, it will be messier. E.g., RemoveCommitReady() accesses cidb and is called by several _Handle*() methods, how are we going to call that directly in the stage?
|_InsertCLActionToDatabase is tied with validation pool atm. I think we can address that issue in a separate CL :)
|You can remove this one.
|I kept this for debugging purpose, but you're right, I should make the formatting better.
|Why not just use mock.ANY?
|Done
|This should be an arg, not a return value of WriteTable().

You should also verify the args of WriteTable(), which seems to be what the original test is doing.
|Done
|Done
|good catch! done.
|Done
|In that case, we should add a wrapper around GetSlaveStatuses() to use the &quot;latest&quot; build for a config. The code here should deal with those builds only.

This would happen even today......We use CIDB to check the statuses of the slaves and we don't handle multiple slave builds.

Added a comment.
|Moved the whole function to clactions.
|Done
|Done
|I'm willing to fix it in a separate CL to avoid unnecessary conflicts :)
|I'll do it in a separate CL, if it's necessary :)
|Done
|Done
|1. If the slave did not start, we defaults to using all CLs in this run. See GetRelevantChangesForSlaves().

This check is by no means required. I was trying to catch some weird logic error that we may encounter (but I don't even have an example yet).

I'll switch to printing a warning and *not* submit any changes. Sounds good?
|Done
|Wow I was consistently wrong in so many places. Thanks.

Done.
|Done
|As far as I can understand, this is not fixing anything other than not spamming gerrit. It also doesn't eliminate spam completely, as this code could still be run at a window where the change has not transitioned properly to merged yet.

Please add more comment as in why we add the check here and potentially what bug (the bug number) might address the root cause.

Also, modify GerritPatch to include a function for this purpose (see IsAlreadyMerged()). Using the strings 'SUBMITTED' and 'MERGED' here are not particularly nice ;)
|&quot;Whether the patch&quot; or &quot;Return True if the patch&quot;?
|All overlay repositories. I don't see why this should be restricted to chromiumos-overlay. Reworded the sentence a bit and hope it's clearer.
|Done
|Done
|Done
|use logging instead of print?
|You can just set archive_urls to None.
|seems like this comment belongs to the &quot;if&quot; block.
|not related to your CL, but this line should be collapsed into the previous (and it fits!)
|Why is this needed?
|remove one blank line.
|Done
|You're right. done.
|You're right. Done.
|I wasn't sure why this was testing. Given that I wasn't sure, I probably should not have removed the test.

Restored it.
|Nope
|yes. done.
|Done
|Done
|No, it does not.

See this line of code:
 assert hasattr(self.attrs, 'release_tag')

It was the assertion that threw the exception.
|My understanding is that before your CL, the tryjobs just ran without any problem, so additional conditions should not be required :)
|we can do that for sure, but it doesn't really help that much. If they change one word in a newer version, this thing won't work :P
|No. Not at all. That's why we pin the gsutil version in chromite.lib.gs and handle all the strange error messages...We should really migrate devserver to use the gs library in chromite, but no one is doing that.

There is no exception type in this case.
|You can use cros_patch.GetChangesAsString() to print changes.
|You don't need the &quot;+&quot;
|It'd make sense to at print ERRORS and WARNINGS on separate lines
|Just a suggestion; not really important: you could make the messages into a list, and '\n'.join() them at the end. Then you don't have to prepend '\n' each time.
|I wrote all the tests........oh no I just moved them to separate modules ;)
FWIW, mtennant@ wrote the test.
|Be careful what you wish for :)
|Do you want to delete the function?
|add a blank line
|add a blank line
|These functions need docstrings to explain their purposes because they are not intuitive. E.g., &quot;delete_keys&quot; doesn't actually *delete* keys here.

disable_overrides_for_keys?
|add a blank line
|Shouldn't this be simplified/merged with line 1400?
|clarify in the description that this option overrides the default timeout in the build configs.
|Done. Thanks!
|I think this deserves a bug number.
|That's why the devserver's change is important :)
|Would there be a case where &#124;directory&#124; does not exist but the parent directory is owned by root? 

E.g. you want to create /foo/bar/dummy, but /foo/bar already exists and is owned by root. Your exception handling does not cover this case.
|s/and its subfiles/recursively

Also, explain a bit more why you'd need to change the permission
|Shouldn't you try to create the directory again here?
|You're right. I was thinking about the case where the parent directory was created by root (my comment in line 49)
|From the last run with duck, this seems acceptable. I'll test again just to be sure.

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/pre-cq-group/builds/38274
|Instead of special casing this for the master, why don't we just get the BuildFailureMessage of the master build?
|Why do we care only about the stage 'summary'?
|pylint didn't complain :\

Done.
|don't need the &quot;\&quot;
|Do we really need the comments?
|Ah...I mistook &quot;waterfall&quot; as the complete build status page url.
|Done
|For the trybot use, we only need the config name, but agree this is more general.

Done
|Yes, it should be. Added to the docstring.
|Done
|&quot;past&quot; means that the build has been passed the inflight status........that means either passed or failed. Some pre-cq config failed before pre-cq-launcher has a change to look at the statuses.
|Done
|In ChromumOSDevice, the init function does a lot of things -- including actually connects to the device to get information about it (e.g. the board). If you move all those logic (which relies on the SSH connection) to a separate connect() method, you can simply set device.is_connected to True in connect().

For example,

   with remote_access.ChromiumOSDeviceHandler(...) as device:
      try:
        device.connect()
        ...
      except Exception:
        if device.is_connected:
          ...

This is just a suggestion. You don't have to do it in this CL :)
|There was a discussion once to make &quot;connect()&quot; a separate method for the device. I think that will be in line with what you are doing.
|You may want to parse lsb-release to the board instead.
|done
|Done
|Nope. It's not atomic.
|Done
|Done
|Done
|You handle draft in both places (line 1559 and here). You can remove line 1550.
|it's
|Is this still true?
|not your CL but it'd be nice to delete this line, as it's not true anymore.
|This is not true.
|The search order/logic seems wrong. Look at the docstring in line 60 and see the comments below.
|&#124;name&#124; is by default a glob pattern. If you check whether the path exists first, you may find an exact match (e.g. a file named &quot;foo*.txt&quot;) instead a list of matches (e.g. &quot;foo1.txt&quot;, &quot;foo2.txt'). This is probably rare but a correctness issue. You can remove this if block completely and let &quot;glob&quot; take care of searching.
|If &#124;name&#124; is regex and there is no match found, you should not continue using glob to find a match. Make this an &quot;else&quot; block.
|s/archive_url/local_path
|s/archive_url/local_path
|remove &quot;Both&quot;
|This is not very descriptive...Could you change that?
|Same here...
|If I understand correctly, you use abspath to allow symlinks in static directory?
|collapse this to the previous line
|New line here
|replace this with &quot;else&quot; and indent line 246-248. It will naturally fall through to line 249 if nothing can be found.
|s/local_path/&#124;local_path&#124;
|s/local_path/&#124;local_path&#124;
|s/path_or_url/&#124;path_or_url&#124;
|s/path_or_url/&#124;path_or_url&#124;
|change this to `os.scheme in ('file', '')` as in line 256?
|Wrong comment.
|447313
|Patch Set 1:

This CL is in all the runs that failed graphics_GLMark2, and it was the only CL in the last run. It's highly likely that this is the culprit.
|Patch Set 2: Code-Review-1

(6 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+1

(3 comments)
|Patch Set 5: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 8: Verified-1

cros flash vmtest failed:
https://uberchromegw.corp.google.com/i/chromeos/builders/stout%20paladin/builds/12680/steps/VMTest%20%28attempt%202%29/logs/stdio

cros: Unhandled exception:
Traceback (most recent call last):
  File &quot;/b/cbuild/internal_master/chromite/bin/cros&quot;, line 132, in &lt;module&gt;
    commandline.ScriptWrapperMain(FindTarget)
  File &quot;/b/cbuild/internal_master/chromite/lib/commandline.py&quot;, line 647, in ScriptWrapperMain
    ret = target(argv[1:])
  File &quot;/b/cbuild/internal_master/chromite/scripts/cros.py&quot;, line 69, in main
    code = _RunSubCommand(subcommand)
  File &quot;/b/cbuild/internal_master/chromite/scripts/cros.py&quot;, line 47, in _RunSubCommand
    return subcommand.Run()
  File &quot;/b/cbuild/internal_master/chromite/cros/commands/cros_flash.py&quot;, line 1041, in Run
    updater.Run()
  File &quot;/b/cbuild/internal_master/chromite/cros/commands/cros_flash.py&quot;, line 775, in Run
    translated_path = GetImagePathWithXbuddy(self.image, board)
  File &quot;/b/cbuild/internal_master/chromite/cros/commands/cros_flash.py&quot;, line 130, in GetImagePathWithXbuddy
    build_id, file_name = xb.Get(path_list)
  File &quot;/b/cbuild/internal_master/src/platform/dev/xbuddy.py&quot;, line 824, in Get
    self._SyncRegistryWithBuildImages()
  File &quot;/b/cbuild/internal_master/src/platform/dev/xbuddy.py&quot;, line 573, in _SyncRegistryWithBuildImages
    XBuddy._Symlink(link, target)
  File &quot;/b/cbuild/internal_master/src/platform/dev/xbuddy.py&quot;, line 446, in _Symlink
    os.unlink(link)
OSError: [Errno 13] Permission denied: '/b/cbuild/internal_master/devserver/static/stout/latest-cbuildbot'
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Abandoned
|Patch Set 1:

I got sidetracked by other issues and didn't get back to this for a long time. Then I figured it'd might be easier to start over even if I want to pick up the bug again...
|Patch Set 2:

(19 comments)

IMHO, we should not be messing with the devserver's internal logic too much. This makes the code hard to maintain, especially now that you mark the artifacts as &quot;staged&quot; directly.

For `cros flash`, we did something (copying the local image into the static directory), which was less than ideal. Piling on top of that is, definitely, much worse.

Moblab needs the ability to stage local artifacts in the devserver. I think that's a strong motivation for you to consider making devserver support this officially.
|Patch Set 3:

(1 comment)
|Patch Set 4:

(11 comments)
|Patch Set 5:

(4 comments)
|Patch Set 6: Code-Review+2
|Patch Set 8: Verified


|Patch Set 9: Verified; Ready

Added unit test.
|Patch Set 9: Not Ready


|Patch Set 10: Verified


|Patch Set 10: Ready


|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified


|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 4: (2 inline comments)


|Patch Set 8: Verified

I forgot to publish the comments for the previous patches. Sorry for the confusion.

In this patch, I change the autotest.tar.bz2 to include the full autotest directory as. This is because the full tarball needs to be used later in hwqual.
|Uploaded patch set 9.
|Patch Set 8: (1 inline comment)


|Patch Set 9: Verified

(2 inline comments)


|Uploaded patch set 10.
|Patch Set 10: Verified; Ready


|Patch Set 10: Looks good to me, approved


|Patch Set 1:

This should be committed after
https://gerrit.chromium.org/gerrit/#change,26612
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: (1 inline comment)


|Patch Set 3:

Yes, I added CQ-DEPEND=I1cd0e3c029cfd0a9fa27f981b68ba2958c94dec1 in the commit message.
|Uploaded patch set 4.
|Patch Set 1: (2 inline comments)


|Patch Set 4: Verified


|Patch Set 4: Ready


|Patch Set 4: Ready


|Patch Set 4:

The &quot;no control files&quot; issues has been fixed in change I00fd30c6fed0e8beae4908d0f2df714f696a08d9

This change is discarded in favor of the new change to support both autotest.tar and autotest.tar.bz2 at devserver I6c4590375a814a83a33ec84693e1cb6231752845
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Abandoned

hwqual needs full autotest tarball
|Patch Set 1: Abandoned

factory_setup does not use the autotest tarballs on google storage.
|Patch Set 1: Verified


|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)

1. The tarball downloaded from try job (R22-2576.0.0-a1-b161) is verified.
2. The trybot+hwtest is currently running.

Sorry for forgetting to verify using trybot for later patches in the previous CL.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 3: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (2 inline comments)


|Patch Set 5: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (2 inline comments)


|Patch Set 2: Ready


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)


|Patch Set 2: Verified; Looks good to me, approved; Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Patch Set 2: Ready


|Patch Set 4: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Ready


|Patch Set 2: Reverted

This patchset was reverted in change: Ic84e4dae4d5d1ab01c48f75dd7f8ed2885881d65
|Patch Set 1: Looks good to me, but someone else must approve

Just noticed that your run didn't actually invoke hw test because of the argument --debug.

There are two ways to invoke hw test.
1) use --buildbot WITHOUT --debug
2) use the remote trybot (--remote) with --hwtest. 

The option hwtest does not enforce hw test for buildbot because it already does that by default.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Not Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 4: Ready


|Patch Set 1: Verified


|Patch Set 1: No score

(8 inline comments)

Please see the inline response.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 3: Verified


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified


|Uploaded patch set 6.
|Patch Set 5: (1 inline comment)


|Patch Set 6: Verified


|Uploaded patch set 7.
|Patch Set 7: Verified


|Patch Set 7: No score

(2 inline comments)

The local autotest setup with one device saves ~2 minutes for a bvt suite run. The real performance improvement in production will depend on how the autotest scheduler reacts. The saving could be more or less.
|Uploaded patch set 8.
|Patch Set 8: Verified


|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10: Verified


|Patch Set 8: (3 inline comments)

Sorry forgot to publish the comments for this patch.
|Uploaded patch set 11.
|Patch Set 10: (3 inline comments)


|Patch Set 11: (1 inline comment)


|Uploaded patch set 12.
|Patch Set 12: Verified

As suggested by sosa, use dargs in the function. Also add a comment explaining why we enable fastsync by default.
|Uploaded patch set 13.
|Patch Set 12: (1 inline comment)


|Patch Set 13: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (8 inline comments)


|Patch Set 2: Verified


|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

Not using this anymore.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as d1d4a5817d3a7439de1e29ef45c8424d9a13971b
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e3792086ed9011c1cb7081d3f84afb32b34cf14f
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as c9a1bfd34a52613e1456114d9bd21945a6fa0c98
|Uploaded patch set 2.
|Patch Set 1: (11 inline comments)


|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Patch Set 3: Verified


|Patch Set 3: (2 inline comments)


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved

Code looks good, but I couldn't figure out how this is related to chromium-os:33573.
|Patch Set 1: No score

Stumbled upon the correct bug: chromium-os:33753
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified


|Patch Set 1:

Yes, I tried downloading an older build without manifest and a newer build with manifest to verify both cases.
|Patch Set 1:

Actually, I did run the unit tests and it didn't break anything, but I forgot to add that in my commit message.

The only thing is that the devserver would log &quot;InvalidUriError&quot; multiple times when there is no manifest present, but it would then fall back to &quot;gsutil ls&quot; and works correctly.
|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified


|Patch Set 2: Ready


|Patch Set 1: Looks good to me, approved

LGTM. Perhaps we can just call index() to see if devserver responds?
|Patch Set 3: Reverted

This patchset was reverted in change: Ib4675783d407b3439dc483ac57e06a357c590d87
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 1:

(6 comments)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(5 comments)
|Uploaded patch set 5.
|Patch Set 5:

There was a race condition in the previous patches that if someone acting as root created the cache directory, no one else could access the cache. This patch tries to prevent that by creating the directory as the PORTAGE user. As a temporary fix, it also attempts to chown the cache directory if it is already owned by root.
|Uploaded patch set 6.
|Patch Set 5:

(9 comments)
|Uploaded patch set 7.
|Patch Set 6:

(14 comments)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8:

(11 comments)

Created separate CLs to deal with directory/file permission issues.
|Patch Set 9:

(2 comments)
|Uploaded patch set 10.
|Patch Set 9:

(2 comments)
|Uploaded patch set 11.
|Patch Set 11:

Update: rebased. Also, both CLs in CQ-DEPEND have been merged.
|Patch Set 11: Verified+1
|Patch Set 11: Commit-Queue+1
|Patch Set 12: Commit-Queue+1 Verified+1
|Patch Set 13:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 3:

No, unfortunately, we had to use gsutil 3.25, which does not support 'stat'. See crbug.com/314404
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Rebase to resolve the conflict. Inheriting the LGTM.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(6 comments)
|Patch Set 2: Verified+1
|Patch Set 2:

Ping! Please take a look. Thanks!
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6:

Updated cbuidbot_stages_unittest.py to reflect the fact that a board can be public, private, or both.
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1

Did a scan and removed redundant use of -cros-debug.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review-1 -Commit-Queue Verified-1
|Abandoned

Abandon this CL in favor of CL:173935
|Patch Set 9:

(1 comment)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(4 comments)
|Uploaded patch set 4.
|Patch Set 3:

(17 comments)
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Downgrade to gsutil 3.25 to avoid problems (see crbug.com/305407) with newer versions.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned

Abandon this CL in favor of CL:175408
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Change has been successfully cherry-picked as 97f4d3b49bfaa0bb2f80fb3e5748e0022a25af0f
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Richard said the base image has the dev packages that he needed.

Inheriting the LGTM.
|Patch Set 2:

(1 comment)
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Code-Review

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Patch Set 6:

(1 comment)
|Patch Set 6:

Please take a look at the CL. We want the beaglebone builders working as soon as possible so that there will be images by the end of the week. Thanks!
|Uploaded patch set 7.
|Patch Set 6:

(3 comments)
|Patch Set 7: Verified+1

The new patch checks whether the package is installed through portage_utilities, and runs strip_package only if the package exists. ArchiveStrippedChrome does NOT rely on the exit code from strip_package anymore.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 7:

(1 comment)
|Patch Set 1:

My CL has fixed this.
https://chromium-review.googlesource.com/#/c/177287/
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

The Commit Queue has picked up your change. You can follow along at https://uberchromegw.corp.google.com/i/chromeos/builders/x86-mario%20paladin/builds/0 .

Commit queue documentation: http://www.chromium.org/developers/tree-sheriffs/sheriff-details-chromium-os/commit-queue-overview
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue -Verified
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

The generated html file is available here.
https://x20web.corp.google.com/~yjhong/out.html-M32-new
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

I am late to the discussion, but seems like we've reached the conclusion to use wrapper.py and keep licenses.py in the renamed directory. I will update that in the second patch.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Code-Review+2 Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Code-Review Commit-Queue+1

CQ failed because of the new stable snapshot of gerrit (crbug.com/325629). Mark this as ready, again.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Reverted

This patchset was reverted in change: I93976ec5a6a5575840e7d95cc3b74416dde7b1d8
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Patch Set 5:

CL:177441 depends on this. Is this ready to go?
|Uploaded patch set 6.
|Patch Set 5:

(7 comments)
|Uploaded patch set 7.
|Patch Set 7:

(4 comments)
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

I missed the comment about unittests before. Added unittests in the new patch.
|Uploaded patch set 11.
|Patch Set 11:

A minor change in the unit tests.
|Patch Set 11:

PTAL. Thanks!
|Uploaded patch set 12.
|Patch Set 11:

(3 comments)
|Patch Set 12: Commit-Queue+1 Verified+1
|Patch Set 12: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 13.
|Patch Set 14: Patch Set 13 was rebased
|Patch Set 14: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting LGTMs
|Patch Set 14: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 15.
|Patch Set 15: Code-Review+2 Commit-Queue+1 Verified+1

Rebased. Inheriting LGTMs.
|Patch Set 15: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 17: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the bug.
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1

CQ failed because of the new stable snapshot of gerrit (crbug.com/325629). Mark this as ready, again.
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 7: Verified-1

CQ failed due to file collision when building platform2. This CL is most likely the culprit.

platform2-0.0.1-r218:  * Detected file collision(s):
platform2-0.0.1-r218:  * 	/build/x86-alex/usr/lib/debug/usr/bin/quipper.debug
platform2-0.0.1-r218:  * 	/build/x86-alex/usr/bin/quipper

An example log:
http://chromegw/i/chromeos/builders/x86-alex%20paladin/builds/14907/steps/BuildPackages/logs/stdio
|Patch Set 1:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1:

Do not review this patch. Need to fix a thing or two.
|Uploaded patch set 2.
|Patch Set 2:

Ready for review.
|Patch Set 2:

(5 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

I renamed the file but forgot to add it back again. Sorry about making the same mistake twice.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Removed SOURCE_URI in libc-bench, try again.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 2: Verified-1

cros_generate_test_payloads.py uses SubCommandTimeout

http://chromegw/i/chromeos/builders/x86-alex%20paladin/builds/14903/steps/cbuildbot/logs/stdio
|Patch Set 2: Reverted

This patchset was reverted in change: I7fe01567c78ba848f1e5dcf086e51b80c3a9b375
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

Chump this so that we can open the tree.
|Change has been successfully cherry-picked as 481cb8ff22e2e70323cd64d624ae0587719b672e
|Uploaded patch set 3.
|Abandoned

Patch set 2 has been committed.
|Restored
|Patch Set 4: Patch Set 3 was rebased
|Abandoned
|Restored
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Chump this to fix the chromite repo.
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 1:

I never said it was not a good idea :)

I started working on it last week, but the extent of changes was more than I thought. We rely on using the license names (GPL, BSD) for many things. This would be a problem if the same license name appears in different overlay/licenses directories.
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Update: all runs passed.

w/ hwtest: x86-alex-release, daisy-release, lumpy-release

others: x86-generic-full, amd64-generic-full, arm-generic-full
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: Icefbc5a4d80f6ae911c67e183ac2e05938e7e8a9
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

Added the comment suggested by sosa@. Also added a logging message to show the type of images we use.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

My bad. Forgot Matt's BuilderRun CL was going to land. Rebased and changed to use the new BuilderRun object.
|Uploaded patch set 1.
|Patch Set 1:

This was previously CL:177441, which was reverted due to unmet dependency.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

All other CLs landed. This one is good to go.
|Uploaded patch set 2.
|Patch Set 2:

There was no previous bug so I created one. Nothing else was changed in this patch.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: Ibde88390820f8b2f6e2687eb9361cb4333f20ed4
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Minor change in the commit message. Inheriting lgtms.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the unittest error. gsutil_flags needs to be set before running init_boto(). Passed all chromite unittests.

Try again.
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(6 comments)
|Patch Set 4:

Yes, I tested all of them with peppy.
|Patch Set 4:

I'm ok with the -1's, even though I won't submit the CL unless I resolve them. :)
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 2:

We have timeout less than 5 min once the gerrit 2-min retry goes live.
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue Verified
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue Verified
|Change has been successfully cherry-picked as 25a9b09e9ccdd4a03a6a3dfad44b4212a244b221
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue Verified
|Change has been successfully cherry-picked as b057ebf1cda22943b3554f2ac31174614817096b
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Thanks for fixing the docstrings!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue Verified
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting LGTMs.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

Mike: Yes, I wanted to import this unmodified first.

Why is using /sbin/ifconfig considered a bad idea?
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

All trybots (x86-generic-asan, amd64-generic-asan) passed.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Ping. This is the 1st CL of the series of 'cros flash' related CLS.

Order:
  This CL -&gt; CL:181361 -&gt; CL:181512
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1:

(10 comments)

forgot to publish my comments.
|Patch Set 3:

(7 comments)
|Uploaded patch set 5.
|Patch Set 5:

Added more docstrings in patch 5.
|Patch Set 4:

(10 comments)
|Uploaded patch set 6.
|Patch Set 6:

This new patch launches devserver with 'python devserver.py' (instead of executing devserver.py' directly on the remote device. This ensures that we can launch devserver even on a partition mounted with 'noexec'.

The rest is the same as the previous patch.
|Patch Set 6:

PTAL. Thanks!
|Patch Set 6:

(8 comments)
|Uploaded patch set 7.
|Patch Set 7: Code-Review+1

Inheriting the +1(s).
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

Minor change to shorten the startup timeout for RemoteDevserverWrapper since it doesn't generate payloads.

Inheriting the +2.
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Trybot passed with the CL:182240. Trying again.
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 9: Commit-Queue+1

unrelated lab issue. try again.
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 9: Commit-Queue+1
|Patch Set 3: Verified-1

https://uberchromegw.corp.google.com/i/chromeos/builders/CQ%20master/builds/161/steps/Report/logs/stdio
|Uploaded patch set 1.
|Patch Set 1:

(18 comments)

Resolved most of the comments in the first patch, but will hold off on uploading the next patch until other CLs are reviewed.
|Uploaded patch set 2.
|Patch Set 2:

Do we really want Args for every function? I was under the impression that if a function is simple and self-explanatory with the one-line doc string, we could skip Args.

I don't mind adding them if it's preferred.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(12 comments)
|Uploaded patch set 5.
|Patch Set 3:

(1 comment)
|Patch Set 4:

(3 comments)
|Patch Set 5:

In this patch I swapped the positions of IMAGE and DEVICE arguments. This is to be consistent with 'cros deploy', which will have an interface such as 'cros deploy device pkg1 pkg2 pkg3'.
|Uploaded patch set 6.
|Patch Set 6:

Updated error message.

PTAL. Thanks!
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 6:

(2 comments)
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

minor exception message change.

Inheriting the +2.
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Minor change due to updated CL:181361 (CQ-DEPEND). Trying again.
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 9: Commit-Queue+1

unrelated lab issue. try again.
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 9: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(13 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 1:

(3 comments)
|Patch Set 5:

PTAL. Thanks!
|Uploaded patch set 6.
|Patch Set 5:

(11 comments)
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7:

Split GetSysroot to CL:182923. The rest stays the same.
|Uploaded patch set 8.
|Patch Set 7:

(8 comments)
|Patch Set 5:

(1 comment)
|Patch Set 8:

PTAL. 

Summary of the new patch:
* In portage_utilities:
  - Extends SplitCV
  - Add pkg_type to BestVisiblePackage
* Various small fixes based on the comments.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

The CL grew too big and lost focus. Spliting it into more CLs.

CL:183133 - remote_access.py: ChromiumOSDevice and rootfs remount
CL:183142 - GetBoard() added to be shared by cros commands.
CL:183144 - RunCommand should check whether we are inside chroot

Hopefully this will make review easier.
|Patch Set 10:

All other CLs are reviewed. PTAL. Thanks!
|Uploaded patch set 11.
|Patch Set 11:

rebased.
|Patch Set 11:

(3 comments)
|Uploaded patch set 12.
|Patch Set 12:

Added --emerge-args for passing extra arguments to emerge (based on sosa@'s suggestion). I think it's clearer than passing all unparsed arguments to emerge.
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 12:

Ping! Mike, are you ok with the CL? You're the only one who has not given a +1 yet.
|Uploaded patch set 13.
|Patch Set 12:

(5 comments)
|Patch Set 13:

PTAL. Thanks.
|Patch Set 13:

(2 comments)
|Uploaded patch set 14.
|Patch Set 14: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 14: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 14: Commit-Queue+1
|Patch Set 14: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 14: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Do we have plans to fix the unit tests?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue -Verified
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Trybot passed. Inheriting the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

unrelated lab issue. try again.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 5: Code-Review+2

Go ahead!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

small nit.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1

Fix a minor index error. Carrying over the LGTMs.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Rebased. Verified chromiumos_test_image.tar.xz and chromiumos_qemu_image.tar.xz are no longer uploaded in x86-mario-paladin trybot run.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Ping! PTAL.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

Ping! I want to land this before sending out PSA for cros flash. Thanks!
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Rebased.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 1: Code-Review+2
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1

LGTM, see if Matt has any comments.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

carrying over the LGTMs
|Patch Set 3: Verified-1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

finally fixed the typo.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

This shouldn't cause any failure.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the typo. Inheriting the LGTMs.
|Patch Set 3: Verified-1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

finally fixed the typo.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review+2

I didn't know we use them.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the LGTMs.
|Patch Set 2: -Commit-Queue
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

cros flash is not actually tested in CQ...
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Added the TODO comment. Inheriting the LGTMs.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

rebased.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

gs upload error. not this CL's fault.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the unit test. Carrying over the LGTMs
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

rebased.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Rebased again.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

rebased.
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1

gs upload error. not this CL's fault.
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

gs upload error. not this CL's fault.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

No, it wouldn't, but now it will.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the typo, inheriting the LGTMs.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased. Carrying over the LGTMs.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

rebased, again.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

Forgot to publish the draft patch....
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

has nothing to do with build package failure
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 5: Code-Review+2

LGTM. The beaglebone change looks reasonable.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3:

Ping! Anyone has more suggestions?
|Patch Set 3: Verified+1

Trybot passed.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue -Verified

Hold off on this. I should add a warning message here.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Added a log message. Inheriting the LGTMs.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

This should not have affected chromite unittest.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

Unrelated GS flake.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

use --yes flag instead
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the commit message. Carrying over the LGTMs.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

trybot passed. pulling forward the LGTms.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

The new patch uses ssh:// to accepts address with ports, but it also keeps the old behavior (accepting pure ip/hostname) for users that do not need to pass the ports for now.

Cros flash will be extended to support image_to_live and image_to_usb, and cros deploy will not; hence the difference in the two scripts.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

PTAL. Thanks!
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Moved the import location of mock. Inheriting the LGTMs.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This CL should not affect the HW test.
|Uploaded patch set 1.
|Patch Set 1:

some background: I'll migrate dev_install test to use the new vm module, then I'll write a new VM test for cros flash.
|Uploaded patch set 2.
|Patch Set 1:

(21 comments)
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Patch Set 3:

(1 comment)
|Uploaded patch set 6.
|Patch Set 3:

(1 comment)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Trybot run showed that portage-utils is included in the dev image, but not in the base image. This is what we want.
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/peppy-release/builds/70/steps/BuildImage/logs/stdio
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Patch Set 2: Commit-Queue+1 Verified+1

Both x86-mario-paladin and peppy-release passed.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

forgot to publish again...
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 1:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

Just a nit. LGTM otherwise.
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1

Passed another trybot run.
|Uploaded patch set 2.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified-1

Fixing the CL. Will upload a new patch later.
|Uploaded patch set 3.
|Patch Set 3:

plta
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Verified with trybot.

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/pre-cq-launcher/builds/392/steps/PreCQLauncher/logs/stdio

The new patch also adds 'NOT is:draft' to our default gerrit query. This helps filters out the real draft CLs (which has no published patch set at all).

Please take another look. Thanks!
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 1:

(2 comments)

By the way, I don't think 'cros flash' should rely on the default board in xbuddy (stored in xbuddy_config.ini) because most users are not aware of the existence of such file. It'd create more resistance if we decide to create the cros config file.
|Patch Set 3: Code-Review+1

See if Don has more comments.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

sosa@, your CL has the wrong CQ-DEPEND number.
|Patch Set 3: Commit message was updated
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Removed the cq-depend. the other CL was already merged.
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+1

As david suggested, some more tests will be good.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1

This is a draft patch. I want to see if my recent CL (CL:184645) is doing its job to reset the commit-ready bit.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

Pre-CQ was down all day but CQ rejected my CL as expected. Published the draft patch set.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Abandoned

This was a test CL. Abandon this in favor of CL:185290
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Abandoned

Thanks for the suggestions. This will be merged into another CL I'm working on.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 67eed2bd4b342e04c99e55ae5f607306cac396c5
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

In the past 25 builds, duck paladin failed more often than others. Is it stable now?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

CQ does not run this code.
|Patch Set 3:

I added vm.py not long ago and had only modified dev_install test to use it since then.

dev_install test runs only on canary builders. The VMTest failures was not related to this CL.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

cros flash is not yet tested by cq
|Patch Set 5:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Verified-1

There is one unit test I forgot to modify.
|Uploaded patch set 2.
|Patch Set 2:

Fixed cbuildbot_stage_unittest. Please take another look.
|Patch Set 2: Verified+1
|Patch Set 2:

Ping!
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1

Ping.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4:

(3 comments)
|Patch Set 4:

(3 comments)
|Patch Set 5: Code-Review+1

See if anyone wants to take a look.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

I see no point of having &quot;DEV&quot; if GS_ALIAS if we cannot extract the image from image.zip. We should just remove it.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Gmerge does not require users to know the installation root, but it also has the same problem.

Gmerge tries to install to root, but when it cannot remount rootfs to read-write, it falls back to /usr/local (with a user prompt to confirm). `cros deploy` can always install to root if it wants (because we can disable the rootfs verification and reboot).

Autodetection is not possible, but needs some fixing (see sosa's comment in the bug). There are still some problems.

1. If a package has not been installed before, where should `cros deploy` install the package?

2. There may be some unexpected situation if users use both gmerge and `cros deploy`.

If everyone agrees that autodetection makes more sense, I'll switch to using that.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

please take a look. thanks.
|Uploaded patch set 3.
|Patch Set 3:

Rebased. ptal.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Fix the problem caused by the rebase.
|Patch Set 6:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(13 comments)
|Patch Set 2: Commit-Queue+1 Verified+1

trybot passed.
|Patch Set 3:

All canary runs failed last night/this morning because of this test, so that was not a VM flake.

For my trybot runs, I ran x86-mario-paladin (with a local patch to enable cros_vm_test, because release builds were too slow) and it passed. All testing on my desktop passed as well.

I'll do more testing to reproduce the failure and find out the root cause.
|Patch Set 2: Code-Review+2
|Patch Set 2:

change looks good, but is the 2-hour timeout sufficient for our builders in current GS condition? Also, if downloading a file takes two hours, the build may be too slow to be meaningful in any way.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

carrying forward the +2.
|Uploaded patch set 2.
|Patch Set 2:

As far as I know (correct me if I'm wrong), Gilad allows cherrypy to bind to any arbitrary port (by passing port=0) and parses devserver log to find the port number.

I don't really want to parse the log for the port number...
|Patch Set 2:

After discussing with Don, I am dropping the CL and wait for Gilad's fix.
|Abandoned

The cherrypy fix is on the way (CL:185700)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the wording and logging level. Carrying forward the +2s.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Changed to passing the values to Verify() directly (there is no reason not to). The rest stays the same. I'll carry forward the +2.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

(2 comments)
|Uploaded patch set 1.
|Patch Set 1:

ping! please take a look.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

Based on Don's suggestion, I made another function to update the names.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Removed the whitespace. Carrying forward the +2s.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3:

yes, it's mostly code shuffling.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2:

Thanks for reverting this one step ahead of me!
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 3: Commit message was updated
|Patch Set 3:

I'd prefer using rsync but scp seems like a more logical choice since stateful partition can be wiped.

Back to the performance question, I did a quick comparison earlier and it didn't show much difference because the files should not have already existed on the device. cros flash cleans up after itself. Also, updating the rootfs (or generating the payloads, if required) takes much more time in comparison.
|Patch Set 3:

we can probe the device for rsync, but is there any advantage of using rsync over scp for cros flash?

It's true that cros flash is not the only one to use remote_access, but it is the only one using RemoteDevice for now. This CL does not eliminate the use of rsync, but simply chooses to use scp by default.
|Uploaded patch set 6.
|Patch Set 6:

ok. change the default back to rsync and adds detection to see if rsync is installed.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: -Code-Review

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)

I doubt the speed difference is worth the trouble, especially when guess work may be involved to determine whether a package needs more space. For small packages, the speed difference should be minimal, while for larger packages, we have to use the stateful partition anyway.
|Uploaded patch set 5.
|Patch Set 5:

Ping! I'm hoping this can land by tomorrow (SNAX day).
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Pulling over the +2.
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 3.
|Patch Set 3:

~15 second. but reliability trumps speed optimization here.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3:

This does not cause HW test failure.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

Don, modify image_to_vm.sh to always generate an updatable image doesn't seem like a good solution to me. Why does the script have to be restricted to always build an updatable image?

Also, this CL is parallel to your suggestion because adding the partition check is necessary for the CreateVMImage function here (because it accepts the &quot;full&quot; layout as an arugument). You never know whether the existing VM image was created with a non-default layout.
|Patch Set 2:

A little bit more information:

For canary builders, the vm image is created in the BuildImage stage. In the end, all images will be zipped in and uploaded as image.zip.

Because this CL generates a larger vm image, the qemu image in the image.zip will be larger (but it compresses well in in the image.zip).

One possible way to avoid zipping the larger (full-layout) vm image is to copy it to a temporary location. Let me know what you think about that.
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Verified-1

This CQ run is doomed anyway, and I want to make some small changes.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4:

Just a minor change to make sure we don't grab the lines that are not needed.
|Patch Set 4: Verified+1

Don, are you ok with the new patch? :)
|Patch Set 4:

(1 comment)
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

Rebased the other CL.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Updated the CQ-DEPEND. Pulling forward the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2:

most functions in partial_mock.py are decorated with @CheckAttr, which replaces mock_attr with DEFAULT_ATTR if it's None.

mock_attr refers to the attribute that's been mocked in this partially mocked class.
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2

(2 comments)

just some nits. lgtm overall.
|Patch Set 2:

(1 comment)
|Patch Set 2:

Thanks for fixing this.
|Patch Set 3: Code-Review+2
|Uploaded patch set 3.
|Patch Set 3: Verified+1

FYI, this has passed the code review previously but was reverted due to the VM image not updatable problem. The problem should be fixed in CL:187026
|Patch Set 3:

Well, you could've changed your mind since the last review...
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

I did not mock out RunCrosVMTest command and the unit test failed in pre-cq. This was not caught in trybots because it happened to have an image around.

Trying again.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Rebased (my other CL went in this morning which demands the rebase)
|Uploaded patch set 2.
|Patch Set 2:

This is not completely done (e.g. unit tests), but I'd like some early feedback.
|Uploaded patch set 3.
|Patch Set 3:

Added unit tests and also did more testing. Fixed a few problems. Welcome to review the CL.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(9 comments)
|Patch Set 4:

Ping!
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

unit test flake.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

gsutil 403 error. not related to this CL.
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3:

Changed the unit tests after talking to Aviv and confirmed that the streak counter would be reset to 0 whenever the status (pass/fail) changes in the next run.
|Patch Set 3:

If no one objects after lunch, I'll take Aviv's +2 from the previous patch.
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+1

Inheriting Matt's +1.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1

This CL won't cause HW test failure.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 640d4d0a728b33af5a505b7cd4b53b99680e0c2b
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I've seen two failures so far (they don't always fail. it's a race condition). I'd like to chump the this CL to avoid breaking more canary builds.
|Change has been successfully cherry-picked as 3cae664d7fc9fd6c24ac39cce71d487252a4ab47
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3:

Rebased.
|Patch Set 3:

Ping!
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Trivial rebase. Inheriting the +2.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the error that src and dest of the copying are the same. Verified by running trybot with devinstall_test. Trying again.
|Patch Set 2: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(6 comments)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as ce1f78b6e0b94e64c2a6e05a7c3a2b077ba65843
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(4 comments)
|Patch Set 4: Commit-Queue+1 Verified+1

trybot run passed.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Pulling forward the +2.
|Patch Set 4: Cherry Picked

This patchset was cherry picked to change: I0c877d0138bebe3ac925238c5f020db923db648f
|Patch Set 2: Code-Review+2
|Patch Set 4: Reverted

This patchset was reverted in change: I964f43e2050ba3cad25f00432d1d9043420042da
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 033d8e1bffbf3d392e976e6a5d8bc5a2f7a7ea59
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This does not cause failures listed above.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as bc91ab6506e0b766c212a999b4ed9e1dfc9b5f9e
|Patch Set 2:

(9 comments)
|Patch Set 3:

(1 comment)

Other than the commit message, there is no change in patch set#3. Did you upload the wrong one?
|Patch Set 4:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

just a nit. looks good otherwise.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to change: Ib44ff8c2b376a2c689d052652756f0093105e6cc
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue
|Change has been successfully cherry-picked as f2fa2d79dbc8650e3acec1238ac0df68bd161afe
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This does not cause HW test failure.
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This does not cause HW test failure.
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 2:

Was the second patch just a rebase?
|Patch Set 1: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks for adding the bug.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

For uploading a single file, &quot;-m&quot; should not have any impact.

For uploading a directory recursively, our high-level optimization doesn't help at all.
|Uploaded patch set 2.
|Patch Set 2:

@Mike: I think you meant composite parallel upload, which splits a file into component for parallel upload.

Moved &quot;-m&quot; to DoCommand since other commands (such as acl set) can use it too.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the typo. Inheriting the +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

pre-cq failed because of an un-related unit test flake.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Abandoned

Abandon this in favor of CL:188768 to avoid confusing the pre-cq again.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(3 comments)

overall looks good. need to fix the docstrings though :)
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as a1d9baaa05c271a07b5825488ef7ec013edd3ee5
|Patch Set 2:

HAHA then please fix the image_extractor bug!
|Patch Set 2: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 4: Reverted

This patchset was reverted in change: Ic8a6ea76dfb8815ee46ac7c6c970abc93e5284e9
|Patch Set 4: Reverted

This patchset was reverted in change: Id915d051b882358095d02d87f32a980daac3a010
|Abandoned

already reverted
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as a370e5656fa06d0c0c398237c082403b1b102a18
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

@sosa: the new patch use &quot;devserver.py --help&quot; to check. This adds more time (copying the devserver package), but I think it's worth it as there are other dependencies besides python.

And if the stateful partition is not corrupted, we can then re-use the devserver package files (rsync will not actually copy any thing).
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2:

The trybot run.

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/x86-mario-paladin/builds/467
|Patch Set 2:

How often do people actually grep the results? I've asked the lab team (who will be looking at the test results) and it's very rare they have to do that. They'd be happy if we have files in google storage and also surface the links to the failed logs on the waterball.

And if you'd really like to download everything, you can still use gsutil to download the folder.
|Patch Set 2:

Hmmm..then my question is what do you do when you're a sheriff and a HW test failed?

If we surface the failed tests like the HWTest stage, wouldn't that be enough?

For example, see https://uberchromegw.corp.google.com/i/chromeos/builders/link%20canary/builds/3424
|Uploaded patch set 4.
|Patch Set 2:

(2 comments)
|Patch Set 4: Verified+1

ok. I upload the tarball as well in the new patch. This is to
 - help with the transition as &quot;magic.mime&quot; needs to be added on all builders to set the correct content type when uploading to GS (crbug.com/349254)
 - allow people to choose how to view the files (e.g. Mike prefers downloading the tarball). We can revisit this and see whether we can get rid of the tarball later.

The new patch also parses the log to surface the links to the failed tests.
|Patch Set 4:

(8 comments)

thanks for reviewing!
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

One small change in the latest patch. 

If there is no match for test name, we'll just grab whatever we can (and more important, don't fail the build).
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2s.
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8:

It failed the CQ run because there was nothing to archive and the results directory does not exist (some builders only run dev_install or cros_vm_test in the VMTestStage).

This doesn't happen on the trybots because we override the trybot to run all the vm tests.

The new patch creates an empty directory to avoid hitting the error. I'll launch a trybot (with only cros_vm_test) to test this.
|Uploaded patch set 9.
|Patch Set 9: Verified+1

OK.... The new patch skips archiving the results if there are NO results to archive.

Tested with trybot runs, all passed:
1. running cros_vm_test
2. running cros_vm_test + AU test (the default trybot config)
3. running cros_vm_test + AU test and display all &quot;PASSED&quot; tests as links (this is to test if we display links to failed tests correctly).
|Patch Set 9: -Verified
|Uploaded patch set 10.
|Patch Set 10: Verified+1

fixed the unit tests.

If you'd like to review the final change of skipping the archiving, be my guest.

I'll set the commit ready later this afternoon. If no one gets to it by then :)

Thanks!
|Patch Set 10: Commit-Queue+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Patch Set 19:

(6 comments)
|Patch Set 21: Code-Review+1

Looks good to me. Let's see if David has any input. If not, I'll +2 this later.
|Patch Set 21: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

I don't see any significant performance degradation after testing a few rounds. I'd prefer landing this first since I've received more than one user complaints.

It'd be nice to try optimizing for the performance though :)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Unrelated upload_symbol unittest failure.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This doesn't cause hw test failure
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 2:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)

The bug is so old...
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

I saw orange paygen stage yesterday. Has this been resolved?
http://chromegw/i/chromeos_release/builders/x86-alex%20full%20release-R34-5500.B/builds/38/steps/Paygen%20%5Bx86-alex%5D/logs/stdio
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Thanks for reviewing.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 397ddd8efec772e74852b6d56cdd6a9e2decf03a
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

More like necessary to migrate to 2.7. Google app engine has deprecated 2.5 :)

I filed a bug: crbug.com/351192

This CL simply meets the reality for now. We can't run the code with the syntax issue.
|Patch Set 1:

Matt, this is probably not the only difference. I can't be sure because I think I overwrote the most recent version while testing (didn't know I had to change the version# when uploading. I thought a new version would be created. my bad).

I looked at our git history, and we've had a few syntax cleanup. We probably didn't update and deploy the instance after those.

FYI, this version (from this CL) is currently running on app engine and looks fine.
|Patch Set 1: -Commit-Queue

CQ's not passing this time. abandoning this in favor of CL:189590
|Abandoned

Abandon this in favor of CL:189590
|Patch Set 1:

Could you use cbuildbot_view_config and generate the diff? I'm trying to advocate doing this for easier/more accurate reviews on config changes :)
|Patch Set 1: Code-Review+2
|Patch Set 1:

Are we going to build Chrome at least once in a group builder in the near future?
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

small fix. Inheriting the +2.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2:

The atom canary with 5 boards took ~7 hrs to finish a run (but it finished!). We probably should think about whether we want to group them aggressively, or we want to have a faster run :)
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 53bb1e53af71924826a73ac49e8fec99fc152332
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(6 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

Ping!
|Patch Set 3: Commit-Queue+1 Verified+1

Thanks for reviewing!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

This is basically CL: 189117 with additional logic to skip symlinks when archiving test results. This is because gsutil consistently hangs on uploading a broken symlink.

Trybots running now.
|Patch Set 1:

I have not yet test with newer version of gsutil. I'll try that later and report the bug if it exists on the latest beta version.

However, they don't accept patches on older branches anymore (we're at 3.38 but the latest is 4.0beta), so there is no use waiting for them to fix this.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the typo in the docstring. trybot passed.

Inherit the +2.
|Patch Set 3: Code-Review+2
|Patch Set 6: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Added unit tests. Also verified the ToT failed the new unit tests.
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Abandoned

In favor of CL:192390
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

This is a cleanup CL that shouldn't break anything.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)

Thanks for reviewing!
|Patch Set 1:

(2 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue -Verified
|Patch Set 2:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Rebased. Addressed the comments. Carrying over the +2.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(6 comments)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(2 comments)

Agree with Mike's point. &quot;Untrusted data&quot; does not apply here. I'd rather not having another format here if possible.
|Patch Set 2:

Could you elaborate more why json failed? It's readable, faster than pickle, and we're already using json everywhere.
|Patch Set 2: Code-Review+1

(1 comment)

Writing a json encoder is trivial in this case.

I'd prefer json (but I'm not sure how much readable yaml really is).

If Don or Mike is ok with yaml, feel free to +2.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 6: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1

Carrying forward the +2.
|Patch Set 3: Code-Review+2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Patch Set 3:

(5 comments)
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Yep. useful for debugging as well :)
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This does not cause HW test failure
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This didn't fail vm test.
|Patch Set 3: Code-Review+2

Just curious, how often are we seeing the flakes? I don't see any recent flake reported in the bug.
|Uploaded patch set 2.
|Patch Set 2:

(10 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Edited commit message only. Inheriting the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

I prefer doing this in gerrit.py. I will upload a patch and see if you're ok with it.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

Ahh...I uploaded the patchset as draft, but I could not publish since I'm not the owner.

David, could you do that? Thanks!
|Patch Set 1:

The change itself looks fine, but I have one question:
I searched through the emails and did not find the reason behind using Xorg license other than &quot;inherit xorg-2&quot;. Is it reasonable to assume they &quot;inherit&quot; the LICENSE field as well?
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue -Verified

scratch this....I forgot the FileImager you added. These two should support the same thing.

I'll upload another patch.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks for reviewing!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

I am not sure how much this'd help in clarity. If you have better suggestion, please let me know.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This can not cause BuildPackage failure
|Uploaded patch set 1.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

corrected the crbug.com bug number.

Inheriting the +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

This can not cause BuildPackage failure
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This can not cause BuildPackage/Image failure
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 2:

Ping! I'm hoping to get this out today.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 324323997bb6efc8e2394a4b3d7f696315bf64d5
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 84f422fc4bee58827346beee9ada16919c00c976
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Verified-1

emerge: there are no ebuilds to satisfy &quot;chromeos-dev-root&quot; for /mnt/host/source/src/build/images/beaglebone/R36-5725.0.0-rc4/rootfs/.

beaglebone failed at BuildImage.
|Patch Set 2:

FYI, beaglebone/brillo_non_testable builds only the'chromeos-base/chromeos' package.
|Patch Set 5: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Code-Review+1
|Patch Set 3: -Code-Review Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

A trivial rebase. Inheriting the +2s
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

How it looks like:
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/peppy-paladin/builds/168

Suggestions of better place/format is welcome.
|Patch Set 1:

You're right. It needs to be rebased :(
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Same as patch1, but rebased.

Aviv, I think the text (bod-id/version) is only relevant to the artifacts. That's why I print it with the link.

That said, if you think it belongs better with the step text, I can change to using that.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 4: Reverted

This patchset was reverted in change: Ic80b97331b971d5a605d59200a66b3906d422f48
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

moved the comment. inheriting the +2.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

I'm pretty amazed that you are still leaving comment every time.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 373ec88bee0a0972295cb1713b391fe2c3822b43
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1:

Chumping this to fix pre-cq-launcher
|Change has been successfully cherry-picked as 3d15f19f981f84606e8a09fc21c33fa929912213
|Patch Set 6: Verified-1

CQ failed twice consecutively with this CL in it. In particular, VMTests failed at security_AccountsBaseline twice:
04/08 23:55:40.550 ERROR&#124;security_A:0039&#124; User baseline mismatch. Expected: 55 users. Got: 51.
04/08 23:55:40.552 ERROR&#124;security_A:0044&#124; No passwd entry for cros-disks
04/08 23:55:40.553 ERROR&#124;security_A:0044&#124; No passwd entry for ntfs-3g
04/08 23:55:40.554 ERROR&#124;security_A:0044&#124; No passwd entry for avfs
04/08 23:55:40.555 ERROR&#124;security_A:0044&#124; No passwd entry for fuse-exfat
04/08 23:55:40.558 ERROR&#124;security_A:0068&#124; Group baseline mismatch. Expected: 76 groups. Got: 72.
04/08 23:55:40.560 ERROR&#124;security_A:0073&#124; No group entry for cros-disks
04/08 23:55:40.561 ERROR&#124;security_A:0073&#124; No group entry for ntfs-3g
04/08 23:55:40.562 ERROR&#124;security_A:0073&#124; No group entry for avfs
04/08 23:55:40.564 ERROR&#124;security_A:0073&#124; No group entry for fuse-exfat
04/08 23:55:40.868 ERROR&#124;  parallel:0026&#124; child process failed
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-mario%20paladin/builds/1934
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-mario%20paladin/builds/1935

This CL looks the most relevant to the failures. Please take a look at your CL before setting commit-queue ready again. Thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Added WipePayloadCache. Inheriting the +2.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4.
|Patch Set 4:

oops. corrected the function name.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

How long did it take to finish your example pre-cq-group run?
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1

I'll let it go through CQ since I'll not be at my desk for the next hour.
|Patch Set 1: Code-Review+2

(1 comment)

Thanks for fixing this.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

rebased
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1

(1 comment)
|Patch Set 7: Code-Review+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(8 comments)
|Patch Set 2:

Ping!
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5:

but where is my +2? :(
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

I usually don't get email for David's CLs though, for whatever unknown reason (I've checked my spam inbox).
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Does not cause HW Test failure.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

So any time we add a new column, we need to bump the version?
|Uploaded patch set 2.
|Patch Set 2:

Trybot running.
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Got rid of the function (thanks David). Inheriting the +2.
|Patch Set 2:

(1 comment)

45k lines of configs...
|Patch Set 3: Code-Review+2
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Change has been successfully cherry-picked as 235d1b5caf1982bec54dcc427d54274d48fe519f
|Patch Set 1:

I would argue the error message should appear BEFORE dumping a long list of configs, which is additional information.

On the other hand, it may be reasonable to print a message asking the user to run `cbuildbot --list` or `cbuildbot --all` to see the configs.
|Patch Set 1:

just to correct my comment. should be

  `cbuildbot --list` or `cbuildbot --list --all`


This is just going to get worse with more targets being added every week.
|Patch Set 2: Code-Review+1

LGTM. Holding off the +2 to see if David has any suggestions.

I'll +2 it later.
|Patch Set 2:

(2 comments)

Just to make sure I understand the premise, crosdl.py will use `cros flash` only to copy a local image onto a usb drive?
|Patch Set 3: Code-Review+1

cros flash does a lot more, but it requires chroot for those features. I suppose that's the reason why you chose not to utilize it more.

The CL is replacing image_to_usb.sh with `cros flash`, and I'm happy to see that happening. I'll leave the rest of the review to people who'd use and/or maintain the script :)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

If I understand correctly, this is just to prevent a grand child config from being accidentally added?
|Patch Set 1: Code-Review+2
|Patch Set 5: Reverted

This patchset was reverted in change: I9e8e91e036866d520233695f9414205601976f23
|Patch Set 5: Code-Review+1

The code looks good. Just have one high-level question: how hard is it to converge/complete these partial-metadata json files?
|Patch Set 5:

Maybe I've misunderstood. 
Your description of partial-metadata.json in the bug (#6) was &quot;At the end of the build, the file is not guaranteed to be complete.&quot; The file would not get updated to the final status?
|Patch Set 8: Reverted

This patchset was reverted in change: Iede7e728b7a31d19e206b303940b3173a840b24b
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

Ping!
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Made the unittest complete. Inheriting the +2.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(1 comment)

trybot passed the CommitQueueSync stage and cherry-picked all patches.

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/peppy-paladin/builds/199
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Removed the TODO comment in gerrit.py. Inheriting the +2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Yes, I'm chumping it.
|Change has been successfully cherry-picked as 26d5eee7fe387809bfe44fbf099bef8eefa77cf8
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

We have lib/namespaces.py and this function. Maybe it'd make sense to put them in the same module?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

trybot passed. I'm chumping this (small) CL so I can get the followup CL tested more thoroughly.
|Change has been successfully cherry-picked as 029cd226c579c1d62cf6a28fd33daa5f4ce76f21
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2:

Just to clarify, devserver does not support using a local image path, therefore `cros flash` had to mess with the static_dir.

In this CL, we rename the image (when copying to the temporary directory) to chromiumos_test_image.bin so that devserver knows how/where to find it. It doesn't mean the image is a test image at all.

This will not be tested by CQ. I'll chump this to fix cros flash.
|Change has been successfully cherry-picked as 44874ccd0a76f0d0b0b7d916ce9ef0a6bc1fd9ae
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2

This is great!
|Patch Set 1: Code-Review+1

LGTM. I'll let the lab sheriff have the final say since this may increase the load in the lab(?).
|Patch Set 1: Code-Review+1

LGTM. I'll let the lab sheriff have the final say since this may increase the load in the lab(?).
|Patch Set 1: Code-Review+2

code looks good. trybot won't really test this because cbuildbot overrides the config to always use the default priority.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as e19934dbc2c9a78e7660ad2d502ca1f2dfeb2310
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 45df8f5e9637f5f7413a80b926a70be625601787
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/peppy-paladin/builds/207
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

trybot running
|Patch Set 1: Verified+1
|Patch Set 1:

The slaves don't check CQ-DEPEND, or any other dependencies at all. They should simply apply what CQ master has already applied.

This CL only tackles the corner case where some CL was chumped before the slave builder applies the changes.

David, does that answer your question? Note that this is a temporary fix and the slave *SHOULD* be able to simply applies all the changes after syncing to the manifest.
|Patch Set 1:

This should not be needed at all, but we've seen failures because of this.

I suspect there is bug in our code logic causing this. This was not seen before because our GoB code block masked it. Now that we don't go through the whole gerrit query block, it manifests.

I'm planning to find out the root cause, but at the meantime, I think it's pretty safe to ignore this exception.
|Patch Set 1:

This is a rather annoying error when it shows up because the deputy/sheriff has to abort the run.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

CL:196963 is the actual fix. Will probably abandon this CL.
|Abandoned

CL:196963 fixed this. No longer need to ignore the failure.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 9273d8938117a6e1e49122365dc3916f292dd5a9
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2:

trybot running.
|Patch Set 2:

Yes, I'm glad it's a bug that I *just* created this week ;)

I'll wait for the trybot to pass CommitQueueSync
|Patch Set 2: Verified+1

trybot passed. I'll chump this since tree is closed, and I don't want tomorrow's deputy having to deal with the annoying failures.
|Change has been successfully cherry-picked as c82e93b9adb4fba40816b81abb7120fd522a11fc
|Patch Set 2: Code-Review+2
|Patch Set 3:

The sticky reviews have been turned on? :)
|Patch Set 1: Code-Review+2
|Patch Set 1:

What Aviv wrote in in CL:196528:

When the ** wildcard was present, it was necessary to include a second / to restrict to metadata.json

Will this CL pick up partial-metadata.json?
|Patch Set 1: Code-Review-1

I just tested it.

This includes partial-metadata.json:
gsutil ls gs://chromeos-image-archive/peppy-paladin/R36**/metadata.json

This does not:
gsutil ls gs://chromeos-image-archive/peppy-paladin/R36**//metadata.json

and both are much faster than using the single '*'

We should just use R36**//metadata.json
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Can we get this out? It happened again last night :)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

More flags for testing is good, but we should probably add more unit tests as well :)
|Patch Set 2: Code-Review+2

(5 comments)

Just nits.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2. Thanks for reviewing.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

Oops, forgot to publish the patchset.
|Patch Set 2: Code-Review+2

(4 comments)

more nits.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This CL does not cause uprev failure.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

as requested, added a unit test.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

PTAL. Thanks!
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

This CL does not cause uprev failure.
|Uploaded patch set 1.
|Patch Set 1:

Not for review.
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1

Ready for review.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Minor change to the exception message. Inheriting the +2
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 8: Verified-1

https://uberchromegw.corp.google.com/i/chromeos/builders/CQ%20master/builds/1336/steps/CommitQueueCompletion/logs/stdio

Traceback (most recent call last):
  File &quot;/b/cbuild/internal_master/chromite/lib/parallel.py&quot;, line 479, in TaskRunner
    task(*x, **task_kwargs)
  File &quot;/b/cbuild/internal_master/chromite/buildbot/validation_pool.py&quot;, line 2410, in _ChangeFailedValidation
    self.RemoveCommitReady(change)
  File &quot;/b/cbuild/internal_master/chromite/buildbot/validation_pool.py&quot;, line 2114, in RemoveCommitReady
    dryrun=self.dryrun)
  File &quot;/b/cbuild/internal_master/chromite/lib/gerrit.py&quot;, line 333, in RemoveCommitReady
    label='Commit-Queue', notify='OWNER')
  File &quot;/b/cbuild/internal_master/chromite/lib/gob_util.py&quot;, line 451, in ResetReviewLabels
    new_revision = GetChangeCurrentRevision(host, change)
  File &quot;/b/cbuild/internal_master/chromite/lib/gob_util.py&quot;, line 301, in GetChangeCurrentRevision
    jmsg = GetChangeReview(host, change)
  File &quot;/b/cbuild/internal_master/chromite/lib/gob_util.py&quot;, line 289, in GetChangeReview
    path = _GetChangePath(change, '/revisions/%s/review' % revision)
TypeError: _GetChangePath() takes exactly 1 argument (2 given)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned

Abandon this in favor of CL:197816

I think only the installer team uses this feature? Lab runs devserver with --production.

Personally, I used it a few times while modifying devserver, but I can certainly live without it.

I could add a flag in devserver to turn it off, if anyone wants to keep this feature.
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1

Perhaps we can submit a revision of the CL instead?
https://gerrit-review.googlesource.com/Documentation/rest-api-changes.html#submit-revision
|Patch Set 3: Code-Review+1

LGTM. This happens quite frequently on CQ. We should get this in (since this does not cause any regression).
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: Iad47e44312038c4dc05b87b0bf8fccab89370746
|Uploaded patch set 1.
|Patch Set 1:

I tested this with a test spreadsheet. I am waiting for CL:197906 to get in to test this more thoroughly. Review and suggestion on the format of the message is welcome.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1

Tested using the latest CQ run, where all slaves failed at SetupBoard.


x86-mario-paladin,beaglebone-paladin,wolf-paladin,leon-paladin,lumpy-paladin,parrot-paladin,stumpy-paladin,x86-generic-paladin,x86-alex-paladin,amd64-generic-paladin,stout-paladin,daisy_spring-paladin,nyan-paladin,daisy-paladin,samus-paladin,panther-paladin,peach_pit-paladin,link-paladin,x86-mario-nowithdebug-paladin,falco-paladin,rambi-paladin,lumpy-incremental-paladin,duck-paladin,peppy-paladin,butterfly-paladin,monroe-paladin,gizmo-paladin: The SetupBoard stage failed: Packages failed in ./setup_board: chromeos-base/update_engine
|Patch Set 2:

Chumping this since CQ does not test the script at all. I will also add new columns in the stats sheets.
|Change has been successfully cherry-picked as 1a85e3be8ce77305d64c3fcabde81abc18a40662
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks for reviewing!
|Patch Set 2:

CQ run is doomed due to a bad CL. Chumping this since it's not really tested by CQ.
|Change has been successfully cherry-picked as 429ec12cb9fd2c88d3fe88a2b30d7ea5ca71662e
|Uploaded patch set 1.
|Patch Set 1:

This CL has to wait because I'm fixing crbug.com/369691

I'll upload another patch later.
|Patch Set 1:

After CL:198074 lands, what I need to do:
1. (probably) need to rebase this CL
2. run gather_builder_stats once to fill all the builds up until or later than CL:198074
3. chump this CL
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as a35324fcd989ff1003e0f44008af20b6d2f463de
|Uploaded patch set 1.
|Patch Set 1:

trybot running
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

Added a unit test.
|Patch Set 2:

It is not very intuitive...

1. builder pickles the builder status object, and dump it to GS.

2. The master fetches the builder status file from GS, unpickles it, and use the status object to annotate failed builders.

3. The master converts status object to a flat dictionary to store in metadata.json.

4. Finally, gather_builder_stats gathers the CQ/PFQ metadata.json files and use the flat dictionary version of builder status to populate the spreadsheet.
|Patch Set 2: Commit-Queue+1 Verified+1

I'll be watching the tree to see if this breaks anything.
|Patch Set 1: Code-Review+2
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Verified+1

Need to chump this so people can use the latest script.
|Change has been successfully cherry-picked as c976305af43798e366eee932772d0c403f95dd21
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

This is currently on hold until we have a discussion with the lab team.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Patch Set 3:

(3 comments)
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Patch Set 3:

(1 comment)
|Patch Set 5: Verified+1
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Rebased. Inheriting the +2
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1

rebased, again.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3:

(6 comments)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2

A comment would be good (even though your unit test'd catch it). Otherwise, LGTM.
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as d1f1a877de726cb04ab85fcacacf89ea6dfc8779
|Patch Set 1:

(4 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1

I did *NOT* review the code itself closely. The return codes look ok to me, hence the +1.
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+1

Can someone from the lab team review this? Thanks!
|Patch Set 2: Code-Review+2

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Fixed the unit test
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+1

Inheriting the +1
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1

The parent CL rebased.
|Patch Set 2: Code-Review+2

(1 comment)

Looks good generally with a nit.
|Patch Set 1: Code-Review+1

LGTM. Thanks for adding the tests as well. Only +1 so other people can take a look at it.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

This is just a temporary workaround, right?
|Patch Set 1: Code-Review-1

Fix the unittest? :)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

We need to fix https://code.google.com/p/chromium/issues/detail?id=363339 first, or at least disable upload_symbols_unittest for now.
|Patch Set 3: Code-Review+2
|Patch Set 3: -Code-Review

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Verified+1

trybot passed: chromiumos-sdk peppy-paladin amd64-generic-full link-release x86-generic-incremental pre-cq-launcher master-paladin
|Patch Set 2:

I would like to get this in before anyone else touch the code again :)
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Commit-Queue+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Verified-1

This makes the waterfall look weird. There are dangling stages with huge space in between.
|Patch Set 4: Code-Review+2

(1 comment)

just a nit.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

This is the same as the patchset #1 with an addition of the unit test file that I forgot to upload (cbuildbot_failures_unittest.py)
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 1:

(5 comments)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Verified+1
|Patch Set 4: Code-Review+2 Commit-Queue+1

Fixed the unittest. Inheriting the +2.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1
|Patch Set 1:

I'll chump this since CQ doesn't test this.
|Change has been successfully cherry-picked as 7c4df7cc285b5fcf2d61d69ab9acadae3ba957c5
|Uploaded patch set 1.
|Patch Set 1: Verified+1

chumping this because CQ doesn't test it.
|Change has been successfully cherry-picked as 0d58a6684cee182ad9388e1d7a838b9dc7955702
|Patch Set 1: Code-Review+2
|Patch Set 2:

I believe you need to change crostools as well :)
|Patch Set 7:

I'm ok with the plan. You should probably add your bug number now that you have one.

I don't mind reviewing the code, but I think the trybot runs will be more meaningful :)
|Patch Set 8:

I was going to offer help rebasing other dependent CLs to speed up things, but then I realized those probably don't need to be rebased?
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2

Is this the only place that needs to be fixed?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Added a blank line somewhere.
|Patch Set 2:

Don, if you prefer landing your renaming CL first, I can wait and rebase this later.
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1

Thanks for reviewing.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

You missed the latest CQ run!
|Patch Set 1:

(1 comment)
|Patch Set 2:

This should be tested by Pre-CQ, so I wouldn't worry that much.

If you want, you can manually launch the pre-cq trybot before getting approvals by `cbuildbot --remote -g 200004 pre-cq-group`
|Patch Set 2: Code-Review+1

Nope, but it will verify that it can build. If you want to examine the artifacts, you need a different target.
|Patch Set 2: Code-Review+2

Ideally, you should run your suite using the artifacts from your trybot run.
http://www.chromium.org/chromium-os/testing/test-code-labs/dynamic-suite-codelab

I'm fine with this change though.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

This is great! Thanks for refactoring!
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

Go ahead.

Symlinks will be removed after the transition :)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

Actually, the chromite import was added by sosa@, so he may know more about whether it's ok to remove that.
|Patch Set 2:

(1 comment)
|Patch Set 1:

sosa's working on changing the timeouts as well. Added him to the review
|Patch Set 2: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Reverted

This patchset was reverted in change: Ied883464c27e5bdff04e6e8c30fadcf7ca15eb66
|Patch Set 1: Code-Review+1

Change looks good. You'll need to rebase because of the recent timeout bump.

+1 to Leave others a chance to voice their opinions.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Anyone want to take a final look? :)
|Patch Set 3: Code-Review+2 Commit-Queue+1

Inheriting the +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the sanity check.
|Patch Set 4: Commit-Queue+2
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

I'm unsure about how to treat SUITE_TIMEOUT. Suggestions are welcome.
|Patch Set 1:

(1 comment)
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1

SuiteTimedOut exception is now a subclass of TestLabFailure, which will be treated as infra failures and CLs won't be rejected.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Commit-Queue+2

+2 this with the hope that we will have clearer waterfall tomorrow.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 1: Code-Review+2
|Abandoned

I'm fine with the alternative which is to turn off paygen on some boards. The intention of the revert was to not cause false alarms, leading to sheriffs wasting time and neglecting real failures.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the unittest. Inheriting the +2
|Patch Set 4: Reverted

This patchset was reverted in change: I04b315dbe2a20893f348730e3fda0e5e2ea1b102
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1

Fixed typos.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 8: Reverted

This patchset was reverted in change: Ia5b401e278b8ad2c3097563ed2be9a1ab62dcc5d
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified-1

Do not review. I'm going to make some more changes.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Remove an extra blank line. trybot passed (for sanity check only). Inheriting the +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3:

(10 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Rewrite the commit message to make it more clear. Also make it the second object in the raise statement a tuple to indicate that we're passing that as an argument. PTAL.

An alternative is to save the original exception class and the string in the new exception. This could be useful in some cases, but would need modifications of existing exceptions.

Let's fix this first.
|Patch Set 2: Commit-Queue+1

(1 comment)
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Abandoned

I decided to go with the quick fix in https://chromium-review.googlesource.com/#/c/200717/

In the meantime, I'll make some more changes to SetFailureType to preserve the original exceptions.
|Patch Set 1:

(3 comments)

Some uninvited comments (I was looking at the internal CL). Unittests will be great!
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

Just a reminder: &quot;SignerResultsStage&quot; are still being used in many docstrings.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2

I hope one day we can get rid of the inconsistencies...
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as ab0f166e4946402d13e6153984026c01316746e7
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I'm going to chump this.
|Change has been successfully cherry-picked as d379d3bdff707e860beec4455cd1005598827a4f
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1

(1 comment)
|Patch Set 3: -Verified

(3 comments)

I rebased the change based on CL:201201 

But I cannot upload the new patch yet because it would also upload a patch to CL:201201, which is currently in CQ. I'll do it after CL:201201 lands.
|Uploaded patch set 4.
|Patch Set 4:

Thanks David for the trick. I rebased to the exact sha1 of the parent CL and was able to upload only my patch.
|Patch Set 4: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

A minor change to make the new function matches the docstring.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Patch Set 6: Commit-Queue+2

This CL handles CQ failures and may not be tested properly in a single run. +2 this to let it go through CQ now, and I'll watch the runs afterwards. Fixing and/or reverting if needed later.
|Patch Set 1:

pre-cq-launcher, master-paladin

You can run them with --remote --buildbot --debug
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

Thanks!
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

So many missing blank lines!
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2

just a nit
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 3:

FYI, CL:200682 just landed (the bug was closed so I posted it here)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

The new patch simply adds the argument possibly_flaky since the use of possibly_flaky is still under investigation.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the typo, inheriting the +2.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3:

Maybe we should stop rejecting chromite CLs on HWTest failure...
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1

Thanks for reviewing!
|Patch Set 1: Code-Review+1

https://chromium-review.googlesource.com/#/c/25379/

The message from the original commit:
&quot;Groups awareness will be used by loman at a later date; revision
awareness is intended to be used by some upcoming manifest inheritance
work in conjunction w/ potential cbranch tweaks.&quot;

Looks like the author never got to it. I'm in favor of deleting unused code. +1 so David can confirm that we have no plans to use the code.
|Patch Set 1: Code-Review+2

I don't see why we can't remove them. Go ahead.
|Patch Set 1: Code-Review+2

Yes, it may be worth looking into the time increase (if there's any). I had never hit the timeout until last week.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1

What a stupid mistake I made ... :-(
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the format. Inheriting the +2. Thanks for reviewing.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1

I see. That's good know. I already filed a bug for 2.7 though.
http://bugs.python.org/issue21664
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the comments. Inheriting the +2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Good point. I'll add some to verify the changes.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Some unit tests added. The rest are already tested in the existing tests.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Rebased.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

Rebased, and also fixed the VMTestStage unittest
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1

@Aviv, yes.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

Trybots still running.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

True. But that has nothing to do with the CLs in the current run. I also think this is an infra failure if we cannot clean up after the test/build.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

I'll fix that in my CL.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Verified+1

Fixed a typo in the docstring. Inheriting the +2.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Reverted

This patchset was reverted in change: I7e603bace6d0f2090839a16a51b51399f0815e18
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

The trybot run:

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/peppy-paladin/builds/268/steps/BuildPackages/logs/stdio
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Abandoned

David is working on a CL which is going to subsume this CL. Given that there's not significant advantage of getting this CL in now, I'll just abandon this.
|Patch Set 10:

Did this CL cause some dependency issues? All BuildPackages are orange in the CQ run with the first try of autotest-tests failed:

ERROR:root:network_DisableInterface import error: No module named routing.  Skipping network_DisableInterface
ERROR:root:network_Portal import error: No module named flimflam.  Skipping network_Portal
|Patch Set 1: Code-Review+2 Verified+1

Chumping this to fix amd64-generic-incremental
|Change has been successfully cherry-picked as d9ac3dd561bd942502af69d6dc05183f863fa9a2
|Patch Set 3: Code-Review+2
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1

Inheriting the +2.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Abandoned
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Rebased. CL:203207 replaced the hw_tests_warn flag with the warn_only flag in the suite. Use that.
|Patch Set 4: Commit message was updated
|Patch Set 3:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

copy/paste with only one exception: I made status_url a keyword argument in most of the functions because they all use the same url.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 1:

My bad. Some of the functions did not use keyword arguments as they were supposed to, but instead relied on the positions of the arguments. This caused the failure to submit the CLs. Fix this by making them keyword arguments. Running trybot (master-paladin) for sanity check.

I am aborting the CQ run because other CLs won't be submitted with this CL in the run.
|Patch Set 2:

I'm going to try again, if no one objects.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2.
|Patch Set 3: Verified-1

This CL failed the CQ run.
https://uberchromegw.corp.google.com/i/chromeos/builders/nyan%20paladin/builds/1681/steps/BuildPackages/logs/stdio

depthcharge-0.0.1-r760: src/board/nyan/board.c: In function 'board_setup':
depthcharge-0.0.1-r760: src/board/nyan/board.c:180:12: error: too many arguments to function 'new_tegra_i2s'
depthcharge-0.0.1-r760:             1536000, 48000);
|Patch Set 2: Commit message was updated
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(4 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

This does not cause BuildPackages failure.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

Does not cause BuildPackages failure.
|Patch Set 1: Commit-Queue+1

There have only been 9 runs, but that's good enough.
|Patch Set 1: Code-Review+2 -Commit-Queue
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

How about this? I renamed it to false rejection ratio and define it differently.

The stats for the past week:
11:04:56: INFO:       Total CL actions: 2154.
11:04:56: INFO:     Unique CLs touched: 499.
11:04:56: INFO: Unique patches touched: 546.
11:04:56: INFO:    Total CLs submitted: 413.
11:04:56: INFO:       Total rejections: 224.
11:04:56: INFO:  Total submit failures: 1.
11:04:56: INFO:  Good patches rejected: 74.
11:04:56: INFO:    Mean rejections per
11:04:56: INFO:             good patch: 0.33
11:04:56: INFO:  False rejection ratio: 0.09.
|Patch Set 2:

Uh....pardon the bad formatting.

The important line is:
11:04:56: INFO:  False rejection ratio: 0.09.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Patch Set 4: Verified+1
|Patch Set 4:

CQ does not test this at all. I'll submit this directly.
|Change has been successfully cherry-picked as 0fab57615f3d36361db9c5dcf36c6a80f7a3aad8
|Patch Set 1:

(6 comments)

Still reviewing. And you may want to run a trybot to test this.
|Patch Set 1:

(10 comments)
|Patch Set 1:

(2 comments)
|Patch Set 3:

(7 comments)
|Patch Set 7:

(4 comments)
|Patch Set 13:

(6 comments)
|Patch Set 14:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

LGTM. You can update commit message to use the bug number https://code.google.com/p/chromium/issues/detail?id=385819
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2. Thanks for pointing out what StepFailure is for :)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

It could only break the failures!
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1

Chumping this to fix stumpy_moblab canary.
|Change has been successfully cherry-picked as c9d15fa3e4d57f4df904b340b747d058db625b51
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Added the args in docstring. Pulling forward the +2.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

The format looks good to me.

Pre-CQ launcher runs for 4 hours. That means it'd be printing this links over and over again. Wouldn't that be a little too much..?
|Patch Set 2: Code-Review+2

That makes sense. LGTM.
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the error. pre-cq-group passed. Pulling forward the +2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 4: Code-Review+2

warning might be good, but it's optional in this case (which is how the current build behaves). 

Thanks for fixing this :)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

both trybot runs passed.

http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/beaglebone-release/builds/39
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/beaglebone-paladin/builds/40
|Patch Set 1: Commit-Queue+1

Yeah I remember it not working when I added the original beaglebone config. Good to see it fixed. :)
|Patch Set 1: -Commit-Queue

(1 comment)
|Patch Set 1:

(I think) ArchiveStage is building at the assumption that all packages have been built before and it was simply using them. That said, I don't know enough to say more.
|Abandoned

After discussing with sosa@, there might be a bug in ArchiveStage such that it's building the packages that non-testable configs don't need. I'll dig more and see what I can find.

In the meantime, the race condition doesn't happen that often and &quot;packages&quot; may be used by future configs, so I'm abandoning this CL.
|Restored
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Verified+1

Both beaglebone-paladin and storm-paladin passed.

Gaurav, the builder for mipsel-o32-generic-paladin has not been set up yet. Would this config change be a problem for the board?
|Patch Set 4: Code-Review+2 Commit-Queue+1

Addressed the comments. Inheriting the +2.
|Patch Set 1:

I suppose the original bad_cl_pickup_count did not account for the scenario where the multiple bad CLs were in the same run, and only one was blamed for the failure?
|Patch Set 2:

(3 comments)
|Patch Set 2:

I agree with Aviv that the script has become too long (1500 lines) which does everything and is hard to read. Breaking it into more modules will help.

That said, if we are switching to the new database soon, it may not worth investing too much time on this script.
|Patch Set 3: Code-Review+2
|Patch Set 1: Verified-1

Could you check if this has caused the CQ failures?

https://uberchromegw.corp.google.com/i/chromeos/builders/peppy%20paladin/builds/4187/steps/VMTest%20%28attempt%202%29/logs/stdio

https://uberchromegw.corp.google.com/i/chromeos/builders/peppy%20paladin/builds/4181/steps/VMTest%20%28attempt%202%29/logs/stdio

Both times dev_install failed at downloading /usr/local/portage/packages/net-misc/dhcp-4.2.2-r1.tbz2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

The trybot run: http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/x86-generic-chromium-pfq/builds/222
|Patch Set 1:

Note that the trybot run includes some random logging information I added, which is not included in the CL.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Verified-1

This has an unwanted side effect that on the master, SyncChromeStage would think the Chrome has already been uprevved and decide to exit. I need to rework the logic.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

The new patch does *NOT* uprev Chrome in MasterSlaveSyncStage anymore. It simply gets the latest Chrome version and stores it in the manifest.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

There is not much difference between patch #3 and #4 (I moved one line).

I'm running trybots (x86-generic-chromium-pfq lumpy-chrome-pfq) to verify the change. Feel free to review.
|Uploaded patch set 6.
|Patch Set 6: Verified+1

All trybots passed the SyncChrome stage with the correct message:

13:33:47: INFO: Using chrome version from the metadata dictionary: 38.0.2071.1
13:33:47: INFO: RunCommand: cros_sdk -- ../../chromite/bin/cros_mark_chrome_as_stable '--tracking_branch=master' '--boards=lumpy' '--force_revision=38.0.2071.1' latest_release in /b/cbuild/internal_master/src/scripts
13:33:48: INFO: RunCommand: svn ls svn://svn-mirror.golo.chromium.org/chrome/releases
|Patch Set 6:

PTAL
|Patch Set 6:

Ping?
|Patch Set 2:

(2 comments)
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Added comment about why we choose to write to the metadata dictionary. Inheriting the +2. Thanks for reviewing!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

The sanity check run beaglebone-paladin passed.
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)

with a nit
|Patch Set 3: Code-Review+2
|Patch Set 3:

(7 comments)
|Patch Set 2: Code-Review+2

Thanks for fixing this!
|Patch Set 10:

(1 comment)
|Patch Set 13: Code-Review+2
|Patch Set 17:

https://b.corp.google.com/issue?id=15934919 is fixed. Perhaps we should give 4.4 another try?
|Patch Set 17:

:-(
|Patch Set 18:

FYI, there were some GS failures in the ReportStage in the last run:
https://uberchromegw.corp.google.com/i/chromiumos/builders/x86-generic%20paladin/builds/19095/steps/Report/logs/stdio
https://uberchromegw.corp.google.com/i/chromiumos/builders/amd64-generic%20paladin/builds/18892/steps/Report/logs/stdio
https://uberchromegw.corp.google.com/i/chromiumos/builders/gizmo%20paladin/builds/232/steps/Report/logs/stdio
https://uberchromegw.corp.google.com/i/chromiumos/builders/mipsel-o32-generic%20paladin/builds/290/steps/Report/logs/stdio
|Patch Set 18: Verified-1

This is easily reproducible.

I logged in to the x86-generic-paladin bot and ran the &quot;-d acl get&quot; command manually. The 3.42 version returned &quot;header: x-goog-generation: 1408630250240000&quot; as expected, but the 4.5 version returned &quot; generation: 1408630250240000&quot; (and the response format was completely different).

In the case where gs.py cannot get the generation, it assumes the file does not exist and use generation 0. That's why the following increment operation fails with precondition error.

Note that the internal bots do not have this problem at all.
|Patch Set 20: Code-Review+1

Looks good to me. I'll leave it to Mike to see if he wants more unit tests :-)
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+1
|Patch Set 3:

(1 comment)

This change will break the case where the user passes &quot;error_code_ok=True&quot; and expects the error output to be returned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

Running trybot to verify dev_install tests.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

trybot passed. PTAL!
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

VMTest passed.
|Patch Set 3:

This has to go in with CL:207952. PTAL! Thanks!
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased. Inheriting the +2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)

yep....it's a chore passing them. If you know a cleaner way, please let me know :)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: -Verified

Good catch. In most cases, no. but in the uncommon cases, you could directly pass the package path or the private key.

This needs a bit more change because I'd need to test each package (in the list) whether they are a valid path.

I'll upload a new patch later.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Reconstructing the arguments is a bit messy and has to be updated whenever the options change. Suggestions are welcome.
|Patch Set 2:

(1 comment)

Gabe, that wouldn't work because user can specify an argument with '=', e.g., --private_ssh_key=/path/to/key. I'd still have to parse that myself.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: -Verified

I'd also prefer a better and more general approach. I'll think about it.
|Patch Set 3:

I thought of changing the commandline module before, and did not pursue it because it'd be a bit more complicated for cros deploy. In cros deploy, you can specify either a package name or a path, so it's not definitely a path, which makes the conversion based on type harder. The same applies to cros flash, but cros flash can spawn a devserver instance inside chroot at all times so it's not really a problem.

In general, I'd say this is good for cros commands, but not for cros deploy, so I probably won't be implementing this.
|Patch Set 3:

SGTM. I probably won't get to this anytime soon. Gabe, feel free to pick this up if you'd like.
|Abandoned
|Patch Set 1:

(5 comments)

I like the simplified method.
|Patch Set 1: Code-Review+2

Most of my comments are nits, it'd be good that if you can address them. If you prefer submitting this to fix the p0 bug first, then go ahead.
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 4:

What caused the failure exactly? Why the problem didn't occur to other tests using ParallelMock?
|Patch Set 1: Code-Review+2

(1 comment)

Assume the trybot run passes.
|Patch Set 1: Code-Review+2 Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

I can make the master config changes. Peter, would you have time to review it?
|Patch Set 3:

Ping! PTAL.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Our unittest does not allow a board to be both private and public. I fixed it. PTAL.
|Patch Set 4:

Yep. Mike did that in https://chromium-review.googlesource.com/204413
|Patch Set 4: Commit-Queue+1

Thanks for reviewing.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+2 Commit-Queue+1

Inheriting the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

Unrelated failure.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Verified-1

CQ has failed once and is about to failed due to error in BuildPackages:

failed to copy --bindir=/bin /usr/bin/old_bins/dump_kernel_config

verify:-1 this CL while looking for the root cause.
|Patch Set 1:

A beaglebone-paladin run with *only* this stack of CL failed for the same reason.

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/beaglebone-paladin/builds/43
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 16: Verified-1

Many of the DUTs in the CQ pool also died after provisioning in the same CQ run. This CL looks the most suspicious, so -1 until we can be sure that it wasn't at fault.
|Patch Set 2:

Hmm...The waterfall change should've gone in first. Sorry for causing the trouble.
|Uploaded patch set 1.
|Patch Set 1:

This CL is in release-R37-5978.B branch only. Thanks for reviewing.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

The config (with master=True) in the trybot run using the name x86-generic-chromium-pfq:

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/x86-generic-chromium-pfq/builds/243
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2

cros flash doesn't call this script directly. It lets devserver invokes it. To be absolutely sure that this CL doesn't affect things, you can run a trybot run with VM tests.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

Gabe, the stack trace was from the TOT code...the builder hadn't even applied my patch at that moment. I'm marking this ready again.
|Patch Set 3:

Would it be possible that the gsutil command was retried incorrectly?

E.g.
  - The first request appeared failed.
  - Launched the second request.
  - The first request was processed and the file created.
  - The second request failed because the file already exists.

I remember seeing a similar failure a few weeks ago...
|Patch Set 1: Code-Review+2
|Patch Set 3:

Was there a reason to commit-queue +2 the change? +1 is recommended for most situations.
|Patch Set 3:

CQ+2 is not the same as chumping...but we have a description next to the label saying it's for sheriff only, which apparently is not in the new interface.

CQ will pick up CQ+2 CLs even if the three is throttled (but not closed), and is usually used to fix tree problems.
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Verified+1

The trybot run:
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/master-release/builds/2
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 4: Verified+1

rebased.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5: Verified+1
|Patch Set 5:

PTAL, thanks!
|Uploaded patch set 6.
|Patch Set 5:

(5 comments)
|Patch Set 6:

Some of the differences in the new patch came from rebasing.
|Patch Set 5:

(1 comment)
|Patch Set 6: Verified+1

PTAL, thanks!
|Uploaded patch set 7.
|Patch Set 6:

(6 comments)
|Patch Set 7: Verified+1

Reviewed all the canary configs again.
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Patch Set 8: Verified+1
|Patch Set 8:

1. I have confirmed the list, and I can confirm again.

2. There are two types of sync problems:

 - We have an important config but it's not on the waterfall (no machine is allocated). This is basically the same as PFQ and CQ. We don't have any test to detect this, but we follow the protocol to *always* add a config with important=False first, add the builder on the waterfall, and mark important=True.

- We have corresponding builders on the waterfall, but their &quot;tree-closer&quot; status is inconsistent with cbuildbot_configs. This is only a transient problem because one of the primary goals is to let the canary master close the tree only (explained in the design doc); other builders should not be tree closers as far as buildbot is concerned. Once we are able to switch to that model, we don't have to keep the status in sync with the buildbot configurations.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.

Here is the trybot run which shows all the slaves the master waited for:
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/master-release/builds/4

I verified that it matches slaves.cfg. 

Inheriting the +2.
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1
|Patch Set 3:

PTAL.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4:

The last patch failed CQ run because timeout was set incorrectly. This is fixed in the new patch.

Basically, this boils down to:
 &quot;cbuildbot_config.IsPFQType()&quot; is not equal to &quot;build_type == constants.PFQ_TYPE&quot;

PTAL. Thanks!
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1

Thanks for reviewing!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Added more comments.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 5: Code-Review+2

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Verified+1

Dropped the redundant config. Inheriting the +2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1

Rebased. Chumping so that we can restart the waterfall.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

FYI, the trybot run:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/master-chromium-pfq/builds/4
|Patch Set 1:

(1 comment)
|Patch Set 1:

+petermayo@. This CL has been reviewed and verified. We can find a time to chump the this CL with your waterfall change, followed by a waterfall restart.
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1

Chumping this to stop canary master from failing.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2:

A minor change in patch 2. Running pre-cq-group and remote trybot again to confirm.
|Patch Set 2: Code-Review+2 Verified+1

Inheriting the +2. Chumping this as this is not tested by CQ.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Deleted the method in CommitQueueCompletionStage. Inherit the +2.
|Patch Set 1: Code-Review+2

A thought: Maybe this will work better if we wait for, say, a minute and then hit the submit button again.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1:

I couldn't really send out the test email from a trybot because the golo smtp doesn't work for the b2 bots.
|Patch Set 1:

I assume we should have. I'll ask the infra team tomorrow. In the meantime, this CL can still be reviewed :-)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Tested using the SMTP server for *-b2 bots and received an alert email.

Inheriting the +2.
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2

Perhaps we should rework the logic so that if there is nothing to build, the master/slave shouldn't even run. That's a longer story though. Thanks for fixing this.
|Patch Set 9:

I was also curious about this, so I checked the diff of patch 7 &amp; 9.

The unittest failed only on external builders (amd64-/x86-generic) which did not have access to certain paygen configs. Pre-CQ did not run on external builders, so it didn't catch it.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Do you mean the 'bvt-cq' suites run on canaries? They are asynchronous suites on canaries and are supposed to be at a lower priority.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Added unittest. PTAL!
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Added another test case (lab_fail=False, infra_fail=True) in the unittest for completeness. The rest is the same. Inheriting the +2. Thanks for the fast review!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(3 comments)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inherit the +2.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

sgtm. I assume tryjobs would cover most of the use cases. Thanks for merging my CLs too.
|Patch Set 3:

This does not include the gslib change?
|Patch Set 3:

I uploaded a CL to update gslib: CL:213660
|Patch Set 14: Reverted

This patchset was reverted in change: Ide1a5247fe8d26ba8f475079a1d6c2c3f60bc860
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

Running a master-paladin trybot for sanity check.
|Patch Set 1: Verified+1
|Patch Set 1:

Ping! PTAL
|Patch Set 1:

Anyone willing to take a look?
|Patch Set 1: Commit-Queue+1

(1 comment)

Thanks for reviewing!
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R38-6158.B as commit 5b36a6e83b990250d61038179f859a5640e871cd
|Patch Set 4:

sorry I just noticed the CL. Will take a look after lunch.
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

This is not really tested by CQ and it has been rejected twice :-(

I'm chumping this to help with the canary timeout.
|Patch Set 1: Code-Review+2
|Patch Set 2:

I think that was from image_to_live.sh, not from image_to_usb.sh.

There is a bug open for removing image_to_live.sh from our test flow, but is currently blocked on AU team merging ctest into autotest:
https://code.google.com/p/chromium/issues/detail?id=355150
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

How much faster? :-)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

no problem. sorry for creating extra work for you during the migration.
|Patch Set 1: Code-Review+2
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

We should increase the pre-cq inflight timeout with this CL.
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2

(1 comment)

LGTM with a nit to add a TODO comment :-)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2

Is one retry sufficient? I suppose you want to test if it's enough and add more when needed.
|Patch Set 1:

I wouldn't say we would be hiding it by adding more retries. We can always grep the logs and figure out how often it has been retried. This is a manual process but seems okay for a new external service.

Of course, I'd much prefer if the retry info can be recorded into cidb :-)
|Patch Set 1: Code-Review+2
|Patch Set 1:

Just an FYI, gslock is also used by pushlive
https://code.google.com/p/chromium/issues/detail?id=408638

You may want to check the unittest there as well.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Comment added as suggested. Pulling forward the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

This doesn't cause buildbpackages failure.
|Patch Set 2: Code-Review+1

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1:

Can we use retry_utils for this? This way we can enhance the module and provides more features when necessary.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Ping!
|Patch Set 1: -Verified

Yes, thanks for catching that. Most of the time, people use &quot;tree is closed for maintenance&quot;, which confuses me. And it wasn't even listed as a valid tree status in constants.py so I forgot about it. :-&#124;

I'll add that in the next patch and check for all proper &quot;keywords&quot; in the new message.

Thanks for reviewing! :-)
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3: Verified+1

Rebased and addressed all comments.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Oops a string in the unittest escaped me. Fixed and retrying again.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

Thanks for reviewing!
|Patch Set 1:

Just an FYI, I'll chump this after pre-cq passes.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

FYI, we don't really have canary master running on other branches yet.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This does not cause HWTest failure
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

This does not cause HWTest failure
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 11: Commit-Queue+2
|Patch Set 11: Commit-Queue+2
|Patch Set 11: Commit-Queue+2
|Patch Set 11: Commit-Queue+2
|Patch Set 11: Commit-Queue+2
|Patch Set 11: Commit-Queue+2
|Patch Set 2: Code-Review+2

We need more retries :)
|Patch Set 1: Code-Review+2

What did we replace gs_probe with?
|Patch Set 1:

(3 comments)

You may want to log the retries so that they are visible in the log, at least for now.
|Patch Set 2: Code-Review+2

logging can be added to your retry filter...
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Commit-Queue+1

This bug killed another canary. +1 to see if we can land this :)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

LGTM w/ one question
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1

chumping this to fix canary master
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

This does not cause archive failure.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

The corresponding chromiumos-status app change is under review:
https://codereview.chromium.org/501243002/
|Patch Set 1:

The suggestions all sound very good  :-)

I just recently added the &quot;tree closing&quot; logic in cbuildbot and this is currently used only by the canary master. The reason why we don't have this for every builder yet is because cbuildbot itself may fail, so we still need to rely on the &quot;buildbot&quot; code to trigger the tree closure, where we have less control over the message. We are (partially) relying on the fact that the master builder should fail less frequently than normal builds due to less code running, and uses the tree-closing logic from buildbot as the fallback.

Also, there are additional benefits of using a master builder to close the tree, so we're migrating toward that (at least for canaries). 

If we had wider usage of the tree closing logic, your suggestions should be implemented. For now, we don't really have that.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1

Added the internal/public identifier in the message.

Also updated https://chromiumcodereview.appspot.com/531223002/ to match.
|Patch Set 2:

PTAL! Thanks!
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the comments. Pulling forward the +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1:

Since we are making it more readable, why not limit the size to 200?
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

I added a TODO comment in CL:216633
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

lgtm.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

I'll address the comments in a separate CL :-)
|Patch Set 1:

(3 comments)

Addressed the comments in CL:216702
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

addressed the comments. pulling forward the +2.
|Patch Set 3:

(2 comments)
|Patch Set 8:

(1 comment)
|Patch Set 8:

(1 comment)
|Patch Set 3:

This is not the right timeout to bump. See my comment on the bug :)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

This has been failing canary and CQ masters quite frequently. Let's see if we can simply retry it
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

failure caused by tryserver waterfall restart
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

failure caused by tryserver waterfall restart
|Patch Set 4: Verified-1

CQ run failed at wakeup_controller_unittest
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-alex%20paladin/builds/17456/steps/UnitTest/logs/stdio

Will also verify:-1 your other CLs to make sure none of them will be retried by CQ
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(4 comments)
|Patch Set 2:

Will address the rest of the comments in the next patch. The trybot run is here:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/master-release/builds/14/steps/CanaryCompletion/logs/stdio
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue -Verified

There is no build status for the external paladin builders...
https://uberchromegw.corp.google.com/i/chromiumos/builders/x86-generic%20paladin/builds/19258/steps/CommitQueueCompletion/logs/stdio
|Patch Set 3:

This is blocked on https://code.google.com/p/chromium/issues/detail?id=398267
|Patch Set 3: Commit-Queue+1 Verified+1

Does not cause hw test failure
|Patch Set 3:

The current CQ run is doomed. I'm inclined to chump this CL since it has been tested very thoroughly by being in so many CQ runs. In fact, failed CQ runs test this CLs more.

Aviv, are you okay with this?
|Patch Set 3: Commit-Queue+2

CQ+2 to trigger a run to check if lab is functioning
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

Ping!
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

Does not cause HWTest failure.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)

Do we have any idea how to fix this?
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the docstring. Pulling forward the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

Does not cause HWTest failure.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

Doesn't cause hwtest failure.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Uhh..this unittest doesn't hang on my desktop. Did you forget to include CL:218220 when testing?
|Patch Set 3:

This test seems to be flaky (failed, then passed):
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-alex%20paladin/builds/17454/steps/UnitTest/logs/stdio
https://uberchromegw.corp.google.com/i/chromeos/builders/parrot%20paladin/builds/12690/steps/UnitTest/logs/stdio
|Patch Set 3: Verified-1

All builders with unittest failed this once:
https://uberchromegw.corp.google.com/i/chromeos/builders/samus%20paladin/builds/3457/steps/UnitTest/logs/stdio
https://uberchromegw.corp.google.com/i/chromeos/builders/leon%20paladin/builds/3458/steps/UnitTest/logs/stdio
https://uberchromegw.corp.google.com/i/chromeos/builders/falco%20paladin/builds/4866/steps/UnitTest/logs/stdio

You may want to increase the timeout and test it on the trybot...
|Patch Set 4: Code-Review+2
|Patch Set 2: Reverted

This patchset was reverted in change: I9ed47c184cb7b57d04c13ddad2f39e27205a3cbb
|Patch Set 2: Verified-1

CQ run failed at wakeup_controller_unittest
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-alex%20paladin/builds/17456/steps/UnitTest/logs/stdio

Will also verify:-1 your other CLs to make sure none of them will be retried by CQ
|Removed the following votes:

* Verified-1 by Yu-Ju Hong &lt;yjhong@chromium.org&gt;

|Patch Set 4: Verified-1

CQ run failed at wakeup_controller_unittest
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-alex%20paladin/builds/17456/steps/UnitTest/logs/stdio

Will also verify:-1 your other CLs to make sure none of them will be retried by CQ
|Removed the following votes:

* Verified-1 by Yu-Ju Hong &lt;yjhong@chromium.org&gt;

|Patch Set 4: Reverted

This patchset was reverted in change: I2eee4cedb0e76b5d77a8d8ae271d80bd7b471f5e
|Patch Set 2: Commit-Queue+2
|Patch Set 2: Verified-1

CQ run failed at wakeup_controller_unittest
https://uberchromegw.corp.google.com/i/chromeos/builders/x86-alex%20paladin/builds/17456/steps/UnitTest/logs/stdio

Will also verify:-1 your other CLs to make sure none of them will be retried by CQ
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

Hmm...but for the modules that do not use &quot;print&quot; at all, the import is still required?
|Patch Set 1: Code-Review+1

I don't mind the CL as it is.
|Patch Set 1: Code-Review+2

I did the math and here is your +2.

I'm fine with the CL as it is. I don't think you need to clean up all the repos since you've already sent out a PSA :)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3:

+1 for adding a check in cros lint.
|Patch Set 5:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified-1

Hmm...this needs more work
|Uploaded patch set 4.
|Patch Set 4: Verified+1

The slaves don't really need to query their own status. Decided to just get rid of the code.

Note that although it may seem good to test that the slave can read their own pickle, or query their own status, the truth is that this code path will *only* be run in production (trybot runs with --buildbot --debug and therefore skip this part). Testing this in production is not very meaningful.
|Patch Set 4: Commit-Queue+1
|Patch Set 1:

https://uberchromegw.corp.google.com/i/chromeos/builders/lumpy%20paladin/builds/17985 failed the same way with this CL in it.
|Patch Set 1:

Looks like it only fails lumpy....I'm not sure why but you can run a lumpy-paladin trybot to debug/verify.
|Patch Set 1:

I'm pretty sure you've checked, but just wanted to ask anyway: there is no other difference between 4.5 and 4.7 that we need to adapt to?

Can we also test this CL with more tryjobs before attempting to land?
|Patch Set 1:

I'd say just launch a bunch a tryjobs and see if any flaky behavior shows. They usually happen under high load. It's better than just letting it through CQ.
|Patch Set 1:

I think 5 is fine. Why with --hwtest?
|Patch Set 1:

We uploaded all the test artifacts w/ or w/o hwtest, so that shouldn't be an issue. paygen seems to hit GS flake the most, but it's not easily testable.
|Patch Set 1:

hwtest really doesn't matter in this case though :\
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2

lgtm. I'd prefer moving the payload generation into chroot, as deymo@ suggested in the bug.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

As you wish.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Commit-Queue+2

for a test CQ run
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

This will probably only be tested in production (on canaries) :)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

I prefer the earlier version with the duplicate code because the newer version (implicitly) makes assumptions about the exception type.
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2:

(4 comments)
|Patch Set 2:

Would it make sense to store the information in metadata.json?
|Patch Set 3: Code-Review+2
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2

(2 comments)

LGTM with one question. Has it ever happened that &quot;board N/A&quot; was caused by misconfiguration (wrong label, etc)?

I am thinking about the possibility that, e.g., lab doesn't have any lumpy because all lumpy duts were suddenly labeled wrongly due to a mistake/accident. In this case, run_suite would think that lumpy hasn't been setup yet, while in fact, we should always have lumpy available. If the chance of this happening is slim, then just ignore me ;)
|Patch Set 3: Code-Review+2

I'm fine with new boards not being set up properly. I was just worried about the old boards :)

Thanks for picking up this!
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 2: -Code-Review Verified-1

You've already have a +2, so marking it not verified to make my point visible
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: -Code-Review
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Ping!
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Patch Set 3: Verified+1

Changed to BoardNotAvailable(failures_lib.TestLabFailure).

This is the only difference in this patch set.
|Patch Set 3:

(1 comment)
|Patch Set 3:

Thanks for reviewing. Chumping this to *not* fail the canaries (bad planning on my side without coordinating with Fang better).
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

It doesn't really matter whether this go in before or after the branch. I'll let the CL go through CQ at the normal pace.
|Patch Set 1:

+2 anyone?
|Patch Set 1: Commit-Queue+1

Thanks!
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Good catch!
|Patch Set 1:

I'm not the best person to review test_that changes. I assume Fang will step in for the review :)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1

David's working on updating binhost config for nyan_freon.
|Patch Set 1: Code-Review+2

Just to clarify, InvalidAccessKeyId could be a real error when GS credentials are not set up properly. In either case, retrying doesn't hurt.
|Patch Set 1: Code-Review+2
|Patch Set 5:

(4 comments)

Still reviewing the unit tests
|Patch Set 6: Code-Review+2
|Patch Set 6:

(2 comments)
|Patch Set 1: Code-Review+1

Test owners are &quot;encouraged&quot; to enable retry for any test run on CQ. There is a bug open for adding a presubmit check: https://code.google.com/p/chromium/issues/detail?id=389385

The main reason is that we want to reduce test flake on CQ. So far job-level test retry has helped significantly in this regard.

Your test, specifically, has failed only lumpy-paladin in a recent CQ run. https://uberchromegw.corp.google.com/i/chromeos/builders/lumpy%20paladin/builds/18090
I believe this is a flake and can be avoided by having retry enabled :)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Yes.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 5:

(2 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6: Code-Review+2

Assuming that beaglebone-release-group and beaglebone-paladin trybots passed.
|Patch Set 6:

(1 comment)
|Patch Set 2: Code-Review+2

I don't have permission to view the spreadsheet yet. We will need to update the deputy page for this too.

Thanks for creating the sheet!
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Running trybot to verify the change.
|Uploaded patch set 2.
|Patch Set 2:

It turns out that we have some master builders which don't have any slaves, and some themselves are the slaves. Added logic in the new patch to handle this. Passed lumpy-pre-flight-branch. PTAL again, Thanks!
|Patch Set 2:

Also running master-paladin and master-release to verify nothing has changed for them.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Passed lumpy-pre-flight-branch, master-release, master-paladin, and link-paladin.
|Patch Set 3:

Ping?
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

I think so. Run some trybots?

You could throttle the tree and +2 this CL to minimize the noise/damage during the weekend :)
|Patch Set 1: Code-Review+2

Don't really need to run the tryjobs. As long as veyron_pinky-paladin is stable (e.g. has been green for a while), it's safe the flip the flag.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

The bug has been there since Nov, but we'd never hit it until this morning ;)
|Patch Set 1: Commit-Queue+1

Thanks for reviewing! I wonder why `cros lint` failed to catch this :\
|Patch Set 1: Code-Review+2 Commit-Queue+1

I think you meant to mark Commit-Queue+1
|Patch Set 1: Code-Review+2

We might want to consider printing the links to the CLs on the CQ master build page. That's a separate bug though.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Verified using the chrome-bot credentials (to verify:1 this change). Minor change to skip path checking. Pulling forward the +2.
|Patch Set 2:

Chumping this as none of our builders use/test it.
|Patch Set 4: Code-Review+2

(1 comment)

Just a nit. The rest looks good to me.
|Patch Set 1: Code-Review+2
|Patch Set 1:

Shouldn't we add a comment here so that we'll remember adding it back for CIDB?
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Thanks for the quick review!
|Uploaded patch set 3.
|Patch Set 3:

This is the first draft. Suggestions are welcome. Basically I want all the configuration process to be documented by code. I'd be more than happy to add comments if anything is unclear.

I verified the commands separately, but need to do a more thorough end-to-end verification, which is blocked by https://code.google.com/p/chromium/issues/detail?id=422502
|Patch Set 3:

The configuration process were adapted from the following three scripts:
chrome os setup: https://chrome-internal.googlesource.com/chromeos/chromeos-admin/+/refs/heads/master/fabric/fabfile.py
chrome slave setup: https://uberchromegw.corp.google.com/viewvc/chrome-golo/trunk/services/slave/linux/setup.sh?view=markup
chrome infra puppet: https://chrome-internal.googlesource.com/infra/puppet/
|Uploaded patch set 4.
|Patch Set 4:

(19 comments)
|Patch Set 4:

I've already done all that (time zone settings and what not) in the base ubuntu image itself.
|Uploaded patch set 8.
|Patch Set 8: Verified+1

I want some feedback, so adding more people for review.
|Patch Set 8:

This is ready to review. The point of the CL is not to create a super user-friendly script nor does it aim to add a complete library for gcloud. Retries are also not added here, yet, as the script will be run by a human being for now.

Also, things are still quite fluid at this point, so I would like to check in some code first and adapt them quickly when necessary.
|Uploaded patch set 9.
|Patch Set 9: Verified+1

Ping!
|Uploaded patch set 10.
|Patch Set 9:

(1 comment)
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the comment. Inheriting the +2.
|Patch Set 1:

We are supposed to deprecate this script ... If no one is using it, I'd prefer deleting this :\
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Thanks!
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)

Fix the bug number.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Pulling forward the +2. Thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 5:

(6 comments)
|Patch Set 6: Code-Review+1

(1 comment)

with a nit
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+1

I reverted it locally, so running the script is not a problem for me. I'll let David decide if he wants to revert this.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

Thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

Thanks for fixing this!
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

I'm late to the party. LGTM :)
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Corrected the typo. Inheriting the +2s
|Patch Set 1:

(1 comment)
|Patch Set 1:

Most of the code in that function has individual knob (debug, dryrun) to not leaving any side effects.

IMHO, it's better that we can test all those code paths properly in a trybot, instead of skipping the function completely.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2

(2 comments)

with some nits
|Patch Set 1:

It already needs to be rebased ;)

Thanks for coming up with the idea and implementing it so fast!
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1

I agree this is better than the status quo.

Another question: if Pre-CQ is indeed very slow (&gt;3 hours), what's the point of keeping Pre-CQ running? CQ will get to all the CLs before Pre-CQ.
|Patch Set 5: Code-Review+2

(1 comment)

The code looks cleaner with the new handle :)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Commit message was updated
|Patch Set 3: Verified+1
|Patch Set 5: Commit message was updated
|Patch Set 5: Verified-1

Don't review this. I accidentally deleted the latest revision. will upload again.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 6:

(1 comment)
|Patch Set 7: Commit-Queue+1
|Patch Set 3:

A more high-level question: how do we count the patch handling time when a change has been picked up by CQ before being marked as re-queued?
|Patch Set 3:

(4 comments)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1

I've decided to add &quot;chromite&quot; into the list. PTAL. Thanks!
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 4: Verified+1

+2 anyone? :)
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

No functional change.
|Patch Set 1: Commit-Queue+1

(1 comment)
|Abandoned

CL:226283 has been merged.
|Patch Set 1:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the comments. Inheriting the +2. Thanks for reviewing!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1

Rebased.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit message was updated
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Gerrit is acting up and I can't access my original CL. Re-upload and carry over the +2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2
|Patch Set 3:

pre-cq-group has passed buildpackages. Chumping this to save the next canary run.
|Patch Set 1:

(1 comment)

To make sure I understand the purpose correctly: You want to update a device from a base image to a test image? How could you ssh into the base image with a test key (used by cros flash)?
|Patch Set 2: Code-Review+2

Cool. I'm sure a lot of devs would love your tool :)
|Patch Set 1: Code-Review+2
|Patch Set 5:

(7 comments)

I might look at the CL again later.
|Patch Set 13: Code-Review+1

(1 comment)

LGTM. Not +2 so that David can check the submission logic :)
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+2 Commit-Queue+1

Inheriting the +2.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the comment. Inheriting the +2.
|Patch Set 2: Code-Review+1

(4 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)

Leave it to beeps@ to +2.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)

Still reviewing
|Patch Set 2:

(3 comments)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 4:

(7 comments)
|Patch Set 5:

looking
|Patch Set 5: Code-Review+1

(2 comments)
|Patch Set 2:

(5 comments)
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

@Don, &quot;kicked_out&quot; and &quot;requeued&quot; do not have corresponding &quot;CL status&quot;. This means that the CL would still be considered &quot;inflight&quot; even though it had been kicked out.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2

CQ just failed with the same error. Time to land this CL?
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

Hopefully parallel pre-cq will relieve the load on the pre-cq bots.
|Patch Set 8: Commit message was updated
|Patch Set 8: Verified+1
|Uploaded patch set 9: Commit message was updated.
|Patch Set 8:

(3 comments)
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 8:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

Uh...I've also did stuff like this for recording chrome version. It didn't occur to me at all when I wrote the previous CL :(
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Also ran *-paladin and *-release tryjobs to confirm status is recorded (or shown in the log.)
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Fix the printing. Inheriting +2.
|Patch Set 1: Code-Review+2
|Patch Set 1:

I'm fixing this in CL:227991, but I guess your revert will go through first.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

Thanks for doing this! :D
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

The flag is rarely set to false (only for LATEST_* and the uploaded list to my knowledge), so I removed it. But this is not really the focus of the CL, I will restore it in the next patch :)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Added a unit test for BuildPackagesStages. For triage_lib, I'd like to wait until the code settles down a little bit, which should be soon.

Inheriting the +2.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the nit. Inheriting.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

Doesn't cause build image/packages failurs.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

(14 comments)
|Uploaded patch set 4.
|Patch Set 4:

Added unit tests in completion_stages_unittest and triage_lib_unittest. PTAL.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

@vapier, your point is valid, but these tests don't seem to test the cidb usage much.

Aviv, you probably wrote most of them. Do you have any suggestions/objections?
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

This is what we agreed to do in the last performance meeting :)
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Verified+1

Chumping this so that we can get correct stats.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

(1 comment)

with one nit.
|Patch Set 3: -Code-Review

oops....David is right.
|Uploaded patch set 3.
|Patch Set 3:

Not really tested yet, but would like some early feedback.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Seems to be working. The tryjob was able to rule out a change one package in chromiumos-overlay that was irrelevant.

Ready for reviews.
|Patch Set 4:

PTAL. Thanks!
|Patch Set 4:

Ping! PTAL.
|Patch Set 4:

(4 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Verified+1

Fixed the indentation.
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 1: Code-Review+1

(5 comments)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2:

Remote trybot patches your change after cleanup ;)
|Patch Set 2:

I don't think there's any unittests for CleanUpStage...
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Ping! PTAL.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Commit message was updated
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

I don't know which gsutil version is currently in use in the lab. You may want to check   whether the error messages are the same for that version...
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

forgot my +2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 4: Reverted

This patchset was reverted in change: Ifd099b7aaffb51f0d90c07eb8123a75b5d5103a8
|Patch Set 3: Reverted

This patchset was reverted in change: I178714a7a40e0469b3288d1d3d546e8ba88a64a8
|Patch Set 1: Verified-1

Let's hold on to this CL for a while longer.
arm-generic-paladin became very slow since build 6. The machine may be in a bad state.
https://uberchromegw.corp.google.com/i/chromiumos/builders/arm-generic%20paladin/builds/6
https://uberchromegw.corp.google.com/i/chromiumos/builders/arm-generic%20paladin/builds/7
|Patch Set 1: -Verified

Unblock this CL since arm-generic-paladin has been performing normally over the weekend.
|Patch Set 2: Code-Review+2

Time to land this CL? :)
|Patch Set 1:

(1 comment)

I'll miss the times when Pre-CQ/CQ removed the CQ+1 on my draft CLs...I always forget to publish them :)
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

The problem with this CL is that we want to set the timeout only for the ToT canary builds. Branched builders may take longer as they generally have longer timeouts; trybots could also be slower if hwtest is requested.
  - You should check whether the manifest branch is master
  - You should check whether this is running as a trybot.
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Verified-1

This CL is suspected of failing the beaglebone-paladin builder

https://uberchromegw.corp.google.com/i/chromeos/builders/beaglebone%20paladin/builds/4307/steps/BuildImage/logs/stdio

chromeos-base-0-r125:  * A shell was specified but it does not exist !
chromeos-base-0-r125:  * ERROR: chromeos-base/chromeos-base-0-r125::chromiumos failed (setup phase):
chromeos-base-0-r125:  *   /bin/bash does not exist in /mnt/host/source/src/build/images/beaglebone/R42-6686.0.0-rc1/rootfs/
|Removed the following votes:

* Verified-1 by Yu-Ju Hong &lt;yjhong@chromium.org&gt;

|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

This is not tested by CQ yet. Chumping it.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the indentation. Inheriting the +2.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

I think there is value of running a paladin trybot and expect VMTests to be run (without having to manually override the config, or look through paladin configs to find one that fits). What's broken here is that we cannot tell whether the config is &quot;not capable of running vmtests&quot; or just &quot;not running vmtests&quot;, and the fact that we need to customize paladin configs to optimize CQ runtime.

It's good to have the code in place for now until we find a better solution that's easily understood by developers :)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

I don't think you can just import chromite from here. First, it's not in the sys.path. Second, the chromite checkout may not be on the machine at all.
|Patch Set 2:

(4 comments)

I think for the long term, we would like devserver to not create root-owned directory in the first place (e.g. see chromite.lib.osutils.SafeMakedirsNonRoot()). Chown the directory afterwards should only be a short-term fix that helps with the transition. The comment in your code could make this clear with a TODO and a bug number.
|Patch Set 2:

(2 comments)

The CL is good as long as you've checked all the call sites and make sure this (chown) is an acceptable behavior. Some caller may expect an exception to be raised in this case. You may also create a flag to turn on/off the chown behavior.
|Patch Set 3: Code-Review+2
|Patch Set 2:

I thought we still want bvt to run before paygen?
|Patch Set 2: Code-Review+2

Thanks for fixing this!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified-1

testing precq.
|Abandoned
|Patch Set 3: Code-Review+2
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

The group config might still be too much for the GCE bots to handle right now. I'll add duck-pre-cq as a separate config.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Trybot-Ready+1
|Patch Set 4:

Discussed with David. This CL is currently blocked by chroimum:439595. We need to reduce the email spam before enabling multiple configs.
|Patch Set 4: Code-Review+2 Commit-Queue+1

This should be ready to land. Inheriting the +2.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 8.
|Patch Set 8:

The new patch split pre-cq-group into 4 configs to err on the safe side. I tested all three configs on GCE bots and they ran ok. I am not sure if we have enough capacity to handle this. We have 25 GCE bots as of now. I am waiting for the GCE team to increase the quota so that we can have 50 bots. David, what do you think?

The name is still a pain. Suggestions are welcome.

To land this change, we will need to restart the waterfall so that buildbot knows which pre-cq config does not run VMTest.
|Uploaded patch set 10.
|Patch Set 10: Verified+1

PTAL.

There's no significant performance difference whether  build_packages_in_background is set or not.
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Verified-1

Don't review yet. I have to fix a thing or two.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Patch Set 5: Code-Review+2 Commit-Queue+1

Thanks for reviewing
|Patch Set 1: Code-Review+2

(2 comments)

Some nits.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1:

This has gone through a CQ run and only one slave failed with unrelated failure. Chumping this to prevent pre-cq failures.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(7 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5: Trybot-Ready+1
|Patch Set 5: Code-Review+2 Commit-Queue+1

Modified BuildStatus to use BuildStatuses. Ran integration test and passed. Inheriting the +2
|Patch Set 5:

Uh...my CL is working as no pre-cq builder has commented here. The pre-cq-group build is here:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/pre-cq-group/builds/38820
|Patch Set 1: Code-Review+2
|Patch Set 1:

If you haven't already done so, you might as well launch more trybots to test this overnight :)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

The CL is not the cleanest because the way we (mis-)use the pre_cq and the is_master flags. I could add another flag, but it seems too much.
|Patch Set 1: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: -Trybot-Ready

There doesn't seem to be a clean solution without introducing yet another CL status for pre-cq submittable changes. Thoughts?
|Patch Set 1:

@Don, It's possible that CQ could still pick up the CL during the window...
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)

Just making sure we are on the same page.

If we add a PRE_CQ_FULLY_VERIFIED state, all CLs that passed would enter this state first. Then, if they can be submitted, they should be submitted. Otherwise, they should be marked passed.

This is already done in the existing logic, and we still don't need the READY_TO_SUBMIT state. That means I should scrape this patch and simply add the new state. Does that sound correct? :)
|Uploaded patch set 3.
|Patch Set 3:

The patch doesn't change the existing logic, so it's safer(?)
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Added unittest to make sure the actions are not repeatedly recorded.
|Patch Set 3:

(2 comments)
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Addressed the comments. Inheriting the +2. Thanks for all the suggestions!
|Patch Set 5:

No....how can i migrate it?
|Patch Set 5:

migration is done
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting the +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

not whitelisted yet for 32-cores :)
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

TBR. Chumping this as it is not tested by CQ yet.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Verified-1

This CL is suspected of failing veyron_pinky-paladin:
https://uberchromegw.corp.google.com/i/chromeos/builders/veyron_pinky%20paladin/builds/1432/steps/BuildPackages/logs/stdio

There were multiple error messages such as &quot;switch -mcpu=cortex-a12 conflicts with -march=armv7-a switch [-Werror]&quot;
|Patch Set 8: Verified-1

This CL failed at the nyan-paladin builder:

https://uberchromegw.corp.google.com/i/chromeos/builders/nyan%20paladin/builds/3728/steps/BuildPackages/logs/stdio
depthcharge-0.0.1-r985: src/board/nyan/board.c:156:17: error: too many arguments to function 'new_spi_flash'
depthcharge-0.0.1-r985:   flash_set_ops(&amp;new_spi_flash(&amp;spi4-&gt;ops, 0x400000)-&gt;ops);
depthcharge-0.0.1-r985:                  ^
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Abandoned

In favor of CL:238856
|Patch Set 1:

Do we no longer need this workaround? I don't see any other CLs posted on the bug.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Verified+1

Rebased. I am going to chump this to avoid another conflict.
|Patch Set 3:

&quot;important&quot; is a knob identifying important slaves to wait for before the master declares the run has completed. Given that we don't have a true &quot;master&quot; in release branches, whether the configs are marked important or not is not meaningful at all. (or you could say all release builders should be important by default)
|Patch Set 3:

I may have mistaken what this CL was for. I assumed this was meant for the release branch/waterfall only. If you meant to change the canary (ToT) release groups, then &quot;important&quot; is meaningful.
|Patch Set 1: Code-Review+2

Would it help to describe what might have gone wrong in the exception? I am trying to think of something that could help the sheriffs... Ignore me if this does not make sense to you.
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3:

(14 comments)
|Patch Set 4: Code-Review+2

(5 comments)

w/ some nits
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2

This looks harmless to me.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

How about I make another flag (e.g. --testing) for this?
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Every precq config would send an individual alert. That might be too much sometimes, but this is a good start anyway
|not sure if a relative path here is a good idea.... would need to look more
|same here...
|move patches to github
|probably do something like:

Add initial acorn overlay

Acorn is an overlay for Armada 385 etc etc
|year nit
|i doubt you mean a7
|not moose
|add the embedded profile here
|year nit
|don't think we need to add the TODO in the commit message- let's actually strip out the u-boot part since it's not working and we can land the remaining initial overlay support
|i think you want to an acorn-u-boot or something to indicate it's marvell's own u-boot
|delete extra white space
|do you need this here and make.conf both?
|no period
|please have at least a build_packages/build_image test case
|it seems odd to list an empty RDEPEND here, so either add an empty DEPEND also or just remove this?
|maybe provide something more specific on this? orm aybe it's ok...
|fix me so i build!
|split fw into a different cl than wifi
|nit on year and no (c)
|4
|do you really need to manually specify this or is it brought it elsewhere
|recommend hosting on github etc
|please have some versioning here
|do you really need to do this manual init? we already use 8897 for other projects
|can you use the modules in our tree or are these binaries somehow different
|can you add gus here as well?
|oh wait... does this need to be r3 - ie see ftp://ftp.denx.de/pub/u-boot has 2015.01-r3 but not r4
|legacy_keyboard shouldn't be needed
|remove (c) and year nit (comments here apply to other ebuilds as well)
|you can use EAPI=4
|newer have BSD-Google
|technically add -*
|why do we need this for sama5?
|fwiw someone did post this - http://linux-serial.vger.kernel.narkive.com/4vblXZOG/patch-serial-atmel-add-missing-dmaengine-header
|we don't really need this file as part of the fw ebuild
|year nit
|i'm not sure i'm a fan of the name of this ebuild - since typically chromeos-firmware-BOARD has a fairly specific meaning and this is somewhat temporary
|do we intend to build this from source somewhere else and you just want to have a 'known good' version here?
|nit
|no c, and 2015
|since this needs to be manually rev bumped, you can start it with a dummy -r1 symlink
|probably you want a license on this file
|do you need either the EGIT_BRANCH or EGIT_COMMIT if it's the default?
|remove blacklist
|use a valid portage license here
|where are you using cros_host
|handle failure case
|is this really the tuning we want? or should we have a bug to modify later?
|don't think you want either legacy_keyboard or legacy_power_button
|are we sure we need the -gtalk part?
|don't end with &quot;.&quot;
|add to signer scripts
|can you file a bug to migrate mtk to split configs?
|this is a fake comment - please ignore
|nit: drop (c) in the copyright
|does this conflict with the BSD license below?
|same nit here in copyright line
|same nit here
|sane nit here
|i'd be ok with this in alphabetical
|can you elaborate on why this is needed?
|same nit
|same nit
|same nits
|same nits
|can you explain why you need this?
|add copyright line
|do you really want a7 tuning?
|please do this alphabetically
also, did you really mean cros_ec here?
|can you comment why you need all of these?
|extra line
|Done
|Done
|Done
|So some very loose brainstorming on this... i2c-dev is not inserted during init on ARM currently whereas it seems to be on x86 (as it is needed for reading EDID info on x86 and due to hw differences not on ARM). Since mosys needs i2c to read the ec firmware version, I didn't think the (potentially) duplicate attempt of inserting the module was too costly and makes the script platform agnostic. If future x86 platforms can query EDID without i2c, it could later be removed from its init. I'm open to other suggestions on where/how to include the i2c driver.
|Thanks for the corrections. micahc showed me &quot;equery b&quot; so running through the script also shows a dependency on coreutils. Should this also be explicitly added or is this otherwise implied?
|In this system, it looks like awk is provided by mawk. Is there a more generic way to request awk?
equery-tegra2_kaen b /build/tegra2_kaen/usr/bin/awk 
 * Searching for /build/tegra2_kaen/usr/bin/awk ... 
sys-apps/mawk-1.3.3_p20090820-r1 (/build/tegra2_kaen/usr/bin/awk -&gt; mawk)
sys-apps/mawk-1.3.3_p20090820-r1 (/build/tegra2_kaen/usr/bin/mawk)
|lsmod is executed by virtue of its mention in etc/sys_log_utils.sysinfo.lst
|I agree that without naming these dependencies explicitly - it should *usually* work. However, what guarantee do we have that these will always exist? Can you please clarify what @system is/does? Are there any set of ebuilds which are guaranteed to be in the root fs without being explicitly named here?
|No, it is for a set of devices that share the same physical HW (ie we can differentiate between devices with a particular modem)
|Should the kaen specific stuffs be in the fdt instead of here?
|Since we're dependent upon this gpio being set (else other failures may result) shouldn't we catch on failure and at least print a warning?
|Did we want to somehow indicate these are symlinks?
|white space?
|Can we file a bug as a tracker (with some history) as a reminder to remove this later?
|export EC_BOARD=$(usev bds &#124;&#124; get_current_board_with_variant)

if use snow; then
EC_BOARD=snow
fi
|alphabetical?
|is it safe to export BOARD? vs using export EC_BOARD...
|Add crosbug.com/p/10377
|if use snow; then
|Can someone clarify how we decided on 110 here?
|this doesn't match the style of the immediately fdt stuffs...
|Doh... I set EAPI=2 to avoid having to set S=${WORKDIR}
|Since we carry Google-TOS in chromiumos overlay, is it ok to use that string for LICENSE?
|either mali-drivers or mali-drivers-bin should be used - maybe do USE=mali_bins? (see opengles virtual)
|Ok got it
|Where are more kosher places to keep extract-samsung-3354.sh  (I was hoping somewhere in the RFS but maybe that's wrong..)
|2 problems come to mind with this:
1) how do users uninstall the mali-drivers-bin
2) should there be a checksum to verify that libmali.so.0.0.39 is actually the latest version?
|Set ACCELERATED_FLAGS= before the first if, and then only change them if armv7l and not ricochet. See other examples of this in this file.
|This is a temporary workaround so I'd prefer to just have a &quot;if not ricochet then set ACCELERATED_FLAGS... we should open a new bug to track its removal.
|Delete this file - you only need to edit the 9999
|can we set +dri in the IUSE options?
|please keep an alphabetical ordering here

If these are normally defaulted to off (which is my current understanding), then use -dri -xlib-glx, and then add them to the default use flags in the ricochet overlay make.conf
|seems awkard
|do we need to be more specific about which rtc? pmic/coin cell vs exynos?
|Take a look at /sys/kernel/debug/suspend_stats
|comment now seems wonky but CROS_WORKON_COMMIT looks like it can point to branches instead of commits fine
|most other tests import os
|nit on naming - seems awkward to have max_temp_delta and max_temp, maybe delta_temp_max, min_temp, max_temp?
|this seems fairly narrow for a default (ie you're expecting all sensors to be within 5 degrees of one another)
|this seems very high as a default - the CPU shuts off way before the thermistors would get there
|do you really need 2 loops for this?
|can we truncate
|maybe something more descriptive here
|maybe add a comment to be very clear what we're measuring here
|Also the CL this seems to be based on included some other temperature functions. Did you want to actually patch in the original CL in its entirety? See 181c6172
|don't think you need to check whether it exists or not...
|seems awkward to say 'if you don't specify a service name, we only test wifi and we check for any AP - probably want to say if you select wifi and don't give a service list, then search for any
|reuse FlimGetServiceProperty?
|year nit
|alphabetical
|more ordering niceness needed
|see wireless.py for examples on setting up flimflam properties
|Maybe change this to something like:
Add SetChargerState to pit board
|Maybe: SetChargeState: Not-functional. See crosbug.com/p/####
|nit on year
|non-verified
|add a comment about what your expected bootargs are to begin with
|maybe standardize all user visible strings to uppercase USB
|fixed
|moved break into if so it falls through to default/&quot;Mode not supported&quot; which seems valid
|similarly in this case, ret starts as EINVAL which drops through so it seems reasonable if you don't have a proximity sensor
|Removed &quot;has_test_register&quot; altogether - the datasheet doesn't indicate it has one but it doesn't seem problematic either
|Done
|done
|still thinking about this one...
|if we undefine this - can we still use the same *var.bin bl1? i assume not... and vice versa, if this is defined but someone tries to use the old bl1 binary, i assume it also immediately dies...
|copy of https://gerrit.chromium.org/gerrit/#/c/61827/2/buildbot/cbuildbot_config.py
|while you're at it, should you just depend on having flashrom e5166f4 (so no one sees the i2c error) vs your current hash
ba0827
|this seems ok overally if you're always using omaha - but you may want to edit run_firmware_update to have a similar check in case someone tries to use a usb key (do they do this in RMA?)
|seems strange you need sudo here
|code check seems like crossystem gets platform_family on x86 via sysfs entry so this should work regardless of the FW on the device to begin with but please confirm with a nv-image
|do you plan on every bumping the RO FW for Ivybridge? If yes, then consider doing a greater than 54 (ie pull out the major number 2685 and minor 54 first)
|it would be nice to realphabetize cardhu too :)
|i think it works... it's just the general eclass convention seems to prefer it with the = omitted
|is the convention &quot;local odmdata&quot; (just did a quick search in the most popular eclass like kernel, firmware, etc)
|nit year
|Do we want to call this Intel-xxx to match the other naming convention?
|can we fix some typos in the commit message?
|change this to:
BUG=chrome-os-partner:22530
|change this to:
TEST=The driver can load...
|instead of using tarball of this, can we just specify a branch of u-boot-next?
|do you need a distclean or any additional build flags?
|do you want the bin, elf, etc?
|max frequency should be listed once at 4MHz or 25MHz?
|add  0x040a002b      /* \ */
|yes have them both to support UK keyboards
|why do we need the retry count?
|why is this 100? seems excessive
|you probably also need something for the trackpad bootloader (take a look at the pit dtsi)
|Kees - can you elaborate how to do this? Basically I'm taking a very old factory branch (R22 era) and updating it to a ToT kernel to pickup some extra features needed for the VE SKU
|doh
|agreed that sensor will always be some path (though possibly invalid) and certainly not empty
|don't think so (as in my VE doesn't spew any errors)
|not sure if this is nitting but pi is a variant of peach (which pit is also a variant of but pi isn't specifically related to pit)
|is this 8?
|I think it's better if we call boards by &quot;revision&quot; instead of by build name (and then match these names to what we're using in uboot etc)
|remove whitespace
|Note that this is for this branch only
|no spaces: 
BUG =chrome-os-partner:24242
TEST=Run gooftool finalize on Snow
|oh good point!
|bahh... was being a bit lazy about this since the general convention is most checksums no longer match but i've done it correctly and here are vague instructions if you need to do it in the future:
~/trunk/src/platform/chromeos-hwid
cp some v2 HWID (like v2/DAISY) to v2/SKATE
../factory/bin/hwid_tool hwid_list -b SKATE
SKATE TEST A-A 0839
|it's permanent enough for now i think...
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|i just copy/paste...
|Done
|didn't see the spacing nit
|This doesn't seem right...

Memory is selected from GPD2 only (GPD0 and GPD1 are for revision)
|thanks, Alim - let's go with this
|shouldn't 0 = micron, 1 =  hynix, 2 = elpida?
|this needs to be on the skate branch and then use the skate dts
|we can set this in exynos5250-skate.dts
|for each type of board you have, please confirm that the board revision and manuf data are as expected
|theoretically these should be alphabetical
|why remote spring here when you keep spring below
|set this in the skate dts file - don't touch daisy or spring
|it should be elan
|small nit - can you change this to something like:
big: Add ectool discharge command
or Add ectool discharge command to Big
|can you confirm that ectool chargecontrol for each option still works (normal, idle, discharge) and verify the battery is discharging via ec console battery command? (see the tests used when https://gerrit.chromium.org/gerrit/60689 was added)
|bug # please?
|where is this actually used?
|can you file a bug with the release notes / diff from previous version?
|comment is wrong now
|is all of this right for this elpida part?
|is all of this right for this part?
|Neil, yes, I get that you emerge ec-utils, but I want to know why no other project with variants does use this. Is there a particular tool you get from doing this that you don't get from regular builds or needs to be built for big specifically?
|One other qq on this... I don't see any of the other boards from the chromeos-ec ebuild listed here which makes me think that others aren't using it. Can you elaborate on why you need this but other boards don't?
|nyan_blaze doesn't exist afaik... don't include it here
|probably this line is redundant
|please file a bug on this and reference it here
|please make sure your ebuild change lands first

also your test should also include flashing and verifying on a live system
|please verify nyan_blaze works fine
|please pad these (see big dts)
|elan right?
|shouldn't these map to _real_ memory types? see the board id spreadsheet...
|I was semi-assuming that you'd already have the BCT timings for the boards already... do you have an ETA?
|add a bug # and then carry over the lgtm
|can you please file a bug (and attach relevant datasheets for the batteries there)?
|i see.. in the table we have a &quot;decimal&quot; = &quot;hex&quot; = &quot;base 3&quot; so I'm missing how when we decode things we don't end up with the same counting method...
|why does REV3 = 4?
|yeah ok... now I get it... lgtm
|no need to list a branch for kernel changes
|this file should be a symlink to the chromeos-bsp-rksdk-0.0.1.ebuild
|fix year to 2014
|in general, we have a platform name (instead of referring to it as rksdk... ie names like nyan, daisy, rambi, etc)... I'm open to ideas for this (obviously the entire overlay should be called by this name)
|year nit
|please add wifi in a separate CL - i'd probably add things from:
1) basic overlay files (just the minimum to do setup_board)
2) add an overlay per feature, like add one for kernel
3) add another CL for things like wifi, etc
|are you allowed to redistribute this FW?
|why do we need this vs using the generic chromeos-login ebuild?
|why do you need to remove the XAUTH_FILE?
|again, why do we need this vs using the default xorg-conf (if we do need modifications to xorg-conf, you should submit it there - noting that you can't break other platforms)
|year nit
|did you fixup your kernel to use splitconfigs? if yes, we should probably use a rockchip specific splitconfig
|not sure you want exynos here
|the r1 should be symlinked to the non-r version
|do you need this?
|wwhy do we need this here vs modifying the wpa_supplicant ebuild?
|i believe we need to blacklist this kernel since we won't be able to automatically uprev it
|year nit
|year nit
|you shouldn't rdepend on this here (this should be for the firmware ebuild itself - ie chromeos-firmware-rksdk (or whatever board name you want) and wifi fw should be depended on in the chromeos-bsp-rksdk (or whatever your overlay name is)
|year nit and this should be symlinked
|we might want to call the mali-drivers-bin something else to indicate it's different from mali-drivers-bin used for exynos5250
|normally we have this in make.conf (but presumably we want to get rid of it also...)
|i might preface this with the ebuild so it's easier to read in the log: xorg-conf: add rk32.conf support
|please file a bug
|you probably want to make sure 198833 lands first or add an explicit CQDEPEND here
|typo in exynos
|can you file a bug at crosbug.com/p to track the initial work
|rebase on top of https://chromium-review.googlesource.com/#/c/200543/ (or add this dependency in)
|this file should be symlinked to the 0.0.1.ebuild
|you have neon listed twice

since you will use your own kernel i don't think you need the kernel-3_14 flag

no need to add device_tree here either

please make sure all use flags are in alphabetical order
|just delete these unused lines
|don't need this file yet
|copy arm-generic for this
|i'd consider naming this just moose-kernel-3.10
|symlink this file to the .ebuild
|separate this out to a new CL
|symlink
|can we rename this to be more specific (ie which wifi)
|don't inherit cros-workon for this
|I still am not a fan of the ebuild file name... I'd rather see &quot;AP6335-wifi-bin-0.0.1&quot;
|can you make this description more detailed?
|should you use ${PVR} instead of ${PV}-${PR}
|are you sure this is correct?
|why changing S from WORKDIR?
|why is this not just WORKDIR
|why are you changing S from ${WORKDIR}?
|are we sure this list is correct? as a guess we wouldn't be different from the overlay-daisy mali-drivers-bin list
|why -r2 instead of -r1?
|probably you want your test to include something about verifying the firmware shows up in the RFS
|add -* to KEYWORDS
|do we have 4G?
|did you really mean kernel-3_14 if you're using a separate msm kernel?
|doh - will fix
|one quick naming q - normally we've had variants just as the variant name - ie chromeos-bsp-pit - were we intentionally changing this?
|ok will do!
|do we want to keep pinky around should our fw for some reason barf on jerry? (or we've installed the wrong fw...)
|i think the latest trend is just to put garbage here...
|extra space
|sorry upload probelm but yes
|why does this fail?
|same for this one?
|please follow the naming convention for dts changes
|shouldn't this be in the jerry dts instead?
|small nit is that (c) can be dropped
|this should be C, 6
|alphabetical?
|did you really need this?
|if we can immediately turn this back on then it's ok - we probably want mickey as a tree closer seeing that we're fsi-ing momentarily
|if you're offering then gladly accepted... we'd ideally like to get these builders up this week if we can
|Patch Set 1: Code-Review+2

lgtm

please don't forget changes like:
https://chromium-review.googlesource.com/254150
https://chromium-review.googlesource.com/258672
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(6 comments)
|Patch Set 4: Code-Review-1

(1 comment)

update kernel hash please
|Patch Set 7:

(4 comments)

a few small nits...

Benjamin, can you clean up and repost?
|Patch Set 8: Code-Review-1

can you actually build_image with this CL? i suspect you are still missing a few of the &quot;accounts&quot; files (see the atmel sam5d3 overlay for details)
|Patch Set 9:

(4 comments)
|Patch Set 12:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review-1

(8 comments)
|Patch Set 2:

can we please cherry pick with -x (or with the gerrit ui) to get a clear message of the original review URL/etc
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Verified+1

marking as verified based on bug comments
|Patch Set 1: Code-Review+2

tbroch - i updated go/cros-names
|Patch Set 4: Code-Review-1

did we lose something in moving around patches? this looks like just a make.conf change
|Patch Set 5: Code-Review-1

this should cq-depend on the mesa-img ebuild at least - where is it btw?
|Patch Set 7:

how do we actually pick out the mesa-img ebuild vs original mesa ebuild? i didn't see a cq-depend cl for this
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Verified+1
|Patch Set 1: Code-Review-1

Doug said to punt on 41 in the bug
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

still not merge approved on bug yet
|Patch Set 1:

please merge request to 42 on the bug - once done,  +2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

needs merge request on bug
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review
|Patch Set 1: Code-Review-1

don't need bcm in 41
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

doug says to punt on 41 in bug
|Patch Set 1:

oops wrong review for that comment - but not approved yet for 42
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

needs another merge request in bug
|Patch Set 1:

approved on bug - i'll let doug +2
|Patch Set 1: Code-Review-1

no merge request for 41 on bug
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4:

one slight difficulty with public gerrit branches is that very few people can actually create/push new ones which makes github a bit easier for a temporary workaround...
|Patch Set 1:

(5 comments)

a few small nits but otherwise lgtm
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3:

ah yes your ebuild uses &quot;P&quot; and not &quot;PVR&quot; so you don't pick up the r version when determining which version to download - so what you have is fine - but normally better to start the initial ebuild with -r1
|Patch Set 1:

please add to the manifest-internal repo as well
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

please fixup the commit message - ie oak will use llama ec so even though llama isn't a supported overlay we will use this ec etc etc - and file a bug with more history since this is kind of an odd thing to do and folks may want background
|Patch Set 2: Code-Review+2
|Patch Set 4:

(4 comments)
|Patch Set 4: Code-Review+2

ok after reviewing your other CL this is tolerable with the current name (though please cleanup the nit)

also, do put an appropriate bug # here
|Patch Set 6: Code-Review-1

(1 comment)
|Patch Set 7: Code-Review+2
|Patch Set 4:

(2 comments)

i assume this is a direct copy of the original ebuilds 

can you create a bug for each of these CLs - since we'll want to remove the dummy versions later
|Patch Set 4: Code-Review+2

lgtm after the small cleanup
|Patch Set 6: Code-Review+2

you can drop the (c) in the copyright but otherwise lgtm
|Patch Set 7: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 1:

(6 comments)
|Patch Set 4:

(3 comments)

please also open a bug to add freon later as a tracked item
|Patch Set 4: Code-Review-1
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review-1

why do we need this vs working with adhd/ucm sources directly?
|Patch Set 6: Code-Review-1

we probably don't need to land this so feel free to abandon
|Patch Set 1: Code-Review+2
|Patch Set 5: Code-Review-1

we can probably abandon this
|Patch Set 2: Code-Review+2 Verified-1

lgtm but update the github sources to something that builds first....
|Patch Set 9: Code-Review-1

i suspect you can abandon this
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

sorry mike - thanks!
|Patch Set 1: Code-Review+2

(2 comments)

lgtm if you fix the small nit
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)

lgtm assuming that the test works
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

arm stuffs look right too
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review-1

(6 comments)
|Patch Set 2:

(11 comments)

a few nits with the copyright and license agreements... otherwise this seems fine for now - though I'd like to still understand the serial console part
|Patch Set 1:

small nit, i'd prefer the commit message to mention cros-board.eclass
|Abandoned
|Abandoned
|Abandoned
|Abandoned
|Abandoned
|Abandoned
|Abandoned
|Abandoned
|Patch Set 2:

please cherry pick from tot with -x arg so that we see where it was originally reviewed
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

yes, though i'm surprised it would build gus/jaq without it in the factory branch
|Patch Set 1:

i'm pretty sure it does...
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

Corresponding userfeedback package ebuild modification at http://gerrit.chromium.org/gerrit/#change,6134. Also note that http://gerrit.chromium.org/gerrit/#change,6093 was abandoned and that upstart logging.conf has been moved to the userfeedback package as conf/firmware-version.conf.
|Patch Set 2:

mdhayter's concern was that mosys would only correctly run a certain time after boot but dhendrix commented that this has been fixed.

Also, the logs are still generated once during a boot, but we are only moving their generation from the session_manager_setup.sh to run after system-services are started.

Patch set 2 attempts to address jrbarnette's previously mentioned feedback.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified

Manually confirmed ec and bios info displayed in chrome://system
|Change has been successfully cherry-picked as cf49c8866f1c0b3ebdd256890ba5c7b41c95dc02.
|Patch Set 1: Abandoned

Adding upstart job to userfeedback package instead of init. See http://gerrit.chromium.org/gerrit/#change,6093
|Patch Set 1:

Note that http://gerrit.chromium.org/gerrit/#change,6095 was abandoned as the upstart job was moved from the chromeos-init package to the userfeedback package, thus this change depends on http://gerrit.chromium.org/gerrit/#change,6134 (userfeedback ebuild change) and http://gerrit.chromium.org/gerrit/#change,6093 (addition of logging scripts and upstart job conf to userfeedback).
|Patch Set 1: Verified

Manually confirmed ec and bios info shown in chrome://system
|Change has been successfully cherry-picked as c59e8d69262d6d32c4ff4c9fed18b9e7e5f3e715.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified

Manually confirmed dependencies via equery
|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved

Pushing from LGTM on patch set 5.
|Change has been successfully cherry-picked as 8529c3c3772d5e21cbd882101039805cae7671f1.
|Patch Set 1: (3 inline comments)

Comments inline.
|Uploaded patch set 2.
|Patch Set 2:

Thanks for the suggestions - removed 4 dependencies assumed present on all systems
|Patch Set 2: Verified

Verified via equery depgraph.
|Change has been successfully cherry-picked as 937e54bd10398a2bc6045fc7efe2c0a9585e43f2.
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Change has been successfully cherry-picked as c072de5ecc8b70db14c0d452690d8b0e76b88d39.
|Patch Set 1: Abandoned

Duplicate
|Patch Set 1:

For reference, the corresponding kernel change is at http://gerrit.chromium.org/gerrit/#change,8296. 

Note that we have a hard dependency on the vmalloc bootarg and kernel - thus trying to use an old u-boot (with vmalloc= not set which defaults to 128MB) will only allow a gfx carveout of 150MB, and a kernel attempting a greater carveout will crash without any serial output as the memory reserve occurs very early.
|Uploaded patch set 2.
|Patch Set 2:

Added changes for asymptote in tegra2-asymptote.dts.

We will need to require a firmware update prior to kernel update. Suggestions/comments on this are most welcome.
|Patch Set 2:

I will verify setting the bootargs in the kernel dts eliminates the need for the vmalloc= portion of this patch (not currently done for kaen). We would still need to adjust the framebuffer address, but I wouldn't expect this to cause a crash on u-boot/kernel mismatch.
|Uploaded patch set 3.
|Patch Set 3:

Thanks for the suggestions folks. It looks like we can remove the u-boot/kernel bootarg dependency (where we'd risk bricking boards) by adding the necessary vmalloc bootarg to the build_kernel_image script instead of the uboot config. Thus even with old firmware, the updated kernel would come with the new bootargs (via dependency of the kernel on the newer script).
|Patch Set 3:

Corresponding gerrits:
Bootarg addition in build_kernel_image.sh:
http://gerrit.chromium.org/gerrit/#change,8373
Kernel ebuild to require newer build_kernel_image.sh:
http://gerrit.chromium.org/gerrit/#change,8389
Kernel carveout: http://gerrit.chromium.org/gerrit/#change,8296

I'll bulk add reviewers of this CL to the above for additional comments on changing the carveout.
|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready

+everything based on patchset 3 &amp; rebase.
|Change has been successfully cherry-picked as 4050fa94797202fa69f640212ac16d4affcd07aa.
|Patch Set 1: I would prefer that you didn't submit this

Posted for reference to http://gerrit.chromium.org/gerrit/#change,8293
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Rebased &amp; +everything due to review of patchset 1.
|Change has been successfully cherry-picked as 6d26a89b56cd949b67f7e5cda7528eca529422e0.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

rebased &amp; +everything from patchset 1 review
|Patch Set 1: Abandoned

Thanks for the insights Olof and David
|Uploaded patch set 2.
|Patch Set 2:

Rebased - slight modifications needed due to http://gerrit.chromium.org/gerrit/#change,9715,patchset=3.

Submitted on firmware-881-u-boot-v1 previously - http://gerrit.chromium.org/gerrit/#change,9795
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Change has been successfully cherry-picked as 7e2f6e6131da700465576911d45ad573e4d3e179.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as d06ae017d8c6bb1b483ab05790f280a34d35da44.
|Patch Set 1: Verified; Looks good to me, but someone else must approve

LGTM, tested with https://gerrit-int.chromium.org/#change,6975,patchset=2 and works great
|Patch Set 1: Verified; Looks good to me, approved; Ready

Pushing based on review at ToT
|Change has been successfully cherry-picked as 1daa094f4f4604108e603999f6edf3ee3089b72b.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as cf4ded965eafaba86d874e462fd602488737d460.
|Patch Set 1: Verified; Looks good to me, approved; Ready

+all based on review on tot
|Change has been successfully cherry-picked as f921e60250bf02fe4e38fe8b9f0776959e303264.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

Olof, LGTM, but OOO - Are these values arbitrary? Do we care they're constant for small vs large memory systems?
|Patch Set 1: (2 inline comments)

A few quick q...
|Uploaded patch set 3.
|Patch Set 5: Looks good to me, approved; Ready

Marked approved based on sjg's prior approval.
|Change has been successfully cherry-picked as 8b0bd1e190d6ae9b5962b3547bb6d28ad56b60a4.
|Patch Set 1: Verified; Looks good to me, but someone else must approve

LGTM and verified on kaen.
|Uploaded patch set 2.
|Patch Set 2:

Agreed that bootargs should be consolidated on a per platform basis. In the interim, I propose adding the vmalloc= arg for all tegra2 platforms to at least get working recovery images.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready

+2 based on jrbarnette's prior review.

verified on tegra2 platform with &quot;before carveout fw&quot; and &quot;after carveout fw&quot;
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 683f2c3abd046c5a170f6cc6dd1514e42d3257e0.
|Patch Set 5:

Is there any reason to use the iic since the bin writing takes considerably less time? 

If yes, can we have an option to convert an iic and directly write the tp firmware (ie if fs is ro)?

If no, then let's host bins on the bcs.
|Patch Set 1: Looks good to me, but someone else must approve

LGTM. Not sure it's worth noting, but I haven't seen the reboot previously work on ARM systems.

Quick q - why did we initially need to reboot when upgrading from gen2 to gen3? What happens when a gen2 is updated but not rebooted?
|Patch Set 1: Abandoned

Abandoned due to zswap enablement. https://gerrit.chromium.org/gerrit/#change,12241
|Patch Set 4: Verified; Looks good to me, but someone else must approve

unmerge/emerge laptop-mode-tools shows the correct behavior
|Patch Set 1: Verified; Looks good to me, but someone else must approve

Verified on kaen.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Brian, can you please clarify what 'necessary deps' includes /  what I need to check?

Are there recommendations on how to test this CL?

Thanks!
|Patch Set 1:

Doh need to bump the revision #... will do momentarily
|Uploaded patch set 2.
|Patch Set 2:

Jon - thanks for the suggestions - will add a default_xorg USE flag and appropriate -default_xorg for tegra2 and tegra3.

Stephane - we would temporarily install the xorg.conf from a private ironhide package. Please let me know if there are arguments against this.
|Uploaded patch set 3.
|Patch Set 3:

After discussing with Stephane, we will post the exynos xorg.conf here. He also believes that installing the default xorg.conf isn't harmful (and may even be ok for tegra, but he'll check).
|Patch Set 3:

and bah, just noticed &quot;arm&quot; doesn't say &quot;tegra&quot; - patchset 4 coming...
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Adding +2 from cmasone since it was a commit message change only.

Thanks again to cmasone for his assistance.
|Patch Set 1: Looks good to me, approved

LGTM
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 2:

What's our policy on r#s for this?

For the BCS stuffs - we'll want to keep it the same r# as on ironhide.

For non-BCS stuff, should we just start at r0? ie  overlay-daisy/sys-kernel/exynos-kernel/exynos-kernel-0.0.1-r11.ebuild should be r0?
|Patch Set 2:

Discussed with micahc:

- We will reuse high r #s for BCS components (ie opengles)
- I'll submit a new CL with r0 #s for non-BCS components (ie exynos-kernel)
- We will create a non-ironhide BCS (probably named exynos) shortly
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Doug's RDEPEND comment fixed.

Dave's year comment fixed.

Dvae's &quot;../base&quot; is noted in the bug and will be fixed by a later CL.
|Patch Set 5: Verified; Ready


|Uploaded patch set 6.
|Patch Set 6:

since exynos-kernel is not public, then it needs to be blacklisted (to prevent the paladins from trying to uprev it) as done in https://gerrit.chromium.org/gerrit/16737
|Patch Set 6: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Fixed vapier's nit.

Marking +2 from prior approval.
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready

Marking ready again as https://gerrit.chromium.org/gerrit/16737 has gone in.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready

Marking ready again as https://gerrit.chromium.org/gerrit/16737 has gone in.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: I would prefer that you didn't submit this

Grr the other way don't read...
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready

Rebased and marking approved based on prior comments.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Rebased and marking approved based on prior review.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)

Had 1 question even though I'm ok with the way it is.
|Patch Set 1: Looks good to me, approved


|Patch Set 1:

Do we have a solution for uprev of exynos-kernel as noted in https://gerrit.chromium.org/gerrit/#change,16737? Otherwise I would expect this to fail.
|Patch Set 1:

It was an interim state - we were going to move the source to a public location... eventually all of daisy will be publicly available.
|Patch Set 1:

Anush - since you are 1-2 days away from public source, can we add the builder then?
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1:

Note this change depends on https://gerrit.chromium.org/gerrit/#change,19789 having landed first.
|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, but someone else must approve

Similar to my feedback at https://gerrit-int.chromium.org/#change,15332 - LGTM for Exynos, but I suspect you need x86 comments and not mine :)
|Patch Set 1: Verified; Ready

Verified cbuildbot_config_unittest.py is fine.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

We should have a fix for this shortly but it's a convenient work around at the moment assuming we don't see performance regressions across images
|Patch Set 1:

We may not need this anymore... 

Doug - this was related to the email thread yesterday on not having emerge-daisy chromeos-u-boot; cros_bundle_firmware -b daisy -w sd:. not working (though everything now seems fine)
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Only updated commit message to include bug # and updated CQ-DEPEND info.

Marking +2 Code Review based on vapier's earlier approval.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 5: Looks good to me, approved

(1 inline comment)

Thanks for fix, Mike. I'll verify it on HW shortly.
|Patch Set 5: No score

I figured it was something like that... thanks

Mike - if you're ok with this we'll go ahead and submit it
|Patch Set 5: Verified; Looks good to me, approved

Verified on daisy.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

How is x11-drivers/mali-drivers resolved? That package doesn't exist anymore...
|Patch Set 2:

We need to also be able to really build (from the builders) the real exynos kernel...
|Patch Set 4: Looks good to me, approved

(1 inline comment)

I'm ok with this if you would file a bug and send out a PSA per the gerrit-int review.
|Uploaded patch set 2.
|Patch Set 2: Ready


|Patch Set 1:

An accompanying CL must remove the RDEPEND in the private daisy overlay from including mfc-fw and openmax.
|Patch Set 1:

It looks like dcba2f13d2be6a84e908966db0ee5c735ab35a2a in private-daisy-overlay causes chromeos-bootimage to be a 'daisy world' dependency - but if you're unlucky with the parallel emerge then exynos-pre-boot may not be there in time.

A failed build that shows this is at http://chromegw/i/chromeos/builders/arm-daisy%20canary/builds/147/steps/cbuildbot/logs/stdio
|Patch Set 1: Verified; Ready

emerge-daisy --unmerge exynos-pre-boot; emege-daisy chromeos-bootimage correctly downloads exynos-pre-boot and builds
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Abandoned

Ugh this didn't work at all like I wanted....  https://gerrit.chromium.org/gerrit/#change,23470 does though
|Patch Set 3: Verified; Looks good to me, approved

Works for me.
|Patch Set 1: Verified; Looks good to me, approved

Can't use r5 as a file of that name exists on localmirror. Submitting for factory branch.
|Change has been successfully cherry-picked as 2ef6b3ac3771f696b98c7a6a58f9af380dc12d2a.
|Patch Set 1:

FYI - already picked into factory.

Couldn't use r5 as a file of that name exists on localmirror.
|Patch Set 1: Verified; Ready


|Patch Set 1:

No luck at 800 but 1GHz seems fairly reliable.
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

I assume we don't ever hit 105 if we run at 1GHz constant (or at least for some time) in some sort of enclosure? Ie we won't accidentally trip during the factory process
|Patch Set 1: Looks good to me, approved

Let's go with this and we can yank it later if we find it problematic.
|Patch Set 2: Fails

This fails - bootargs=snow vs bootargs=console.... etc...
|Patch Set 1: Looks good to me, approved

please edit the gerrit project summary for clarity
|Uploaded patch set 3.
|Uploaded patch set 3.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

change comment?
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Hit submit! :)
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 55e3e5e8a35cc40112fd24547aa6f4ec362a2e14.
|Patch Set 1: Looks good to me, approved; Ready


|Change has been successfully cherry-picked as b5bdd8aa6a3b87f87476fb53a4e570bde5d83a1d.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as c63129b8ed622215b1af01c7af3ef4e963107999.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as e5f0532e06f5d0ee72af3bf703059eb5f9e2f2d8.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 665fe45aef0970602ed0fa115f2b73c7c8255300.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 2154cefcc28b916fa32c3c05f5a180e0a67177a9.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 3dbef7589d6c71930923ec12413cf3b986fc1007.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 41594a79ff833cb57f753f188f138c11bd1faf3a.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 1043af704a702cd0d6d5cf335bfa1af57ea359fc.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 310549f4f15912c9bc4623f8965b31303a98d3fe.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as b4df4729554eb27a9f9b61ddcd90af115e25d4b0.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 66cbbe9a25a25591460aba727cd6e1b6f99cdf79.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 5831d994782f9f41cef7b7a6f2dc0e3d2337744c.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 6723a16a7946271facccbece172363a3b3ceeaea.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 78782aa5a2f8b07be009f6ea7835cb23af7a9ac3.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as d1df37cb721a8e295315a111bdc4ff3fb80135df.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 9ac23da4826ce9711fb4e88f81974ce776f5b984.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as da7db886f99fd6edc1b1f930709cdb844e489f41.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 0991429b5853e3bc8f0376688bdc15e5264cc641.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 1ba78f0e267f7c6e5a2a6b8eb7712fc232d48962.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot, flashed to SPI, and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as b0adda4c432a6f75af1645c3b2bb2918c6a01b44.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Built uboot, flashed to SPI, and verified 3.4 kernel boots. Submitting so factory branch is on parity with master.
|Change has been successfully cherry-picked as 683091e96b1196dbc58ebf7354547c148d050f43.
|Patch Set 1: Looks good to me, approved

Good reminder Doug - we also want 312fc8af32fd2d8c0b67d62a9cc573ff1b71b876 - I'll throw a CL up for that too.
|Change has been successfully cherry-picked as 31171af0de10145c6503982c34072137ebd0f595.
|Patch Set 1:

err nevermind... already there, looks good!
|Patch Set 1: Looks good to me, approved

We'll need this on 2394 so submit when you're inclined :)
|Patch Set 1:

Kernel is fairly frozen for the DVT build so let's not add this to 2338 to avoid confusion.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as e74491491f008c6ffc516aa3dd85035fcd9a9831.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: (1 inline comment)

Should we really be doing &quot;export BOARD&quot;?
|Patch Set 2: (4 inline comments)


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1:

Changes to 2338 are no longer needed as the branch is dead.
|Patch Set 1: Looks good to me, approved

Let's go with this on 2394 and if we get a better fix in master we can bring it over then.

CL - can you also update the stable FW on BCS once the builder has gone through?
|Change has been successfully cherry-picked as e9a758e48927820f8dd3e8033830ed79833089c6.
|Patch Set 3:

Can you confirm:
1) what happens if you run this on SMDK
2) what happens if you use a new uboot (ie with dev_extras=snow removed) then your cmdline will not have a snow vs daisy variant)
|Patch Set 2: Verified; Looks good to me, approved

Submit when ready David
|Patch Set 2: Looks good to me, but someone else must approve

I'll let the +2 come from sjg.

Also note that we do NOT have this in the 2394 branch (so the stable FW we have based on 2396.21 is missing this...)
|Patch Set 2: Looks good to me, but someone else must approve

Anush/Pawel - please approve based on the the tarball content. From an ebuild pov it looks ok.
|Patch Set 2: I would prefer that you didn't submit this

Anush is right. Permissions indeed need modification. Right now it is only readable by root (so other build parts from user die)
|Patch Set 2: No score

Is this the latest version?
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

We could edit the tarball itself to have correct permissions... however there is a new mfc-fw tarball posted at https://gerrit.chromium.org/gerrit/#change,25814 that should replace this CL in the next few days.
|Patch Set 1: Looks good to me, approved

+2 as cherry pick from master
|Patch Set 1: Abandoned

Abandoning all together as we're using 2394 as stable EC for 2475.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 6872d270d1c361d62d71e17a4dc2a01b41ed1dfc.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 37ac1e0017581f43d20d98c11318eacf393bd027.
|Patch Set 1:

All seems ok without it.. so we can probably abandon...
|Patch Set 1: Abandoned

Won't use 2475 uboot
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as c10d39f79ab0b0c773fedb8d8734cc91a05e33fe.
|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as 2c319cd29fca62ef345746b97f2ab72da233c262.
|Patch Set 1: (1 inline comment)


|Patch Set 1:

A todo on this should be to beautify this in device tree, etc. I can file a bug for that. Mostly looking for a quick way to get the charging more correct.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Carrying over sjg's +2, verified on snow board.

Rong - feel free to CR it if you're around to watch it else I'll do it when I'm back on IRC
|Uploaded patch set 2.
|Patch Set 2:

Is the purpose of this test to verify the lid switch is plumbed through suspend/resume (ie if you shut it, it suspends, then you open it again, and it resumes)? If yes, there are many known bugs with the suspend/resume part (including that it shuts down) and I would prefer you didn't submit this. If the purpose is only to test whether we hit the lid switch GPIO then this seems ok.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Patch Set 1:

Doing a diff of the config generated from the private kernel to public one, I noticed we needed to add the following configs.

--- a/chromeos/config/armel/chromeos-exynos5.flavour.config
+++ b/chromeos/config/armel/chromeos-exynos5.flavour.config
@@ -238,16 +238,24 @@ CONFIG_SPI_S3C64XX=y
 # CONFIG_USBPCWATCHDOG is not set
 CONFIG_USB_ARCH_HAS_OHCI=y
 CONFIG_USB_ARCH_HAS_XHCI=y
+CONFIG_USB_DWC3=y
 CONFIG_USB_EHCI_S5P=y
-# CONFIG_USB_OHCI_BIG_ENDIAN_DESC is not set
-# CONFIG_USB_OHCI_BIG_ENDIAN_MMIO is not set
+CONFIG_USB_GADGET=y
+CONFIG_USB_GADGET_VBUS_DRAW=2
+CONFIG_USB_GADGET_STORAGE_NUM_BUFFERS=2
+CONFIG_USB_GADGET_DUALSPEED=y
+CONFIG_USB_GADGET_SUPERSPEED=y
+CONFIG_USB_OHCI_BIG_ENDIAN_DESC is not set
+CONFIG_USB_OHCI_BIG_ENDIAN_MMIO is not set
 CONFIG_USB_OHCI_EXYNOS=y
 CONFIG_USB_OHCI_HCD=y
 # CONFIG_USB_OHCI_HCD_PLATFORM is not set
 CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+CONFIG_USB_OTG_UTILS=y
 CONFIG_USB_SERIAL_FTDI_SIO=m
 # CONFIG_USB_ULPI is not set
 CONFIG_USB_XHCI_HCD=y
+CONFIG_USB_XHCI_PLATFORM=y
 # CONFIG_USB_XHCI_HCD_DEBUGGING is not set
 CONFIG_V4L2_MEM2MEM_DEV=y
 CONFIG_V4L_MEM2MEM_DRIVERS=y

After running kernelconfig oldconfig, this is the resulting kernel change.
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as 3fcead626aaea90024ea0176172afd4c0237b549.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as ead349591b2a04fc6ed872c8575db3fdf31c7cb6.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as ed507504dd48251ce1abafb1662ceb87f609aef6.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as a7095d2e4e16ff04d4e18f371071b78d3b7b86ff.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as 87cc39de32f5b6c11cf641803644aefe02cc442a.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as 1a9150693273dddfdadcd575154fad8263871c6a.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as b2b3cd2e87db1dc84fa46af6e639ce53ed924eea.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as 87565476e3631e2d2593a330926636e123bf6955.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already merged in master
|Change has been successfully cherry-picked as 8ecbfa9b02223d051bc7248198426bfa502494f2.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already +2 in master
|Change has been successfully cherry-picked as 18bb5678febe523b4992e02b282cd65d42a8df36.
|Patch Set 1: Verified; Looks good to me, approved; Ready

cherry-pick to factory branch - already +2 in master
|Change has been successfully cherry-picked as 8331a4d753d938299f13051a623f2f04880cc08f.
|Patch Set 1:

Picked this over from master for the factory... some notes about this though...

- I hard coded in 1366x768 in omap_driver.h
- A corresponding change to exynos.conf is required (ie HDMI -&gt; true and HWCursor -&gt; false)
|Patch Set 1:

Actually this depends on https://gerrit.chromium.org/gerrit/#change,27132 so they need to go in in the correct order
|Patch Set 1: Abandoned

Original version already checked in.
|Patch Set 1: Abandoned
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 7def3a9dfb56da418aa5dca0cf76e4448b9ba27e.
|Patch Set 1: Abandoned

abandoned
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as b56ea971b57d36fc93d51476253b33a44b40051b.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 17a42f51f01f1acb9f0c86744f7d32b4da368213.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved

Discussed with dhendrix via chat and tested that on snow board.
|Change has been successfully cherry-picked as 270f798aa80ac959e1db0a6fee4ccae200afa097.
|Patch Set 1: Verified; Looks good to me, approved

Rebooted 20 times. Haven't seen recovery.
Toggled back and forth from dev to normal to dev etc and it seems to behave correctly.
|Change has been successfully cherry-picked as 8ef0129a04b5b400c501754b715c2bb0c3907392.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Rebased - not sure why merge failed before since it applied fine.

Carrying over adlr's +2
|Change has been successfully merged into the git repository.
|Change has been successfully cherry-picked as 4c6b263d7c1d8f7001d760ff59312d4c75ae57db.
|Change has been successfully cherry-picked as 592f065e9bb4864a6ec9c49b75a93c16c26b1942.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as cdd9b0db8c5f7f5868694b0b1bf02522faa140a2.
|Patch Set 1: Verified; Looks good to me, approved

Wonjoon has tested this on a modified board.
|Change has been successfully cherry-picked as b4c7b8e78bdc496babb90951baaf3e20c75281ac.
|Patch Set 1: Verified; Looks good to me, approved

Wonjoon has tested this on a modified board.
|Change has been successfully cherry-picked as eb224bbfddec84d7f6256290ae8d996c40e986ec.
|Patch Set 2: Verified; Looks good to me, approved

Works for me. crosbug.com/p/11387 filed.
|Change has been successfully merged into the git repository.
|Patch Set 1: Do not submit

This doesn't work... debugging...
|Patch Set 1: Abandoned
|Patch Set 3: Verified

Tested with test and factory images.
|Patch Set 2: Verified

Tested with factory test.
|Patch Set 1: Verified; Ready

Verified by Wonjoon. crosbug.com/p/11658 as a gift to Sean
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as d7cb9228d27439152fc39e9b61dcc4a6da585124
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as aaf1aa93b41127e4432fbb821ef38428fc5c15cc
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 42f34ed7f9b0770a74554f21136eed2ecad55770
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as ce25935545c362e21240fb8355ed7fb52c7245ae
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b078dfe0f60a6c39962e8ac109f8407c86207a37
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 0bfe9d4fa7b6e343215600d4fe478a780f3ca8b6
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e20d5cce4a223a0cfef63653bdafb5ebd417d386
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e3a72555e2cca63eccdee48ad4e3e2ffafdcb871
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as c5b7d0f0b02d2ce9c576920890bd6ab6c2a31228
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e080dc915a411ce3f7f9f11b1ebcb8ad83f510d8
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 63149c37aaa59622c9ac0c5b473b61751ac28555
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as fe8f2d1775de56e552869238c56e0ff93924cee4
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 44de838ed6b5a20e867a3dad421b4da3df266c28
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 058d26a752dc03bd4ce3a28367c67070057e93f2
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 14813f52b27044e4618fb9ae04c089eff2c19525
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 3815e389644448498306d973b39f4ca8b5285d57
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as d4ce81bdca6b8bed1471aea1b59542bb59050480
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b849db12e00175e802ef134b5950a3f5061acdfa
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 0d64a2be8a49afc39fda06ff0366fb617ad00dc5
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b2170ebf2f3f20cbc1caf725be28a5d85233f7be
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 1b85e2c8c8afa8e8b0cf682d3e43b7d599e2503b
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 527152db639edff02093631300995fdeeafe7254
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as f050b7fcce48ce0df97c4377ee95b2db7bc60555
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 67796926b9b3ee17abdaef7d49c725c98edee50d
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 4f490d2dbc716fbd6dfb5c19518d9741a79c87f3
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 4dced05d2d07d1f44271a681a779e4c13a37b512
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as cc90fbb4932c894d7cc92e52e8aee6d0c0f2f24c
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 93f89520d9598a2ccd21c89bc7229d2e87774ab6
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e73c6e71ea04a66afc934d37ff0549b22b022af9
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 756c878dd60e9322b29c9e192d74d5427a7cfcec
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 63b4e980fcb80a3d9f123a42670acacc6526c2de
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 06a324a1ce8b9c6fa0b12d9cf70364a0d38ccbda
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 29ca926e4b690cc328369697e8bb0fbd04163285
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 12ecf14221d57744c95da997c0c097e498669a20
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b88295a267242ff4ae667719e4a8e5b37ca17952
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved

Verified today

I figure we can clean it up later if we want but it'll fix the factory install shim.
|Change has been successfully cherry-picked as 1b23dff71226c5bf107975794e8987246ea2cef1
|Patch Set 2:

I suspect that we fundamentally want different probing results for x86 vs ARM here so perhaps we should reinstate the ARM specific call so we can land it in master?
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

LGTM - merging for factory since we need this working.
|Change has been successfully cherry-picked as 074898efd7adc9727436a15c6a84d29cf18be157
|Patch Set 1:

Thanks Gabe and Doug
|Change has been successfully cherry-picked as 0f4c20c759ef2b0c1e056f58d03661c87b66d69a
|Change has been successfully cherry-picked as 3112d66dd34aa42ecdf04c50b8bb60c26666eb31
|Patch Set 1: Verified


|Change has been successfully cherry-picked as d37ae02c7cc60483fbda6e3a2ef7b512575d2e35
|Patch Set 1: Looks good to me, approved

Thanks Doug
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as c93019c977965b6217e8f70734d993551f550804
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b3cadbca31148e0112948333c78d468049399f21
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 67e88efd1615042bf7603ece73b079ef6b9fed43
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 4ed95fad4fd2f612b5724c212b0f5cd41f85edb4
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 0e4fad9674e6e9715f68f2b3792c654ede4cdd2e
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 01e373e9c7ddaf6c58f2dc3a837ed680e2bd5d14
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as bfef23430bb861aa0961324302effd1bc21f0342
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e726e8fe094ccbfb24cb337903f9b6d7d4bead92
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 5a592e94b5fb26eb2ca5b65121fca0f37e270492
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 08ed1b3b2403d40204cb6641678b9a01b27aea7d
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 8ce4332e94464c3dc78f4344a5fffbc4fabd1437
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 3ebd0544c2502930e6a30937c3f7d73adc1c40c7
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 8214587137b320f20899e3cfad187da551e6613c
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as a90ababd35284155dce00a0e62cb970cb9acba0e
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 72215731fe49e37da4af50e405765f91c4aac063
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as b62eb932c7b2da7afc797e5b16903d0ebcd01b5d
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e83c4c4129f55a378c63e4e3fc2c2252334898c3
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 5d10d9d0db3c1f71208c2ce685720f01a4037cfe
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as ffea7e69a2e1673e7932842707b98e59721e9d99
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 707b9d7c2b38666d0985bec4ce48c9207187f7d2
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as adaec0a75eca8a6ef574c4c252abe2b97aa2aab7
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 7f9c442fb473ce286fbaeab3edafc1b503851f1c
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as d9cc105a1a82a0c8e781ba97d6635be14136b66e
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as f122b5e5e09b4699af2c65a13da8333c574fc381
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved

Thanks Doug
|Change has been successfully cherry-picked as 8c41817585ae9b30a0ed6c0de5aba91ec2992da9
|Patch Set 1: Verified; Looks good to me, approved

Thanks Doug
|Change has been successfully cherry-picked as 86b9525cb34ef3f5285ef4108746da93d3367769
|Patch Set 1: Verified; Looks good to me, approved

Discussed with kliegs via chat
|Change has been successfully cherry-picked as 88d1fa2ab9d558b458fdc4c868172079b24bea5a
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 8c109b5101fd97940b06a2cb5520c8bbf919b506
|Patch Set 1: Verified


|Change has been successfully cherry-picked as bab48a8eeb954e4b0d058c28a46b6972a489f12c
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as ea42a5ff394bc4403a92445c9a7ebc3eddad3871
|Patch Set 1: Verified


|Change has been successfully cherry-picked as d6cadc849551bcc6307e8dedaa95ef4b92dc0308
|Patch Set 1: Verified


|Change has been successfully cherry-picked as dcca6efc69d23e4c581ac378045298290f7ec0c9
|Patch Set 1: Verified


|Change has been successfully cherry-picked as d50342b8f63dc8e98c793fb9ce3670077c5ed9ea
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Please post another CL to remove from the private overlay
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 4066131736a4ce934ca6f25424b0e2fb2aef8da2
|Patch Set 1: Looks good to me, approved


|Patch Set 1: No score

Argh you're right... not paying attention...
|Patch Set 2: Looks good to me, approved

thanks for the catch
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as cd59b7312163c25fbd6287803453bdc0fc5f4522
|Uploaded patch set 2.
|Patch Set 2:

Horrible in 20,000 ways... but good for a sanity check
|Patch Set 2: Abandoned

Right, forgot : were toxic in yaml...
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 3b2bc1e298feead10770b91956a53360829edce9
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

LGTM though we need to sort out the BCS parts since it's not actually public accessible (but as Benson pointed out, the depends is in the private overlay)
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as d20142b8f20b97b78374c8ecceecaea263c380f8
|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as 41f5d537e76dcf93e3f07735869329747a13365a
|Patch Set 1: Verified

Verified on R23 - recovery time on snow is normal.
|Patch Set 1:

passed trybot
http://chromegw/p/tryserver.chromiumos/builders/alex-paladin/builds/421
|Change has been successfully cherry-picked as fb1de2d2483008b5a7f3b16d3d470b3314c97e16
|Uploaded patch set 2.
|Patch Set 1:

Can we get the bsp ebuild cleaned up first so we're very distinct about daisy vs snow?
|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as 6d69ba31767ec03c3253b929c7aa03b6f91da2c0
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 58a073f7494e10b7816d684d92da6a08737cbfd3
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 66eff3172ea0df16f8af595f76deb8ec81ed50e0
|Patch Set 1: Verified


|Change has been successfully cherry-picked as fb432b221ef3efcb84aefd11a791b6f96d2a0d92
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 5d548aba1430933ac2d0a147cbff547e6992b87a
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

Logically looks correct - but I don't know enough about kernel style guidelines
|Patch Set 1: Do not submit

(2 inline comments)

WIP - it's not practical but for early comments on the shellball/etc.
|Patch Set 1: (4 inline comments)

questions for vapier...
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as a54431010d092cf439235f7564edb6e56ced160f
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as b6d7da74b151108f7b6f3bf16f0a8be99ecc07a3
|Uploaded patch set 2.
|Patch Set 2:

Can we abandon this now that we've merged the changes to v2/SNOW?
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as f772b8bd3c112cbeb86305af39b353ba57fc2e14
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as e42414fcbb39a52b6b2b960f615adf5530b9379a
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as ce673835f6e86cf82df6e39ba02225330886589f
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 63be5ea76140fa67b707db13ac5d8033279f8bdb
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified

sjg has done done basic target testing with the bl1 (and other bl1 changes have landed)
|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as cede1f9ec7e93e744b1325e9fc19036ea579dd69
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 83c966fcb0e0fc41b39718681fcbe31990d5ec91
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 0e28dada6c876481d1c61a0c4a596982a012ff8c
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as b2d95293a6bad587d86c80cbffffe558381cc993
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 4c5700a9a9f9cfa7775f4d294aca79be4fa2bc4b
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 5eb2701932b628547bb7ab6a43eb8b65e922517a
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 2: Looks good to me, approved


|Change has been successfully cherry-picked as c7bb3eda9bc72c7da06686f0576370ca46ef6dc0
|Uploaded patch set 2.
|Patch Set 2: Ready


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 1032f4d874495542b97de9db975dca866e7e2565
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 1e3fe3841e94ea0989a7765c5e03fc3675ea1400
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as d3546e4f6136fe53f8e221224d9ecb3ec8f4fdaa
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 3caef5a4adc079b6a147205508b09cbf02b69cce
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as f79db6359be623de495995dcb19b0c9587c0601a
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 738593e2b7a04dce7f8f528bc56fc53a2fb12b4d
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 4ca109f7fc7b536e4abd5114d85b26f17e589f1c
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 34522494a332bd2408ed77d028637b9c664c1b48
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as b107930eb9142532e236fd6db4422258f8b2cc0b
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as c54fa4697db15d30651bcccb5b945b338743847e
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 4f7c063b751fab04165d3df3f06f958eaa6c4d16
|Patch Set 1: Looks good to me, approved; Ready; Verified

davidjames gave a +2 via chat so submitting
|Change has been successfully cherry-picked as e0f58353954a59963a80778f663c7cabeb1256a1
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

fat fingering which cherry pick commitid....
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 1dae21afa7f36c7518f2a6b12f652a62c421a637
|Patch Set 2: Looks good to me, but someone else must approve

CID 55:48 matches the list of eMMCs under investigation.

Didn't see this in an upstream kernel but Android (and some datasheets) seems to call it prv (production revision) instead of fwrev
|Patch Set 1: Ready; Verified


|Patch Set 6:

We can do something like https://gerrit.chromium.org/gerrit/#/c/16737/

Caveats are: there will be no upreving to this package - meaning someone has to manually update the hash in the stable ebuild every time the kernel is updated.

Please file a bug to make sure we remove the blacklist once the kernel is public.
|Patch Set 1: (2 inline comments)


|Patch Set 5: Looks good to me, approved; Ready

44160 is in, adding this too
|Patch Set 5: Verified


|Patch Set 1: Looks good to me, but someone else must approve

sosa/dianders - is this still the right way to fix https://gerrit.chromium.org/gerrit/#/c/42829/
|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 1:

marcheu - can you clarify which board we want to enable dri for and which ones we don't?
|Patch Set 2: (1 inline comment)

It seems like you're not actually using most of the ebuild... perhaps trimming out all the features you don't need.... off hand (and not checked for correctness something like):

EAPI=4
CROS_WORKON_PROJECT=&quot;chromeos/vendor/nvidia-u-boot&quot;

inherit cros-debug toolchain-funcs cros-board flag-o-matic

DESCRIPTION=&quot;Das U-Boot boot loader&quot;
HOMEPAGE=&quot;http://www.denx.de/wiki/U-Boot&quot;
LICENSE=&quot;GPL-2&quot;
SLOT=&quot;0&quot;
KEYWORDS=&quot;~arm&quot;
IUSE=&quot;profiling&quot;

CROS_WORKON_LOCALNAME=&quot;../partner_private/nvidia-u-boot&quot;

# This must be inherited *after* EGIT/CROS_WORKON variables defined
inherit cros-workon

UB_BUILD_DIR=&quot;${WORKDIR}/${ROOT}&quot;

IUSE=&quot;${IUSE} ${ALL_UBOOT_FLAVORS}&quot;

src_configure() {
        local ub_arch=&quot;$(tc-arch-kernel)&quot;
        local ub_board=&quot;$(echo &quot;${PKG_CONFIG#pkg-config-}&quot; &#124; tr _ '-')&quot;

        export LDFLAGS=$(raw-ldflags)

        COMMON_MAKE_FLAGS=&quot;CROSS_COMPILE=${CHOST}-&quot;
        COMMON_MAKE_FLAGS+=&quot; O=${UB_BUILD_DIR}&quot;
        COMMON_MAKE_FLAGS+=&quot; -k&quot;

        CROS_U_BOOT_CONFIG='puppy_config' ;
        CROS_FDT_DIR=&quot;board/puppy&quot;
        COMMON_MAKE_FLAGS+=&quot; USE_PRIVATE_LIBGCC=yes&quot;
        COMMON_MAKE_FLAGS+=&quot; ARCH=${ub_arch}&quot;
        elog &quot;Using U-Boot config: ${CROS_U_BOOT_CONFIG}&quot;

        emake \
                ${COMMON_MAKE_FLAGS} \
                distclean
        emake \
                ${COMMON_MAKE_FLAGS} \
                ${CROS_U_BOOT_CONFIG}
}

src_compile() {
        tc-getCC
        emake \
                ${COMMON_MAKE_FLAGS} \
                HOSTCC=${CC} \
                HOSTSTRIP=true \
                CHROOT_BUILD=y \
                all

}

src_install() {
        insinto &quot;/firmware&quot;
        doins &quot;${UB_BUILD_DIR}/u-boot.bin&quot;

}
|Patch Set 2:

I'm not super opinionated on the topic but my thoughts are that the 2011.03 u-boot should be going away soon (I hope?)... and in it's current state we won't be running verified bood anyways so making it as simple as possible was the goal. I'll leave it up to you if you think it's easier to keep the one matching the regular ebuild.
|Patch Set 1: Looks good to me, approved


|Patch Set 4: Looks good to me, approved; Ready

44160 is in, adding this too
|Patch Set 4: Verified


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Ready

44160 landed so this should be good to go.
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 2: (2 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1:

https://gerrit-int.chromium.org/#/c/33979/ with -dri in make.conf builds for me...
|Patch Set 1:

marcheu - what check do you want me to make? I can verify that it builds +dri and -dri platforms.
|Patch Set 1: Abandoned

peach builds without this change now
|Patch Set 1: Looks good to me, approved

I'm not opposed to this change but it may be indicative of other things wrong in this branch. No harm in adding though.
|Patch Set 1: I would prefer that you didn't submit this

Let's make a u-boot-3 virtual ebuild in the private overlay to take care of this instead.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

9999 is now out of sync...
|Patch Set 1: Looks good to me, approved

Ah ok... got it... we're still manually upreving it anyways so now just pointing it to a new tag. LGTM.
|Patch Set 1: Looks good to me, approved


|Patch Set 15: Reverted

This patchset was reverted in change: Ia587da7ac45ba4f4ac368c16e3c9a02abb0d4161
|Patch Set 1:

Don't we need the same mod in 9999? Otherwise it certainly builds with USE=xlib-glx which is an improvement. Thanks!
|Patch Set 5: Looks good to me, approved; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1:

trybot passed with https://gerrit.chromium.org/gerrit/#/c/47567 - http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/arm-generic-full/builds/307
|Patch Set 1: Ready


|Patch Set 1: Ready

offending cl of last batch was https://gerrit-int.chromium.org/#/c/35212/ - note trybot previously passed on arm-generic
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1:

tested with https://gerrit-int.chromium.org/#/c/35345/
|Patch Set 1: Ready; Verified


|Patch Set 1: Ready

wasn't me
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as e0da0faa23c0c3dd600df28937f77d21b04a0b7b
|Uploaded patch set 2.
|Patch Set 2:

Thanks Jay - needed an extra amend to get that right :)

I originally titled the vpd entry as enterprise but figured custom is a little more versatile
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 033ac10bff913fb332cb3d32dc8b6ec0eb67e571
|Patch Set 1: Looks good to me, approved


|Patch Set 4: (6 inline comments)


|Patch Set 2: I would prefer that you didn't submit this

(3 inline comments)


|Patch Set 5: Looks good to me, approved

lgtm after you fix the commit message
|Patch Set 2: (1 inline comment)

Probably can clean this up a bit but otherwise lgtm
|Patch Set 2: Looks good to me, approved

after discussing this causes some other problems but lgtm for now
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified

Frank tested this and it looks good - Thanks Todd!
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 2: (4 inline comments)

I think it's better to slightly modify wireless.py instead of creating a new test. Can you take a look?
|Patch Set 3: (2 inline comments)


|Patch Set 4: Looks good to me, approved


|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Do not submit

(3 inline comments)

don't submit to master
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 2c6ef977091b2b8c569b74ba62409dbe9db72718
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 11686c9be9fb02951ef975f648b81236807df8b1
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 0d50ece0bfd28fdbfa326a5ae9a914c8a5ed87d6
|Patch Set 1: Looks good to me, approved; Ready; Verified

please enable the audio test in the test list
|Change has been successfully cherry-picked as f4db08bf98866d47ed1276baa2f420dcb734f887
|Patch Set 1: Abandoned
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 2ce4062512973eb4ab9084b21298a5a772720157
|Patch Set 2: Looks good to me, approved; Ready; Verified

This is a hack and only checked into this factory branch.
|Change has been successfully cherry-picked as 8ea4140c71bc59c8f7525aa63f48f345215aaf44
|Patch Set 1:

Do we actually need this since we won't be doing any probing for now?
|Patch Set 2: (1 inline comment)

can we land this in master and then cherrypick to this branch?
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 037c50af15ef8472ceb291432e4b38b672e9f118
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as c524bcde4dadc868480c76dbfbc63c4ee789c317
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 5428f32cf975b71e400c629ef3f1867051bb5f88
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 1a6a26811c7de5e70c53f5d4fe9bcf610594fc90
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 645f8119b920d76dfa1923477de827cdfb36cfbd
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 7ad32623a753b36e370488f4a9c37106efa0dc06
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 1858742759a124e8fde78c6b56c7ff141d67eea3
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified

thanks Rhyland for the tips today - seems good here
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned
|Patch Set 1:

This change will break a daisy private ebuild - grep bl1 in the private overlay. If you post a change for that as well, then +2.
|Patch Set 2: Looks good to me, approved


|Patch Set 1:

Penny - please confirm this on a shipping platform (or make sure your kernel config defaults the localhost name correctly)
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (7 inline comments)

Hi Doug - Just posting current progress but not ready for review yet as I haven't finished the device tree table part....
|Patch Set 4: Abandoned
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 3: Ready

i wouldn't fail a lumpy hw test
|Patch Set 3: Ready


|Patch Set 1: (1 inline comment)

just a question...
|Patch Set 1: Looks good to me, approved

unfortunate that there's not an easy way to pair non-variable size spl with variable... but let's do it
|Uploaded patch set 2.
|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Patch Set 4: Ready

i wouldn't fail a lumpy hw test
|Patch Set 4: Ready


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

carry over Andrew's +2, just fixed up commit message
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

awesome job getting this to work!
|Patch Set 1: Fails

oddly enough this fails - if you cherrypick the 2 patches from factory-pit-4390.B then the LCD is properly turned on...

without the 2 patches, we get read edid errors and then the backlight is not enabled (see pin 6 of the connector) whereas LCD enable is always 3.3 (pin 28)
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified

thanks Chirantan and Vadim!
|Abandoned
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

just for reference, djkurtz setup the license/shellball following instructions at  https://code.google.com/p/chromium/issues/detail?id=219410
|Patch Set 1: Looks good to me, approved

lgtm based on https://gerrit.chromium.org/gerrit/#/c/61827/2 working fine
|Patch Set 2: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 68c81fbe95855731e378fc51abc9177f2c04c5d4
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as faa4e02e2c8c6817cfffc75e253f2f55010b06aa
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as c5f5bf2446cf6b236906b58ae54b3f78851eb734
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as 0ea0f0dfc8612346c8c4877a8472a1dddb4c2bd0
|Patch Set 1: Ready; Verified

works with https://gerrit.chromium.org/gerrit/#/c/63672/
|Change has been successfully cherry-picked as 685b4b16e3d1bab6270d9213cc3cbc48d863902f
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

patchset 3 matches https://gerrit.chromium.org/gerrit/#/c/63317/ patchset 9
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 86d99e4db0be8e14bc109198b2e049e3d3bf4099
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as d9f293b21bdca22856954ca180ffbe34eac42cc7
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 657b48d220df3bca58417648dc78c9e72040e830
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 837441fd0dfcbfdd0785c67f13af36e37d3bd47a
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved

go nyan! :)
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 3a313c6eea00ce00a41a5272c373a1e7c469e147
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 949d11a8f106781a2829d051f8d6c5aa8cff267e
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 2d18471cb3e149f3220401be0b527cae4124c2ba
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 93c4a0f15c3b33720714627b8915d78c0637d657
|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

can you uprev your ebuild too?
|Patch Set 2: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as adf6fd167816c4db9a3d8aeabe2bdead3ceae497
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 545eaf27e7a791c233b563de94f2473c61b7ccd4
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 86e96692d1959b3a510b6e0e17a1b962abac89ab
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 706d9486be69b495ecc5a31e21c73aea6ad26180
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 65819a1bb33ebbe9895c0a2044f6a7b854ee6bfc
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 34f8d11df480f59aeb5b630d7b9e295430e0499e
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 1da18c77487699c4d894c0a412e93a12ff97b5fe
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as a9830b803c4de43e8be4eda7d6b5c5669375fdc9
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 6dab6d848a9c743d2b05f2128918aa4ef7dd71ff
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 5f2c157bfb415d2156cbd853e7d20d191b060ddc
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 9c0b072399b7e71de77d07442a5899dec300cce6
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 00f7a666e0967554c8e0e84138e255ef37c83a3c
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as f852fe69c569ca80a6f15ce82ed258d0a5d3c8da
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as cb8b50b585808df70dfbc4d0e9c79deb4cffa306
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as fb74803cbdcb9b8edca8e1f1b68c6bd92857ed8e
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as e04d2f142a5e9aadea6027c4ea89cd0a8658828c
|Patch Set 1: Looks good to me, approved; Ready; Verified

discussed with Randall and he's OK with this for the factory branch
|Change has been successfully cherry-picked as 7a17b9830054429d9e864289ff3a4760369690a3
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 477460cc4fe3678151ae5874d300ef5f5785e8c1
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 0d6669bec1e8271a93fb010e12cff362ce0de0f8
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 038cc71324271afa4072b646be4371a33232c2b3
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 970a9b8e9aefbb8c1318fd090cb306bdcbddf848
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Carrying over sjg's +2 - just tidied up the commit message and bug #.

Testing results for this have been included in crosbug.com/p/20306
|Change has been successfully cherry-picked as 38102f9a561bef01362a704a1ab095c710624d1e
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as f4f01d75ebc4a79455d615b3be8239bad83f3601
|Patch Set 1: Looks good to me, approved

this is fine but as a nit - can you reorder the USE flags to be alphabetical?
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as c77ec7d788ece2338ef8f8fd46d2f852b469eb80
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as 05c0fbf4426feaf9327fbb704c4adb7ce2baa383
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified

patch 1 vs 2 - just a commit message typo fix
|Patch Set 2: Ready


|Patch Set 1: Looks good to me, approved

this change is fine but please see my email regarding this
|Patch Set 1: Looks good to me, approved


|Patch Set 2:

I get this error even building locally - ie USE=cros_host emerge chromoes-ec

Looking at the cros-board eclass, I'm not sure it correctly returns the board name when building for the host - ie should get_current_board_with_variant have an ifuse cros-host then echo host or similar?
|Patch Set 2:

doh i'm being dumb :) you're right...
|Patch Set 1: Do not submit

Wonjoon, please post this patch to apply to master. It must land there before we can cherry-pick into a branch. We should target R29 or R30 for it.
|Patch Set 1:

Andrew - this looks good
|Patch Set 2:

can we change the tegra-bct files to match the same copyright? note tegra2 files share the chromium copyright
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 1: (4 inline comments)


|Patch Set 4: Looks good to me, approved

it may have been nicer to create a function that compares versions but i know you want to land this quickly so it looks fine given the circumstances
|Patch Set 2: I would prefer that you didn't submit this

Please remove the nvidia copyright
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 6f444dd2312c0c689304955f14fe4d6165d0adc1
|Patch Set 2: Looks good to me, approved

small typo in your commit message - so please fix that and carryover the lgtm

thanks!
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved; Ready; Verified

lgtm'd on master but not landed so pushing into factory for now
|Change has been successfully cherry-picked as f44e4d3f73825aaf207798fc547e1602c3a71cc0
|Patch Set 1: Looks good to me, approved

it's better to use cherry-pick -x as it auto-fills in the &quot;cherrypicked from&quot; info
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 9fc886ad7772b2c32fcf77ea3ae0929e6b9e1634
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

lgtm with the assumption you land the related change first
|Patch Set 1:

err... not literally first... but that you get an lgtm on it to move forward with this USE flag
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 32f7b3e1f67f70a05fe588959c1a35a90547cb24
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 86f251f83515a736adfbf6e91991a40d1e534578
|Abandoned
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 3cd5a998124d4095239182cb8a3b012c4013724a
|Patch Set 1:

Note that tip of factory-pit-4471 now matches tot kernel and is at hash 8c6d1796. I've created a factory-pit-4471-old.B branch should we need to reference the original branch.
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 298ed8ade9625edef1d920eabe6a54dcc0eeea61
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3:

don't we also need this for peach-pi?
|Patch Set 4: I would prefer that you didn't submit this

(2 inline comments)

It seems like most Intel wireless stuff is done as iwl#### - is there a reason this is named differently?

In general, I'm not a fan of the ibt-* name as it seems a little vague. If you pointed me to another example where this is done, I could be persuaded
|Patch Set 4:

vapier - there is wifi fw for this part as well (and if we can have them) - or better, we are also checking if Intel can host these binaries like they do all of their other firmware
|Patch Set 5:

13k... want to post to localmirror? Can we not get Intel to host it?
|Patch Set 1: Looks good to me, approved

thanks for keeping the puppy code there (it does need it for now)
|Patch Set 2: (1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 2541347cd495fa6cb61bde44cd14d099ff2b49d6
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2 Commit-Queue+1

let's do it... thanks Doug!

2695.117 will be the last FW for x8 boards (ie NOT rev4) and we'll have a tbd &gt;2596.126 FW for x16 boards
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

don't we just need to do this on the chromeos/manifest?
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2:

Randall, can you make sure this lands in the firmware branch too?
|Patch Set 3:

(2 comments)

HJ - does the .conf apply to all 8797 devices or only pit? If it's generic, then please take a look at src/third_party/chromiumos-overlay/net-wireless/marvell_sd8787

You can post a CL to add the firmware there and modify the 9999 ebuild to copy it for the SD version.

If it is board specific, then you can create a CL in the overlay-variant-peach-pit that copies it to the file system appropriately.
|Patch Set 3:

Hi HJ, since the marvell_sd8797 ebuild is cros-workedon, you can just modify the 9999 version (and then the r version will be automatically changed when you commit it). Basically I think you want to modify the doins to copy this new conf file to the correct path. Let me know if you have questions.
|Abandoned
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

yup, sorry I missed this
|Patch Set 5: Code-Review+1

(3 comments)

I'm generally fine with this but had a few questions
|Patch Set 1: Commit-Queue+1 Verified+1

Thanks for the options Dave - I think we'l just keep it simple since we need to tell them apart asap
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

I think it can be abandoned... I didn't see it before. Doh!
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2

I double checked all board revisions and updated https://docs.google.com/a/google.com/spreadsheet/ccc?key=0AoPbDGnMeAOodFkxc3dGVTZQenJsOURMWFJmQ2lzMVE#gid=0

The rest looks similar to tot
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

normally i'd recommend bumping the ebuild version....
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1

As discussed with Wonjoon, this change will only be used for the VE model (ie new version but not old version) as this is a new policy.

JH - please add a BRANCH=snow to your commit message so we can pull it over to 2695 branch.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: Ifc407ccbbbe5f2f381a0a1e5db2f6fedf0a376aa
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: Ifc407ccbbbe5f2f381a0a1e5db2f6fedf0a376aa
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: I47321aab92a9ea47be6b6091337789a9e0fef2c8
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: I47321aab92a9ea47be6b6091337789a9e0fef2c8
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 4:

do we need to explicitly disable for rev5 snow like https://chromium-review.googlesource.com/170812
|Patch Set 4: Code-Review+2

thanks for the explanation
|Patch Set 1:

Wonjoon, please test on the boards you receive from Jongpil
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

did you run scripts/kernelconfig oldconfig on this?
|Patch Set 1:

Andrew - can you post a commit to normalize and then repost yours? Thanks!
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Andrew - can you test this on a pit before we knock it in?
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

k thanks for the explanation
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

merging here is fine - though folks might like it on tot too
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 4c84627bd3ddd78c830d26ed1c55dc04c4ba5dd8
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to change: Idfcfbc5ea3123c737c42778b198aa965d2358f11
|Uploaded patch set 1.
|Patch Set 1:

keybuk - this is a cherrypick to a factory branch (taken from our master branch) - can you remove your -2?
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Abandoned
|Patch Set 9: Cherry Picked

This patchset was cherry picked to change: Ie59a905a722b3dca1590a8eab7bf0101da45a935
|Patch Set 1: Verified+1

these seem to fix problems related to https://code.google.com/p/chrome-os-partner/issues/detail?id=23543
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 4: Cherry Picked

This patchset was cherry picked to change: Ie0562c6c2d52081c47ebb9f30df470c4b154222f
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1

Samsung has verified this - we don't have any boards with the FET change in MTV
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

benhenry ok'd this for merge-approval via chat  but wants to wait until https://chromium-review.googlesource.com/#/c/175029/1 lands on tot
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked

This patchset was cherry picked to change: Ic57a4e0b39c7c913224782ec615d9647cb97f487
|Patch Set 1: Cherry Picked

This patchset was cherry picked to change: Ib04e7725d7a02c3c029cc2f63657b230f5b8064e
|Patch Set 3: Commit-Queue+1

bvt failures weren't related
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

wasn't me
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 25: Reverted

This patchset was reverted in change: I954ce836715b068bdb52aa76e9c67b7279cda2ff
|Patch Set 2:

(2 comments)
|Patch Set 5: Code-Review-1

this is being merged here - https://chromium-review.googlesource.com/#/c/181226/
|Patch Set 5: -Code-Review

got it - is it version 11.3 or really 113? (the last version is p11)

please also add a BUG= to this
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: I49142fc877b7e385c0a2a564d1f38f6bf268a125
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Commit-Queue+1 Verified+1

thanks Mike!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review-1

We should try to resolve this
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 8: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 6: Commit-Queue+1

wasn't you
|Patch Set 2: Reverted

This patchset was reverted in change: I246cdcfc33a11114f466dff6a89e09f1cb7f8f76
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)

thanks Doug!
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks for the feedback, Doug. I'm trying to land this primarily so the skate overlay (which builds firmware from tot for now) is generally happy.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned

wrong branch
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

carrying over doug's lgtm
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

matches spreadsheet now
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

I'm inclined to agree with Doug that landing this and reverting later so we can all carry on seems good...
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

carrying over doug's +2 - only a date change

tested this on a skate with https://chromium-review.googlesource.com/#/c/182542/
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(10 comments)

To dparker's question: I see there is a firmware-spring-3833.B branch after the series of 3824 spring branches. I take it that the 3833 branch didn't actually ship?

No - apparently 3833 was accidentally created - bhthompson confirmed that 3824 is the right branch (in addition to the current spring shipping firmware being 3824.129 which is what the skate fw branch was branched from)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

flashed on a board and it seems alive and well
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

agreed - not ideal but it works for now and we can modify going forward as needed
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

not sure about the commit message but feel free to carry over lgtm
|Patch Set 1:

ah - just gerrit viewer weirdness - lgtm
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Abandoned

argh peter did this yesterday :)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as bca808241c22597b7f4208266f34df9d8595c0f6
|Uploaded patch set 1.
|Change has been successfully cherry-picked as ce83fc665dff674e5c6e09d39394d9f1c6df067d
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)

please post against the skate firmware branch

what we have doesn't seem very scalable - what if we add another memory type? seems like we may want to add a revision system similar to pit for this. what do you think?
|Patch Set 2:

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

not really easy to try via trybot atm so chumping away
|Change has been successfully cherry-picked as a97452641282406fea29e61cac12dda5db11fbaf
|Patch Set 2:

Peter, I'm open to other suggestions to fixing the lack of ability to sync chrome down for a branch that's this old and then we can remove it. I just don't quite know how to fix it correctly :)
|Uploaded patch set 1.
|Patch Set 1:

http://chromegw/i/chromeos/builders/skate%20canary%20%28experimental%29/builds/1/steps/cbuildbot/logs/stdio is failing due to Non-existent configuration skate-release specified. I'm a little concerned this CL won't actually work since I'd typically expect a release name like daisy_skate-release/daisy_spring-release/etc and this is looking for skate-release....
|Patch Set 1:

i'd go for daisy_skate since the other boards are called: daisy_spring, peach_pit, etc
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

did you run this?
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

boots for me
|Patch Set 1: Code-Review+2

(1 comment)

please fix the nit and then +2
|Patch Set 1: Commit-Queue+1 Verified+1

ignoring the nit for now, let's land this
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

fix the nit then s ubmit
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2:

(1 comment)

please file a new bug and add it to your commit message
|Patch Set 9: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Patch Set 2: Code-Review-1

Can we get a root cause analysis/errata for this (posted to the bug is fine)
|Patch Set 1: Code-Review+2
|Patch Set 1: Verified+1
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 2: Code-Review+2

maybe a more explicit test listed? :)

I would hope it builds and actually comes up on a device...
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+2 Verified+1

vapier - we weren't able to get in touch so apologies in advance if this isn't the right revert... diff tool isn't poniting out other candidates though
|Patch Set 1: Verified-1

vapier says to revert https://chromium-review.googlesource.com/#/c/179894/
|Patch Set 1: Verified+1

going to be chumped with https://chromium-review.googlesource.com/#/c/183980/
|Change has been successfully cherry-picked as 154e886957317df464659bb97e33dd6067691d81
|Patch Set 2:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

discussed via chat and on bug to chump
|Change has been successfully cherry-picked as 84b36908a0eece9de4c73d2cc78538705ccc8bff
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+2 Verified+1
|Change has been successfully cherry-picked as 0d9de1128a53ec5104bec394ba44a16e67a426b6
|Patch Set 5:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

originally we had a board with the strappings as above - as a test, remove resistor R99 which would get you to:
v0=LOW v1=FLOAT v2=FLOAT
Thus the revision for skate is expected to be:
2*1 + 2*3 + 0*9 = 8
Which refers to DVT ELPIDA in the table

mosys platform version returns DVT
mosys memory spd print all returns ELPIDA

Yay... so it seems to work...

We can clean up the code later as needed... it's a bug ugly
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

filed a bug at https://code.google.com/p/chrome-os-partner/issues/detail?id=25440 for permission issues
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

not sure we need to land this if we expect to land the actual 4gb fix shortly...
|Uploaded patch set 1.
|Patch Set 1:

should we just pad in rev1, rev2, rev3... maybe up to rev5 or whatever we reasonably expect could be built? then if we have a hw change necessitating a new dts file (ie tegra124-nyan-big-revN.dts) we remove it from this dts? this way we don't have to remember to pad it every new build...
|Patch Set 1:

the boards are currently stuffed for rev1 (see the green highlight in the strapping table) meaning we need a rev1 dt in the kernel...

this was a problem on peach-pit so we proactively put in revN, revN+1, revN+2... into the dt so that any new build would just keep working...
|Patch Set 1:

chatted with gabe offline

summary is boards are actually stuffed as rev1 so we need at least this fix

the question is whether we want to pad in extra versions as well or not
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

added in revisions through 5 which should be good for a while
|Patch Set 1: Commit-Queue+1 Verified+1

Samsung has urgently requested it and so we assume they've tested it well enough
|Patch Set 2:

please post this to tot as well
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

carrying over jwerner's +2 with comment removal

thanks!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

this was verified by nvidia so let's get it in
|Patch Set 1: -Commit-Queue
|Patch Set 1:

will wait - thanks andrew!
|Abandoned

use andrew's change - https://chromium-review.googlesource.com/#/c/185706/
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

land when you like - we're good
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Patch Set 2:

quiche will merge to 34 today
|Patch Set 2:

Please shorten the line length of your commit message
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

thanks for fixing message

dgreid remotely +2 the original patch via chat and Wonjoon has already verified it so putting it in
|Patch Set 4: Cherry Picked

This patchset was cherry picked to change: Ibb1f72d34ef37c2c1792427092c764ad55e08724
|Patch Set 2: Code-Review+2
|Patch Set 3: Cherry Picked

This patchset was cherry picked to change: I167ee288af4860d5c7d22d5cfdf17e6c77a30a18
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

tested with https://chromium-review.googlesource.com/#/c/187469/
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: I55a346c2ce6a717bb5e3935b882a0884d1ef071d
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

thanks Doug!
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R34-5500.B as commit 0c82af13c9fbb797bec1ac34c8c2b85e2a9e62e1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to change: I6518023f547d642d2fb7cf6bc4f4da9a07e8cde9
|Patch Set 1: Code-Review-2

we don't build the kernel on the firmware branch anyway
|Patch Set 1: -Code-Review

sorry confusing mutiple patches - this is the right branch
|Patch Set 2: Commit-Queue+1 Verified+1

adding Doug for a heads up but landing it - ODM has verified it matches the datasheet requirements
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1

Merge approved on bug
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1

yjlou - looks like we need both - just added branch to commit message
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

carrying louis' earlier +2 - just a rebase
|Uploaded patch set 2.
|Patch Set 2:

fixed Louis' nit and then moved the change on top of the big ec code instead
|Uploaded patch set 3.
|Patch Set 6: Commit message was updated
|Patch Set 7: Commit message was updated
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

carrying over Louis' +2 earlier (just fixed up his nit)
|Uploaded patch set 1.
|Patch Set 1:

sure, I'll wait until the other merges - but why do I need a BRANCH for an ebuild change? since any nyan/big fw branch will be branched from ToT after this changes goes in (and there's no reason to think it will be reverted since it is the correct behavior), then I don't think we need any label
|Patch Set 1: Commit-Queue+1 Verified+1

big ec support landed earlier so we should be good to go
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

sorry, forgot to delete the skate.xml file earlier :)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 4: Commit message was updated
|Patch Set 4: Commit-Queue+1 Verified+1

I just edited the commit message
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

not me - it's one of the kernel-next cls

Louis and Vincent chatted offline and I think reached an agreement so putting it back in now
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

do we expect any deltas for this other than new bcts in the near future?
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 5: Cherry Picked

This patchset was cherry picked to change: Id78256c19ab71410576a750c3ac3fee335bb84d3
|Patch Set 1: Code-Review-1

why do we need both big and nyan_big? ie the util/flash_ec --board=big --image=... works fine (and follows the same convention as pit etc)
|Patch Set 1:

we specifically didn't do this for the other projects... doesn't seem useful to start now (unless we go redo the existing boards too)
|Patch Set 2: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)

this seems to match the falco/peppy/etc implementations - just a small nit on commit message and looking for some additional testing
|Patch Set 3: Commit message was updated
|Patch Set 3: Code-Review+2

I just removed the period from the commit title
|Patch Set 3: Commit-Queue+1 Verified+1

no, it's fine to submit it now
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3:

Cloud - please rebase your change and retest. Then we'll submit it again
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1

ITS verified
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

original review is at https://chromium-review.googlesource.com/#/c/189021/  but dropping into 34 early per TPM discussion
|Uploaded patch set 1.
|Patch Set 1:

original patch at https://chromium-review.googlesource.com/#/c/189452/ - landing early to 34 per TPM discussion
|Uploaded patch set 1.
|Patch Set 1:

original patch at https://chromium-review.googlesource.com/#/c/188700 - landing early to 34 per TPM discussion
|Uploaded patch set 1.
|Patch Set 1:

original patch at https://chromium-review.googlesource.com/#/c/189025/ - landing early per TPM discussion
|Uploaded patch set 1.
|Patch Set 1:

original review is at https://chromium-review.googlesource.com/#/c/189569 but dropping into 34 early per TPM discussion
|Patch Set 4:

(2 comments)
|Patch Set 5: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1

samsung says this is good
|Patch Set 1: Code-Review+2
|Patch Set 1:

(3 comments)
|Patch Set 1:

actually submit this to tot - we should make sure our mosys in tot and factory both agree with each other
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review-2

don't edit the non 9999 version... also, match the BOARD info from the chromeos-ec ebuild
|Patch Set 4:

(1 comment)

the revbump is automatic - don't move the non-9999 manually
|Patch Set 6: -Code-Review

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 2:

(3 comments)

please fix the nits but otherwise this lgtm as it is essentially a copy of nyan

since we have not created a firmware branch, I'm inclined to let this land on ToT and then revert later (can you add a note in your commit message that this can be dropped when the branch exists and doesn't need to be carried in master forever?)
|Patch Set 2: Code-Review-1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 5: Code-Review+2 Commit-Queue+1
|Patch Set 2:

(3 comments)
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R34-5500.B-chromeos-3.8 as commit ae3af8989614d9cba127c59ddcbbde1209fa494c
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

though I wouldn't mind the eventual deletion of some of the unused ebuilds...
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

fixing typo
|Patch Set 1: Code-Review+2 Verified+1

http://chromegw.corp.google.com/i/chromiumos.tryserver/buildslaves/build4-b2  is good
|Patch Set 1:

Peter - can we send this in now that the tryjob (and bsp change have landed)?
|Patch Set 1:

note to self:
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/nyan-release-group/builds/4 was ok 

peter's current go:
http://chromegw.corp.google.com/i/chromiumos.tryserver/builders/nyan-release-group/builds/5
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

Hari answered by email.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R35-5712.B-chromeos-3.8 as commit 539b527f2e7eb8552f2fa95bcc3b7b62ed854bef
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Patch Set 3: Verified-1

according to larry's email there are issues with this l4t release so marking as failed now...
|Patch Set 3: Commit-Queue+1 -Verified

now larry says we're good... so let's go...
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R35-5712.B as commit 73d8cb27fb216c81b5648ebe9ed524dc2c9660ee
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R35-5712.B-chromeos-3.8 as commit a6974f7b64b4bbd3af9b2805d504484251e863c3
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R34-5500.B as commit 1401e258f852bd9b57b5b096cf66112953068505
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R35-5712.B as commit 6884b5657651abd1fe346dd5000f21cd6a7e9ba2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1

Dave - any comments?
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 6: Commit message was updated
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

fixing up one other typo in commit message:)
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

do you want 42?
|Patch Set 1:

do we have a bug with merge approval on it anywhere? (if we're trying to be bug)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 5:

Cloud, I don't have this battery so please mark it verified (and commit queue ready) and then we can land it.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R35-5712.B-chromeos-3.8 as commit fa31d0cfa6b6346d514517c302288764c689ca87
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R34-5500.B-chromeos-3.8 as commit ee0eb3b5709800a7c52903a9388a42b3b6e977c2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1

this looks fine but I'll let Luigi +2

Luigi, Jongpil would like to add this to the pit/pi factory branch only
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Mao, I think you want something slightly more involved like https://chromium-review.googlesource.com/196944... I haven't tested this but PTAL
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1

logs look fine - they've all failed for different reasons
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

still not me
|Patch Set 1: Code-Review+1

lgtm +2 but keeping as +1 in case you want to modify for this comment

did you also want to remove the reference from flash_ec or do we keep those around on tot?
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review-2

(21 comments)

This is pretty hard to review as is. I'd like to see it split into smaller CLs as I noted within the code itself.

Also do take care that your -r1.ebuild versions are symlinked to your .ebuild versions instead of copying the file.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-2

don't land to release branches before tot
|Patch Set 1: Code-Review+2

if this works from a trybot, go ahead and land... not sure why mine didn't work
|Patch Set 1:

one other thought, you could always mask the package in the big overlay itself... but i guess since it's a factory branch and we'll never go back, doing this is fine
|Patch Set 1: Code-Review+2
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 1:

this is fine but it's better if you do &quot;git cherry-pick -x &lt;hash&gt;&quot; since it'll carry over the info from the earlier CL
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Miles, it landed in ToT this morning so this is just a fixup to the commit message with the cherrypick info). I'll go ahead and commit it for you.
|Patch Set 1: Code-Review+2

can you post back power load #s before and after this CL to the bug #?
|Patch Set 1: Code-Review+2
|Patch Set 1:

my reading of this is that we'll only start seeing the extra ec binaries for platforms that need them (but existing platforms will have the same updater) - if that's correct it seems fine
|Patch Set 1:

that's fine by me...
|Patch Set 1: Code-Review+2
|Patch Set 4: Commit message was updated
|Patch Set 4: Code-Review+2

(1 comment)
|Patch Set 1:

(3 comments)

small nits but otherwise lgtm
|Patch Set 2: Code-Review+2 Verified-1

this is also fine - but we shouldn't submit until CLA is signed
|Patch Set 2: -Verified

CLA is fine
|Patch Set 2: Code-Review+2 Verified-1

This is fine - but we shouldn't land until the CLA is done
|Patch Set 2: -Verified

CLA is fine 

Sunqian - please update the BUG ID but otherwise this LGTM
|Patch Set 2: -Code-Review

discussed with marcheu...

shunqian - can we start posting patches to add rk support to armsoc instead of this?
|Patch Set 1:

(2 comments)

please fix the typo and file a bug and then it lgtm
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

you're welcoem to use 28739 for the bug # and for a TEST - I'd hope that you had a video test... assuming these two are fixed, it lgtm

As far as having a nicer/cleaner feature flag for this, I'd be OK landing this as-is and filing a public crbug... I would guess our future scenario has this turned on for everyone :)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

don't do this - we're going to move the entire kernel over - please talk to larry or hari if you have questions
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-nyan-5772.B-chromeos-3.10 as commit 7e0f579787f30aa466bdfd6f6eed751142ce241b
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2:

Please post this to the firmware branch - we won't ever actually use this CL!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned

this is ancient
|Uploaded patch set 1.
|Patch Set 1:

I'm not quite sure why we didn't add nyan_blaze to the nyan group of builders (it made it into the ARM board listing with nyan_big but didn't make it into the group...)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

please wait for merge approval on the bug
|Patch Set 1:

(9 comments)

please confirm that:
./setup_board --board=moose
./build_packages --board=moose
works fine
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review-1

please fix the bug # first!
|Patch Set 3:

you must file a bug - do not use BUG=None :)
|Patch Set 5: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review-1

(3 comments)

i think the tgz may be corrupted... can you try to reupload (maybe use tbz2 while you're at it)
|Patch Set 3: Code-Review+2

thanks - lgtm!
|Patch Set 4:

(2 comments)
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 7:

woah... how was this merged like 6 months later (which was used for early boards)? let's just revert...
|Patch Set 7: Reverted

This patchset was reverted in change: Ia9665ae3b15d4475c7db3e7512ee5a37f2ee8e1d
|Patch Set 2:

(3 comments)
|Patch Set 4: Commit message was updated
|Patch Set 4: Code-Review+2

discussed with vapier and marcheu - and filed 29617... let's do this for now and we can unify things later
|Patch Set 4: -Code-Review

Shunqian - please remove the LICENSE variable in the virtual ebuild
|Patch Set 5: Code-Review+2
|Patch Set 3:

(2 comments)
|Patch Set 5: Commit message was updated
|Patch Set 5: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

we need merge approval on 29586 before we land this
|Patch Set 1: Code-Review+2
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R36-5841.B-chromeos-3.10 as commit d91da828151dbf239e9de381cf33ed6202ebae1b
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R36-5841.B as commit 71638714825a27c9c81a5048bb183da971c9b798
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R36-5841.B-chromeos-3.10 as commit 5deeaa77032509778430d9999ef487a81f11982c
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

approved for merge on bug
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3:

Miles, you're now added to the bug per your request
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

this works for me but we could consider some slightly more specific method as requested by miles
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

i think we can abandon after https://chromium-review.googlesource.com/#/c/207102/ lands
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

ping for review please :)
|Patch Set 1: Code-Review+2

having the commit message with the version would be handier but this is fine
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R37-5978.B as commit 5c1383e392ed725f15bf9b1ff9fdcb7c18403779
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

it looks generally fine - one possible nit
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

we are landing this a little early - normally we'd wait until we release an r37 image (which has this ldk) to land it in the factory branch
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

DO NOT LAND UNTIL A RELEASE IMAGE IS PROVIDED
|Patch Set 1:

don't merge until you have merge approval on the bug.
|Patch Set 1: Code-Review-1

no merge approval for 36
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

please wait for this to be merge approved and then go ahead and +2 it
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R37-5978.B as commit ed8c7aeb03f4f1cf3eb30c292b8de986a2668a5b
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R38-6158.B as commit bd0ee5852684564b539200fbdd5575f1dc328638
|Uploaded patch set 1.
|Patch Set 1: Code-Review-2

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: -Code-Review

ok fixed typo
|Uploaded patch set 3.
|Patch Set 3:

signer cl is up at https://chrome-internal-review.googlesource.com/#/c/173688/
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Puthik - we can review/land your preferred patch on tot and then cherrypick to the factory branch
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1

yup this looks good to me now that https://chrome-internal-review.googlesource.com/#/c/175085/ has landed - and sheriffs said chumping is fine...
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R38-6158.B as commit 94455572f2d3ee00127203a93a6c952b27f43c88
|Patch Set 1: Code-Review+2

sure, this seems fine if you care - was it creating any specific problem?
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2:

Can we get the full series and eval whether we want to branch from this or not then? If it's a lot, I'd vote for branching...
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

note to self:

&quot;rev 5&quot; = &quot;001z&quot; (per stuffings) = 00 00 01 10 (moving tristate to two binary digits) = 6 (in decimal)
|Uploaded patch set 1.
|Patch Set 3: Code-Review+2

feel free to upload as yourself... i wasn't originally planning on moving all of the private overlay at once... anyway lgtm - thanks
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

can we finalize on our naming of the mali-drivers-bin to somehow coincide with the branch names of the mali-drivers (and across all projects)?
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1

grr sorry, Doug... picked up your commit message and fixed the Makefile

on a pinky rev2, with hacked fw that says I am jerry rev1:

FW says:
Compat preference: google,veyron-jerry-rev1

Kernel says:
localhost ~ # cat /proc/device-tree/compatible 
google,veyron-jerry-rev1google,veyron-jerrygoogle,veyronrockchip,rk3288
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

boots and works with correct kernel dt
|Patch Set 3: Code-Review+2

carrying over Julius' +2 as we just added a missing Makefile line
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3:

just updated the TEST HWID hash
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Uploaded patch set 4.
|Patch Set 4:

the idea is that we will have some boards that are stable (like veyron-pinky) but some that are experimental (like veyron-jerry) and we'll add more to the latter group and slowly migrate them from the latter group to the former group
|Uploaded patch set 5.
|Patch Set 5:

i've rewound to patch #1 (since all jerry pieces seem to be landed and building fine so we should go ahead and mark it as important)

thanks for the tip Mike to manually add the board manually to a group like beaglebone. if folks feel this is important we can do that first but we'd be following it up with a cl that would make it then important
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 4: Code-Review+2

let's land it - lgtm
|Patch Set 1: Code-Review+2

(1 comment)

small nit, please fix and then +2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

well apparently they stuffed rev1 wrong (so rev1 actually has the stuffings of rev0)... if we don't want to carry around the hack, it may not matter since rev2 will be stuffed correctly
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2

carrying over jwerner's +2... will equalize the different boards after it lands
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(2 comments)

lgtm - though i'd like to see the mic and webgl resolved (video is known and ok)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1

seems ok to me but i'll let julius +2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

please add to makefile
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review-1

(2 comments)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: Code-Review+2
|Patch Set 1:

we just created a firmware branch today - so I think we can just post that there (and no need to populate master with more pinky derivatives)
|Patch Set 1:

you can post to the firmware-veyron-####.B branch
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

lgtm after ac present fix up
|Patch Set 1: Code-Review+2

please pick to factory branch too
|Patch Set 1:

please cherry pick with -x so we can see where it was initially reviewed etc
|Patch Set 1:

actually you shouldn't need this as the fw branch only builds fw and not the kernel....
|Patch Set 1:

yes, please post this to the factory branch - no need on firmware branch
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

if someone else thinks this is sane, let's see if we can reopen the tree
|Patch Set 2:

chumping this... the tree has been closed for a long time and I don't anticipate making things worse with this (and we do need some green builds sometime soon...)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1

shunqian, please mark verified once confirmed it works

wei-ning, thanks for the original patch - this is just tidying up the commit message and comments so we can land to the factory branch asap (feel free to modify for your tot patch)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

looks like a copy - let's go ahead and land this and then do any fixups later to get a working image out
|Patch Set 2:

do we really need this if we build the ec from the branch?
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

yes, branch builder will use the branch's make.conf

and yes, to enable a build on pinky, just add this USE flag into the private pinky overlay
|Patch Set 1:

please add a bug # here

also, i don't think we need this quite yet and can leverage the llama ec instead of adding the oak ec - what do you think?
|Patch Set 1: Code-Review-1
|Patch Set 1:

Dmitry, this has landed on ToT and is a cherry pick to 41. Can you post a new patch on ToT with your alternative?
|Patch Set 1: Code-Review+2
|Patch Set 4:

can you clarify what ctrl-L is ever used for (vs up+down+pwr=dfu for ec)

volume up = up
volume down = down
power = select
this was approved by ui
|Patch Set 1: Code-Review+2
|Patch Set 1:

puthik - camera parts are all landed - can you retry from tot?
|Patch Set 1: Code-Review+2
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

daisy_winter, rush are both fine to remove 

maybe tbroch should confirm bobcat
|What I don't understand, just from reading this commit message is the &quot;Why&quot; part of the whole change; what is the motivation, and what is the result?

From what I can tell, this will just export the GPIO values through sysfs, but what for?
|It would be nice if you could make all of the elements in this definition line up in columns.
|If the variables in lines 31..47 are not used by other source files, would you mind marking them 'static'?
|It looks like you will cache the fact that debugfs is mounted or not mounted.  If not mounted, you'll continually look for it.  But, if it's discovered to be mounted, my reading of this is that it's assumed to be continuously mounted from that point on.

What happens in the case where it gets mounted, and then unmounted?
|According to the manpage for fscanf:

    If the number of conversion specifications in 
    format exceeds the number
    of  pointer  arguments,  the  results  are undefined.

Wouldn't that mean that this code itself becomes undefined?
|I think this line can have a potential buffer overflow.  You can read up to MAX_PATH charactgers for this string at line 67, so it's possible that this buffer is entirely full when you concat to it.
|It seems like 'enable_event' and 'disable_event' share a considerable amount of code, which could be factored.  In the end, you might be able to collapse enable_event() &amp; disable_event() to something like:

enable_event(...)
  enable_disable_event_helper(name, 1);

disable_event(...)
  enable_disable_event_helper(name, 0);
|This blank line could be removed.
|This blank line could be removed.
|Is there a difference in semantics between 'fatal()' and 'perror(); exit()' (line 121..122)?

If not, can you use one version or the other across-the-board?
|Should this line be indented?
|Should this line be indented?
|Can this function be removed, since it's not even compiled in?
|Should this line be indented?
|I still wonder if this function can be combined with the other code that's practically the same thing (in a different file).
|(minor nit): There's a stray space at the end of line 39.
|I suggest annotating 'tracing' with 'const'.  It will generate better code because 'tracing' won't need to be initialized in each invocation.
|The sizeof(tracing) will include the NULL terminator from the string which was used to initialize it.  Is the '+ 1' extra for a NULL terminator?  If so, you might not need it.

Just a minor nit: Technically, you probably want the number of elements in 'tracing', not its size.  However, in this case, since the size of an element is 1 byte, the size and number of elements should be the same.
|I'm still concerned that you will cache the fact that debug_fs is mounted.  What if it gets unmounted?
|If you assigned debug_fs=1 in the body of this if(), you could get better code in line 77 by checking 'debug_fs' instead of using strcmp().
|At line 64 you explicitly compare the result of fopen() with NULL, but here you use '!'.

 If you don't mind, could you use the same technique (either compare with NULL or use '!') consistently?
|I recommend making this a 'const'.
|I also recommend making this a 'const' too.
|I can't seem to find where Dump is defined.
|It would be nice if you could make all the columns line up.
|Since you've got a TODO here, is this code going to be away or be reconstructed differently?

If the whole block is going away, then you could wrap it all in a '{ }' block and move the declaration of 'err' into that block.  That way, if you delete the whole block, the 'err' is cleaned up too.

If the block is not going away, ignore.
|I'm not sure that 'some' is very descriptive.  Which types of counters are reset?
|I have trouble parsing the '&lt;' and '&gt;' option help text.
'...display timer internal by...'?

Should these options take a number as an argument -- otherwise how does one override the default of 1 second?
|personal nit: I think it would be nice to delimit the '%c' with quotes or something.
|I've done this.
Should the SPDIF version also be doing the 'mclk_changed' section of the code? It currently doesn't, changing it to use the new function will cause it to do something...
|I've done that, though I don't agree with it.  I prefer to keep data as local as possible as it makes reasoning about the code easier.

Can you explain why you like it better that way?
|Done
|Done
|I respectfully disagree here. 

If we never add another board, my approach will generate less object code and no harm will ever be done.

If we do add a new board type, both options will fail equally well, and the way to fix the issue is also equally clear.

The difference is the amount of object code that will be generated between the two snippets, and I think smaller is better.

Adding code for a new machine will be clean in either path, if the new machine is added before the 'else', and the 'else' path always remains the same.  For example:

     } else if (machine_is_some_new_machine()) {
         /* ... */
     } else {
       BUG_ON(!machine_is_aebl());
       /* .... */
     }
|A brief perusal of your patch doesn't reveal any use of snd_soc_dai_set_sysclk().

Also gmail has mangled it by converting tabs to spaces, so I cannot apply it.  Can you resend as an attachment?
|I'm not sure I agree with this sentiment.   But, ok.
|Where is SYSROOT defined? 
(I don't recall that it's a predefined macro)

If it's not used, please remove it.
If it is used, can you comment on how it gets defined.
|CXXFLAGS are for the C++ compiler, aren't they?
|Isn't CXX going to use the C++ compiler?
I think it's preferrable to use $(CC) over $(CXX) since your code is not C++.
|It looks like you have no dependencies on 'looptest.o'.  From source examination, it appears to depend on loopaudiodev.h.  
If not on looptest.o, then at least a dependency is necessary on 'looptest'.
|Convention normally places local headers at the end of the include list.
|Shouldn't the actual rate come from the stream being played?
|Please put spaces around binary operators.
|This function is quite long, and might gain some readability benefit through refactoring.  If you desire.
|These superfluous blank lines can be removed.
|I'd prefer to see assignments outside of if() statements.  it's easier to read, and it will generally generate the same code.
|sprintf() is not a good function to ever use because you can end up with buffer overruns.  Please use snprintf, and also ensure that your output is always '\0' terminated (which, I believe snprintf() will do)
|Using realloc each time through a loop is not very efficient.
Can you do it more efficiently?
You also are not handling the case where realloc() can return NULL.

Also, since you use 'devs' as an array, could you try to be consistent and use other pointers the same way (in other places you use 'ptr + i' instead of 'ptr[i]').
|What if your uses of 'malloc' return NULL?
Is there a guarantee that getting these card info values (snd_ctl_card_info_get_name, et al) will not return NULL?
|These three sections which get a string, allocate memory and duplicate the string could easily be shortened with something like:

   devs[...].xxx = strdup(source_string);
|snprintf is preferrable to sprintf.
|If the loop exited because an open failed, is it correct to close the handle?
(It's hard to tell with the size of the function and all my comment blocks sitting on the page)
|The return of '0' in an error case is not normal.  Can you make the error case return a non-zero value?
|Please change success to be '0' and failure to be non-zero.
This will at least follow the convention of the Alsa libraries and make it easier to reason about the code overall.
|Shouldn't '&#124;&#124;' be on the preceding line? I think that is the convention.
|Is the maximum name length 15 or 16? 
That is, does your size here include space for the terminating '\0'?
|If this cannot be a negative number, how about 'unsigned'?
|If this cannot be negative, how about 'unsigned'?
|Placing strings at the end, depending on their ultimate size, will normally result in better structure alignment and packing.  If your string eventually becomes 17 bytes in length (for a terminating '\0', there will be wasted space in the structure for alignment)
|Please be consistent in the placement of the '*'.  I believe our convention places it with the type, not with the variable.
|For the following char * fields, is the referenced data intended to be mutable?  If not, how about 'const char *'?
|Can you document what these parameter values can be for these function prototypes.
|Style normally puts includes with &quot;&quot; after all includes with &lt;&gt;.
|Shouldn't the opening brace for a function be on its own line?
|Please place spaces around keywords and binary operators.
|I prefer pointers to be treated as arrays rather than using pointer arithmetic.  It gives a better visual indication that it's an array of something rather than just the result of some kind of addition.

Do you have any way to note that 'buf_play' is in-bounds?
What if it is negative?
|What if pthread_cond_wait returns a non-zero error code?
If the pthread_mutex_unlock correct in that case?  Or, even the access to the data?
|Formatting:

while ((ch = fgetc(fp)) != EOF &amp;&amp; ch != '\n' );

What is this function supposed to do?  It doesn't dump anything.
|Can you move the import to the top of the file?
|Are our local source files supposed to have tabs like the kernel?
|Can you please remove commented-out code, like this block?
|If 'chunk_size' should never be negative, perhaps it should be unsigned?
|If you can avoid having forward declarations of static functions, it would be prefferable; no since in having to modify two locations if the function signature changes.
|I believe it is preferred to have the opening brace of a function on a new line.
Also, what's the coding standard for indenting C?  Is it really 2 spaces?
|Is there a precondition that states that 'device' is never NULL?
If so, can you put an assert into the code as a form of documentation.  If not, please check 'device != NULL' before deref.
|I've got a few comments overall for this function:

The use of '_'  &amp; '__' as a prefix are reserved in C. (for compiler implementations).  (This is part of '_END').

Is the whole 'goto' mechanism necessary? I'm guessing that you'd end up just cascading errors if something goes wrong.  I personally think that a cascade of errors when something fails is easier to reason about than having a 'goto' in the program.

The function, while trivial to reason about, is a bit long.  Is there any logical way to break this into smaller helper functions?  If you don't think so, feel free to ignore.
|Please remove this dead code.
|Can device be NULL?

Is it appropriate to ignore requests to create a new handle when one is already created? I guess I'm wondering why this isn't considered a logic error.
|I personally do not like assignments in if() statements, particularly when they are further used in a comparison.  With modern compilers, you don't save anything by doing that.   Do you mind rewriting these so that they are easier to read?
|'Devie' probably ought to be 'Device'?
|The type of 'rate' and 'ret' are not the same.
Are there any type promotions going on which might cause problems?
|The first format specifier should be for an unsigned value.
|Superfluous blank line.
|Unstall?
|Superfluous blank line.
|I think the convention is to make second-line parameters line up with the first-line parameter start.  If not, disregard.
|Unstall?
|I think an comment is in order about what this function returns.
|In a previous function you used 'ret' for the return value from functions.  Being consistent is nice.  Can you adjust accordingly?
|Please put a space between keywords and '('.
|Please be consistent in the use of spaces around binary operators.
|This dead code can be removed.
|Might it be a good idea to assert(r &gt;= count), just to ensure that you have no wraparound issues?
|I think you could refactor the body of pcm_read() and pcm_write(); there's an awful lot of shared code here.
|This dead code can be removed.
|This function can leverage refresh_playback_device_list() and refresh_capture_device_list() -vs- calling the same two functions.
|This function is quite long.  Would you be willing to refactor it into some smaller functions which perform the work?
|Does MAX_HWNAME_SIZE include the space for '\0',
or are you allowing a maximum device name one character too short?
|Please be consistent in the placement of, and spacing around, '*'.  Google guidelines, as I understand them, place the '*' with the type.
|248..250 are superfluous lines which can be removed.
|snd_card_next() states it returns 0 on success.  It would be better, I think, to check '==' rather than '&gt;='.

Also, if() bodies with only a single line should not be enclosed in curly braces. (sigh... that's the standard...)
|This whole if() does nothing, and could be removed.
|This code seems pretty random, since it's at the bottom of the function.  Is it intentional?
|Good safety!
|In this structure you have many pointers.  Is it valid for the pointers to be NULL?
|Is the maximum name size supposed to be 16 characters or 15 characters?
|Please put spaces around binary operators.
|nit, feel free to ignore

Personally, I think several of your for() loops in this could would be easier to read as while() loops.
|What should happen when (completed &gt;= 0 &amp;&amp; completed &gt;= count)?

(See comment on line 347)
|Should there be an assertion here that completed &lt;= count?
|I'm not sure it's correct to have the increment of buf_play not be exclusive.  What happens when two different threads are both updating it at the same time?
|Can this function ever fail?  What if it can't get enough memory for the buffer?

What happens if a buffer size of 0 is requested?
What about a negative buffer size? Might it not better to have an unsigned buffer size?
|What is the 'type'?  How is that determined?
|How does one know if it is big enough?
What about the case for recording, if allowed?
|I think there is a mismatch here in the return type and the 'count' parameter.  It would seem that they should be the same size and have the same sign.
|Buffer count should never be negative.  Why not use an unsigned?  Of course, then 'ct', which is assigned to this variable should also be unsigned.

Or, you could have a check 'buffer_counter &lt;= 0' to prevent errors and leave it int.
|Since you have an array of buffers, and an array of mutexes, I'd like to suggest putting them both in a structure and allocating the structure. (buffers, buffer_mutex)
|Personally, I don't like 'no' variables.  it makes it difficult to reason about the code, particularly in cases (which you don't do, thankfully) like 'if (!noterminate)'.

But, even in this case, the polarity of the valariable in comparison to its name makes for easy cognitive disonance.

I think that the overall flow of the code would be better if you use a the C operator '!' to denote the 'no' part of the variable.  

Instead, for example:

static int terminate = 0;

Then, your code reads more naturally:

   while (!terminate) {
   }

The signal handler, of course, would set terminate when invoked.
|buf_play is a global.  Shouldn't it be inside the mutex lock too?

Spaces around the binary operators would be nice too. (I notice a few inconsistencies in this file)
|Is 'last' needed here?  You are not signaling on the new value of 'buf_cap', so it looks like you could do away with 'last' altogether.
Of course, I could also be misunderstanding...
|I think you can probably combine the two 'invalid choice' code paths.
|The allocation of the buffer pointers doesn't really belong in a function which is initializing the mutexes.  I'd argue that it's more approrpiate to put this allocation at line 139, where you are allocating the individual buffers.

(Or, better yet, put the mutex and the buffer in a structure.  Allocate the 'buffer_count' structures, allocate the buffers  and initialize the mutex for the buffer all in one place.)

Might I suggest writing a helper function which initializes all the global data?
|ANSI C does not allow the creation of variables in the middle of code.  Could you move this definition to the top of the function?

(I'm surprised we don't have this diagnostic turned on)
|Please consider if the caller of this function passes in 'cdev' and / or 'pdev' with the value 0.
(Hint: start at lines 148, 149)
|I think it would be a much better API if 'create_sound_handle' returned an error, instead of having to check that the data is not NULL.
|If the program is going to summarily exit with an error code, wouldn't it be nice to indicate why it exited on stderr, especially when the same exit code is used multiple times?
|Are you thinking about 'getopt_long()' or something like that for parsing the arguments?
|If this does nothing, is it necessary to have it in the file?  My understanding is that Portage doesn't require actions, like src_configure, which do nothing.
|Yes.  Fixed.
|Done
|Mea culpa.  Bad Copy &amp; paste.
fixed.  And, unfixed.
|I totally disagree here.  This codec code for the Seaboard &amp;
derivative boards is already trying to be too generic and too
board-specific at the same time.

For being too generic, we've got the pdata structure which is
statically initialized, and then overridden at runtime for special
cases which don't fit the static initialization.  The mutable nature
of the data structure makes it difficult to reason about how the code
actually behaves at runtime without extremely detailed knowledge about
each and every board / codec combination that is implemented.

For being too specific, the code has many different code paths at
runtime based on the board / codec combination.  This too makes it
diffucult to reason about the code because the attributes are changed
at different points in time.

The mixing of static data, which is mutated at runtime with
conditional execution makes this code overly complicated and hard to
reason about.

I would prefer to see this code move in the direction of being totally
data driver, or totally runtime driven.

In regards to the current issue, however, I don't believe there is any
benefit to calling a function which is known to do nothing on the
max98095 codec, even if it's going to do nothing by design.

The contra argument is the fact that there are all sorts of other
special cases for each different type of board and their special
characteristics, and in that respect, this is nothing different.

Furthermore, if you weigh the cost of having a more complicated
'pdata' structure which more fully describes each board / codec, I'd
wager lunch that the total size (code &amp; data) would be smaller; there
is a significant amount of code dedicated to handling all the special
cases.

That said, if you still prefer to call a function which is known to be
a nop, I'll do it.
|Done
|Done
|Fair enough.  Consider it done.
|I don't know all the intricasies of this HDMI code, but I am concerned
about the following:

  o HDMI output is enabled
  o Something is played with a frequency different than 44100.
  o This function is called with a value that results in
    'tegra_dc_hdmi_setup_audio' failing and returning a non-zero
    value.

It seems to me, that this would cause 'hdmi-&gt;audio_freq' to have a bad
value, which would result in HDMI sound not working until this
function is called with a valid frequency.

Would it not be better to save the frequency only if it can be used?
In other words, move line 736 below 740?
|I don't know how all these config files work; my question may seem stupid.

What makes the 'exec' happen only on the 'start' path, and not the 'stop' path?
|You're right.  It's 'store' everywhere else too.
Fixed.
|I want to deprecate it for the following reasons:

1) I don't think it's present for all machines
2) It only initializes some of the controls.
3) It will be redundant work when the 'alsactl restore' is in place.

By using 'alsactl restore' with a doped 'asound.state' file, we will be assured that the sound system is in a factory state with each login.
|We could.  Before I do that, could you explain the benefit, as I don't understand why you'd want to do that.  Would a comment suffice to provide the same information?
|Do you have a zgb I can use for testing?
Or do we have enough that I can just one to call my very own?
Should I talk to Ameet?
|I'd prefer to cross that bridge when we run into it.
|Done
|That's a good idea, but it's not something that will happen with this changeset, or even a precursor.  Since we've got it now, I think we need to test that it is available.

See http://code.google.com/p/chromium-os/issues/detail?id=19340, and I've added TODO markers.
|Do you have a better solution?
|Isn't BOARD is set through build_packages, and transfers to all subprocesses in the environment.

It's a good question; my scripts automatically set BOARD when in the chroot, so I'll have to verify that my assertion is true.
|Neither -Wall nor -Wextra covers all gcc's possible warnings.
It's easier, IMHO, to select the ones I know I want and use them explicitly.
(But I also include -Wall and -Wextra just to be doubly sure, because compiler updates will sometimes update the warnings turned on by those options.)
|Ok.  Patch set 4 will be up tomorrow morning.
|Done
|Done
|I can't say that this is an uncommon style or not, but I disagree that it's hard to extend.  It's no more difficult to add another 'elif' than it is to add an element to an array.  I find the 'if' version much easier to reason about, too.

However, I don't have a problem changing this.
|Done
|Done
|Done
|BOARD is used during the compile to compile-time conditionalize the code based on the specific hardware being targeted.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Mea culpa.  Will fix.
|I've actually changed the flow to leave BOARD unset when the value cannot be determined.  I've used 'ewarn' to output a warning in that case.
|Done
|Instead of using 'die', I now use ewarn.  I don't think the build should fail if the board cannot be determined.  Instead, just warn and leave BOARD unset.
|I will test your suggestion.
|Not by me.  I was copying the alsa ebuild, and thought it was something that should be present.  Removed.
|Semicolons aren't needed in a lot of places, but I like to put them.  Electrons are free!

Done.
|Can you sensure that these controls are set the same way in the /etc/asound.state that is delivered for the wm8903-based boards?

See, for example, src/private-overlays/overlay-variant-tegra2-asymptote-private/chromeos-base/audioconfig-board/files/asound.state

Also, seaboard, kaen, and aebl.
|Can you make the spacing consistent.
|Have you tested this on kaen, aebl and seaboard?
|Done
|This is good general advice, but it's not needed in this case.  The resultant pathname is going to be at most '/dev/input/event31'.

It shouldn't ever happen, but I'll add an assert for it.
|Yes, it may.  But there is no way to know how to detect the failure.  The man page for ioctl indicates that the return value is not reliable.

So, until I have time to investigate the input system and see how it reports errors for ioctls, I am going to punt on trying to handle them; in other words, I'm doing the same thing the sample I found is doing.
|We don't have the udev system ready yet.  Terry is still looking in to some issues regarding gpio events -- which he just figured out last night.  When the udev events are ready, and processed here, this code will be removed.

(My justification for this is that I'm trying to get this up to a point that we can start talking with the Chrome folks about communication, and to remove headphone-jack-monitor.  The removal of headphone-jack-monitor helps yufeng (asymptote work) and jrbarnette (the keeper of init stuff, who doesn't like the script)
|I originally had it written that way, but decided to get rid of the extra call. 
(I see an error in this code right now, which I will fix).
With the current implementation, the idea is to make sure 'state != current_state' on the first iteration through the loop.

The error I see is that 'current_state' is not initialized properly.
I will fix this.
|I poll because I had the code already written to check the status and set the output accordingly.  Since jrbarnette goes on vacation tomorrow, I was trying to get this in today so that I can remove 'headphone-jack-monitor' (which jrbarnette gates).  So, I took the expedient route.

I originally implemented it to do the read, but realized there could be multiple events, so I'd have to loop over all events to get the final value.   So, it also seemed prudent just to read the final state, instead of reading all the events.

No other reason.
|Mea culpa.
Fixed.
|Done
|I'm removing this mechanism entirely.  It isn't useful at this point in time.
|All of this code is removed.
|No, it shouldn't hurt.  I'll test it and add it as a follow-on due to the difficulty in getting anything checked in recently.

After I get this committed, I can remove headphone-speaker-jack and we'll be back down to one system to maintain.

Ultimately, this initialization command will be removed -- once we start using /etc/asound.state to init the sound system.
|I originally tried using daemon(), but it was incompatible with my compiler options.  I've since changed the options, so maybe it will work now.
|Done
|Done
|Is this going to install /etc/init/adhd.conf or /etc/init/upstart/adhd.conf?
|Do you have a suggestion on how this should be handled, then?
|It's fine to sort the lines, but I've found it easier just to paste (and fixup) the output of the program without numerically sorting.
|Regardless how long this change will be in the u-boot source, i think it best to follow the coding convention already existing in the file.  Can you use the convention shown in line 157 to add the new option to CFLAGS?
|Done
|I could swap the order of statements, but the result would be the same.

I'm going to punt on renaming the label.
|Done
|Done
|I've changed the 'no device' to be PTR_ERR(-ENOENT).
I think that should cover all the existing cases.
|Done
|I don't think a new label needs to be used.  The regulator needs to be released if it exists, right?
With this code, if the regulator doesn't exist, the code just continues on.

There are two cases:

1. vdd_dmic cannot be found, and and no further error occurs.
    vdd_dmic should not be released.

2.  vdd_dmic could be found and an error is found later
     vdd_dmic needs to be released.

Have I misunderstood something about this code flow?
|Done
|I can make it a separate commit.
The reason for doing it this way is for better code generation,a nd shorter source code.
It's better code generation both when BUG_ON is enabled, and when it's disabled.
|Done
|Done
|Done
|Done
|Do you know why they would have these mappings?
|I think I added these on the request of Yufeng. IIRC, at least some of them were needed to get sound on Asymptote.
|Is this a clone or the actual output from the bumblebee?
If you have a bumblebee working, it's greatly preferable to get the output from the actual hardware.  (I have no knowledge of this device...)

If you don't have actual hardware yet, then a blank file would be better than copying another machine's file -- a blank file will be more blatantly wrong and require a fixup later.
|Is the bumblebee like any existing Arm board?  If so, it probably needs to have some defines here so that the headphone and mic jacks will be watched.

But, that can wait for later.
|The only purpose of this is to alphabetically sort the file names.  Cleaning house, and making it easier to read &amp; find files in the set of files that are built.
|I don't understand your question.  There are no qemu-specific files for this test.
|This file is copied from the ADHD repository, which uses all the defines.
Ultimately, I would like to enable the majority of these compilation options, but doing that from the beginning would have made this set of changes more difficult -- I'd have been addressing C issues just to get the build process improved.

This way, the build process will be finished up, and then I'll begin enabling these additional checks and options.
|Consider the following four cases:

[ ! -d /tmp ] &amp;&amp; echo &quot;Create /tmp&quot; &amp;&amp; echo &quot;remainder not executed.&quot;
[ ! -d /tmp/tmp ] &amp;&amp; echo &quot;Create /tmp/tmp&quot; &amp;&amp; echo &quot;remainder executed.&quot;
[ ! -d /tmp ] &amp;&amp; echo &quot;Create /tmp&quot; &#124;&#124; true &amp;&amp; echo &quot;remainder executed.&quot;
[ ! -d /tmp/tmp ] &amp;&amp; echo &quot;Create /tmp/tmp&quot; &#124;&#124; true &amp;&amp; echo &quot;remainder executed.&quot;

The 'true' part makes sure that the rest of the 'remake' command is executed when a build directory already exists.
|Looks like $(ECHO) is not defined.  I'll reorder the changes so that it's defined first.
|Should value.{0,1} be true by default?
|I totally agree, but it's much better than the way it was going to be: each one of these files would have been in a separate git repository.

Also, who knew there would be so many different types of boards so quickly...  I thought that this system would serve well enough until we got things up &amp; running well.
|This ends up modifying the file in the build directory and not the source directory, right?

(If it's the source directory, then I&quot;ve done something wrong in my other changes...)
|No, I haven't.  Are we using clang in our build process?
(Argumentatively speaking: clang is wrong, then. :-))
|It wasn't done on purpose. :-)
Probably some artifact of the rebase that didn't get flagged as a conflict....  Will fix.
|Done
|Done
|Fixed.  (This is not the kernel. :-))
|Done
|I think Dylan's meaning of type is more along the lines of 'plugged, unplugged'.  Terry's meaning is 'unsigned' -vs- 'unsigned int'.

Dylan, is my assessment right?
|Where is the mixed use?

I didn't make the switch into an enum only because it seemed like more overkill than necessary.  It is envisioned that this information will be ultimately sent to Chrome, and I though it easier to specify the interface through integers rather than requiring them to duplicate an enumeration.
Depending on compiler settings, the enumeration in two different compilations can end up being different sizes.

So, as it turns out, it gets converted into a boolean when being sent to dBus, and I've defined the usage a the point of conversion.

Let's discuss; this is getting to be painful to write in an HTML editor.
|I do prefer the three line because I don't like remembering arcane syntaxes.
|At present, the only thing that is tracked is the active card.  The actual device on the card that is being used is going to be dealt with at a lower layer.

Perhaps, as I think about this now, a better question might be &quot;How is this going to work if you have input from one card and output to another card?&quot;  Or, &quot;What if I want output to two different cards?&quot;

When we subsume audio / video output to HDMI, this becomes a little more complicated.

Perhaps what is needed is a 'capability' set for each device (audio input, audio output, video output) and a corresponding set of flags indicating 'active' or 'inactive'.

Setting the active / inactive states becomes more involved, but not more complicated.
|Ultimately, when this system is used, functions in this unit will be able to be called.  Specifically, utimately it will be possible to change the 'active' bit(s) on devices.  So, the locking is necessary in the long term.
|&lt;more chagrin&gt;
It's not a small amount of work to make every thread have TLS to store this variable.  I'm going to remove the check in the interim, and think about addng a TLS section for each thread as a follow-on.  Then, think about putting the check back in.
|&lt;chagrin&gt;
Yes.
Intentions didn't match implementation.  'locked' should be in TLS.
|Consistency, mainly.
|This assert is checking that the invariants of the device list are met, more than checking for the no-devices case.  If there is no internal device, we'll use the first device on the list of devices.  If there are no devices on the list (which is circular with a dummy head), then we don't do anything.

So, the no device case is already handled.
|It's unclear from the documentation if NULL can be returned by this function.  I'd assume that every device will have a 'sysname', but it's probably better not to assume.

Will address.
|A more correct answer is that in this case, this is actually needed.  The sysname has digits tacked onto the end, and I only want to compare the first 4 characters to know if they are 'card'.  Using the literal with strcmp() will generally yield no matches.
|I like consistency...  but... I can look into it.
|The enumeration only occurs during startup, before any threads are running.
I suppose it might be possible to lose an event between the enumerate and all the threads starting up, but I suspect it would be very rare (and solvable by replugging).

If you think we need more granularity on the enumeration &amp; monitoring, I can think about some other solution.
|This will ultimately have the exported functions, but since this isn't used yet, there is nothing to export.
|Consider it done.
|No, the dependencies are not specific to am64-generic.  They were just found with that setup because I didn't have a full build and I just emerged adhd.
|With gerrit's display of change sets, it's hard to know chronological order.   And, there doesn't seem to be a dependency on any other cras change (though, there is a dependency on my change...???  How did that get wired up?)  So, should this header be included in this change?
|Can any of the pointer parameters be NULL?
|Is this a pointer to the raw data that should be played?

The gist of the question is &quot;Why use a specific integer size; is an 8-bit integer required?&quot;.  It's almost always better to let the compiler decide the size of the implementation if you don't need a specific size.
|If this is the number of frames to play, does it really need to be sized to be 32 bit?  This will generate poorer code in a 64-bit environment.
|Should this file include the headers necessary to get 'struct timespec'?

(Personally, I think it should)
|Can you explain the semantics of this argument?  What would I use it for?
|What value is capture, what value is playback?
|Are these fields all specifically sized because they are shared between different processes?  If not, you'll get better code generation if you just use 'unsigned'.

Also, if this is going to be memory shared between two processes (cras &amp; chrome?), then you've got to be aware that memory layout &amp; padding of structures can &amp; will vary when different compilation options are used.  

If we can't guarantee that we have all the same options all the time, then we need to have some way of verifying the layout is the same.  One way to do this is to have an init function that verifies that all the fields offsets are at known positions:

   assert(offsetof(cras_stream_params, direction) == 0);
   assert(offsetof(cras_stream_params, buffer_frames) == 4);
   etc
   assert(sizeof(cras_stream_params) == known_size)

Been bitten by this issue in the past, and it's hard to find.

Another way to do this is to have a compile-time test program do the validation.
|Is cras_client supposed to be opaque, or should a definition be available here?  (Same question as the one about the header file I asked above)
|Is this an errno value, or some other negative value?  Are these documented?  If not, can they be?
|To be consistent, can you say that this should be the pointer from cras_client_create?

I'm confused about the difference between create, connect and start.  Doesn't create implicitly connect?  Why would you need to connect?
|'in' -&gt; 'from'?
|Is the negative return value an errno?  Can you enumerate the possible values? 

(This comment applies to all 'negative return' comments.. .just so  I don't litter the review with the same comments)
|This function sort of comes out of left field.  There has been no discussion of 'stream_type' or 'iodev' indices.  Are these described somewhere?
|Would 'of a stream' at the end make this a better description?
|I don't know how this information is calculated, but would it be possible to construct a malicious audio stream that ended up having more than 2^31 bytes in a frame?  This would result in an error condition being returned; how would such a thing percolate through the system?
|Good catch.
Fixed.
|Fixed.
|Done
|Done
|Done
|Picked up 'inv:' many years ago from a book.  Now I'll be bothered all day about which book.  Possibly &quot;The Science of Programming&quot;?  Or was it Dijkstra?  Argh...

Fixed, by the way.
|As far as I've seen, the card will come and go as a whole.  However, this new device management systems splits out the devices on a card and managements them individually -- basically as separate devices.

When the card is removed, there will be several udev events stating that each one of the card's devices was removed.  This ends up triggering this code to remove each of the devices; each 'pcm' device is managed as a separate device in the set of devices.
|This goes hand-in-hand with your comment in the DEVICES_ITERATE macro.  I've fixed the error in the macro, and made some comments about what shouldn't be done when using that macro.

In short, the macro now gets the next device before processing the current device.
|My reading is that the 'change' event heuristic applies to the 'card', not to the individual 'devices'.

Since this new mechanism is watching for Alsa devices which match the regular expression 'pcm_regex_string', I'm not sure this applies. 

I can test it, but I think it would be better to be a follow-on change as it might add a host of other changes to accommodate possibly different semantics.
|Yes.  There is a small window of opportunity where a device might not been seen.
There are currently 6 threads, and it takes about 1060 microseconds to start those threads.

Because the window is so small, I don't think that it's a practical problem that we need to worry about.  If we do want to worry about it, we can intellectually satisfy ourselves with the fact that human nature with USB devices will generally cause the user to remove and reinsert the device.

I think that we can treat this as a non-issue for now.
|called?  Or caller?
|Is 'buffer_size&quot; really the number of frames?
Could you call it something better, if so?
|This file has an inconsistent brace style at the function opening.
|Suggest that you remove the 'will add more later.
|66?
|You could save one byte of rodata by removing the \n; it's not necessary with syslog().
|Is it possible for the number of frames to be 0 or less than zero here?  Is it ok to not check?  Perhaps an assert()?
|If the stream was already mixed, and this fails, I guess you want it to remain as being mixed?

In other words,  curr-&gt;mixed = rc &gt; 0 is a bad thing?
|This function might be clearer if you have a 'rc' value which you are going to return, initilaized to zero.

int rc = 0;

Where '*used' is set to 0, set 'rc = frame' &amp; 'frames=0' instead.
Then, fall through to line 257 and change 'return 0' to 'return rc'.
Finally remove 'return frames' at line 254.
|Chaning?
|Might be nice to have a comment that 'out' must be 2 times 'in'.
|Does conv-&gt;buf need to be 2 times the size of the input?
|Could this be 'const'?
|Could this be 'const'?
|What does it mean when sound has 0 channels?
|If 'num_found' increases in lock step with 'i', won't this final assignment be to an index which is outside the bounds of 'channel_counts'?
|Through this 'goto', will the file descriptors associated with the two pipe calls be orphaned?
|Is supported_channel_counts guaranteed to not be NULL?

Considering it never to be NULL, the whole if() can be removed, as it will be subsumed by the loop below.  The loop will exit before the first iteration, and then 0 will be returned.
|/dev/input/event5:      HDA Intel Mic
/dev/input/event6:      HDA Intel Headphone

Those are the devices for the HDA code (alex &amp; zgb at least).  The won't currently match the regex.  I use 

&quot;^.*Mic Jack$&quot;
&quot;^.*Headphone Jack&quot;
 (headphone jack should have a trailing '$'; will fix in immeidate patch)
|Testing section is wrong; I didn't update that. 
Yes, ARM boards do use this for testing, and I have verified that things still work.

Will update commit message.
|Mea culpa.  Stand by for new patch.
|'orpthread' -&gt; 'or pthread'?
|'calling'?
|Should to_threads_fds[0] be set to -1 to prevent these two handles from being used again?

Same comment for to_main_fds[0]

I know I'd never do anything for it either, but what if the close() fails?
|Done
|What unit is used to measure this volume?
|Might be nice to apply the idiom '!!mute' to ensure that this remains a 0/1 value.
|Is it intentional to have the addition to occur as a floating point expression, too?

If not necessary, you'll have better code generated by doing the addition as an integer.
|I'm no floating point savant (in fact, I hold that if you think you need floating point number, it means your integers are too small), but I've heard that comparing for exact matches is a bad idea because some numbers have multiple representations in IEEE754.
|This comment about zero is somewhat conflicted with the one at line 69.  Why only zero if the first index?
|Fiven?
|Is it common to consider volume a scale?  I ask because the Chrome folks have a mix of dB and percent (according to derat).
If there is any chance of ambiguity, would 'volume_scale' be a better name?
|Is this a dB or a percentage.
Why float?
|Could you add a little commentary about the relationship between stream &amp; system volume?
|I was curious about this code.  At vmware we had an assert-on-compile macro that we spent a lot of time developing because we wanted to ensure that we always got the same error message from the compiler.  This was prompted because the original implementation which was crafted used inline assember, and it ended up producing really cryptic error messages.

So, I thought that this macro would produce different, probably confusing error messages when it failed -- depending on the expression being used.

For example, if you did something like:

   assert_on_compile(0.5);
   assert_on_compile(&quot;what happens?&quot;);

(Yes, these are concocted for experiments-sake)

So, I made a test program to see what errors would be produced:

#include &lt;stdio.h&gt;

#define assert_on_compile(e) ((void)sizeof(char[1 - 2 * !!(e)]))

int main(void)
{
    const char *fnord = NULL;

    assert_on_compile(0 == 1);
    assert_on_compile(fnord != NULL);

    return 0;
}

But, no errors are produced, even with -Wall.o

Ultimately, I'm not sure this macro works properly; if it does work, it may produce different errors depending on the type of the expression used.  It could, no doubt, be fixed, but it might be easier just to take the assert_on_compile() macro from src/third_party/hdctools.
|I now see that you have another change to rename 'volume' to 'volume_scaler'.   So, the above can be disregarded.
|Given that you have another variable 'volume' which is being used as a float value, I think there might be some confusion here about this volume.  Is it possible to differentiate the names to avoid confusion, and make c-scope or grep easier?
|I suggest adding an assertion to ensure that the callers of this function don't provide a larger-than-allowed value.  You do avoid propagating the error, but it might be useful to know where someone is passing a bad value.
|If you had a small, static, function here which would be the callback in the case there is no defined callback, you could get rid of the if() check.

OTOH, always calling through a pointer might not be better than avoiding a branch.
|You could use linker sets to automatically manage initialization functions.

(They are really useful, but would require a little file moving in adhd for cras to have access...)
|Could you be more explicit as to when the revision should be incremented?  When cras_message changes?  

When you add a new message id in the middle of the set of messages? :-)

Could a build-time rule be created which will produce an error when the revision should be updated?
|I imagine you've got this 'write, check, return' idiom at least once for each message that can be sent (for example, see lines 1078..1082).  Seems like it's ripe for refactoring into a 

   return write_message(client, &amp;msg, sizeof(msg))

type idiom.
|-EIO?  Shouldn't that be -EPIPE &amp; -EINVAL?
|Is it proper for a 'server' message to have a 'client' prefix?
In juxtaposition with the CRAS_CLIENT_MESSAGE_ID enum, I don't think I would be able to tell the difference between a client &amp; a server message just by inspection.

For further safety, I recommend starting your enumerations at different values.  Say, 4K for one, and 32K for the other.  You can then assert that the values assigned for the id field are of the correct type.
|This comment might be subtly disjoint from the actual code now, since there are two base classes.

As I've been reading the rest of this change, I come to the realization that 'client' messages are sent from the server to the message, and server messages are sent from the client to the server.  This makes perfect sense in the code, after I realized it.  My suggestion for this point in the code is to make some type of comment here which describes that the server messages control the server, client messages control the client; it's easy to fall into the thinking that client messages are encapsulated by the client, and that the client might be sending them.
|Crates -&gt; Creates?
|I'm curious why you don't statically initialize 'settings'?
|Is this change temporary, like the hard-coded devices?  Is it going to move back up to the other location?  If so, how about a static boolean in this file which allows you to leave the code in the above function in-situ.

const unsigned use_hard_coded_devices = 1;

In the above function, you just wrap the call with an if(), and here you'd wrap the hard-coded support code with an if() with the opposite polarity.
|I don't know how to parse the second sentence in this comment.  Should there be a comma after '0dB'?  
Also, instead of 'volume level' and 'level' being used in the comment, perhaps use 'volume', the argument name?
|If volume is 0, then won't the result be -100 * 100?  Does that match with the comment?

The header file indicates the allowable range, but you don't do anything to ensure that bad arguments are not propagated out as bad results.
|You can end up with a negative value as the card index here.  Is this desired?  Are all uses of this going to work if the value is an error (negative)?
|I think you should say that if the value is &gt;= 0, then it's a card index.  If it's &lt; 0, then the actual card index could not be found, and the value should not be used.
|Does this length of 16 include space for the '\0'?
In other words, is the maximum name length really 15?
|Are these standardized enough to rely on them?
|Do you need to leave space for the terminating '\0'?
|nit: should be unsigned or size_t -- due to comparison with ARRAY_SIZE (which, I think, is a size_t).
|If card_index is less than 0, shouldn't this routine fail, possibly with a unique message indicating why it failed?
|You might want to log a failure here.
|In most other contexts in which I've seen a volume, it has been just an 'int'.  Why does this one need to be a long?
|Is there any possibility that actual_dB will be greater than to_set ever?  In other words, can to_set end up being negative?
|create -&gt; created?
|How is the system volume changed?  Is that the volume keys on the keyboard?
|Should this be avoided if the card_index is negative?
|nit: I find the initialization outside of the for() loop to be a little weird.
|I'm unclear about this.  

If there is already a playback switch, you don't set a new one.  I  guess I wonder why there would be more than one, and why you will only use one if there *is* more than one?

How do you know you've selected the 'right' one if there is more than one?
|It might be useful to have a log here that you have muted some switch.
|If the connect fails, does client-&gt;sock_dir need to be released?
|Should this be 'Give'?
|Is there any need to cleanup 'mixer' if this path is reached?
|In this function, is there any need to cleanup iodev-&gt;aio-&gt;mixer?
|Just realized this; sorry for not pointing it out earlier.

Why not strdup().
Then you can nuke the strcpy().

Course, it's perfectly ok the way it is too.  Your choice.
|Is this comment still relevant?  I guess it must be, since the cards are still hard coded?
|Will alsa_card-&gt;mixer be released via this failure mode?
|It might be better to log that a playback device has been found if new_dev isn't NULL.  I suggest this because it looks like the device will be ignored if an iodev cannot be created; no point logging about a device that won't be used.

But more important questions are: What does it mean when this failure occurs?  Should the whole card be ignored?  If the card is ignored, should gavd / chrome be notified that it is being ignored?
|Same comment above about playback devices, except for capture devices...
|I don't understand the semantics of the card index.  Is this the Alsa card number?  Or just some unique unsigned integer value?

If this is an Alsa number, can you add the precondition that it must be &lt; 32?
|Should this function be able to return NULL for errors or ENOMEM?
|Would an assert(dev != NULL) be useful.
|It would appear that if you go to cleanup_iodev at this point you will be leaking the aio-&gt;dev allocation?

Since aio-&gt;dev is either NULL or a valid allocation, and since free(NULL) is a NOP, should be pretty easy to fix.
|What are the semantics of the name: from where is the name derived -- Alsa?
|How are the permissions set for this directory?  How is this directory created?
|Your change ensures that this function will not return NULL.  Perhaps an assert() would be better?
|Perhaps an assert() would be better here, as there will never be a NULL return.

Or, at the least, if you want to retain the error checking, please make the different failure cases produce the same errno across the project.
|I don't know.  If we need to classify that as a slower speed, we can certainly do that after we gather more information.
|Not going to quote ${board}; let's hope we never have boards with spaces or deleterious punctuation.

Next patch will comply.
|Ok, I'll give it a try.
|Might prove to be useful if you print the name of the socket out too.  Since chown can fail due to a variety of reasons, errno might be helpful too.

Your call.
|I believe your comment is now incomplete with the mechanism employed now.
|My reading of this new mechanism is that 'to_set' can eventual reach zero before all controls have been adjusted.  if this happens, will the unset controls end up with a volume of 0?

In the case of HDA, don't we have Master + Speaker as the additive controls (or was it multiplicative?)?  What would it mean if master was set to some non-zero value and Speaker were set to zero?

What prevents all of the change being applied to the first control in the list, and then all the other volumes being set to zero? 

Can a single control be in line for two or more outputs?
For example, Master on HDA affects both speaker &amp; headphones (right?).  Is it desirable for change to one control to have an affect on more than one output path?

On a more high-level thought, HDA has 'Master', which affects the output for everything across that device.  However, if we've got USB devices available, the HDA Master control will not affect them.  Does this mean we need a Master-Master, or something which crosses device boundaries?
|For sanity, it might be a good idea to:

  assert(to_set &gt;= 0)

after the decrement; it wouldn't be good if somehow the 'to_set' ended up being negative.
|I am so confused, now.

My understanding was that a volume of zero is now the maximum volume, and volumes more negative than zero were quieter.

Perhaps we need a nomenclature which distinguishes these different semantics without the context sensitivity we have now.
|Wouldn't 

  cras_alsa_mixer_set_mute(aio-&gt;mixer, cras_system_get_mute() &#124;&#124; volume == 0);

accomplish the same thing?
If you really wanted to save clock cycles and avoid a conditional jump, you could use '&#124;'; the 
drawback is that's more tricky and will confuse in the future.
|Can you copy line 25 to line 29?
|minor nit: should the 'db' in cras_volume_get_db_for_index() be 'dbfs'?
|CO-INNECT?
COIN-NECT? :-)
|I'm not sure that your comment about returning non-zero means you are connected is true.  Looks like you'll return a negative code on error.
|549..552:  How about:

   if (rc &lt;= 0)   /* Error or timed-out -&gt; failure */
      return rc;
|At line 550, you return a non-zero error code.  Doesn't seem like this failure check is going to catch that case.
|586 versus this line.
Is it ok to have these two increments?
|(nit) 
For consistency, you could have logs for the other types of failures here, too.
|(nit, suggestion)

Since SERVER_CONNECT_TIMEOUT is only used in one function, you could move the declaration of this to be local to that function.

... unless you have plans to use it somewhere else in an upcoming change....
|Would it be more semantically correct to replace 'suspended' with 'resumed' or 'resumed from suspend' in these logs?
|Is it possible that snd_pcm_prepare() also returns EAGAIN?
|The possible error return from cras_alsa_attempt_resume() is ignored here. Is it ok to continue in this case as if everything is working?
|What should occur fi the resume failed?
|(nit): This comment can be interpretted as 'a failed commit was recovered'.
|Deletion of the 'expect fork' was deliberate; Scott described that the minijail will essentially do the fork() and if my process forks, it will be seen as an exit and the process will be shut down.

Now that you mention it, respawn is needed.  Will fix.
|Alright, I'll fix this and fix it it the cras upstart script too.
|gavd does not have a user for itself, but I suppose it could.
What would be the advantage of them being a different user? 
How do I go about creating a new user?

gavd needs to run as the cras group because it will need to access the socket directory created by the cras upstart script.
|Yes, it could.  But, personally I prefer to have the full path shown because it shows where the executable resides without resorting to a search, and it prevents executing anything but the gavd that I want.  

(Of course, if someone were able to modify PATH, and put a new executable on the system, the could probably just replace /usr/bin/gavd, too.  So, maybe my caution is just too much paranoia.)
|If we get to this point and *frames = 0, you'll have always done a bit of work that will be rendered moot.  If you moved this check above the check of 'rc' at 330 and 335, you would cheaply short-circuit that extra work.  

I don't know enough to say that the semantics will not be changed, but it would be a good way to save a few cycles if the semantics are ok.
|Have the number of frames chagne between line 571 and 573?
Why is this an error at this level, and not at cras_alsa_mmap_begin().  It just seems like it would be better to set up an error at the most localized point rather than requiring every caller to have a special case.
|Done
|(curiosity): Is case significance important?
|(nit) This comment and the one at line 94..95 say almost the same thing.

This comment also says it grabs the first playback switch, but I don't understand that, as the code just uses the passed-in 'elem' if it is a switch.  Is the finding of the switch done up higher?
|(nit) The comment for has_volume and has_mute sort of read like a question that was left in for the developer to answer.

Feel free to ignore.
|Is this the alsa device number or a cras index?
How does this deal with 'card,device'?
|(nit) no name for first parameter, but name for second parameter.
|Is there an invariant that there will be only one output that can be found?  If not, should this break out of the loop?
|form -&gt; from?
|would it be better to add that the volume_curve is also non-null or is it ok for the curve to be NULL?
|funcitons -&gt; functions
|is means db down form full scale?
|Does this intentionally not have a 'cras_' prefix because it is static?
|Does this now conflict with the default of 75db change?
|If so inclined, you could refactor the allocation and initialization of cras_volume_curve_create_default(), and the code in this function which does practically the same thing.
|Is there a minimum volume allowed? Is it clipped at that minimum or something else?

Is there an allowable range for volume_step?
|(minor nit):

You could save a few cycles by using malloc here -- since you're immediately filling in the fields, it's not really necessary to zero them before filling them.
|Is this meaning a 63 character string + '\0' or a 64-character string, and the user must add space for the '\0'?

(I see the answer below, but a comment would be useful)
|Does this need to be released at some point?
|My reading of this code is that if the volume curve type is not recognized, it will return NULL.  Is that in conflict with this header comment which indicates it should fall back to the default?
|It's unusual to preprocessor things not on column 1; just checking if this was intentional.

Also, is this size including the '\0'?
|A comment somewhere which describes your ini file format would be very nice to have.
|I haven't seen all the code which uses this yet, but since the called function can return NULL, is that accommodated in all uses?
(Or, was the return of NULL a mistake, as asked above?)
|form -&gt; from
|voluem -&gt; volume.
|I think you have a memory leak: if card is allocated, but card-&gt;card is not.
|Might it be useful to have the card index, device index, etc. in the log?
|A delimiter to offset the actual message from the function name will make the log easier to read, IMHO.
|Is there any device information which could provide additional information when / if these get logged?

If there are multiple threads which can execute this code, then it could become confusing: Are these multiple instances of the log message from the same thread / device?
|If the messages in this function are running in separate threads, then I'd suggest to have more information which discriminates them from each other when they appear in the log.
|Is there an alsa error that can be converted to a string?
|Does the order of stream attachment have any affect on the output? 

i.e., If the DL list doesn't traverse items in the same order they were added, would removing the streams and reattaching them in a different order to another device make any difference in the output?
|You'll only get that warning if you've got it enabled.

       -Wswitch-enum
           Warn whenever a &quot;switch&quot; statement has an index of enumerated type and lacks
           a &quot;case&quot; for one or more of the named codes of that enumeration.  &quot;case&quot;
           labels outside the enumeration range also provoke warnings when this option
           is used.

I think the warning may even trigger when you have a default, which is probably the behavior you desire anyway because enum values are simply an int.  So, even though you have a set of values that are 'allowed', you could easily have an out-of-range value.

There are a lot of useful warnings that gcc can produce, but most of them are off by default, and not all of them are even covered by -Wall.
|It might be nice to have a 'default' here which logs an error or fails -- in the case of error, or in case a new messages is added.
|This name is not very mnemonic.
|It might be worthwhile to also state that as long as there in built-in hardware on Chrome OS boxes, this should never happen.  But, on Chromium OS, it could happen.
|Why only one capture stream?
|Combined with my comment about initializing first_stream, you could replace this test with a reference to first_stream.
|You could make this into an initializer, and make first_stream const.
|One could argue that this comment is not really needed because you've named your variable well.
|If this path is taken, won't this end up leaking resources?
|Ah, I hadn't factored the non-negative return value. Mea culpa.
|By my reckoning, err is uninitialized in this path.
|If the 'default' is taken above, will sending a response only make matters worse?
(Can't find this in the sources that I have, so I assume this is a new function, and I can't check the answer...)
|Is there any need to check that the amount of data being written is within the size allocated for 'dst'?
|Looks like the code ignores anything that it reads.  Should that be in the header comment?
|How much?  Frames?  Bytes?  Time?
|If a single error occurs, will all streams be removed?  To me it looks like only streams that get errors.  (Does one error induce a cascade?)

On second thought, it looks like the return of -EIO would violate the rule that all streams would have been removed.
|If an error is received, and all streams are removed, what does returning success mean?
|Won't guarding the free() lead to a memory leak in some situations.
|an new -&gt; a new?
|How are these streams added to the new default output
|How do these streams get added to the new default input?

Are there still security issues surrounding auto-switching of input?
|It looks like you have a potential write to unowned memory with this loop.  I suggest providing the number of elements in 'dev_info' as an additional argument, and either asserting that the number of elements on the list is less than the output size, or never writing beyond the end .
|Would it be a good idea to have an assert or comment that 'msg' is not NULL?

Or, allow NULL and just don't send any message?
|(nit): msg_size could be inited and const.
|Looks like this path does not free(buf).
|If you've made it this far, shouldn't the memory allocated at line 822 be released?
|(nit): could be const if you use min().
|I think you could harmlessly get rid of the test for zero, in exchange for a few more clock cycles of copying 0 bytes of memory.
|Didn't you end up making a 'min' macro?  Would it be better to use that in the memcpy() call?
|Same comments for this function as above.
|Possible NULL dereference here.
(When is this memory released?)
|Possible NULL dereference here. (When is this memory released)?
|cras_client_get_output_devices() and cras_client_get_input_devic es() are significantly the same.

What do you think refactoring them into a helper function would be beneficial?

For example, each of these functions could boil down to calling a static-incline function:

   your_chosen_name(client, devs, max_devs, 
                                (CLIENT_GET_OUTPUT_DEVICE_LIST &#124;
                                 CLIENT_GET_INPUT_DEVICE_LIST))
|By 'user', do you mean a physical person/user, or a client application?
|If this runs in a separate thread, is it possible for other threads to change the volume or mute values concurrently with this access?  Would this lead to any type of confusing mismatch between the actual system setting and the device's setting?

Is this something that even needs to be of concern?
|acrtive -&gt; active?
|Should this data be of any specified format?  If so, could you describe what it should be?
|Is it the responsibility of the caller to free(arg) if needed?
(Basically, where is 'arg' released?)
|Why are volume and mute callbacks removed during initialization?  Are there even any to remove?
|Might I suggest 'cras_system_unregister_mute_changed_cb'  as a name?  Same for the volume changed cb?

(Just a suggestion)
|With this unregistering semantic for mute &amp; volume, is it possible that callbacks will accumulate because they don't match for removal?
|Since the muted stored in the message is already '!!'-ed (in a previous chagne), this one should be unnecessary.

Personally, I think it would be better to state that the value in the message is always 0, or 1 and not muck with the value beyond the original assignment.
|Is there any cleanup necessary on pcm_cras-&gt;client?
|Should the check on 'rc' also be checking for '0', end-of-file?  Or is that covered by the EWOULDBLOCK?
|Suggestion: You can combine the enumeration and text values handily.

#define CRAS_MIXER_INFO \
   M(CTL_CRAS_MIXER_PLAYBACK_SWITCH, &quot;Master Playback Switch&quot;) \
  ...

enum CTL_CRAS_MIXER_CONTROLS {
#define M(_enum, _name) _enum,
    CRAS_MIXER_INFO
#undef M
    NUM_CTL_CRAS_MIXER_ELEMS
};

static const char * const ctl_cras_mixer_names[] = {
#define M(_enum, _name) _name,
    CRAS_MIXER_INFO
#undef M
};

Now the enumeration &amp; strings are always in the same order, and always the same size.
|Since numid is unsigned and since unsigned numbers are guaranteed to wrap around 0 by C, you could simplify this a bit to avoid a jump.

  if (numid - 1 &lt; NUM_CTL_CRAS_MIXER_ELEMENTS)
     return numid - 1;
|Building on the comment at the top regarding the mixer controls &amp; names, you could also add 'type', 'acc' and 'count' fields to the M macro, and initialize a structure with the name and the additional information.  

If you had that, this function might be able to reduce to a bounds check, and then array accesses to gather the data from the initialized structure.
|Is this the step for dB?  Doesn't other stuff in cras use .75 dB as the step?
|Should there be an

   // TODO: handle capture

here?
|Is this constifiable?
|Should the fprintf() calls here be syslog?
|Are you guaranteed that all your strncpy() here are short enough to end up with a '\0' terminator?

It might be better to ensure termination, just for safety sake.
|Looks like you've got only one use of 'error'.  Why not move the error case up into the body of the if()?
|I'm curious why you chose long for this dB value.
|I don't understand why gain callbacks are being removed during initialization.
|I don't understand why this needs to be long.
|Can you ultimately document the semantics of the new fields?
|I seem to recall reading some other code that distributed volume across different controls.  Is there any way to share some of the logic between these two?
|Is this only being applied to one channel -- front left?
|Why 5000?
|I still don't understand why these are done on init.  So, I'm going to ask you right now.

I understand now.
But, a comment describing that it's done for unit tests might be nice.  Or, you could refactor all this stuff into 'reset_state_for_unit_tests()' and I think that would do it.
|Can this be called by different threads?  Is there a danger of ending up with incoherent data for the assignments because multiple threads are writing to the same address in multicore systems?
|Might be nice to have an 'assert(aio-&gt;base.direction == CRAS_STEAM_INPUT)' here.
|With the idea that reducing the number of functions called, and communications to / from the client &amp; server would be an overall win, is there a way to combine these two messages into a single message?  (It looks like they would normally be called in a pair, anyway...)
|Your comment here made me think, &quot;Hmm, I've seen this one before... but it's only got two patch sets &amp; no rating.  Weird.&quot;

Then I looked more closely and see that your subject indicates 'gain'.  Should 'volumes' here be 'gain'?
|As min &amp; max are signed integers, is it allowed for them to be negative?  If negative values are allowed, what would it mean for an individual element, and what would it mean for the total gain?
|Same comment as asked for the minimum case.
|Should this 'volume' be 'gain'?
|Should this 'volume' be 'gain'?
|As with the min/max volumes, would there be an easy way to combine these two messages?
|Might be nice to assert somewhere that the min &lt; max.
Is it possible that 'min = max'?
|If it's allowed that min = max, this could end up being a divide by zero.
|How would the _CARD variable be assigned?
|You could straighten the source &amp; generated code by something like:

  if (num_clients &gt; 0)
     memcpy()

  return num_clients;
|This is hopefully initialized to NULL.  (I don't know where the initialization is at the moment)
|Looks like the return value should never be less than 0.
Would this be a good candidate for returning an 'unsigned'?
|(feel free to ignore) (FFTI) It looks like you don't need this prototype because the function is declared &amp; defined before use.
|I haven't commented on this before, but a sincere &quot;thank you&quot; for going the extra distance to use the identifier values for the second field.  I've always been bothered by the getopt_long man page because it uses integers in the samples, even though it documents the identifiers.
|If state.fd_rm is null, this function doesn't return a value.
Should EINVAL be returned in that case?

(Might be a good idea to turn on the warning for returning w/o a value)
|Might be nice to have the return value documented for this and the other function.
|I'm not sure I understand this comment.  Is this right?

A client registers a callback with the server associated with 'fd'.  When 'fd' has data available, the client-registered callback will be invoked by the server.

What would 'fd' typically be?  Why would a client do this?
When data becomes available on 'fd', is the server or the client responsible for reading the data?
|funciton -&gt; functions
|Can you document the semantics of 'mask'?
|I see that this variable is not used other than this small section.  Is that intentional to just use it for error checking, or was there some other envisioned purpose?
|(nit) An interesting use of '%s' here.  I'm curious why not just use 'plugged' and 'unplugged' as the argument?  It would make grepping easier if you were searching for unplugged...
|Is it desirable to simply return 0 if there is an error return when adding an fd?
|Suggestion to assert that direction is CRAS_STREAM_INPUT.
|Uh oh.  Is this a memory leak?
If this occurs on anything but the first loop, won't all allocated memory be orphaned?

Maybe not... caller looks like it may handle the list correctly.
|Is this guaranteed to be on the program exit path?  If not, do you think setting jack_list to NULL migth be useful?
|1 -&gt; plugged

0 -&gt; unplugged?
|How would one add a jack which is input &amp; output?
|beginning
|one
|(nit) Suggest an assertion that direction == CRAS_STREAM_INPUT.
|You could combine the if() statements at 395 &amp; 397 into a single if() with a nice comment.
|(minor, minor nit)

We will probably never reach the point where this matters, but unsigned values are not guaranteed to wrap around the minimal &amp; maximal values in C.  

Just to be pedantic, it wouldn't hurt to add an assert that next_iodev_idx != max value of size_t.

Or, you could modulo arithmetic the number say 2^20.
|(nit): Recommend assert here that the direction is 'input'.
|Might want to log what _kind_ of plug event; headphone?
... might end up logging something similar for other types of device arrival, so it would be nice to distinguish between then easily in the logs.
|I'd recommend to ultimately assert(conv-&gt;num_converters &lt; array-length-of-buffers)
|Might be good to ultimately assert(buf_idx &lt; length-of-buffers - 1) before line 285.

Same comment for line 278.
|Should this be a single increment; won't this resulting index already have been used by line 285?

Same comment for line 279.
|(nit) client _is_ not connected

It's also semantically different to have a non-zero result indicate success, when compared to the rest of the cras infrastructure.  Might lead to some confusion in the future...
|Does this mean that connecting to something already connected will close &amp; reconnect?

I'm curious why you chose that instead of just returning an error?
|Is __func__ C99?
(Or is __FUNCTION__ C99?)
|nit:

You could use '--retries' as the condition of the loop.
This would get rid of the if (--retries), and move the 'return -EIO' to the final return of the function.
|I think you could combine these to if() statements into a single conjunction like:

  if (connect_to_server(client) == 0 &amp;&amp;
     check_server_connected_wait(client))
       return 0;
|If the server crashes and is restarted, how will this fare?  Are the client connections cleaned up in that case?  Are they re-established, or just dropped on the floor?
|Since your commit message indicates that this is not in the build system, it would be useful to include instructions on how to build this.
|Wouldn't double quotes be better for the include, leaving angle brackets for system headers?
|A more descriptive error message might be welcomed in 6 months time when this fails for some weird reason.
|Lines 50 through 52 could probably be refactored into a helper function which could be also used in lines 53..57.
|Are the samples also int he shared memory?  If not, this probably won't output valid data.
|(nit) You could move 616 up to 614 and modify the memcmp() to use sfmt too.
|(nit) These two lines might be separated in the log by other intervening syslog() calls from other processes; this isn't a big problem when using grep for 'cras_server', but if you are grepping the result of 'grep cras_server', you'd have to have a more complicated regex to ensure you get all the information you want.

Long story short, it's still a nit you can ignore, but making a single syslog() might be nicer.
|In fmt_conv.c you have a tmp_buf field, but it's not removed.  Instead 'input_buf' is removed.

This this intentional?
|The converted was being...

I don't quite understand this sentence.  Is a word missing, or was 'conversion' intended?
|Isn't the client also waiting on the same barrier?  Everyone should wait at the same barrier until all threads have reached it.
|nit: code before variable declaration
|audo -&gt; audio?
|:-)

The Y in &quot;hw:X&quot; ?
|I recommend putting little functions like this directly into the header file as a static inline function.  You'll end up with much better code generated -- particularly because you won't actually incur the overhead of a function call.
|This would be another good candidate to make 'static inline' in the header file.
|I think the if() guarding the call is not needed, as you also guard the body of the called function with the same condition.
|Another good candidate for a static-inline function.
|I don't understand what it means to have no volume curve.  Does this leave the volumes unbounded?
|Is it intentional to return NULL?
Judging from the body of cras_volume_curve_destroy(), I'm guessing it might be...
|It doesn't seem like this actually does what it's supposed to do.
|This comment seems a bit out-of-date with respect to leftover volume now.
|In both these log messages, but particularly this one, it would be very useful to include the name of the log file.
|For replication by others, it would be nice to describe how you watched the same client be reused.
|Would it be a good idea to assert that the reply fds are both -1 here?
|Since you set them to -1 in the cras_client_create, it would be good to continue with that invariant here -- and assert() in cras_cleint_run_thread().
|If new_dev() returns NULL, is there a point in continuing to enumerate devices?

If there is a point, wouldn't it be incorrect to set first_playback to 0 when the new_device() call fails?

Same comment for the first_capture flag.
|I don't quite understand how tab completion is removing streams rapidly.
|Is the assignment of stream_id necessary?  From my reading, this is always 0, right?
|What happens when the dev-&gt;info.priority == cur-&gt;info.priority and priority is the last node in the new list?
|Will new devices be placed into the priority list when they are identified -- so no further sorting is needed?
If not, when will the list be re-sorted?
|You've got MVOT (multiple versions of the truth) with the comment at line 264, which is almost but not quite the same as the one in the header file.  I'd suggest yanking that line and sticking with the single comment in the header file.
|What if frames_out &lt; in_frames, particularly if there is no conversion?
|A comment here describing what happens to the remaining converted frames would nice a nice touch.

Also, I think this is would be a good place to ultimately use 'min'.
|(nit): Given the semantics of this function, the function name doesn't clearly indicate that it's only using the write buffer.
|This function would be a bit easier to read by leveraging cras_shm_is_buffer_available() (which is right below) for the if().
|I think you a word in this sentence.

Only log frames (that) don't fit...?
|I think a better way to do this, which avoids a block of
conditionalized Make code would be this:


MODPROBE_CONF_FILE := $(DESTDIR)/etc/modprobe.d/alsa-$(BOARD).conf

optional_alsa_conf := $(wildcard $(ADHD_DIR)/alsa-module-config/alsa-$(BOARD).conf)

MODPROBE_CONF      := $(if $(strip $(optional_alsa_conf)),$(MODPROBE_CONF_FILE))

$(MODPROBE_CONF_FILE):	       $(optional_alsa_conf)
	       $(ECHO) &quot;Installing '$&lt;' to '$@'&quot;
	       $(INSTALL) --mode 644 -D $&lt; $@

Finally, add a dependency to the existing 'install' target:

install:	$(DESTDIR)/etc/init/adhd.conf				\
		$(DESTDIR)/etc/init/cras.conf				\
		$(DESTDIR)/etc/asound.state				\
		$(DESTDIR)/usr/bin/gavd					\
                $(MODPROBE_CONF)                                        \
		$(DESTDIR)/lib/udev/rules.d/99-dev-input-group.rules	\
		cras_install

If the board-specific file is found with the wildcard, then
'MODPROBE_CONF' will be set; otherwise it's an empty value.  If
'MODPROBE_CONF' is not set, then the additional prerequisite on the
'install' target will just be a bunch of whitespace.

Your way works too.  Your choice, though I (expectedly) cast a strong
vote in favor of this way. :-)
|(nit):

Ensure that when a circular buffer wraps around the end that the ...

(Sounds a little easier to read this way to me...)  YMMV
|sine wave?
|I don't think I understand this first sentence.
|estra -&gt; extra?

It's also not clear until you look at the code where the reference to '16' comes from.
|Is it possible for the max value to be negative?  If this happens, would that effectively reduce the final maximum volume?
|board -&gt; boards?
|Why 101?
|A comment here like:

 volume in (0, 100) 

might be helpful.

Oughtn't your maximum index be something like ARRAY_SIZE(c-&gt;db_values)?
|C consts are fun.  The value referenced by 'c' is const, but not the values referenced through fields of 'c'.  So, while textually 'dB_values' should be const, it's really a pointer and doesn't qualify for const protection.

I guess what I'm saying is that your use of const here is a bit confusing.
|Why 101 here too?
|Another 101.  Maybe this deserves a manifest constant (preprocesor value)?
|A prose commentary for the '[Speaker]' configuration would be nice.
|Shouldn't this header be a full Chromium OS header?
|My changes for the gpio based jacks have regex capabilities.  If things get hairy, you could always switch to that.
|jack -&gt; jacks?
|You could get better code if you declare this as an array:

static const char pcm_search[] = &quot;pcm=&quot;

Instead of using 'strlen' at line 124, you could use ARRAY_SIZE().
|substr cannot be NULL at this point.
I think you want to test 

   *substr == '\0'

I think you don't even need the check; if this is true, then you're at the end of the string.  In this case atoi() will find no number, and just return 0.

(So, your current test will always succeed, but the code will still work)
|It would seem that this parameter will always be filled by the value of cras_system_get_mute().

If that's the ultimate case, why not remove the parameter and make the call directly in this function?  It would make this change, overall, more localized and keep the API simpler.

Stated another way, is there a reason why you would want to ever override the system mute setting?
|This could be simplified to:

  keep_looping = !exit_after_done_playing;
|Would it be better to return the result of this function?  It would propogate errors upwards...

But, maybe you don't care about volume errors?
|Could simplify to 

  stream_playing = !rc;
|269, 270:

Looks like you are unconditionally setting stream_playing?
(And doing it twice)

If you're going to set it based on the return value,

  stream_playing = !rc

would remove at least one jump in the generated code.
|This snippet &amp; the one at 47..52 could be made into a helper function.

Is it possible that duration_frames *is* zero?  In that case, shouldn't keep_looping be set to 0?
|Remvoe -&gt; Remove
|Done
|Done
|Looked ok to me, but I deleted the whitespace and reinserted.  Still looks right.
|This isn't for the plug event, this is for the identification of the jack.  If the jack is identified as a microphone jack, it will be opened and monitored.

If you've got a maxim with only one jack, I presume you want the headset jack to identify as a microphone port too.

Sadly, we don't have anything at this point to test this with, but you raise a fair point that this will have to be tested.
|I don't know.
|Done
|Done
|The /dev/input/event nodes will not be identified as jacks through this system. 

The is_microphone_jack() and is_headphone_jack() will fail to recognize the events on (at least mario):

/dev/input/event7:      HDA Intel Mic
/dev/input/event8:      HDA Intel Headphone

But, I'll change it to only enumerate gpios when no jacks found.
|Done
|Was it itentional to delete 'old'?
|Done
|Done
|Done
|Done
|Punt for later.
|Punt for later....
(in progress)
|I don't want these, but the original Samsung file from the Linux kernel, from which the majority of this code is directly taken, uses them. 

I did not want to change the Samsung code so that any comparison that people want to do between the sources is as painless as possible.
|I don't really want to change the original samsung code; keeping the two code bases synchroniized will become a horrible pain, otherwise.
|I think this is specific to the SATA implementation that the Exynos has.  It's not entirely clear what it's for via the documentation, and I haven't looked deeply at the driver for comprehension yet.

If it is specific to the exynos, I don't see what benefit it would have to be put into the DT.

Punt for later.
|Samsung code, so I want this.
|My reading of SATA/AHCI material is that clock *must* be 66MHz. What's the benefit of parameterizing it when it must be a fixed value?
|Only SATA_GENERATION3 is used.  
I don't know why they chose to make an enumeration for this particular register value... but they did.
|This function is odd, with unusual capitalization.  I had originally changed this, but put it back when I decided to reduce the number of differences.
|Punt for later to preserve original version.
|Original Samsung linux driver code.
|Punt for later.
|It's ensuring that the clock gates for the DMA and the SATA port are pass-through and not masked.  There doesn't seem to be any existing code for this.
|Done
|It fails during compile, rather than liniking; faster turnaround.  But, ok; done.
|Done
|I imagine that this Alsa API is not marked as a 'pure' function, but it will probably return the same value for the same input.

This ends up cause the compiler to call the function more than necessary.  If you're concerned about runtime or code size, you would have to assign the result to a temporary.
|Done
|I don't understand this comment.
|I will punt on this until later.  The daemon is not able to include common.h at this point.  It gets all sorts of compilation issues, and the headers may conflict with the system headers that are used by the daemon.

So, since this function must be accessed by both the daemon and the sandbox u-boot, it's gotta be here for now.
|It's an enumeration of the devices that are in the system.
It's used to identify the device that rang the doorbell.

When the first device is installed, which will be the SPI, the DEVICES above will contain the identifier and a string which describes the device.

The string will be expanded into a static array in the daemon so that it can output the names of the devices rather than integers.
|I am also going to punt on this one until later.

I have already tried to use the standard types, and even u32.

Using u32 requires additional u-boot options which causes other compilation issues.

Attempting to use uint32_t ends up with conflicts between the standard include headers and the u-boot headers when building the daemon.

Both of these can be fixed, but it's not really worth it at this time to go down a rathole of compiler issues, particularly since __u32 is a u-boot type.
|Is there a problem with inline functions?

It's the shortest, fastest and easiest way to get both the sandbox u-boot and the sandbox-daemon contexts have the same function.
|Done
|This could be a const pointer.
Don't think it will buy anything except semantics for the reader, however.
|This could be a const pointer, with the same comments as above.
|Could be a const pointer.
|In another change, you assert_on_compile that this is a power of 2 (IIRC).  Might be good to put that here to indicate that fact.
The upshot is that the compiler should use a shift rather than an expensive multiply.
|Consider if your buffer is 10 bytes in size.   This would mean that [0..9] are valid indices into the buffer.  

I'm assuming that the valid bytes in the buffer are [0, used_bytes).

If my assumptions are true, shouldn't this check be '&gt;=&quot;?
|Is CRAS_SHM_BUFFERS_MASK == CRAS_NUM_SHM_BUFFERS - 1?

Might be good to assert that during compilation, if the mask is not created from the buffers identifiers.

You could also just do a '%' with the 'buffers' identifier and the compiler will generate code to use a mask.
|master controls?  (or 'master control'?)
|Done
|Operational modes on files (blocking, binary, etc) is a historical mistake and I don't think it's a good idea to perpetuate it.  

Having the operational mode separated from the action makes it difficult to reason about what will actually happen when code executes, and is the source of some very subtle issues that are difficult to track down.
|Done
|Done.
It  can't be anything other than an int....
|KB.
|Is there a distinct benefit of obfuscating it like that?
|Done
|I copied this style from os.h, and have already done the same in os.h because that's what you put there originally.
|Done
|Done
|I think that the idiom of checking memory and sleeping is pretty straightforward here.
|What is wrong with them? 
 It makes all the assignments line up and that makes it easier to read the Makefile.
|I don't particularly like short options, but ok.
|What is the advantage of percolating a fatal error up and reporting it at another layer?
|Let's do this as a follow-on change.  There is just a whole bunch of stuff that is queued up behind this.  It would be tremendously easier to do a single git move on the entire directory contents once everything is commited.
|So that the build will  fail if it is not invoked correctly.
|It is not yet integrated into the u-boot build.
There may be issues with macros which are defined by the u-boot build system that would be passed to the Sandbox build.  Decided to avoid fighthing that battle for now.
|Is there a problem with them?
|You mean like the function comments in os.c? :-)

See associated header file.
|Timeout.  It's defined by U-Boot.
|Maybe not.
|It's not for debug code.  It's to output more infromation, if it's desired.  With the --verbose command line option, the daemon will print more information -- such as a memory layout, and what GPIOs are set to at startup time.
Withtout --verbose, it operates silently.
|If the shared memory initialization fails, it's a fatal error; there is no error to check.

The functions below either initialize correctly, or the device does not exist.
|See associated header file.
|There is no file handle.  This is just a region of memory.
The only other mechanism would be some sort of semaphore system, but that involves non-U-boot-y functions included in Sandbox.  Might not be a bad idea in the long term, but polling the memory is probably more-than-sufficient for the time being.
|That's already done: SANDBOX_SHM_KEY.
|There is nothing that can be done with the error, so there is no point in returning one.  If the shared memory doesn't exist, then there is nothing to do.  If the shared memory cannot be removed, then it's a system-level problem that cannot be solved.

It's better to log the issue locally than to separate the issue and the reporting.
|I don't agree.  This is a fatal error.  There is no point in returning a fatal error up through layers of calls to simply abort in some other context.  It makes the source &amp; executable larger, as well as making it harder to maintain because the fatal error cause and the fatal error processing would be done separately.
|Sure, that's possible, but let's do that as a follow-on change since there is already so much stuff lined up behind this.
Will add TODO.
|No, it can't.
This memory area must have the full definition of the structure because it's shared between processes.
|I will add such a TODO, but it will appear in a future commit because something like this should not hold up a commit.
|Both functions are void.
|fatal is only used on the startup path.  Again, there is no point in pushing fatal errors up to higher levels because it ruins the abstraction, and it's a situation that can be easily ignored by simply ignoring the return value.
|Will fix with a follow-on commit.
|There is no way to return an from the daemon back to the U-Boot process unless using the doorbell region.  This function flags that the u-boot-request action has failed; this particular function has not failed.  The error handling all occurs inside the U-boot process.

Returning an error here doesn't make sense because nothing has failed in the context of this process.
|The fprintf() is used  to ensure that unhandled commands output to the console, as it is likely an error in the implementation of the driver.  The requested command will fail in the context of U-Boot, and without this additional information printed on the console, finding why any command failed can be a huge burden.

Hiding this via a logging function would be approximately the same as removing it, because it will never be seen.
|Done
|Printing directly to stderr should be very rare.
|There is no error to check.  The error occurs in the context of U-Boot.
|Will update comments, but renaming will come as a follow-on.
|Done
|Done
|Done
|Done
|Done
|There are no keys in the Sandbox U-Boot.  You might be able to select one, but it won't verify.
|As I understand it, the signing &amp; keys happen in some other part of the Chromium OS build process, and are not part of U-Boot proper.   I haven't seen anything that does signing, but I also haven't looked that closely because actually making progress on getting this system working has been a higher priority.

I agree that it is an eventual goal to be able to do the whole verified boot, but not having it at this point isn't really a strong reason keep this change from going into so that forward progress can continue to be made.
|The function is no longer referenced when compiling for Sandbox.
|Done
|The reason there is no enum yet is that the build processes &amp; directories have not yet been melded into a coherent amalgam.  Without that, it ends up having either two copies of the same enumeration, or one side having constants while the other side (the daemon) has an enum.

In short, adding an enum here doesn't really solve the significant problem of two pieces of software having to agree on tokens which represent commands.

There is an intention to do this, but there is no sharing mechanism at this point; sandbox-api.h shouldn't have all that information, as then it would drastically explode in size.  So, some rework is necessary to make this more integrated as a whole... it's just not there yet.

As more information is gathered, it will become more clear how to do this.  For example, you could start out with an enumeration for SPI, and then add an enumeration for each additional device.  In the end, this would expand the global name space unnecessarily.  So, you could have a single  all-encompassing enumeration for every command (that also defines the parameters) which would be better for reasoning about the code, but having only three devices isn't really enough information to do a quality job on enumerating the necessary attributes.
(Having a single enumeration would also allow a set of global doorbell meta-commands that can be executed by all devices.  For example, for memory-mapped or command-based devices, you could bracket a series of actions with meta 'begin' and 'end' doorbell commands)
|Absolutely.  The memory is at a known address, and 32-bit addressable.
|You suggestion is an equivalence.  There is nothing wrong with the code as it is written.
|s cannot be greater than len, but it can be equal.  That's why the comment describes the situation and what is done to remedy the issue.

(As I read the comment, I feel ti can be better, so I'm updating it too)
|Simon, these are really *not* issues which should prevent code from being comitted.

Done.
|Done
|Done
|Done
|Done
|Done
|Done
|No.  size_t is an unsigned integer on the target machine.
These values are 64-bits in size, so it needs to be sized to 64-bits.
|Done
|Done
|An enum won't help here.  This function also directly returns the status of lseek().  Having the seek position rather than a pass/fail result might prove useful in error reporting.
|Done
|That's an equivalence, but won't generate better code.
The return length is never going to be greater than the requested write.
|Do you have a reference that shows it to be inclusive?  IIRC, my testing of the command is the reason for the current implementation.
|Done
|The error occurs in the context of U-boot.  There is no error which occurs here.
|Done
|Done
|Done
|These are values that must be returned by the device to be able to function.  Without these, the U-Boot driver doesn't function properly.  IIRC, I deterimined this value by tracing the actual MMC hardware on a Daisy.
|Done
|Done
|Isn't that obvious based on the file name?
|I think that's a premature optimization.  The compiler can do a better job of live variable analysis and data access than trying to manage the fields that are globally correct.
|Done
|Done
|See comment above in next revision.
|Done
|Done
|Done
|Done
|Agreed, but where?
|Compilation only.  It's a type that's unused in this driver, but defined &amp; used in the API.
|Done
|Done
|Done
|The compiler handles this just fine.

The first assignment will be removed by dead code analysis, and the second and third will be a single conditional assignment.

Given that the compiler will likely generate the same code regardless the approach, I prefer to write code that is easier to read &amp; reason about.
|Done
|Done
|Done
|Done
|It's a comment that labels another section.  It's really not going to change anything except provide more information for others.
|Agreed
|Mea culpa
|I'll use ARRAY_SIZE(). 
Reduces pollution of the global name space.
|Agreed
|That above comment makes no sense.  I was thinking about something different when I wrote that.

Loop-ified.
|It's not necessary.  Since the MMC devices are assigned sequentially, if the first one does not exist, then none of them exist.
|'dev' is a pointer into the 2-element array.
This function returns the index of the device.

dev == &amp;mmc_dev[0]  produces 0
dev == &amp;mmc_dev[1] produces 1.

Will comment.
|For genericity, probably.  This was intended to simply support the two devices, so from that perspective, no.

(I also tried to add more MMC devices by enlarging the array, but u-boot didn't cope well as it is written.  I've forgotten the errors, however.
|Done
|Since u-boot doesn't work with more than two devices, I'm not sure there would be much value here.  

I'll take a look.  A cursory glance makes me think the ENODEV condition will be somewhat uglier.
|I so rarely use #error that I didn't even think about it.  It's a better idea.  Done.
|I'll move it to sandbox.h, but as for another commit, I don't think that's the right thing.  Putting it in another commit would be a non-sequitor, as it wouldn't be useful for anything.  This is a change required to get vboot to compile &amp; link, so I think it logically belongs here.
|Done
|Ok.
|This would require another variable which would be global.  So, that means not using ARCH, since it's used in other targets.  It is really worth it to introduce a new symbol that is only used in one rule?
|The memory wipe isn't configured for the sandbox.
The shared memory is already zeroed on each start-up of the system.  The only thing it could do here is zero out the memory that is probably already zeroed.
|Is this a companion to the question above?
I can do that.  In fact, I'll log that the memory is not wiped, too.
|Okie dokie.
|Could you elaborate more on this?  I don't understand what prompted this comment.
|Done
|Done
|Done
|Done
|This syntax does not appear to work.  Do you have an example DTS which uses this for comparison?
|As far as I can tell, this identifier is checked only to see if it has been set, but is otherwise unused.

Ok, will unchange.
|I did.  And I posted a response.
I don't understand the reasons for changing or not changing these definitions.  Can you elaborate?
|Yes, why not?
|I don't know.  I'm copying a pattern here.  What's the difference?
|Patch Set 2: Looks good to me, but someone else must approve

Seems ok to me.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as e247f7ac4fceb44731ed9bcb37960561e9e69698.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 7d43665551c789ae1d2d71dd8b1cdcd6c25fdcc7.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as f48303bb40a90a2cf4ed845001874f6ccd2103ac.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Patch Set 2: Abandoned

This has somehow appeared in the tree without this being closed.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as ca0ae0e6ad23dcb881a8c607ae196f793ae0ceba.
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 18eb98b33b2c7160d9dfd730d50e73bc0bc3ff89.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Abandoned

This is superceded by another upload.
|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

Just two small comments.
|Patch Set 3:

This looks great.  Thanks for adding the description to the checkin message.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

This has somehow appeared in the source tree without this being closed.
|Patch Set 1: Abandoned

This was addressed upstream by modifying the underlying data structure to have the proper const-ness.
|Patch Set 1: (14 inline comments)

I think my Chromium.org account is finally fixed.  I've got some more comments, mostly they aren't that important.... but a few are pretty important.
|Patch Set 2: (8 inline comments)

Hi Paul,

I have taken a look, and while most of my comments are probably just being pedantic, there is one in particular that I do have a genuine concern: The caching of the fact that debug_fs is mounted; what happens if it gets unmounted?

Do you envision any problems running on a Tegra system?  It feels like a slower machine, so it might have more of an impact.  If you don't have a Tegra machine, you can certainly borrow one of mine -- if you want to try ktop on such a beast.
|Patch Set 3: Looks good to me, approved

Looks fine.  Thanks for putting up with my nits.
|Patch Set 2:

If you care, I've got a more generalized approach to passing environment variables through the chroot.  

All you need is an environment variable which contains the names of all the environment variables you want to pass through. 

I can provide a pointer to it if you're interested.
|Patch Set 1: Verified; Looks good to me, but someone else must approve

Pushing to source tree.
|Change has been successfully cherry-picked as 2a29bd4ec060d80ef5190b14c8758df93b9563cb.
|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

Thsi change looks good to me, but I do have a couple questions:

Does this change cause the amount of memory used to increase?  (We have limited memory)

Does this change alter the performance of the display in a negative manner?  (There is an X benchmark program, that used to be part of the standard install, but I can't recall the name...)
|Uploaded patch set 2.
|Patch Set 2: Verified

Anyone have time to take a look at this?
I'll also attempt to upstream.
|Patch Set 2:

In response to Olof's comment: 

I'm certainly not someone who knows the inner details of the ASoC sound system yet, but I'd like to throw out a couple things:

First, the original code (and the 98088 driver) have the check.  That's not
a clear indication that it's necessary, for sure.   It appears that the
98095 code was started from the 98088 code.  So, it originally could have been
unnecessary defensive coding which was carried over.  The impetus for the 
change was that if the check is actually needed, then the 98095.c code 
was wrong.

Secondly, is there a possible path where the two modified functions are called while something else is in the process of shutting down the driver?  Can shutting down the driver free memory that might be used by the other in-flight calls?

I'll point out the code to the original author and see what his take is on it.
But, for us there are three options:

   1. Take the change
   2. Do nothing, leave the code as it is, wait for the original author.
   3. Remove the check

#1 and #3 are nearly polar opposites.  If check is necessary, then #1 is correct and #3 is wrong.  If the check is unnecessary, then #1 is superfluous code and #3 is the correct tack.  I'm currently not qualified to know if there is a possibility of failure during shutdown, so I have to defer to one with more experience here.

In the meantime, I'll point out the issue to Peter H., the original author.
|Patch Set 2:

I wrote to Peter (the original author) about this.  Essentially he added the checks
as a 'future proofing'; as code moves forward, the sound system behavior may change.  So,
the checks are a hedge against people making semantic changes w/o fixing up all the code.

I'll send this upstream and try to get it submitted there, and then we can take it down from there.

And here is what he said, exactly:

Yes these error checking are there with the intent of catching conditions
that can happen if the later on the higher level code is changed in a way
that no longer check for the conditions they check today.   The source
code is open source and the ASoC interface is continuously evolving
and the ASoC tree is modified by many different people all the time.
Sometime new architectural changes will break previously working drivers.
If they are thorough, they will go through and change all the drivers that
are impacted by those changes. 

Since they are not speed performance bottleneck, having these extra
error checking that are not necessary adds a level of prevention against
kernel errors that could potentially happen in the future as a side effect
of some other code change in the layer above.  

Thank you so much for checking and improving this software.

Yes I liked your solution of moving the check of pdata above the use of it.

Removing them is a possibility if code space is a concern, although I think
you might encounter some resistance from the kernel.org maintainers
for removing error checking code.     

Yes a patch will be helpful.  Thanks for your help!

Regards,
Peter
|Patch Set 2: Abandoned

Abandoned in favor of review 1177.
|Patch Set 1: Verified

This change supercedes the one we have been discussing.
Perhaps the change of subject caused repo to create a new record.

I've addressed Doug's nit about alignment of '='.
Everything else is the same.
|Patch Set 1:

Also, this will be upstreamed first.
|Patch Set 1: Abandoned

Abandoned in favor of review 1177
|Patch Set 1: Verified

Here's a fix for chromium-os:15413.
Anyone got a few seconds to take a look at a one-liner?
|Patch Set 1: Do not submit

A variation of this change has already been checked in.  It sets CONFIG_NET_KEY to 'm' rather than 'y', but it should be good that way too.

I will not submit, unless there is enough feeling to change it to 'y'.
|Patch Set 1: Abandoned

This has been addressed satisfactorily by Mandeep with 
bcff5d047c17560d74d304e8ef7da6ce2e4d8361 in kernel.
|Patch Set 1: Verified

This is a cherry pick from broonie's tree of the change I upstreamed which prevents a potential NULL pointer deref.

Are there any special considerations for the commit message?  I don't see anything specific in the Kernel FAQ about that for things we take from upstream.
|Patch Set 1: Looks good to me, approved

Pushing to to main repository.
|Change has been successfully cherry-picked as b274e977c47824b971acbbe7f7d7cbf3dfab3ebb.
|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)

Tiny little suggestion that can be ignored.
|Patch Set 2: Looks good to me, approved

(3 inline comments)

Just a few comments.  
Since it's just personal opinion of the text, I don't think it will hurt to check it in without changes, if you so desire.
|Patch Set 2: Looks good to me, approved

LGTM
|Uploaded patch set 2.
|Patch Set 2: Verified

I've verified that this works for Tegra systems.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved

Shortened comment subject line.
|Change has been successfully cherry-picked as 60da642e64906fa22c1b32329a2892b03032ac4e.
|Patch Set 1: Verified

Here's a cherry pick of some Maxim 98095 code I just upstreamed.  It's fairly trivial.
|Patch Set 1: Looks good to me, approved


|Change has been successfully cherry-picked as 96dce1e7e288a6f408e0c7d6d3213b1375c9bf9e.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Abandoned

Superceded by a set of smaller changes which encompass this change.
|Uploaded patch set 2.
|Patch Set 2:

This is pared down enough that it shouldn't be too controversial.  There are several more commits which will follow this one.

Testing has not yet been completed; I'm at home right now waiting for comcast to fix the TV reception they broke yesterday, so I don' thave physical access to the machines for testing.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified

Argh.  Gerrit is frustrating.

I did have a response to your request to put the EQ data elsewhere, but it's disappeared.  I don't agree with that sentiment.

The data is private, and there is no need to make it public (another global symbol) by placing it into another location.  Plus, pedantically, making another file will have a greater impact on build times than compiling more lines in an existing file.

The EQ data was provided by Maxim.  It's not in the max98095.c file probably because it's not related to that layer of the driver.

I also don't agree with breaking every single change into separate changes; it promotes needless code churn, and slows down moving forward as each change should be tested, no matter how small.

I do support breaking conceptually disjoint alterations into separate revision control changes.

However, my personal views are not always relevant, and for this iteration of this change, I've taken the approach of just moving the arthur device data.

I will re-add the EQ data in a follow-on.
|Patch Set 6:

Anyone else got a few minutes?
Trivial change.
|Change has been successfully cherry-picked as cb1df0c421a599b7482006d611e9399a813a3423.
|Patch Set 1: Verified

Another precursor to enabling the max98095 codec for Arthur.
|Patch Set 1:

Anyone got some time?
A somewhat ugly but necessary change / cleanup for upcoming Arthur sound changes.
|Patch Set 1:

Thanks for the comments, Steven.

I didn't mean to imply that chrome-os-partner:3337 was causing the failure; my meaning was that my change did not cause a regression and break any currently working systems.

My priority is to get sound working on Arthur, and then start to reduce the outstanding issues, while improving the current sound for the boards the Chromium project is concerned about.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Merged source tree and re-uploaded.
|Change has been successfully cherry-picked as 47df50a9ed7bbb37858a2efa79bdd4a002744534.
|Patch Set 1:

If you've only got time for reviewing one change, review this one too!  It will double your productivity.

This is an addition of Max98095 Codec equalizer coefficient data.... and the added data is not even used yet!
|Patch Set 1:

Olof,

What's you opinion on the topic of adding this data?
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Re-uploaed to allow commit.
|Change has been successfully cherry-picked as 466b656ac191e13ec31c32f2d220f860a7a3234f.
|Patch Set 1:

Another precursor change before adding the max98095 initialization.

Pretty simple stuff.
|Uploaded patch set 2.
|Patch Set 2: Verified

Fixed nit.
Will probably commit after lunch; got stuff sitting in line behind this one.
|Patch Set 2: Looks good to me, approved

Commit...
|Change has been successfully cherry-picked as f5f94cb3c1891ccc1144c4afbdfce56b283ee6f2.
|Patch Set 1:

Still rebuilding, and need to validate with testing.
Diffs are a bit ugly, but the resulting code is easier to read.
|Uploaded patch set 2.
|Patch Set 2: Verified

Building &amp; testing done.
Had to fix on error in compilation, but everything is ready to go now.
|Patch Set 2:

Steven,

Can you point me in the right direction to get the upstream tegra stuff?
|Patch Set 2:

Stephen, 

Sorry about the 'Steven'.

As for the max98095 affecting the seaboard.c file, this is because I'm following the current methodology in seaboard.c, which has wm8903-related initialization in it.

Let me ask you this:  Would it be a big problem to proceed with this change and then integrate with the upstream code later?  I'd really like to get these changes committed so that some remote people can easily access them as-is.
|Patch Set 2:

The justification for adding the max98095 support into the seaboard.c file is that it's a seaboard with a different sound codec.  The changes to initialize the max98095 are small, isolated and really not significantly different than the other board-localized changes for Kaen and Aebl.
|Patch Set 2:

Stephen,

Regarding your comments from 6/30:

I do not have the other changes out for review yet, as it involved another set of cleanup which 'needed' to be done first.

However, I've decided to back off on that cleanup to get these max98095 changes in to the tree so that they can be used by other non-local teams.

I will probably have that up for review by late morning 2011.07.07 PST. 

Overall, I agree that there is a lot of room for cleanup &amp; improvement in this code, but I'd like to undertake that after I have this change in.

As for the other people on the review list: can you folks take a look?
|Patch Set 2: (5 inline comments)

I've addressed most of your comments and will have a new upload very shortly.
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)

Waiting for an updated patch so I can see what to do with snd_soc_dai_set_sysclk().
|Uploaded patch set 4.
|Patch Set 4:

I think I've addressed all the issues.
Anyone got some time?
|Patch Set 4: Verified

Thanks Stephen.
Anyone else got some time to take a look at this.
No new features, just cleanups.
|Change has been successfully cherry-picked as d481821b0c6e62586952471426b217ce51ce3ae0.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned

It's not appropriate to do this now.
|Patch Set 2: I would prefer that you didn't submit this

(39 inline comments)

Besides the comments I've made inline,  I've got a few global comments:

  o Your commit message ought to be more descriptive. 
    I don't know what 'dep.' means.
    What does this commit do?
    More importantly, *why* is this being done.
    Please be dscriptive in your testing information:
    how should one run this code?  What is the expected 
    output -- console, speaker, headphone, HDMI?

  o Comments about what work functions perform 
    would be a good thing.  Not every function probably 
    needs detailed descriptions.  If you structure the 
    code nicely, it will frequently be clear what's 
    going on

  o Consistency is a virtue.  Please be consistent in the
    use of punctuation in your comments (i.e., sentences
    should end with a period, etc.).  

  o Consistency in code is also a virtue.  Please be 
    consistent in spaces after keywords and around binary
    operators.

  o Be careful when mixing signed and unsigned types in 
    expressions.
|Patch Set 4: I would prefer that you didn't submit this

(32 inline comments)

Sorry for the delay in responding.
I think there are still lots of little nits, some of which really should be addressed and some which are not that important.  I think it's important to have a consistent approach to writing code, so that's one of the things I pick on; it's not personal.

You've got a couple places where you use functions which should be avoided, and a couple places in the code which would benefit from refactoring or providing helper functions.

I'm still not clear how to invoke this code, and I think it would beneficial to have the invocation concept documented.
|Patch Set 7: I would prefer that you didn't submit this

(16 inline comments)

I don't feel I know enough about the Python part to give a cogent review of it.  There are a few logic errors which I hope you can fix before submitting this.
|Patch Set 8: Verified; Looks good to me, approved

(4 inline comments)

I have a few small comments, one of which can be ignored.  Given the time constraints to get this checked in, I think it's ok to check this in.  If you agree that any of my comments are legitimate concerns, can you address them, or barring that, at least put a TODO in the code which explains the issue?
|Patch Set 10: Looks good to me, approved


|Patch Set 1: Verified

Here's a quick change which addresses chromium-os:17558.
Anyone got time to take a look?
|Change has been successfully cherry-picked as d6ae1ec95ef1532828bbf82f1b642d0966f08ca5.
|Uploaded patch set 2.
|Patch Set 2: Verified

Trivial change I've got laying around that provides some cleanup for the Tegra boards.
|Patch Set 2: No score

The common table + additional data seems ok to me.  The one subtle difference is that I don't have an audio device in the arthur table at this point.

This change, at least in my current tree, was facilitating further cleanup around the individual devices and the fact that they all have similar function tails.

But, I'll resubmit with a common table and additional devices.
|Uploaded patch set 3.
|Patch Set 3: Verified

Second attempt.  This time the common devices are handled as it was, and the board-specific devices are handled as a separate set of data.

Arthur will ultimately get a device for the audio codec, but it does not have one yet.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved

Fixed if() brace &amp; '!= NULL' issues.
|Change has been successfully cherry-picked as de1b3ad247b90d191e210315177dfa27b30e15c8.
|Patch Set 3: (1 inline comment)

I've only one small comment.
|Patch Set 3:

Grant asked me to take a look at Abhishek's outstanding reviews; I just wanted to point out that I'm not a qualified reviewer for Portage related stuff; I'm just learning myself.
|Patch Set 1: Verified

Final public change for Max98095 codec on Arthur.

Sound won't play on Arthur with this change because the Camera is not powered on.  I have a hack which will always enable power on the camera, but I don't think it's appropriate to check that in.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified

I think I've addressed all the comments.  In the process of doing so, I did a little more refactoring to try and keep wm8903- &amp; max98095-specifics from becoming intertwined.

Set #2 can be ignored.  That was an overzealous application of 'tabify' on the entire source; 'tabify' should probably be done at some time, but now is not that time.
|Uploaded patch set 4.
|Patch Set 4:

Updated response comments.
|Patch Set 4: Verified

Updated code to address Doug's issues.
|Patch Set 3: (6 inline comments)

Maybe this time my comments will be published.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified

I've moved the speaker enable to the desired location.
|Uploaded patch set 7.
|Patch Set 7: Verified; Looks good to me, approved

Rebased, and now committing.
|Change has been successfully cherry-picked as 5ec62b208fb76672c572aae676b2a27c3e0cee17.
|Patch Set 4:

I don't feel I'm qualified, yet, to provide any type of authoritative review of ebuild files.  I've added David and James, and hopefully they will take a look.
|Patch Set 1: Verified

I was getting odd output when exiting the chroot this morning.  I tracked it down to the handling of the syncer process handling, and offer this patch to make it a little more robust.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved

Addressed comments from David James.
Retested with changes; same results.
|Patch Set 2:

Addressed comments from David James.
Retested with changes; same results.
Unable to self-approve, and tree not closed.  So, I guess we've turned on approval checking.

Anyone want to approve for me?
|Patch Set 2: Verified

Ah, perhaps it's because my poke of the 'verified' didn't register.  Let's try to submit again.
|Change has been successfully cherry-picked as 25bf949c636ba2668696585ee88237fe5e6b864d.
|Patch Set 1: Verified

Turns out '-s' isn't correct.
I could use 'stat' to get the size if you don't like the 'cat'.
|Patch Set 1: Abandoned

Have a better solution.
|Patch Set 1: Verified

Ok, I've applied the fix, and made a simplification which will make it easier to remove the warning message at some time in the future: immediately remove the file when it's found to be of size 0, and no second size check is needed.
|Change has been successfully cherry-picked as 18594a87ba4095e60ec2838610f82b31b73632fd.
|Patch Set 1: Verified

Here's a little more information that's not really meant to be part of the commit:

  o Would like to ultimately start this script on login
  o Would like to ultimately stop this script on logout

The PID of the script needs to be stored for killing, but
that is not implemented yet.

This script can be present on all machines; it will only function on Seaboard, Kaen &amp; Aebl; it exits with a 0 error code on other machines.  If running on one of the aforementioned machines, it runs forever in the background.

This change set adds the script to the repository, but does nothing else. The next change should put the script on the device, and that will allow the factory to do their testing.
|Uploaded patch set 2.
|Patch Set 2: Verified

TODO is at the beginning of the file.
|Change has been successfully cherry-picked as 73240ddcf872e726d9e2e963d74af9236db3071f.
|Patch Set 1: Verified

This change is the second step for enabling the automatic headphone / internal speaker switching.  It will also make the factory able to test that the headphones, internal speakers and headphone switch works.

It installs the headphone-jack-monitor script onto the device.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 9b729bf92a11fd3e64cdab5727a0b9709fb67ac5.
|Patch Set 1: Verified

This change adds the saving of the PID so that the process can be killed on logout.   It also provides a little cleanup, and adds a piece of hardware that is being used for Tangent (?) in Waterloo.
|Change has been successfully cherry-picked as 86707fe24b868066fe1ebfed5bcec290ffc581b2.
|Uploaded patch set 2.
|Patch Set 2: Verified

Final change, for now in the process of getting the headphones  &amp; internal speakers multiplexed based on the state of the headphone jack.
|Change has been successfully cherry-picked as 0eab2c3d290c45db8f6064bdc62573e271ae4d60.
|Patch Set 1: I would prefer that you didn't submit this

Hi Tom,

It's great that there is progress being made to get the T30 u-boot
changes committed into the mainline u-boot sources, but I think that
this change is way too large to be reviewed &amp; reasoned about in one
chunk.

We've got a variety of different boards that are using u-boot, and as
we've recently experienced more than 7 days of bricked boxes due to
issues with u-boot, and I'm afraid that checking in such a large
change (by Gerrit's count, it's nearly 8000 lines of code) may
accidental cause those other boards to suffer more downtime-inducing
regressions.  And, with a single change that's 8000 lines long, we
can't leverage 'git bisect' to find the actual error quickly.

Furthermore, the amount of time required to sit down actually produce
a quality review by trying to reason about such a large change is time
prohibitive for everyone, as we're busily working on a variety of
things.

It's of the utmost importance that we keep TOT working for every board
we have, so I'd like to suggest that you break this single change set
down into much more manageable changes which keep TOT working, and
which gradually adds functionality towards being able to boot Linux on
the T30 system.

A colleague at vmware used to tell new hires &quot;each person providing a
review for your code is doing you a favor: you can't get the code
committed until it's reviewed, everyone is busy, and no one likes to
do code reviews, so you can at least try to do them a favor and
produce smaller sets of changes for them to review.&quot;

I've always been impressed with that; I think it's sage advice and I
believe it results in faster turn around and higher quality on
reviews as the task will immediately be perceived as something that's
easily approachable.

Can you help us out and split this review into chunks which are easily
reasoned about and won't take hours / days to review?
|Patch Set 1: Verified

Time to commit.
|Change has been successfully cherry-picked as 4d88a138e4763bf1c748e7f69c03b6e77097b85e.
|Patch Set 2: Looks good to me, approved

LGTM
|Patch Set 2: Looks good to me, but someone else must approve

Is there any risk of arithmetic overflow in any of expressions you've created?

If there is, what are the consequences?
|Patch Set 2: (1 inline comment)

I have a small concern, but since I'm not sure if it's a valid concern, until I understand more, I prefer to give no score.
|Patch Set 3:

I don't know how all this comes together.  Is it ok to update the manifest if the repositories are not yet commited?
(Are these repositories committed yet?)
|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)

This change conceptually looks great to me, but if I'm reading it right (and I'm certainly no expert on our boot process), it looks like (and according to the commit message) you are moving the monitoring script to be started during boot, and killed during shutdown.

My preference was to start it on boot-up, but I was discouraged from doing so.  Instead, I was encouraged to make it started on login and stopped on logout.

My understanding is that we are very sensitive about our boot-up time, and any changes to it trigger some pretty demanding justification for the change.

I suggest speaking with Puneet and / or Micah about making this start at boot up.

If you want to split out the headphone-jack-monitor script change, I'll +2 that in a heartbeat.  Please explain what issue it resolves; it makes it easier when reading commit logs to know what a checkin does, especially since access to chrome-os-partner is restricted and many people will not be able to look at that ticket.

Also, could you be more specific about the tests that you did?  Could you please verify that sound is still multiplexed through the internal speakers &amp; headphones.  And, please provide details on how you tested that your change to the script works -- so that others can reproduce the test.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Verified

Is there anything else I should do, other than building for seaboard?  How can I verify that this file is actually used?
|Change has been successfully cherry-picked as e40a5fa731dc570bbcc551874aedaf810a4f7d02.
|Patch Set 1: Verified

First step in making a comprehensive sound infrastructure test.
|Uploaded patch set 2.
|Patch Set 1: (5 inline comments)

A few comments to your comments.
|Patch Set 2: Verified

Besides correcting the 'alsactl save' error, I've made a few changes with this patch:

  1. Support for ZGB.
  2. Improved the method of determining the codec.
     It will be easier now, in theory, to add support
     for a new codec.  (see get_codec)
  3. Better error handling if a codec is found and
     no test data is present.  (see run_once)
|Uploaded patch set 3.
|Patch Set 3: Verified

No codes changes between #2 and #3.
I just updated the commit message to reflect that it was also tested on an Alex.
|Change has been successfully cherry-picked as c53d77d4212c38d972fa414c9b79cd3552d24adc.
|Patch Set 1: Verified

Add the Alsa saved state file to the Seaboard build.
|Change has been successfully cherry-picked as cf7bac2040668751d049d2e8ba50a02c7f5722e8.
|Patch Set 1: Looks good to me, approved

LGTM.

Shortly, this will be superceded by  the use of /etc/asound.state.
|Patch Set 1:

I just realized that your subject mentions the microphone.
Is 'Digital' a microphone volume?
Why does it control the internal speakers?
Also, could you mention on which hardware the sound is inaudible?  Does this change have an adverse affect on any other machines -- is the sound too loud there?
|Patch Set 1:

I'm increasing the revision number because Portage is still opaque to me.
|Uploaded patch set 2.
|Patch Set 2: Verified

I've updated the file name to be '...3-r1' instead of '...4'.

(What affect will this have on my next build?)
|Change has been successfully cherry-picked as 93a1ae78af81a3d89d9d05a1845b6a4f00c4af38.
|Patch Set 1: Verified

I think this should fix the errors like at: http://cautotest/results/dashboard/netbook_MARIO_MP/x86-mario-r15/kerneltest.html for the sound_infrastructure test.
|Uploaded patch set 2.
|Patch Set 2: Verified

Uploading.
|Change has been successfully cherry-picked as 1080977f60c6cce7d36e102675b2f3a2344742be.
|Patch Set 1:

We've made progress on sound issues between Chrome and Chrome OS.  We're working on a daemon which will send a message to Chrome when Alsa is ready to use, and Chrome will simply wait until it receives the message before it does anything sound related upon login.

With this work pending, I am not sure that we need this change.

Terry is working on the udev notification to the daemon, and after we have that available, I'll be talking with the Chrome folks about the message they need.

If this isn't necessary for other reasons, I think this can be abandoned.

See chromium-os:20618 and what it is blocked by.
|Patch Set 1: Verified

Improvements to the sound test.  It's a little bit more complete, and now supports stumpy.
/etc/asound.state is now on all boars, and now tested for existence.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified

Addressed, mostly, comments from last upload.
|Patch Set 2: (1 inline comment)

Todd raises an interesting question, but I don't know how to avoid the situation *and* have a test which works with appropriate recognition of hardware.

I suppose we could put the data for the test into separate files, and only load the data from files which exist which exist...
|Patch Set 2: Looks good to me, approved

I've got approval from both hayter &amp; puneetster that showing these code names is ok, after all, they are code names.

Also talked to Todd and he had no other issues with the change.
|Change has been successfully cherry-picked as c2ff10a7a3cea13e7cd81b6369c2b6445311ba13.
|Patch Set 1:

I'm not yet qualified to review this, but if it fixes the boot issues on Seaboard, I'm all for it.
|Patch Set 1: Verified

This is a very early review of what will become the daemon which will handle audio &amp; visual devices.

It is not functional at this point, other than outputting a 'hello, world' type message.

I expect that this project will grow dramatically, so I've made a flexible and extensible build process for it.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified

Another update of the daemon, working out a few things about the build process &amp; how it will interact with Portage.

If 'BOARD' is set in the environment, then that will be used to set up board-specific hardware details at compilation time via the include files that I've added with this update.  The actual mechanism for doing this is not yet determined.

But, I imagine that boards with HDMI support will have something like:

#define ADHD_HDMI 1
#define adhd_hdmi 1

While boards without HDMI would have

#undef ADHD_HDMI
#define adhd_hdmi 0

The uppercase identifier allows easy HDMI-specific conditional data definition, while the lowercase allows easy compile-time checks, like this:

    if (adhd_hdmi) {
        ...
|Patch Set 2:

In response to Dylan's comment, please read my comment for the upload of patchset #3.

Essentially, the board-specific header files will define attributes of the hardware in a non-board specific way.  So, boards which have HDMI capability will have an identifier that indicates such by being '1', and those w/o HDMI will have the identifier set to '0'.

These files might also define inline functions which do the work.  Those with the capability would have bodies, and those without capabilities would have empty bodies, or be empty CPP blocks.

For example:

static inline hdmi_helper_function(...)
{
   /* some work */
}

-vs-

#define hdmi_helper_function(...) (void)(0)


This facilitates writing board-specific main source code that is not dependent upon CPP-isms; let the compiler do the work of removing dead code.  Here's a continuation of my contrived example:

   if (gavd_hdmi) {
      /* do some HMDI-specific work */
   }

...


   hdmi_init_function();
|Patch Set 3:

Disregard my previous message.

In response to Dylan's comment, please read my comment for the upload of patchset #3.
Essentially, the board-specific header files will define attributes of the hardware in a non-board specific way. So, boards which have HDMI capability will have an identifier that indicates such by being '1', and those w/o HDMI will have the identifier set to '0'.

For example, Kaen might have:

#define gavd_hdmi (1)

While Seaboard would have

#define gavd_hdmi (0)

These files might also define inline functions which do the work. Those with the capability would have bodies, and those without capabilities would have empty bodies, or be empty CPP blocks.

For example, for Kaen:

static inline hdmi_init(...)
{
   /* some work */
}
While, Seaboard might have:

#define hdmi_init(...) (void)(0)

This facilitates writing board-specific main source code that is not dependent upon CPP-isms; let the compiler do the work of removing dead code. Here's a continuation of my contrived example:

   if (gavd_hdmi) {
      /* do some HMDI-specific work */
   }

  // Init HDMI if present, otherwise, NOP
   hdmi_init();
|Patch Set 3: (3 inline comments)

If I must do a 'review' to release my comments, then I guess I must.
|Uploaded patch set 4.
|Patch Set 4: Verified

I've changed the comment around the VERBOSE construct in make.mk.

I've also confirmed that BUILD is NOT set by build_packages.  Instead, the BUILD variable is set by the ebuild, and the ebuild I'm working on does that now.
|Uploaded patch set 5.
|Patch Set 5: Verified

Addressed Terry's comments on patch set 4.
|Patch Set 5: Looks good to me, approved

Everyone is happy now.
|Change has been successfully merged into the git repository.
|Patch Set 1:

I was told by David James that the old style of ebuild-creation was to use a symlink, but now they'd prefer that you uprev the actual file and dispense with the symlink altogether.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified

My first ebuild, so I don't doubt I might be doing something wrong still.  Can you take a look at let me know what I need to fix?
|Uploaded patch set 5.
|Patch Set 5:

Uploaded new patch.  Now retesting.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 4: (10 inline comments)

I think I've got everything in order.
|Patch Set 5: (2 inline comments)

I've addressed all these issues.
|Patch Set 6: (1 inline comment)

Moved the IUSE data to the eclass.
|Uploaded patch set 9.
|Patch Set 9: Verified

I think I'm done.  Can someone take a look?
|Uploaded patch set 10.
|Patch Set 6: (4 inline comments)

I've addressed all your issues.  Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: Verified

The only difference between this and #10 is that I added a comment about the values in the 'boards' array.

I think it's ready to look at again.
|Uploaded patch set 12.
|Patch Set 11: (1 inline comment)

Removed unneeded ';'(s).
|Patch Set 12: Verified

Updated with removed ';'(s).
Re-testing all cbuildbot commands.
|Patch Set 12: (5 inline comments)

Addressed the comments, and am currently retesting.
Will upload new changes shortly.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14: Verified

I've addressed all the comments.
I've run the x86 build bot tests, and will now go and do the arm ones.

Have I missed anything?
|Patch Set 14:

David,

Is everything good enough to submit with patchset 14?
|Uploaded patch set 15.
|Patch Set 14: (1 inline comment)

Addressed with next patchset.
|Patch Set 15: Verified; Looks good to me, approved

Updated 'a86-alex' to 'x86-alex'.
Transferring +2 from previous review.
|Change has been successfully cherry-picked as 1cbeca5fae5d0f993e11d22c6359e8b52129ee5d.
|Patch Set 1: Verified; Looks good to me, approved

This change improves the build process for the ADHD project.
|Change has been successfully merged into the git repository.
|Patch Set 1: Abandoned

No longer needed.
|Patch Set 1:

Switch from warning to dying when the value for BOARD cannot be determined.  See commit message for justification.
|Patch Set 1: Verified

Switch from a warning to a fatal error if the value for BOARD cannot be determined.

A follow-on change will add support for the overlays which are not yet handled.
|Change has been successfully cherry-picked as ac43a88f1735ec786a96a37f0a16045f3bee711e.
|Uploaded patch set 2.
|Patch Set 2:

I don't know if this is the right thing to do, but it appears to me like these overlays need USE flags to discriminate between different boards.
|Patch Set 2: Abandoned

This approach is deemed not right.
The issue will be addressed through setup_board.
|Patch Set 1: Abandoned

No longer needed.
|Patch Set 1: Abandoned

No longer needed.
|Patch Set 1:

My attempt at adding the missing boards to the 'cros-board.eclass' file.

I've followed my method of trying to be like the BOARD variable, but that breaks with some history such as 'alex' and 'mario'.

I'd prefer the full name for the keyword, but whatever is deemed correct is ok with me.

These keywords will, of course, need to match whatever approach is taken in setup_board.
|Patch Set 1: Abandoned

Superceded by Matt T's change http://gerrit.chromium.org/gerrit/#change,7509
|Patch Set 1: Abandoned

No longer needed.
|Patch Set 1: Verified; Looks good to me, approved

Another update to the infrastructure of the ADHD system.
It's still not useful yet.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved

Another drop of infrastructure for the ADHD system.
Next step is to integrate this into the full build process.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

Same as revision #1, but rebased as required.
|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved

The only suggestion would be to put an exact example of the shell prompt at level one, and above level one, into the commit comment.

Other than that nit, this will be a nice addition.
|Patch Set 1: Verified

Here is my attempt at making the ADHD ebuild get built when Chromium is built.
|Change has been successfully cherry-picked as efba40e7ad292aa9adcc741dfaf828ca1a1e8488.
|Patch Set 1: Verified; Looks good to me, approved

This should fix the x86-generic build.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved

Builtbots build in ways I didn't understand.  Add missing file 'board-tegra2.h'.
|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

A little cleanup on the header files and obsolete linker scripts.
|Change has been successfully merged into the git repository.
|Patch Set 1: Abandoned

Wrong commit message.
|Patch Set 1: Abandoned

No longer needed.
|Patch Set 1: Verified; Looks good to me, approved

This change updates the build process to make linking with system-provide libraries easier.  Now, you just add the system library to 'MY_LIBS' and everything is handled automatically.
|Patch Set 1: Abandoned

No ready to be committed.
|Patch Set 1: Verified; Looks good to me, approved

A change which simplifies the use of external libraries.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved

Rename 'alsainfo' utility to avoid confusion with anything provided by the Alsa utilities.
|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

I understand Richards complaints, but sadly we're not ready to replace the script with the daemon.  I've nearly gotten to the point of replacement, but... maybe next week.

This change is really necessary to make the asymptote sound with the script.

If you're so adamant about fixing the issues, please point me to your change and I'll make sure it works -- but my seaboard is on loan right now to unbrick it, so I can't finish the testing until my seaboard is fixed.

Yufeng, do you have the resources to ensure Richard's changes work?

Richard, any chance of letting this slide in?  The script will be removed very soon, I promise.
|Patch Set 1: (1 inline comment)

Added another comment about your change to the controls.
|Patch Set 1: Verified; Looks good to me, approved

A small set of improvements.  See commit message for details.
|Uploaded patch set 2.
|Patch Set 2:

Updated to have volatile on 'exit' and 'quit'.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Commit.
|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2:

Comments back at ya!
|Uploaded patch set 3.
|Patch Set 3: Verified

strlen(len) has been replaced with the correct strlen(name) in sys_input.c
|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)

Addressed the major comments.
|Patch Set 4: Verified

Addressed most new comments.  See my responses in patch 3.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved

Remove checking for OSS files, because after an upcoming kernel configuration change, they will no longer exist.
|Patch Set 1: Abandoned

Superceded by 8220.
(I don't know why repo upload did that!)
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified

As Dylan pointed out, I didn't remove all the references to 'oss'.  
Fixed.
|Patch Set 2: Looks good to me, approved; Ready

In to the repository it goes...
|Patch Set 2:

David, can you explain the chrome-bot error?  I don't understand it.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transferring approval to new patch.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready

Another attempt to get through the automated build system.
Transferring approval from last upload.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready

Transferring approval to another shot at making it through the submit system.
|Patch Set 1: Verified; Ready

And now we wait for the mysterious system which plucks changes from gerrit and ushers them to their seat in the repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready

This change makes sure all boards compile.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

This change is another step to removing headphone-jack-monitor.

It's not the idea way to implement things, but it does move us to a point where headphone-jack-monitor no longer exists, and all sound-related details will be done in the daemon.
|Patch Set 1: Abandoned

Superceded by 8280.
|Patch Set 1:

I don't know why repo/gerrit decided to make a new review... but here it is. 

This is supposed to be a second patch to 8279.
The only difference is that I added a descriptive comment to board-tegra2_kaen.h.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Provide monitoring of the headphone jack.  A precursor to actually remove the headphone-jack-monitor script.
|Patch Set 1: Looks good to me, but someone else must approve; Not Ready


|Patch Set 1: (4 inline comments)

I will address the comments in the next upload.
|Patch Set 1: Abandoned

Subsumed by 8381.
|Patch Set 1:

This change stops the spawned Alsa utilities from spewing text to the console.
|Patch Set 1: (3 inline comments)

Changes will be made with the next upload.
|Patch Set 1: Abandoned

Subsumed by 8381.
|Patch Set 1: Verified; Ready

The commit message says it all.
|Patch Set 1: Not Ready


|Patch Set 1: Abandoned

Subsumed by 8381.
|Patch Set 1: Verified; Ready

Enable headphone jack monitoring on Able in gavd.
|Patch Set 1: Not Ready


|Patch Set 1: Abandoned

Subsumed by 8381.
|Patch Set 1: Abandoned

There is a typo in the file.
|Patch Set 1: Abandoned

Subsumed by 8381.
|Patch Set 1: Verified; Ready

Gavd is up-to-date, now it's time to throw the switch and stop using the headphone-jack-monitor script.
|Change has been successfully cherry-picked as af26631333984d187d7e365fd94fc21461555912.
|Patch Set 1: Verified; Looks good to me, approved; Ready

A simple readme file.
|Patch Set 1: Abandoned

Subsumed by 8381.
|Patch Set 1: Verified

Sorry folks,
I smashed all the changes into one change because I couldn't figure out how to modify a previous commit.  I wanted to modify the first commit in this chain of changes, via git, but I don't know how.

So, I squashed everything to bring everything in with one commit; I've been testing with all these changes in the tree anyway, so the software will still work as an integrated commit.

Please take a look.
|Patch Set 1: (2 inline comments)

Why do we have to do a 'review' to send our comments out to the public?
|Change has been successfully merged into the git repository.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified

Some new things to test for in regards to the sound system.
|Patch Set 1: Looks good to me, approved; Ready

Submit.  I am the only one using this test anyway.
|Patch Set 1: Verified

A change to make asymptote work out-of-the-box. 
At least until we can use /etc/asound.state.
|Patch Set 1: Looks good to me, approved; Ready

Submit.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

First in a set of changes which will move audiopolicy.conf to be under the control of ADHD.
|Patch Set 1: (2 inline comments)

Uploading new patch shortly.
|Uploaded patch set 2.
|Patch Set 2:

I've removed the ';' and added 'expect fork'.
|Patch Set 2: Verified; Ready

Submit.
|Change has been successfully merged into the git repository.
|Patch Set 1: Abandoned

Drat... did not want a new change.
|Patch Set 1: Verified; Ready

Submit.
|Change has been successfully cherry-picked as 557e7b7618bc214e7a8bd4a55fcfd2099552e7ec.
|Patch Set 1: Verified

Part 2 of 4 in moving the ADHD Upstart script into the ADHD package.
|Patch Set 1:

FYI: This whole set of changes was suggested by jrbarnette, and part 1 was approved by keybuk.
|Change has been successfully cherry-picked as 11c1b42c7e685099dfe5b02de93d70969d458b8f.
|Patch Set 1: Verified

Part 3 of 4.
audiopolicy.conf is now removed from source tree &amp; device.
gavd still started.
|Change has been successfully cherry-picked as b7e435d240b1dd5bcd66d00ea1b9befdc19c6c2d.
|Patch Set 1: Abandoned

Superceded by 8496.
|Patch Set 1: Ready

And this concludes the move of the init script.
|Patch Set 1: Verified

And this concludes the move of the init script.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

A simple change which adds some commentary about a specific API, and adds some diagnostics to help diagnose a defect with /dev/input.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

Let's move the asound.state files so that they are easier to maintain.  At least for the time being.
|Patch Set 1: Abandoned

Superceded by 8520
|Patch Set 1:

A reduction of one step.  From 5 to 4, because audioconfig-board cannot be removed yet.  It still installs chromeos-per-session.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2:

Renamed, uprevved, ebuild.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 362fd06858b4525155ca7f98d7c9cfb3945e7630.
|Patch Set 1: Verified

Part 2 of 4.  

(Disregard step 3 at this point.  I have think I need to uprev the ebuilds.)
|Change has been successfully cherry-picked as 56e4753936a2ec7bf2a862a981b02db9197c1e57.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Adds missing files; should fix build breakage.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

Final step in moving asound.state to be part of adhd.
|Uploaded patch set 2.
|Patch Set 2: Verified

This update incorporates Mike's improvements to the ebuild.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved

Improved comment on line 35 and tabified line 37.
Assuming approvals stil stand.
|Change has been successfully cherry-picked as e74a06bdaef0fef2f4964b5c6917802f45807a35.
|Patch Set 1: Looks good to me, approved

I can incorporate your changes into part 4 of this set of changes, if you like.

If not, then your change looks ok, and I'll deal with the conflicts on my end for part 4.
|Patch Set 1: (1 inline comment)

I have a question / comment about the upstart install.
|Patch Set 1: Looks good to me, approved

Mea culpa. :-(
|Patch Set 1: Verified; Ready

And now, let's wave a bouncing dead cat and hope this change can make it through the auto-submit feature.
|Patch Set 1: Abandoned

I don't like this anymore.  It's not my friend.
|Patch Set 1: Abandoned

This one doesn't like me anymore.  I'm not its friend.
|Patch Set 1: Verified

This change implements an outstanding suggestion by Terry.
Don't really need this yet, but as I'm sitting around waiting for tests on the Portage package 'alsa-plugins' upgrade,  I figured this would be easy to do and not very disruptive.
|Patch Set 1: Looks good to me, approved; Ready

Trivial enough.
|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2:

Hi guys,

I used the documented script (in the commit message) to upgrade the alsa-plugins package.  However, Jie Sun had put a 1.0.24  into the system, and it resides in portage-stable.

The script I ran upgraded the one in portage_stable.
You said to never touch portage stable.

What should I do?
|Uploaded patch set 3.
|Patch Set 3: Verified

Matt,

I've updated the commit message to show the equery information you requested.
|Change has been successfully cherry-picked as dc29aa4eacc4271ece4e763c5307993b0c10ceba.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified

A stop-gap fix which addresses stumpy sound volume.
This must be committed after #9739.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

An easy review which updates the sound_infrastructure test to reflect the true hardware stumpy has.

This needs to be committed before #9736
|Patch Set 1: Looks good to me, approved; Ready

This change allows the autotest to pass on Stumpy hardware.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified; Looks good to me, approved; Ready

Fix build breakage resulting from undefined use of 'NULL' for some build types.
|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved

Thanks for fixing this.
|Patch Set 1: Verified

Yet another stop-gap measure (YASGM) in the ADHD.
This time it's to facilitate the move to Kernel 3.0 -- the names of the input devices have changed.

The names of the devices are needed until we can start using udev events.
|Change has been successfully merged into the git repository.
|Patch Set 2: Looks good to me, but someone else must approve

LGTM, modulo other comments.
|Patch Set 1: Abandoned

msb points out that it's already supposed to be sorted.
It's almost sorted.
|Patch Set 1: Abandoned

msb pointed out that this file is already supposed to be sorted.
It almost is.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved

Any possibility that you can get a real asound.state file for Waluigi yet?

(alsactl -f /tmp/asound.state store)

That would be better than an empty file, but it can be filled later.
|Patch Set 2: Looks good to me, approved

Thanks!
|Uploaded patch set 2.
|Patch Set 2:

The plan is to abandon this change.
|Patch Set 2: Abandoned

Taking a different approach to incorporating the wm8903 code.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 3: Abandoned

Taking a different approach to incorporating the wm8903 code.
|Patch Set 1: Abandoned

Squashed change into a different review.
|Patch Set 1: Restored

I want this to be my friend.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

This is superceded by another changed.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Abandoned

Taking a different approach to incorporating the wm8903 code.
|Patch Set 1: Looks good to me, approved

If this is for kernel-next, please submit.
If this is not for kernel-next, then isn't this already in the sources?
|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: I would prefer that you didn't submit this

Since the data for the test is now split out into separate files, I think this change should be abandoned.
|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

Nothing serious, but I think it's better to follow the existing coding convention.
|Patch Set 1: I would prefer that you didn't submit this

The idea behind the initialization and finalization system was to initialize &amp; finalize resources, and I'm not particularly keen on the idea of making them asymmetrical.  I believe that if something has been initialized, then it should be finalized.

So, from the standpoint of approaching this particular problem (which, IIRC, is that the sound is unmuted at logout), I don't like this approach because it alters a piece of infrastructure in a way I don't believe is correct.

I imagine that this particular issue will eventually be solved through close communication between Chrome and gavd, but I do also agree that we ought to fix it in the interim.

As an (indefinite length) interim fix, I'd rather introduce a new linker set* specifically for this issue instead of modifying the existing infrastructure (which I don't think should be modified to cover this case).  That way, when the time comes to deprecate the feature, it's easy to remove it, and no other code will be relying on the fact that you can have optional initializers &amp; finalizers.

Granted, the only think using the initializer function now is the sound restore code, so I was probably wrong in the original implementation.  I was also wrong in writing the iterator to implicitly create a 'desc' variable instead of providing the name in the macro parms.

I implemented this in a hurry to fix some issue with, IIRC, stumpy not having good volume at login and because the wonderful 'get sound working with Kernel 3.0' needed to be done.  My original thought of doing this was to make the factory-default a thread.

That idea fizzled quickly under thought because there is no imposed ordering on the way threads are started, and because you'd need to block until the sound was correctly initialized.

Perhaps we should re-think this and actually make the factory default setting a thread and do the work to impose ordering on the threads and add locking?

* Linker sets are the system used to make the arrays of data for the initialization / finalization system.
|Patch Set 1: I would prefer that you didn't submit this

See my comments for review #10462 for my reasoning on this.
|Patch Set 1: Verified; Looks good to me, approved; Ready

We've moved to 3.0.
sound_infrastructure is failing, so it seems like a good time to get this committed.
|Patch Set 1: Verified; Ready

Merged.
|Change has been successfully cherry-picked as fbb1cb765116582745a46f2e889dbbd29772b2e3.
|Patch Set 1: Verified; Ready

Merge!
|Change has been successfully cherry-picked as 0270ee43eab3cb90bb5f2c46a00f858649b442c5.
|Patch Set 1: Verified; Ready

Merge.
|Change has been successfully cherry-picked as 43dfde0374d3fb4c63a5d5494abd539a9928b9bd.
|Uploaded patch set 2.
|Patch Set 2:

Stephen,

I have no idea what your comment ultimately means.

The first upload had a commit message with no 'Tegra' in the main subject line.  I fixed that an re-uploaded. 
I don't know exactly what magic lies behind repo upload, and I have had changes to only the commit message get uploaded without a new patch.

However, this time it made a new patch set; perhaps because I have another change outstanding in the same source tree?  Maybe your guess on this is better than mine.

So, with that explanation, can you please explain your reason for the -1?
|Patch Set 2:

Stephen, 

I think I understand your complaint now; I did not know that you had made comments on the other patchset.  I didn't think anyone had time to even look at the first one before I fixed the commit message.

I will take a look at your comments.
|Patch Set 1: (6 inline comments)

I think I've addressed all your issues.  The next patch will contain the fixes.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)

I've addressed at least 50% of your comments, and have uploaded a new patch.
|Patch Set 4: Verified; Looks good to me, approved; Ready

LGTM from the original commitor is enough to commit this to the kernel 3.0 branch.
|Change has been successfully cherry-picked as 5b16cfc26b4b0862c90288de3a217846383ee1d1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready

LGTM from original commitor is enough to get this into our Kernel 3 tree.
|Change has been successfully cherry-picked as 3975151f7090df7c71d16067c134094ae5f0638f.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Change has been successfully cherry-picked as b9eabae595d350bb16a9adbdd02d5e0949a6eec8.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 2a8820383c41736651b0fa345748e20db8c182b9.
|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 1: Verified


|Change has been successfully cherry-picked as 037bbd1b1d104cdcca8e071494f6c234568787de.
|Patch Set 1:

Anyone have time to check this out?
|Patch Set 1: (1 inline comment)

New upload coming up.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as aeba895cd00cb9f9b44e14d5686d423b94b91f10.
|Patch Set 1:

Anyone have some time to look at this?
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as b020831263a9abde0b177364764bfab5bc7883d7.
|Patch Set 1: Verified

A simple cleanup to make source code navigation easier.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Ready


|Change has been successfully cherry-picked as 869bd07127750e06caa33c6e8023e2ee405d6846.
|Patch Set 1: Verified

A somewhat simple change that codifies linker sets into a standard set of macros.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)

I've addressed your comments, Terry.
|Patch Set 3: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

A step towards giving threads start up priorities.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

All nits have been now picked.
Transferring approval.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified

Add a priority field to the thread descriptors.  This will allow us to order thread startup based on their respective priority.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified

A small change that ensures each thread is fully started before the next one in the chain can begin to start.

This allows higher-priority threads to export functionality that can be used by lower-priority threads when they are started -- with no race conditions.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Addressed Terry's issue with verb tense.
|Patch Set 2: Looks good to me, approved

Is this something that will more generally affect systems using the wm8903 (or a wider set of processors from Wolfson)?

Can the setting of this be moved up a layer to be associated with the board rather than the whole codec?

Seems a shame for us to carry such a such a small change forward (versus upstreaming), if it was approachable in another manner.
|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

I think Yufeng should comment about this.
Or, maybe we could look at the history of headphone-jack-monitor, which is removed to see if I left annotations about why those were put in.
|Patch Set 1: Looks good to me, approved

If Yufeng says it's correct, then let's get it in.
|Patch Set 1: Verified; Looks good to me, approved

(2 inline comments)

I don't know about the OWNERS info; how is that updatedS?
(I am basically the owner of ADHD)

As for the asound.state file, if you don't have actual hardware yet, then an empty file will be better.  It's better because it'll be obvious that the file needs updating.  Comparatively, a populated file will leave us believing that it's correct.

At the present time, the asound.state file is not used, but it is installed on the device and could be used from the command line.  So, it's better to have an empty file than one that is subtly incorrect.

There is no set of dummy values that you should be using for asound.state.

For the header file, an empty header file will result in a gavd executable that essentially does nothing.  That's ok if you don't intend on sound being used very much.

As I don't know anything about bumblebee, I can't give specific advice yet on how to fill out the header file.  If it's another derivative of Seaboard, then you should be ok in setting up the header file to be like one of the other Seaboard derivative header files.  If you're not ready to test the sound system, it's better to have an empty header file and fill it in later, when you can verify that it works.

Once you have the system booting, can you run the 'sound_infrastructure' autotest to verify that it passes?  If bubmblebee is not using a wm8903 codec, you'll probably have to modify the test; I am the owner of that, too, so I can give you a hand in doing the work.

(Approval modulo the asound.state file comments...)
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready

(1 inline comment)

Trivial change.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: (1 inline comment)

Dylan,

You are right that we have multiple versions of the same data.  I don't know of an option to 'alsactl restore' which produces useful information about any control that does not exist.  However, it probably would be a useful thing to have the sound_infrastructure test run 'aslactl restore'; we can at least detect failures to restore the sound state.  (It will fail with kernel 3.0, due to the rename of the card from 'tegraseaboard' to 'tegrawm8903'.)

The ultimate goal with the control name checking is to *also* check for newly added controls, and I don't think that using 'alsactl restore' would fail if a new control did not have a state in the restore file.

So, I'd prefer to stick with the control checking (and eventually adding a check for new controls), and I'll add a test which will ensure that 'alsactl restore' functions properly on each device.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Talked with Dylan.  We agree that so many manual steps are objectionable, but this is acceptable for the time being -- until (/ if) we can think of a better way to handle this.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Part two of the simplification to the sound_infrastructure test.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Ready


|Change has been successfully merged into the git repository.
|Patch Set 2: Looks good to me, approved

I assume that this is for after we officially switch to 3.0?
|Patch Set 1: Looks good to me, approved

Is this 3.0 specific, or can it go in now?
|Patch Set 1: Verified; Looks good to me, approved; Ready

Trivial renaming of module exports.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified

Addressed Todd's concern of using --parents; switched to -p for Mac builds.
|Uploaded patch set 3.
|Patch Set 3: Verified

I found some objectionable traits with the original implementation of the 'remake' function, and I've addressed them with this change.

The short version is that multi-directory recursion didn't work properly.  I've addressed it with a 'REL_DIR' (relative directory) variable.
|Patch Set 3:

The differences between the last two patches are in make.mk.
|Patch Set 3: (1 inline comment)

Will reorder changes to ensure that ECHO is defined.
|Uploaded patch set 4.
|Patch Set 4:

I've added the necessary definitions to 'utilities.mk'; this patch should work now.
|Patch Set 4: Verified

verified that the patch works via cherry-picking into a different source tree.
|Patch Set 4: Ready

(2 inline comments)

Sending out comments.
|Change has been successfully cherry-picked as 7296b345a5946f9b0016d7adadf7975c0dfe46e6.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Trivial change which reduces spew to /var/log/messages on DUT.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Addressed all of Dylan's comments.
|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Trivial change to stop sound_infrastructure test from failing.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: I would prefer that you didn't submit this

(-1 just to make sure this stands out as being viewed.)

Is it true that there are no files now?
If it's true that there are no files now (which seems suspect), then LGTM.
|Patch Set 1: Looks good to me, approved

(1 inline comment)

LGTM, modulo the inline comment.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as ccaa1dadcba69fc5ce342ce9e03af2b01cd981f9.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as e8ce45253bcb53a499261786acb94ca159ef70ac.
|Patch Set 1: Verified; Ready


|Patch Set 1: No score; Not Ready


|Patch Set 1: Abandoned

This is now included in I7c8d0dcf
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as fd5e5eb9bab5aa731dff6f3e06e16beede5cacbe.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 603fd91796e62db1ed2db7631d51e7771e40d581.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as cbf2820947f5e00c064c6d0479c54037f923470c.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

This change removes an '.egg' file that accidentally got in to the repo.
|Patch Set 3: Verified; Ready


|Change has been successfully cherry-picked as ebe91a053f93a59187ba08550a8f3952450732ca.
|Patch Set 1: Looks good to me, approved

(1 inline comment)

Is it possible to get access to one of these machines to get a real asound file?

Will an empty asound.state pass 'alsactl restore'? 
(In other words, will this pass the sound_infrastructure test?)

If we can't get a real asound.state, then neither one of these issues should stop you from checking this in.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Change has been successfully merged into the git repository.
|Patch Set 1: Abandoned

Use change e97c28302f4bbcba...
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Trivial change.
|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Trivial change which adds two more utilities to the build process.
|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

My mario was not running 3.0.8; was running 2.6.38.
ALC272 files should not have been included.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2:

Patch set 3 will address the concerns.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as ad22c218f22e88d2725ea8ea394e68a7d7236627.
|Uploaded patch set 2.
|Patch Set 2:

Removed '-implicit'; it will be added back in a later change.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transferring approval; removing -implicit does not change the semantics of this change.
|Change has been successfully cherry-picked as 9244410b427d22e526a5dd63293f1628619ef5cd.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 435c1c980c7976ffa381eb48b57ed0f89cb77ad3.
|Patch Set 1: Looks good to me, approved

(1 inline comment)

LGTM, but if it modifies the file in the source directory, please let me know -- because that means I've done something wrong in the rest of the changes I've made.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved; Ready

This adds the missing 'include' directory, and it should cause the build to go green.
|Change has been successfully cherry-picked as d7444256aaa1a3b529de56220c69d1997c3692de.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transferring approval; no changes.
|Patch Set 3: Not Ready


|Patch Set 3: Ready


|Change has been successfully cherry-picked as 73f49e5f8dd6abcbf50a7f689c348e0f8e85e333.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3:

Transferring approval
|Patch Set 3: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 02bd7550b8d54879a882095cb8939f52e20fde19.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved

Transferring approval
|Change has been successfully cherry-picked as 08f0cfd425bbb3018f319cd106518c29052e66de.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved

Transferring approval.
|Change has been successfully cherry-picked as 5dd6bb9185993c383af78b0d2886e292ce81ef3e.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved

TRansferring approval.
|Change has been successfully cherry-picked as 78f537f11aa70c1dc055068d97d6e519f5923629.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Transferring approval.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved

Transferring approval.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved

Transferring approval.
|Change has been successfully cherry-picked as d68dc9b6230df898ce69a5d407453d6fe93bd60a.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved

Transferring approval.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved

Transferring approval
|Change has been successfully cherry-picked as 44b700bb8dc97de98dba8b78ed90053a3d1739e9.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready

Transferring approval to new patch; no changes in the patch... just uploaded due to chain dependency.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Looks good to me, approved

Transferring approval.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved

Transferring approval.
|Change has been successfully cherry-picked as 8be047c2a7f3633df7e74aa88713bbfa1aa612a3.
|Patch Set 1: Verified


|Patch Set 1: Looks good to me, approved; Ready

This should fix the build breakage.
(Last time I chain changes through gerrit &amp; git)
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transferring approval.  Removed duplicate definition of CDEFINES.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as 86d4f93848cb990feffa79a996b269f4eec7d670.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

I've verified that this does indeed work.
It' faclitated me geting the analog headphone jack working on Kaen.
|Patch Set 1: Verified; Looks good to me, approved

This change makes it possible to flash u-boot into the clamshell Seaboard provided to me from Anton.

Thanks for fixing this.
|Patch Set 1: Looks good to me, approved

Thanks for cleaning up.
|Patch Set 1: Verified; Ready


|Patch Set 1: (3 inline comments)

Spacing has been fixed.
As for the declaration thing, the benefit is mainly personal preference.  But, it makes it easier to find declarations of variables too.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready


|Patch Set 3: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

In response to Terry's comments on change #3:

I had not considered a file which turns off the warnings, but that's a good idea.

Before we go down a twisty passage about how best to address this, let me just state that the ability to compile on the Mac is not an officially supported mechanism; it's just something that Todd has kept working for his own convenience (and some other hardware guy) in using his MacBook at home.

So, while making it work nicely would be ideal, it's a bit of overkill (from the &quot;I have to do the work&quot; standpoint) to support two people on a platform that I can't test.

If Todd would be willing to do some testing, I'll set up the infrastructure to do this.
Let's discuss what exactly you had in mind.

I've also fixed the issue in the commit message.
|Patch Set 4: Verified; Ready


|Patch Set 4: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 4: Ready


|Patch Set 4: Ready


|Uploaded patch set 5.
|Patch Set 5: Abandoned

This has been checked in through a different change number.
This one is stuck for some unknown reason.
|Patch Set 1: (1 inline comment)

Uploading new change set.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Defined and using $(INSTALL).
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

No changes; uploaded again due to dependencies.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

No changes; uploaded again due to dependencies.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2:

No changes; uploaded again due to dependencies.
Let's discuss.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved

This microphone change has been approved, and it's the same thing as this -- just a different jack.
|Patch Set 2: Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

No changes; uploaded again due to dependencies.
Let's discuss.
|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 3: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

This is a re-upload of Gerrit change 12263.  That change is being kicked out by the PFQ, but clicking on the links for the failed builder shows all the steps as green.

This upload is test to see if it will go in through this upload.  If it does, great.  If it does not, this change will be abandoned.
|Patch Set 1: Looks good to me, approved

I don't think that having ftdicommon compiled in to each shared object is going to impact anything; it's probably a bit easier to maintain with it linked it, as there won't be any further dependencies.

One question:  Is the ftdicommon shared object hard coded in the install?  Does that rule need to be updated?
|Patch Set 1: I would prefer that you didn't submit this

I have a few questions:
  1. I thought waluigi was discontinued.  
     What waluigi is this?


  2. Can you please make a defect report and use 
     it instead of 'None' for the 'BUG=' attribute?


Ultimately, the chromeos-per-session file is going to be deprecated, so if there is no pressing need to have it for this board, you can actually skip checking on in.

The 'ultimately' is undefined, but I hope it to be before the end of January 2012.


Please be aware that you'll have to make some changes for the ADHD (src/third_party/adhd) software to be able to build for a new board.  It's possible that waluigi has no been removed; if whatever waluigi you have is different than the previous incarnation, you'll have to make changes to the ADHD project.  (Ultimately, changes won't be necessary, but sadly they are right now)

This change looks good, but I'm going to give a -1 for the purpose of making this note visible.
|Patch Set 1: (8 inline comments)

I'll be addressing the logic errors (the assert() which will fail on contention, for example), but I think I'd like to kick the can for the 'active' bits down the road to a follow-on checkin which will revamp how that is handled -- since this change is a little large as it is; making those changes as a follow-on will make them clearer.
|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Patch Set 2:

I think I've addressed the issues except for the 'active' flag (which needs to be entirely redone, and I'd like to do as a follow-on, before we start using the device list).

However, it's hard to tell if I did everything, because changing the base to patch set 1 and then diffing still shows the whole file as new.

Rather than using TLS to check that the mutexes are not re-locked or re-released, I now use a mutex attribute which accomplishes the same thing; it returns an error for those situations.  The lock and unlock code specifically checks for those error cases (the failure will be unique, as an aid to diagnosing the issue).
|Patch Set 2: Verified; Looks good to me, approved; Ready

This is still unused code, and the internals will change very quickly to support input &amp; output information.  Need this to be in the source to make forward progress.
|Patch Set 2: Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved

Great work.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified

Is it preferrable to have full revision numbers for the dependencies?
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)

Fixed the issues
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved

Looks great.
Would you mind filing a ticket to entirely remove the script, and assigning it to me?
|Patch Set 2: Looks good to me, approved

INSTALL would allow you to set the permissions, owners and a few other esoteric things about the destination files.  But, for this package, I think it's fine to just use CP.
|Patch Set 2: Looks good to me, but someone else must approve

(16 inline comments)

There are a few issues which must be fixed (for example, deref before NULL check), but most are not serious enough to prevent a checkin and follow-on to address.

I'm also trying something different for reviewing since I hate editors built-in to browsers.  Hope this isn't too objectionable.


cras_client.c:

  13: to talk listen -&gt; to talk and listen?
  17: specified -&gt; specifies?
  22: Should this line have a '.' after 'samples'?

  68: What value means playback?  What value means capture?
  69: If flags are not used, can they be removed until needed?

  76: Perhaps I misunderstand, but wasn't format conversion going to
      be done in Chrome?

  86..87, 116, 118:

    You've got two structures with two fields each which describe
    properties of a thread.  For simplicity in documentation and
    reasoning, you could take the thread id and the flag from both of
    these structures and make a substructure.

       typedef struct thread_state_t {
          pthread_t id;
          unsigned  running;
       } thread_state_t;

   I wouldn't gain much other than collating related fields so they
   would be together and it would easier to reason about the code when
   related things are related in the source.

   If you agree, this would be good for a follow-on change.

  134: DL_SEARCH_SCALAR?  Haven't seen that defined anywhere.
       Ah, uthash.h.  But that's not in this change... how can this
       work then?

  138: This line could be deleted.

  139: Are 'm' and 's' meaningful?  Would 'beg' and 'end' be more readable?

  145: You're counting a difference of only nanoseconds as no difference?
       I don't understand why.

  148: For mental simplicty of readers, a comment or assertion right
       before this line would be helpful, something like one of these:

         assert(m-&gt;tv_sec &gt; s-&gt;tv_sec);
         // invariant: m-&gt;tv_nsec &lt; s-&gt;tv_nsec =&gt; m-&gt;tv_sec &gt; s-&gt;tv_sec

  151, 152: Inconsistent space before ';'.

  161: Not sure this comment entirely makes sense.

  162: Inconsistent '{' on function signature line.

  191..192 (etc):

    Personally, I don't like unbracketed 'if' (et al) bodies, but if
    that's your style, it's ok.

  195..201: Will it ever be a problem if 'read_fd' and 'wake_fd' both
            have data, but 'read_fd' fails to read 'len' bytes?  This
            will leave the 'wake_fd' with pending data until the next
            iteration.  Will this cause any anomalous behavior from
            wakeups?

  207: Is handle_capture_data_ready() a callback?
       Could you document the returns.
       Should the failure at line 218..220 return '0'?

       In general, for speed-critical code, you'd end up generating
       better code by using gcc's 'unlikely' system or putting the
       correct case in the body of the if() and the failure at the end
       of the if().  (unlikely() being the best option)


  219, 253, 390, 395:

    A better error message might be helpful in the long run.

  266, 267: This looks like it will be less than 80 columns.
  286, 287: Same as 266.

  268: You're mixing 'size_t' and 'int' here, and that can lead to bad
       things, since one is unsigned.  I'd recommend turning on as
       many compiler warnings as you can.

  303..305:

    I think these three lines can be just 'return aud_msg.error'.

  308..309: indicating that stream -&gt; indicating that the stream?

  329: Did you mean to leave the perror() in?

  347, 352:  If so inclined, you could generate better code with the
             following:

     thread_terminated = &lt;function call&gt;

     (As a nit, you've created lexical blocks for the two cases in the
     'switch', but you've got nothing scoped in them.)

  319, 331, 340:

    Are these returns going to end up orphaning the shared memory
    which is detached at 362?

  455: Your error code gives no indication of the failure, and only in
       the case of 'msg-&gt;err' is there any log output.  Perhaps you
       might consider logging the different types of errors that can
       occur (i.e., line 435, 443...)

  458: 'withing' -&gt; 'within'?

  473: Is writing unitialized memory ok?  Why bother if the stream is
       being removed?  Is this the wakeup to make it known that it's
       dead?  If so (and I guess, if not), can you comment about this?

  484: Might be nice to log if unlink() fails.  Actually, maybe it
       would be good to unlink the path right after creation... that
       way it would be automatically reclaimed when the last use is
       closed.

  488, 489: Might be nice to log if the close fails.

  505, 506: Might be &lt; 80 columns when combined.

  539..542:

    free(NULL) is defined to be a nop, so you don't need both the if()
    at line 539 &amp; 540.  If you prefer the if(), which is ok with me,
    please be consistent in using it at line 492.

  562: This is duplicating the initialization at line 554.  I advocate
       removing one of the two.

  563: Textual output of the id which is found would be nicer.  It's
       pretty easy to make enumerations into text... if you aren't
       familiar with it, I can show you how.

  591: Would it be a good idea to log unrecognized commands?

  599: Looks like this only returns 0; a good candidate for a 'void'
       function?

  188, 685:

    Two good candidates for a max().  I like the one described
    in the gcc info pages:

     #define max(a,b) \
       ({ typeof (a) _a = (a); \
           typeof (b) _b = (b); \
         _a &gt; _b ? _a : _b; })


  714, 722: What is unlocking the mutex before you lock it again --
            line 643?

            A barrier might be better than a mutex here.  It would be
            better because you can add attributes (at line 739) to
            your mutex so it is only locked &amp; unlocked by the same
            thread, and to ensure that it is never locked more than
            once by the same thread.  Further, it appears (if line 643
            is the correct answer to my question), that you are using
            it as a synchronization point across multiple threads --
            and that's what barriers are for.

  739: The mutex is not destroyed in the failure case.  In fact, the
       pthread initialization itself can fail.
       The mutex should also be destroyed in cras_client_destroy().

  787: Is snprintf() going to '\0' terminate if you write exactly the
        specified number of bytes?  Or, stated another way, is it
        possible that you can end up with a non-'\0' terminated
        string?

  822 -vs- 811, et al:

    I prefer the style in 822 over 811, but more important than my
    preference is consistency.  Can you be consistent?

  891: If the stream fd less than 0, close it?  Is the polarity of the
       test correct?

  893 -vs- 891:

     Either 891..892 should be moved into the 'if (stream)', or the
     if() can be removed.

cras_test_client.c

  Haven't looked at this very closely, but nothing stood out in my
  brief run-through.


In general, as I've said before, I think that it would be better to
use the natural size of the compiler rather than sizing every integer
-- unless there is a requirement that these be sized.  For example,
matching a variable's size to a hardware port or Alsa specification.
There are a couple reasons why you should not size to specific types:

  o The compiler will generally generate better code.

  o When you reserve size-specific integers to the place where they
    must be specifically sized, the person reading the code has a
    visual clue that something special is occurring -- slow down and
    be careful about overflow, wraparound, etc.  If all your types are
    specifically sized, the places where one needs to be careful get
    lost in the noise.
|Patch Set 4: Looks good to me, approved

It's a total shame that gerrit is so cumbersome, and the fact that
viewing differences between patch sets with entirely new code doesn't
work at all.  Oh well..

Despite that, I'm still trudging along.  Won't be as careful on my second pass through, but will read and look at most of the things I've already commented about (well, the important ones anyway).

   191..192 (etc):
           Personally, I don't like unbracketed 'if' (et al) bodies, but if
           that's your style, it's ok.
   - Neither do I but we're supposed to do kernel coding conventions for new C
     code.

:-)  You gave me a pass on not following the rules, or whoever
started reviewing gavd...


           473: Is writing unitialized memory ok?  Why bother if the stream is
           being removed?  Is this the wakeup to make it known that it's
           dead?  If so (and I guess, if not), can you comment about this?
   - I'm missing the unitialized memory.  This is the message to the server to tell
     it to remove the stream.

  Mea culpa.  My explanation was not very precise.  In patchset 4, at
  line 495 you've got a stack variable 'msg' which is used at line
  505.  'msg' appears to be uninitialized, but is used in a write()
  call.


          484: Might be nice to log if unlink() fails.  Actually, maybe it
          would be good to unlink the path right after creation... that
          way it would be automatically reclaimed when the last use is
          closed.
  - added log. will have to think about unlinking right away, have to wait for the
    server to open the file first, then handle the case where it never
          does.

  I see.  I didn't think about the other end being opened.  Never mind.

Let's start getting this in so we can make forward progress....
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

cras_shm.h:

  13: '2U'?  It's always compared with a 'size_t', so why not make it
      unsigned?


  86..88, 157..159, 176..178:

    You could generate a lot better code by ensuring that  you
    number of buffers is a power of two.  You could then get rid of
    the branches associated with the if() statement.

      #define assert_on_compile(_expr)                                        \
          do {                                                                \
              enum { assert_on_compile_enum = ((_expr) ? 1 : -1) };           \
              typedef char assert_on_compile_type[assert_on_compile_enum];    \
          } while (0)

      assert_on_compile((CRAS_NUM_SHM_BUFFERS &amp; (CRAS_NUM_SHM_BUFFERS - 1) == 0);
      buf_idx = (buf_idx + 1) &amp; (CRAS_NUM_SHM_BUFFERS - 1);

    The current code generates something like for x86:

      0000000000000000 &lt;f0&gt;:
         0:   48 8d 47 01             lea    0x1(%rdi),%rax
         4:   ba 00 00 00 00          mov    $0x0,%edx
         9:   48 83 f8 02             cmp    $0x2,%rax
         d:   48 0f 43 c2             cmovae %rdx,%rax
        11:   c3                      retq
        12:   66 66 66 66 66 2e 0f    nopw   %cs:0x0(%rax,%rax,1)
        19:   1f 84 00 00 00 00 00

      0000000000000020 &lt;f1&gt;:
        20:   48 8d 47 01             lea    0x1(%rdi),%rax
        24:   83 e0 01                and    $0x1,%eax
        27:   c3                      retq

    And for ARM:

     00000000 &lt;f0&gt;:
        0:	e2800001 	add	r0, r0, #1
        4:	e3500001 	cmp	r0, #1
        8:	83a00000 	movhi	r0, #0
        c:	e12fff1e 	bx	lr

     00000010 &lt;f1&gt;:
       10:	e2800001 	add	r0, r0, #1
       14:	e2000001 	and	r0, r0, #1
       18:	e12fff1e 	bx	lr

  78 -vs- 92:

    Want to add a gcc attribtue which requires 'frames' to be
    non-NULL...  Or, an assert that 'frames' is not NULL?

  cras_shm_get_frames:

     Should the number of bytes queued always be evenly divisible by
     the number of frame_bytes?  If so, might be a good idea to assert
     that it's true.

     Same question about cras_get_frames_in_curr_buffer().

crash_shm_buffer_free()

  This name has an unfortunate feature of easily being confused with
  something that releases memory.

The only comment about the test program is that is uses an
function-opening-brace style that is inconsistent with the other code.
|Patch Set 3: Looks good to me, approved


|Patch Set 2:

Your bug=, test= lines are combined in your commit message.
|Patch Set 2: Looks good to me, approved

cras_fmt_conv.c:

94 -vs- 102, 103

  If you are going to use 'conv-&gt;buf' and 'out_buf' as 16-bit data,
  why not declare them as 16 bit, rather than 8-bit?

  Are there any endian issues with this cast?
  Will there always be an even number of bytes in the buffers, or is
  there a risk of casting the last byte in the buffer to a 16-bit
  value, and accessing memory not in the buffer?
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

This change fixes an issue where internal devices on ARM-based systems were not being recognized as internal.  Added 'platform' bus detection in udev_listen.c
|Patch Set 1: (10 inline comments)

These comments will be associated with patch 3, after it's uploaded.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved

cras_mix.c:

  10:

     ... if it's the first stream added

     Is being the first stream different than being the 'only' stream?
     (aka: Is it possible to add 2 streams, and then remove the
     first?)

  11: min and mas?  Should that be 'max'?

  21..27:

     Rather than incrementing three variables, why not use 'dst' and
     'src' in array notation.  Then you can increment just 'i' and let
     the compiler deal with all the addresses.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(2 inline comments)

43..53:

  Putting these three functions in the header file as 'static inline'
  functions will generate better code.

79..80, 83..84:

   When returning due to failure, does this leak the handle that was
   opened at line 68?

110: Is this truly an stack-based alloca?  Will this space be auto-reclaimed?

114: Might be nicer to use the full name of the called function in the
     log.

In cras_alsa_set_hwparams(), is it ok to leave the the settings in an
unknown state if you return due to failure?
|Patch Set 3: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 4: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

cras_rstream.h:

  25, 44:

    What value is input, and output?

  30:

    If memory usage is important, putting embedded structs at the
    end might yield better field packing (no internal padding).

  32, 48:

    What are the semantics of this the callback threshold?  Percent full, ms
    remaining, frames, bytes?

    Ah, I see at line 69 there is an indication that this is frames.
    Can you move this up to be more clear at the declaration point?

  34, 49:

    What are the semantics of the flags?

  91: cras_rstream_set_format()

    I recommend making the source 'fmt' be a pointer to const.

  97: cras_rstream_get_format():

    This could be a 'void' function, since it only always returns 0.

 137: cras_rstream_get_shm_size()

    Header comment incorrect.

 153: cras_rstream_set_io_dev

   Recommend making 'o' parameter a pointer to const.
   Also, this function could be a 'void'; only returns 0.

cras_rstream.c

  37: shmget()

    Could something more restrictive than '666' be used?

  46, 47:

     You've already set the 'shm_key' &amp; 'shm_id' to valid values, but
     have no encountered an error.  Will there be any possibility of
     using the now-useless values Should they be set to invalid values
     to prevent use?

  72..78:

    A bit painful, but might be useful to check the validity of each
    parameter individually and logging when ones violate the
    preconditions.

  80..83:

    Could use calloc() and get rid of the memset.

  98:

    The return code isn't really going to provide much information in
    the failure case; you don't have any indication what produced that
    value.  But, it's certainly no big deal.

  cras_rstream_destroy

    If there is no shared memory, you return without freeing the
    'stream'.

  cras_rstream_audio_ready

     Is it possible to have any validation done on 'count'?
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

There are a few issues in this code which probably should be fixed before commiting.  But, since it's not yet used, I'm also ok with fixing in a follow-on.

cras_iodev.h

  48: anonymous enum

      Haven't mentioned this before, but I find it helpful to typedef
      enums, even though the are just an int.  This allows you to use
      the enumeration type for variables and makes it easier to reason
      about what values a variable should be able to hold.

cras_iodev_info.h

  11: Did you want the maximum name to be only 31 or did you want to
      allow 32 characters for the name?

      Perhaps a better name would make it less enticing to assume it's
      the maximal length of the name:  CRAS_IODEV_NAME_BUFFER_SIZE?

cras_iodev_list.h:

  46, 54:

     'Removes an output to the (output &#124; input) list'?

      Should that be 'from the (output &#124; input) list'?

  97: Would be nice to indicate which parameter will be modified.
      (Sure, it's obvious looking at the code, but complete
       documentation is nice! :-))

      Also the header comment and the 'Args' comment conflict a bit.
      The former indicates the 'fmt' is filled in on error, and the
      latter indicates it's always filled in.

cras_iodev_list.c:

  26: 'non' -&gt; 'none'?

  96: 'Copys' -&gt; 'Copies'.

  104..105:

     In the case that you return 0 elements, it might be good idea to
     set '*list_out = NULL', just so whatever uninitialized value
     provided by the caller isn't used by the callers of
     cras_iodev_list_get_outputs() and cras_iodev_list_get_inputs() on
     a non-error return value.


 157..164: cras_get_iodev_for_stream_type

   You could generate much better code by restructuring your if()
   statement:

     if (direction == CRAS_STREAM_INPUT) {
       ...
     else {
       assert(direction == CRAS_STREAM_OUTPUT);
       ...
     }

   This gets rid of at least one jump for all target processor, and
   will end up always doing something that is &quot;not bad&quot;.

   In your current code, if assertions are ever turned off, and both
   conditions fail, 'dev and 'def' will be uninitialized when they are
   used in lines 166 through 169.  With the above idiom you'll at
   least end up initializing the variables and not crashing later with
   uninitialized values.

  cras_iodev_list_rm_output(),
  cras_iodev_list_rm_input()

    If the device cannot be removed from the list, wouldn't it still
    be preferrable to stop using it as the default input/output?

    In your code, a failure to remove it from the list immediately
    returns, and the default remains as the default device.

  204..207:

     I argue that the following is equivalent to your code:

       default_output = outputs.iodevs;

     Similarly-wise for 220..223.

  cras_iodev_detach_stream()

    If the stream cannot be removed, you immediately return with an
    error code.  Wouldn't it be preferreable to still change the iodev
    (line 258) and then return the error code?

  cras_iodev_set_format:

    276:

      At line 270 you've allocated meory.  At line 276 you return an
      error without releasing the memory you allocated.

  cras_iodev_move_stream_type:

   291:

     You could simplify here by assuming that curr_dev is going to be
     set for the call to get_curr_iodev_for_stream_type();

       list     = &amp;outputs;
       curr_dev = get_curr_iodev_for_stream_type(list, type)

       if (curr_dev == NULL) {
         list     = &amp;inputs;
         curr_dev = get_curr_iodev_for_stream_type(list, type);
       }

       if (curr_dev == NULL)
          return 0;   /* no streams to move */

cras_iodev.c:

  Nothing to say.
|Patch Set 2: Looks good to me, approved


|Patch Set 4: Looks good to me, approved

cras_rclient.h:

  Nothing to say.

cras_rclient.c

  94:  Success is zero?  I'm confused by this line.

 102:

   Error conditions above this line goto 'reply_err'.  Should this?
|Patch Set 5: Looks good to me, approved


|Patch Set 5: Looks good to me, approved

60, 111:

  The use of the name 'playback_started' for capture streams is a
  little incongruous.  How about something like 'started' or
  'enabled'?

133:

  You might want to combine these three logs into a single line (which
  will output a long line).  The advantage would be that the
  information will not be split apart by different programs also
  logging.  OTOH, 'grep' makes it easy to find only lines from the
  desired program.  So, your choice.

thread_remove_stream():

  If the operation fails or if there are still streams attached, it
  seems like this will end up never releasing the accquired resources.
  Is this desired?

  If there are still streams attached, is this assumed to be called
  when all the attached streams are closed?

thread_add_stream():

  174..177:

    Why only allow one capture stream to attach?  What detriment is
    there to attach more than one?

  186:

    It would be nice to indicate which alsa device was intented to be
    used in the error message.  Also, '\n' on syslog is not needed.
    (Haven't noticed this before, but there are probably others in
    your whole codebase)

 183..190:

   Is aio-&gt;handle still set to NULL when open_alsa() fails?

   What is expected to happen if you have a thread with no streams,
   and the addition of a stream fails.  Does the thread get
   automatically cleaned up?

192:

  Is the check that there are streams necessary here?  Shouldn't there
  be at least one stream since one was just added?

set_capture_timestamp()

  This function is a good candidate to become a 'void' function.

 457 -vs- 459:

   Why does only one '1000000000' have the 'L' suffix?

 522:

   Is it ok to return without a cras_alsa_mmap_commit() following the
   cras_alsa_mmap_begin()?

 579, 580:

  Why drop all the frames?  Couldn't you return 0 and the caller would
  be responsible to call again, or to do the discard on their own?

630..633, 655..658, 660..663:

  You'd have a better execution path for code like this if you just
  initialized the variable according the mostly-executed path; the
  integer assignment is basically free, especially compared with the
  jumps that would be generated for the if-else.

     num_to_read = 0;
     if (frames &gt;= aio-&gt;cb_threshold)
       num_to_read = aio-&gt;cb_threshold;

639..640:

   I assume that cras_alsa_mmap_begin() can modify 'nread', otherwise
   nread could never be 0.

   Let's assume that cras_alsa_mmap_begin() has set 'nread' to zero,
   and returned a zero.  If this occurs, this code will return with a
   code of zero.  Is that desired?

   Also, it returns without executing cras_alsa_mmap_commit().  Is
   that ok?

688:

  Why the 256 byte limit?

872..878, 899..903:

   Recommend an 'assert(direction == CRAS_STREAM_(not input))' at line
   902 &amp; line 876.
  
908: free(NULL) is a NOP.  You don't need the NULL check.
|Patch Set 1: Looks good to me, approved

cras.c:

  88: In many other places in the code for this project you explicitly
      check against NULL.  I like consistency.  (See line 145 in this
      file, for example)

 120:  Should 'connection_fd' be released?

 run_server():

  In your 'bail' section, shouldn't 'serv' be released?

 211..219:

  Don't forget this needs to be removed....

set_signals:

  Why not use SIG_IGN instead of settig them up to call an empty
  function?
|Patch Set 2: Looks good to me, approved


|Patch Set 2:

Why configure?
Seems like we could do with something much simpler, after all, we are controlling the environment in which this is going to be used.

(I also know nothing about configure internals, so I'm not qualified to review this)
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 3: Looks good to me, approved

(1 inline comment)

I don't understand the decimal 66, but otherwise looks good.
|Patch Set 2: Looks good to me, approved

(1 inline comment)

You have two different conventions of outputting the id.  One is %u, and the other is %x.
Also, %x alone can be ambiguous (1234 -- hex or decimal).  I like to use '%#x' to get a '0x' prefix for everything except 0.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 4: Looks good to me, approved

(2 inline comments)


|Patch Set 5: Looks good to me, approved


|Patch Set 4: Looks good to me, approved

(1 inline comment)


|Patch Set 5: Looks good to me, approved


|Patch Set 1: Verified

This is one step in the direction of getting rid of board-specific information in gavd.
|Uploaded patch set 2.
|Patch Set 2:

Fixed copyright complaint.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Transferring +2.
|Patch Set 1: Looks good to me, approved

(3 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(5 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: (3 inline comments)

Grumble.. somehow I've got a new change set.
This one is now replaced by https://gerrit.chromium.org/gerrit/#change,15100
|Patch Set 1: Abandoned

Replaced by https://gerrit.chromium.org/gerrit/#change,15100
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Frob the status bits.

Anyone know what will happen when the build of this change (patch 1) completes and the software returns to update the bits to indicate it's committed, and then finds two more patches....
|Patch Set 3: No score; No score; Not Ready

Let's see if I can kick this into getting automatically submitted by tweaking the attributes.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Tweak everything.  Test, and commit!  Darn you!
|Patch Set 3: Abandoned

Things have gotten messed up.  Will resubmit as a disjoint change.
|Patch Set 1: Abandoned

What?
|Patch Set 1:

I don't have a Waluigi to test, so any changes I could make to accommodate this difference would be untested.

What I suspect needs to be done is to simply extend the regex to include the Waluigi information.  I don't know if it should be included for both the headphone &amp; microphone, or for just one of them.  My gut says it should be for both -- that way a change notification would occur for both the headphone and speaker.

Rhyland,

Can you provide me the menu output from 'evtest' on your Waluigi?
|Uploaded patch set 2.
|Patch Set 2: Verified

This change updates the headphone &amp; microphone regular expressions to accommodate the max98095 codec (thread_gpio_switch_monitor.c) and removes the device names from the max98095 header file.

I've tested the change on Kaen, but cannot test that it will now match on waluigi.
|Patch Set 2: Looks good to me, approved; Ready

Transferring +2.
|Patch Set 2: Abandoned

Things have gotten messed up.  WIll resubmit as a disjoint change.
|Patch Set 2: Looks good to me, but someone else must approve

(3 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Verified; Looks good to me, approved

Re-upload of change; disjoint from other changes.  This should get no conflicts when building
|Patch Set 1:

Rhyland,

I've added the necessary regex information to the code in thread_gpio_switch_monitor.c for the max98095 codec.  I gathered that information from the codec_max98095.h header file.

As it stands, this code should match the switches available on waluigi.  (according to the header file, there is a switch for the headphone and for the microphone, though both may not be present on waluigi).

Please take another look and see if this meets your needs.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved

This new patch should trigger insertions for the microphone and the headphone for waluigi.
|Patch Set 2: Ready


|Patch Set 1: (1 inline comment)

New patch coming right up.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready

Fly, be free!  Go nestle in the repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 2: Looks good to me, approved

(3 inline comments)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 4: Looks good to me, approved

(2 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

If you know what sound codec is going to be used, and if we are already using that codec, you could copy the asound.state from a board using that codec as an approximate starting point for the asound.state.

Or, if you've got physical hardware, you could get an asound.state from that hardware.

If we have no ability to get an approximate asound.state file, then an empty file will do for now.

The following change:

https://gerrit.chromium.org/gerrit/#change,15418

obsoletes all the board-specific header files.  If you could hold off committing until the above change is checked-in, you could just delete that file altogether.  And, it would save me a follow-on commit to delete the unused file.
|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1:

Rhyland, I don't understand all of your comments.  Specifically, 


I know the commands for alsa were not flushed out yet in the max98095 codec, is that the problem right now?

I will upload another patch with more diagnostics to help figure out what's wrong with waluigi.

Please stand by.
|Uploaded patch set 2.
|Patch Set 2:

The second patchset removes some logging that doesn't need to be present.
|Uploaded patch set 3.
|Patch Set 3:

This new patch adds some documentation to codec.h and it improves the code in codec.c.
|Uploaded patch set 4.
|Patch Set 4:

This patch fixes 'NULL-terminate' to 'NULL-terminated' in several comments.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready

Addressed compilation error on x86-generic
|Uploaded patch set 9.
|Patch Set 9: Verified; Looks good to me, approved; Ready

Fixed error with amd64-corei7
|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(6 inline comments)

-1 only because of the assert_on_compile() macro issue.
Otherwise, +2.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)

Modulo the revision comment...
|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 2: Looks good to me, approved

Thanks for doing this rename.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 4: Looks good to me, approved

(3 inline comments)

I like this change; the separation is a good improvement.  I've got a couple suggestions that could make things even better, but they are suitable for a follow-on change.
|Patch Set 1: Looks good to me, but someone else must approve

My only comment on this is that it could be integrated into the ADHD ebuild itself.  I understand why you are doing it this way, but having a single ebuild for all the audio stuff we are doing would be simpler in the long run.

Moving forward, when we start using cras, I'd advocate incorporating this into the ADHD build, or at least making this dependent upon the ADHD ebuild.

I think the build team should take a look at this.
|Patch Set 1: Looks good to me, but someone else must approve

I'm no Portage savant... added the build team folks.
|Patch Set 1:

I grabbed this change, and worked on flimflam.
Still got the same error:

test -z &quot;src/flimflam.ver src/flimflam.exp src/flimflam.conf scripts/wpa_supplicant.conf src/builtin.h  include/connman/types.h  include/connman/log.h  include/connman/plugin.h  include/connman/security.h  include/connman/notifier.h  include/connman/storage.h  include/connman/service.h  include/connman/device.h  include/connman/network.h  include/connman/inet.h  include/connman/crypto.h  include/connman/blob.h  include/connman/dns_client.h  include/connman/version.h  include/connman/assert.h  include/connman/driver.h  include/connman/element.h  include/connman/property.h  include/connman/rtnl.h  include/connman/wifi.h  include/connman/task.h  include/connman/dbus.h  include/connman/rfkill.h  include/connman/option.h  include/connman/resolver.h  include/connman/ipconfig.h  include/connman/profile.h  include/connman/provider.h  include/connman/assert.h&quot; &#124;&#124; rm -f src/flimflam.ver src/flimflam.exp src/flimflam.conf scripts/wpa_supplicant.conf src/builtin.h  include/connman/types.h  include/connman/log.h  include/connman/plugin.h  include/connman/security.h  include/connman/notifier.h  include/connman/storage.h  include/connman/service.h  include/connman/device.h  include/connman/network.h  include/connman/inet.h  include/connman/crypto.h  include/connman/blob.h  include/connman/dns_client.h  include/connman/version.h  include/connman/assert.h  include/connman/driver.h  include/connman/element.h  include/connman/property.h  include/connman/rtnl.h  include/connman/wifi.h  include/connman/task.h  include/connman/dbus.h  include/connman/rfkill.h  include/connman/option.h  include/connman/resolver.h  include/connman/ipconfig.h  include/connman/profile.h  include/connman/provider.h  include/connman/assert.h


make VCSID=9999-47a73ef7604f9fc6b6be626db9583123856cd755 
make --no-print-directory all-am
  CC     plugins/plugins_modemmgr_la-modemmgr.lo
plugins/modemmgr.c:34:28: fatal error: connman/assert.h: No such file or directory
compilation terminated.
|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)

I think the semantics of 'card_index' need to be worked out and documented.
|Patch Set 3: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(9 inline comments)


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 1: Looks good to me, approved

(3 inline comments)


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: (1 inline comment)

I have only a simple question about resource allocation, but otherwise looks ok.

I wonder if it would be a good idea to have heapzone allocation for each connection -- so rather than having all connections allocating from the main program heap, they would allocate from their own heap zone.  When the connection is closed, the entire heap zone and all dynamically allocated memory could be destroyed all at once.  It makes memory leaks really hard to create, but there is definitely some amount of overhead in having a heapzone mananger.  

I think Doug Lea's memory manager supports this sub-allocation mode of operation.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

Thanks, this is a lot clearer.

(I still think it would be a good diagnostic aid to make the server &amp; client message numbers disjoint)
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

I don't understand how the 'mixer' will be released (I'm am presuming it will be allocated at some point).

Other than that, looks ok.
|Patch Set 2: Looks good to me, approved

Just a rebase?  Then I better transfer the +2.... :-)
|Patch Set 3: Looks good to me, approved

+2 just to make my table view of changes not look like I haven't reviewed this.
|Patch Set 3: Looks good to me, but someone else must approve

(9 inline comments)

Just a few comments, but nothing that should stop moving forward.  Well, except if there are memory leaks...
|Patch Set 5: Looks good to me, but someone else must approve

Did you miss the comment in cras_alsa_io.c:963 where I think that you might be orphaning 'dev'?

If I'm wrong about that, this looks fine to me.

(Gerrit's base-compare system just doesn't work well.  If you choose patch 3, cras.mk shows up in this change!  And, new files always show everything as new...)
|Patch Set 6: Looks good to me, approved

(1 inline comment)


|Patch Set 7: Looks good to me, approved

I like check marks in my table view.
|Patch Set 1: Looks good to me, approved


|Patch Set 3:

It's it's just a rebase, then have another +2.
|Patch Set 3: Looks good to me, approved

Didn't mean to be stingy with the +2.  I'll give it out this time for sure.
|Patch Set 1: Looks good to me, but someone else must approve

(3 inline comments)

Forgot to do some actual marking on this set.
|Patch Set 3: Looks good to me, approved

Have another +2.
|Patch Set 1: Verified; Ready

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

Now using the right ebuild file.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

True enough, the install function could be entirely removed.

Verified that the files are installed as desired.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3:

I have no idea how removing src_install(), and creating a new chroot worked for my testing, but when going through the PFQ, the previous patchset failed because 'BOARD' was not set.

This iteration reinstates the src_install() function and ensures that BOARD is set before invoking 'install'.
|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)

Have uploaded a patch which does as you ask.  Can you +2 it?
|Patch Set 4: Verified; Looks good to me, approved

Another whirl....
|Patch Set 4: No score; Ready


|Patch Set 4: Ready


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

(3 inline comments)


|Patch Set 3: Looks good to me, approved


|Patch Set 2: Looks good to me, but someone else must approve

(2 inline comments)

Just a small nit on how you could improve the code.  Nothing wrong with what you've got.

Oh, and a request to make me unconfused.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

I added Richard to the review, as he's had useful comments to make on my upstart script in the past.  I'm not qualified to review that part.

I had one small request for the Makefile, but it shouldn't stop you from committing this change if the upstart folks are happy.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)

One minor nit.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

It would be nice if there were some commentary which described the threads that will use the barrier.
|Patch Set 1: I would prefer that you didn't submit this

(6 inline comments)

You might have an issue with return codes.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved

Disregard my comments about being consistent and adding logs for the remaining failure cases in a previous review... I see you did them here.
|Uploaded patch set 2.
|Patch Set 2:

Made my additional code to cras.c to better follow the existing code.
|Patch Set 2: Abandoned

Rather than shoehorning a dBus listener in to cras, I'm going to use a pipe instead.  This will require some infrastructure changes in gavd to create &amp; send information over the pipe.
|Patch Set 1: I would prefer that you didn't submit this

(5 inline comments)

I have some concerns about ignoring the return code from the attempt to resume the stream.
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Verified; Ready

With the use of linker sets, all the threads are started automatically.  So, with the current implementation, there isn't really any way to know that the thread should not be started until the thread starts and determines that it has no work to do.  At that point, the thread exits.

So, it's a minor hit on initialization, but after that no resources will be consumed for the thread.
|Patch Set 1: Verified


|Patch Set 1: (1 inline comment)

Did not see your comment until just now...
|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified

As it turns out, as the commit message describes, it's not yet possible to run as non-root because /dev/input files must be read to handle the headphone / microphone jack on Arm-based machines.

It would be nice to use udev for those events, but I don't think the jack switches are connected to udev on Arm machines.
|Patch Set 3:

And, beyond using udev for the switches, there are some unfinished plans about how to handle the switches in conjunction with cras; better to not perturb the system until that has been worked out.
|Patch Set 3: (1 inline comment)


|Patch Set 3: Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Not Ready


|Patch Set 1: Ready


|Patch Set 1: (1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

I have another small suggestion that might save a few cycles...
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1:

Doesn't this need a companion change to the cras build process in src/third_party/adhd/cras?
|Patch Set 1: Looks good to me, approved

Didn't know about the other change.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Looks good to me, but someone else must approve

(2 inline comments)

I don't understand how the first switch element is found.
|Patch Set 4: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2:

I have upreved the ebuild file; mea culpa for not doing that.

As for the udev rule, that was the culmination of a short discussion with Will.  

The gavd process starts when cras is started, and cras is started on system-services.  As long as gavd can read /dev/input/event* files, I am not particular about the details.  If Will's suggestion doesn't work, is there another route which can be taken to provide gavd limited access to these files?
|Patch Set 2:

In response to vapier's comments on patch 2:

  You are correct that I deleted the symlink; I verified that action was ok with David James.  I prefer having one less superfluous, obfuscating, file, but will do it your way.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

gavd needs to be in audio group, too.
This is required to execute amixer commands.
|Patch Set 4: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(2 inline comments)


|Patch Set 4: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve

Transfer +1
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

Switch to using 'access' instead of 'open', as suggested.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved

Transfer +2
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Reverted

This patchset was reverted in change: I2b420f47e3d36f5daaf39d1ad7e003d45b89b1e6
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(4 inline comments)

Nothing big preventing this from going in, but there are a few follow-ups to fix typos.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1:

It does have a relevant BUG= and TEST=.
Is there something I'm missing?
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Allow tree to turn green.
|Change has been successfully merged into the git repository.
|Patch Set 1: (4 inline comments)

I have a few questions.  The most important one is about the different between the 1db default and the 75 db default.
|Patch Set 1: Looks good to me, but someone else must approve

Let's give this a score so I can see that I've looked at it.
|Patch Set 2: Looks good to me, approved

(1 inline comment)

Just a small comment on how you could save a few cycles if so inclined.
|Patch Set 3: I would prefer that you didn't submit this

(2 inline comments)

Possible memory leak of the loaded ini file.
|Patch Set 4: Looks good to me, approved


|Patch Set 6: Looks good to me, approved

Still looks good.
|Patch Set 3: I would prefer that you didn't submit this

(5 inline comments)

-1 because I have concern about a difference between a header comment and the actual return value.
|Patch Set 4: Looks good to me, approved


|Patch Set 6: Looks good to me, approved

If there were no changes in patches 5 &amp; 6, this this still LGTM.
|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

Nothing much to say here.
|Patch Set 4: Looks good to me, approved


|Patch Set 6: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready

Let me put this in; hopefully there are no other build-breakers that I haven't discovered.
|Patch Set 1: Looks good to me, approved

In the C source files where you only change the name of an included header, but no other symbols, do those files need to be included?
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

I think you have a memory leak.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(5 inline comments)

None of my comments should stop this from being committed ... unless you think that they are important.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)

Really a +2, but a +1 just to make sure my curious comment is noticed.
|Patch Set 4: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

One minor suggestion for future-proofing...
|Patch Set 2: (1 inline comment)

Just a review-button poke to send this out.
|Patch Set 4: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: I would prefer that you didn't submit this

(15 inline comments)

There may be some resource leaks, so -1 just to make sure my comments do not get hidden.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(2 inline comments)

Just two questions, but that doesn't affect if the change should go in or not.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

Overall I like the idea, but there is one small issue which makes me give a -1.

The issue is that there are comments in the sound_infrastructure.py file which describe how to regenerate the files you have modified.

I think that the comments should be updated to reflect a new way to generate the control files -- when they need to be generated or regenerated.

I suggest:

   amixer controls&#124;cut -d ',' -f 2-&#124;sort



(It would be nice if the files were sorted in this commit, but that's really totally unnecessary)
|Patch Set 2: Looks good to me, approved

Thanks for doing this...
|Patch Set 2: Looks good to me, approved

It would be nice, in the future, if you could try to put a 'why' you are making the change into the commit message.
|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)

Possible buffer overrun...
|Patch Set 4: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)

Inconsequential question about checking for NULL... but LGTM.
|Patch Set 4: Looks good to me, approved

(1 inline comment)


|Patch Set 5: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 4: Looks good to me, but someone else must approve

(1 inline comment)

Possible memory leak detected.
|Patch Set 4: I would prefer that you didn't submit this


|Patch Set 5: Looks good to me, approved


|Patch Set 4: I would prefer that you didn't submit this

(7 inline comments)

Possible NULL pointer deref.
|Patch Set 5: I would prefer that you didn't submit this

(1 inline comment)

I think you might have a possible memory leak now.
|Patch Set 6: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

I assume that the '--use-cras' flag is correct and handled.
|Patch Set 4: Looks good to me, approved

(8 inline comments)

Just a few musings &amp; comments.
|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 4: Looks good to me, but someone else must approve

(2 inline comments)


|Patch Set 5: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 4: Looks good to me, but someone else must approve

(9 inline comments)

+1 just to ensure comments are read.
Really +2.
|Patch Set 5: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, but someone else must approve

(2 inline comments)

LGTM, but I don't understand why gain callbacks are being removed during initialization.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 5b0ba39d0a363cd71eeaa30cbc9d9a5c4a8e4817.
|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, but someone else must approve

(3 inline comments)

Really +2, but a few comments.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(2 inline comments)

I have a question / concern that setting the min / max values might be racy if it can be performed by different threads.  
But, that could be mitigated in a future change.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

+1 for suggestion to reduce the number of messages flying around, but really there is no reason why the change could not be made in a future commit.
|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

Modulo the commit message, this is really a +2.
|Patch Set 3: Looks good to me, but someone else must approve

(4 inline comments)

Really a +2.  Might be some errors in comments, and I have a question about negative values for gain.
|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 3: I would prefer that you didn't submit this

(2 inline comments)

If 'min' is allowed to be equal to 'max', then you the potential to perform a divide by zero.

If min cannot be equal to max, then +2.
|Patch Set 1: Verified; Looks good to me, approved

Chat-based approval to backport from Orit.
|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(3 inline comments)


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)

There is a case which will return garbage instead of a meaningful value.

(The compiler has a warning/error which will catch that situation; gavd has it if you want to snag it)
|Patch Set 3: Looks good to me, approved


|Patch Set 4: Looks good to me, approved


|Patch Set 3: I would prefer that you didn't submit this

(1 inline comment)

I don't understand the semantics of this system.  Can you please clarify?
|Patch Set 5: Looks good to me, approved


|Patch Set 4: Looks good to me, approved

(10 inline comments)

-1 because of comment on line 150 of one of the files -- you're returning an error when it might not be a good thing.

+2 otherwise.
|Patch Set 4: I would prefer that you didn't submit this

Sorry, I mean -1, for the reason previously stated.
|Patch Set 5: Looks good to me, approved


|Patch Set 4: Looks good to me, but someone else must approve

(4 inline comments)

+1 for typographical errors.
+2 for actual content.
|Patch Set 5: Looks good to me, approved


|Patch Set 7: Looks good to me, approved


|Patch Set 7: Looks good to me, approved

(2 inline comments)

LGTM, two minor suggestions which you can feel free to ignore.
|Patch Set 7: Looks good to me, approved

(1 inline comment)

Small suggestion on making a better log message for the long term.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Pushing for chromium-os-partners:30347.
Dylan in Singapore, and will be sleeping soon.
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

Let's get this change in to silence the autotest failures.  The file is not yet used other than the autotest.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready

Pushing for Dylan, who is sleeping in Singaport.
chromium-os-partner:30347, too.
|Patch Set 1: Looks good to me, but someone else must approve

(3 inline comments)

I have some worry about some use of a buffer management index, and I don't have enough confidence that I understand your intentions to push this in.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(5 inline comments)

Couple of small nits, but nothing that should prevent this from going in...
|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

Looks ok to me, but I wonder what happens when the server crashes an is restarted.  What happens to all the client data?  Is it ever recovered?
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved

(5 inline comments)

A few nits, but nothing which should preclude this from going in.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1:

This was not meant to be reviewed.
|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

+2 in reality.
+1 to make sure comments are read.
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Ready

Let's try again to get this through the commit queue.
|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

I don't understand why the client would exit before all threads have reached the barrier.  Isn't it waiting on the same barrier?
|Patch Set 1: Looks good to me, approved

Dylan explained the issue to me.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved

(2 inline comments)

Minor nits that can be fixed later.
|Patch Set 1: Looks good to me, approved

(1 inline comment)

Suggestion for making the function a static inline, but that won't halt getting this in...
|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

+1 because of superfluous if().
It's harmless to have the extra if(), so it can be addressed later if desired.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)

-1 most because I don't think I understand the details.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified

Partial fix for sound_infrastructure test failures for stumpy on R20
|Change has been successfully cherry-picked as 43e719b21a4779d8d0b905f7698352b0d1ff22a2.
|Patch Set 1: Verified

Partial fix for sound_infrastructure failure tests on R20
|Change has been successfully cherry-picked as cbb2642f951bb6f10f347b3de19bc8df283ba7b2.
|Patch Set 1: Do not submit

FD_SET and FD_ISSET are both defined to take an 'int' for the 'fd' argument.

As a file descriptor has been defined to be an 'int' for decades, it seems unlikely that either one of these two APIs will suddenly receive a long unsigned int.

Can you provide more information about this?  What was the failure?  How were things being built?  For what board?
|Patch Set 1:

To me it's pretty clear that this is a defect in glibc; they've done the cast to avoid using '&amp;&amp;' in their range check, and what they've done is arguably incorrect, particularly for use in a macro.

What I would prefer for this case is to file a defect against glibc 2.15, and workaround the code with a local variable, mentioning the glibc defect in the assignment to the variable.  For example:  (I suspect that just using 'unsigned' will work)

unsigned ufd = (unsigned)fd; /* See glibc defect #xyz */

   FD_SET(ufd, ...)
|Patch Set 1: Looks good to me, approved

(1 inline comment)

Minor nit about comment being out-of-date.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)

Minor nit about naming the file in the syslog messages.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(3 inline comments)

Just a couple nits...
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved

Just curious: Why a module and not 'Y'?
|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

Looks pretty good to me, but I'm concerned that there are corner cases where the first device found fails the new_dev() call, and then there will be no auto-routed device because the flag is set to zero in the failure case.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

Not sure what you mean by not being able to map them to a particular mode, but ignoring the boost controls certainly won't make things worse.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)

I'm not sure I'm reading this right, so I'm going to punt for now.

From my reading it looks like you're passing a pointer from the client of cras and dereferencing it in the context of the server?

Since that seems wrong, I'm surmising I must be misunderstanding at this point...

-1 to get this notice seen because of my own ignorance, not the actual content of the change.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

To aid with knowing that the function needs to be removed, you could use the 'deprecated' attribute.


void deprecated_function(void) __attribute__((deprecated));
void deprecated_function(void) { }

int main(void)
{
    deprecated_function();
}

'course this won't work so well if you have warnings turned into errors....
|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

I think you might be orphaning nodes in the sorting algorithm.
|Patch Set 1: Looks good to me, approved

Mea culpa; missed the appending on '&lt;='.
|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: I would prefer that you didn't submit this

(3 inline comments)

-1 because I have a concern for the case where frames_out &lt; frames_in, with our without conversion.

In that particularly case, wouldn't you still have the possibility of an overrun of the output buffer? 
And, I think the return value is wrong, at least with respect to the comment in the header file.

If I'm wrong about this interpretation, then +2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Fixed complaints.
|Patch Set 4: Verified; Looks good to me, approved; Ready

Transferring approval.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

A nit and a suggestion to leverage existing code.  Both, or neither can be done later, of course.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1:

I don't understand this change.  Your commit message talks about using the maximum frames of the server and the client.  But, I am not seeing that there is a comparison between the two (server, client).  It looks like the maximum number of frames is just calculated from the input stream.
|Patch Set 1: I would prefer that you didn't submit this

-1 because I don't understand the change.
|Patch Set 1: (1 inline comment)

As you can see, I made a comment on the Makefile, but as I was reading the other files, I realized that you could do this, in it's entirety in the Makefile.

Here's a little sample makefile that shows how it can be done:

 --- cut here ---
 
MODPROBE_BOARDS	:= stumpy x86-alex x86-alex_he x86-mario
ACTIVE_BOARD	:= $(filter $(BOARD),$(MODPROBE_BOARDS))
MODPROBE_CONF	:= $(addsuffix .conf,$(addprefix $(DESTDIR)/etc/modprobe.d/alsa-module-config/alsa-,$(ACTIVE_BOARD)))

install:	$(MODPROBE_CONF)
	@echo &quot;**** Installed modprobe configuration file&quot;


$(MODPROBE_CONF):
	@echo &quot;mkdir --parents $(dir $(MODPROBE_CONF))&quot;;
	@echo &quot;echo options snd_hda_intel model=$(ACTIVE_BOARD) &gt;$(MODPROBE_CONF)&quot;
	@echo &quot;chmod 644 $(MODPROBE_CONF)&quot;

$(info boards: $(MODPROBE_BOARDS))
$(info board : $(BOARD))
$(info active: $(ACTIVE_BOARD))
$(info conf  : $(MODPROBE_CONF))

--- cut here ---

(ACTIVE_BOARD isn't a particularly good name...)

If the board being compiled is not in the MODPROBE_BOARDS list, then MODPROBE_CONF will be 'nothing'.

make BOARD=tegra2_kaen
make BOARD=stumpy
make BOARD=x86-mario

From my perspective, this is the easiest way to do it: it keeps all the information in adhd, you don't have to go off dealing with overlays &amp; files scattered all over the disk, and it's entirely trivial to add a new board, or remove an old one.

Your choice, really.  Your method will work, and it can be changed later, if desired.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, approved

(2 inline comments)

Just two trifles in the commit message.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, but someone else must approve

(6 inline comments)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)

You've got a logic issue; the code will still work, but it would be nice to fix it.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

+1 because I have a question / suggestion for making the change smaller.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(4 inline comments)

-1 for lines 269..270.

Otherwise, all my comments are suggestions (which may not help readability) that you can ignore.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

Possible infinite loop when duration_frames is exactly 0?
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (1 inline comment)

Noticed typo in commit message.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (9 inline comments)

I think I've addressed everything.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 4: Ready


|Patch Set 4: Ready


|Patch Set 4: Looks good to me, approved


|Patch Set 4: No score; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

ebuild revision incremented.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified

Unit test is in progress, but not finished.
|Uploaded patch set 3.
|Patch Set 3:

Fixed indentation issues.
Have not addressed the comment about testing another function; for a follow-on.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Addressed indentation comments.
|Patch Set 3: Verified; Ready


|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

Looks ok, but you may have accidentally deleted some characters which should not have been deleted.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1:

This change, and the other two in the series are originally from a set of patches from Samsung.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1:

Did not notice request for tags... will update.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Transferring previous approvals; set up tags properly.
|Patch Set 1: Verified; Looks good to me, approved


|Patch Set 1: No score; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready

Tag fixed.
|Patch Set 2: Ready


|Uploaded patch set 3.
|Patch Set 3: Ready


|Patch Set 3: Verified; Looks good to me, approved

Transfer approval.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Ready


|Uploaded patch set 3.
|Patch Set 3: Ready


|Patch Set 3: Verified; Looks good to me, approved

Transfer approval
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready

Not only was s8 (versus u8) needed, but also a header was needed for getting the type definition.
|Patch Set 3: Looks good to me, approved

Transferring scores...
|Patch Set 3: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Functionally abandoned.  This is superceded by a couple changes where the GPIO is initialized via the device tree.
|Patch Set 7: Abandoned

This is now handled by the driver side.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready

Reordered changes; transferring approval.
|Uploaded patch set 6.
|Patch Set 6: Do not submit

This needs an update to deal with a compilation model where sizeof(unsigned long) != sizeof(void *), which happens with some paladin build.
|Uploaded patch set 7.
|Patch Set 7: No score

Upload a fix for the case where sizeof(unsigned long) != sizeof(pointer).  Reasoning why this is harmless is now in the commit message.
|Patch Set 7: Verified; Ready


|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Verified; Looks good to me, approved; Ready

Fixed subject.
Transferring approval.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, approved; Ready

Reordered changes; transferring approval.
|Uploaded patch set 6.
|Patch Set 6: Verified; Looks good to me, approved; Ready

Transferring approvals.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Simon,

The largest part of the code in sata.c is taken directly from the Samsung exynos5 driver that's in the process of getting into the linux kernel.  I didn't want to change it because then keeping the two files in sync will be quite painful.  As it stands, the diff is very easy between the two files right now.

Since the code is essentially a drop in, and since Samsung does not support u-boot, this seems like the right choice; no point in making our maintenance any more difficult than it needs to be.

With that in mind, I haven't done much to the body of the file; want to get an idea of your position on this before changing things.

Ultimately, I also think it would be better to commit the code as-is (i.e., working) and then make the device tree type changes, if that's the ultimate desire.  Iterating in gerrit is much less efficient when compared to actually iterating in the committed code base.
|Patch Set 8:

I will upload a whole new set of patches after the virt_to_phys() change goes through; I do not want to perturb gerrit in it's progress.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

I hope this releases all my drafts from patch #2.

I am also considering splitting the file into two parts: one with the code I added, and one containing just the samsung code in a same-named file that they used in the linux kernel.  I'm not sure how much that would make things easier... it's just in the back of my mind right now.
|Patch Set 2: (18 inline comments)

Very strange.  Patchset two had not 'review button' until I closed and reopened this CL.

Review to release my comments.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 2: (1 inline comment)


|Patch Set 12: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: Verified; Looks good to me, approved; Ready

Fixed subject.
Transferring approval.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14: Verified; Looks good to me, approved; Ready

This enables the self-configuration for the SATA device on Daisy. 

Just set  CONFIG_SATA_AHCI to turn it on.
|Patch Set 3: Looks good to me, approved

(1 inline comment)

Trivial comment for optimizing code...
|Patch Set 3: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Do not submit


|Patch Set 2: Abandoned

This change was split into two.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

split change as requested
transferring approvals
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

split change as requested
transferring approvals
|Patch Set 1: Do not submit

This is the approach I'm taking for making the SATA FDT-enabled.

Comments?
|Patch Set 1: Abandoned
|Patch Set 1: Do not submit

This is the approach I am taking to making the SATA FDT enabled.

Comments?
|Patch Set 1:

Drat... it's an entirely new file (because it's not committed yet).

Lines 34..46 and 409..447 are new as compared to the other uploads of this file.
|Patch Set 1: Abandoned
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready

Let's try again.
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Removed 'driver' tag.
Transferring approval.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Removed 'driver' tag.
Transferring approval.
|Uploaded patch set 3.
|Patch Set 3: Verified

This change fixes the type errors that didn't kill my build (and I didn't see...)

Tested w/ daisy.
|Patch Set 3: Looks good to me, approved; Ready

tegra2_kaen worked too.
transferring approvals.
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready

u-boot failed to build, but there are no errors other than the failure.  Let's try again.
|Patch Set 1: Ready

vmtest failures.... not u-boot-related
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 1: (7 inline comments)

...
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved

Thanks for doing this.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(2 inline comments)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Looks good to me, but someone else must approve

(2 inline comments)

Might be an off-by-one issue....
Otherwise +2.
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1:

This doesn't address any issues with piping to the u-boot process.  Control of the sandbox u-boot is an issue that's still up-in-the-air.  

This change is specifically for having a multiplexed console -- one that takes input from the pseudo-serial port (implemented now) and a keyboard (not yet up for review) at the same time.
|Patch Set 1: (4 inline comments)

Release the drafts!
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 1:

I don't think your argument is particularly convincing.  First, the FDT describes things in terms of memory addresses of the system.  Second, there will be devices an many systems that are memory-mapped at particular addresses.  U-Boot is not a virtual memory system -- it's running on a computer (real or sandboxed) with a particular memory layout; you just can't get away from the fact that there is a memory layout.  The user either has to know the memory layout, or they have to know the base address of the mapping.

I think it's just overall better to deal with the memory addresses defined by the architecture, and sandbox currently has memory that starts at 0x10000000.

Also, the reason that this was changed in the first place is because the different devices are accessing memory differently -- the MMC does not do a mapping of the memory, while the SPI does.  Without this change, the user will have to know to access things diffrent ways, *or* all the drivers would have to be modified to ensure that they either all do, or all do not map memory.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

Will not be identity mapped.
|Patch Set 1: (2 inline comments)

&gt; Could we make the memory 32MB, and separate out the 64KB
&gt; region (i.e. make it something that sandbox has that is
&gt; unrelated to the memory).

Linux has varying amounts of shared memory that can be allocated.  It's somewhere around 30Mb as the default.  I chose 24Mb just to be well-within that limit.


&gt; Then in the code you could check the memory size, 
&gt; and if it is larger than 32MB - 64KB you could throw an 
&gt; error.

The 64Kb is really out-of-band as far as U-Boot is concerned.  Another implementation could create two SHM regions, but the extra overhead of doing that doesn't seem to be worth the effort.  

First, the memory in the second (out-of-band) region would still be accessible to U-Boot through an errant pointer.  Second, if U-Boot does end up corrupting the doorbell area, then it's a defect in U-Boot, because it's beyond the available physical memory.

Exposing this out-of-band region to U-Boot isn't really happening.  It's being exposed to the Sandbox portion of U-Boot, which is really supposed to be separate.  I liken it to arguing that os_read() is exposing the C-library read() function to U-Boot.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (15 inline comments)

release the draft comments...
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)

Release the hounds.
|Uploaded patch set 4.
|Patch Set 3: (5 inline comments)

Fly, comments.  Be free.
|Patch Set 4: Verified; Ready


|Patch Set 1: Abandoned

Not yet.
|Patch Set 1: Abandoned

Not yet.
|Patch Set 1: Abandoned

Not yet.
|Uploaded patch set 2.
|Patch Set 1: (11 inline comments)

release comments.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 3: Ready


|Patch Set 1: Abandoned

Rearranged this simple change earlier than it should have been.

MEMORY_LAYOUT has not yet been defined.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

The calls to VbDisplayScreen() are coming from vboot proper, not from U-boot.

Is there a set of registered functions that provide this callback arleady, or are you proposing a set of new infrastructure to accommodate this simple change?
|Patch Set 2:

Simon pointed out how it works.  Never mind.
|Patch Set 2: Abandoned

Different implementation in U-Boot.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2:

done
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1:

done.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: (2 inline comments)

Is this really a -1? 
Both of these are 'wouldn't it be nice' rather than &quot;This code won't work&quot;.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Transferring approvals.
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Transferring approvals.
|Patch Set 1: Verified; Ready


|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transferring approval.
|Patch Set 1: Abandoned

Subsumed into I905718e1
|Uploaded patch set 2.
|Patch Set 1: (29 inline comments)

release the drafts!
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1:

There is no capabiility to see a dev screen in the Sandbox U-boot at this time, nor is there an ability to play any sounds.  

The timeout, in sandbox mode only, only serves to delay the progress of testing for the timeout period.

Sandbox can run with the timeouts, but it's not really useful since all we care about (at this point) is *which* kernel &amp; firmware have been selected.
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: (9 inline comments)

Will upload after previous change is commited -- otherwise it won't commit even if it passes the build.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Moved extern to header file.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transfer approval
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transfer approval
|Patch Set 1:

Nothing is wrong with the default.  It's a default.  The advantage of having an invalid value is simply for finding out where the value needs to be initialized.  If there is a crash because a pointer has not been initialized, it's bothersome to figure out where it's initialized.  This particular variable is unique enough that it wasn't too hard, but if it's something like a 'data' pointer, it's bothersome.

It's not a necessary change....
|Patch Set 1: Abandoned

Not necessary.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2:

Commit message updated.
|Patch Set 2: Abandoned

Abandoned to avoid and commit queue issues with prerequisite changes being abandoned.  (See the recent changes I abandoned).

Will upload again.
|Patch Set 1: Verified; Ready


|Patch Set 1: Ready


|Patch Set 1: Abandoned

Genius.  Abandoning a prerequisite prevents a dependent change from being committed because the prerequisite hasn't been submitted.
|Patch Set 1: Verified; Looks good to me, approved; Ready

Transferring approval from change which was abandoned because the commit queue wouldn't allow it in because its prerequisite was abandoned.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready

Transferring approvals.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: (6 inline comments)

Will upload in a bit.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: (6 inline comments)

Release the hounds.
|Uploaded patch set 2.
|Patch Set 2:

No changes made to this yet.
|Uploaded patch set 3.
|Patch Set 3:

I see no comments on patch set 3.
Patch set 2 had no changes, so shouldn't have comments (and I see none there either)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (3 inline comments)

If you really want this split into several changes, it may have to wait until Monday.

Personally, I think having one change which makes vboot compile &amp; build is much better than having several.
|Patch Set 5: Verified; Ready


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified; Ready


|Patch Set 7: Ready


|Uploaded patch set 8.
|Patch Set 8: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

Transferring approval; this has been reordered and can now go in.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Abandoned

This is superceded by another change.
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: (4 inline comments)

Upload after previous change sucked in by PFQ.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)

Release things...
|Uploaded patch set 3.
|Patch Set 3:

Please see my comments in first two patch sets.
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Abandoned

This change is split into two.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 4: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready

configuration split to separate change
|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|a question off the topic, I vaguely remember paygen test always starts a devserver process on a different port, will this count tells how often it does that?
|with labels__in=shard.labels.all(), we are doing an &quot;OR&quot; logic on the shard's labels, i.e. boards to shards is many-to-1 mapping. 

By doing this, we are giving up its alternative, i.e. the 1-to-many mapping where a board's load could be sent to multiple shards. This might also be a valid use case if we will in the future use some vm and each vm has limit capacity.

I am not oppose to choosing the first route. But I'd like to just keep this in mind and it probably worth making the docstring more clear about the decision we made.
|nit:
note that if a host happens to have two board labels at the same time, e.g.
board:stumpy_freon and board:stumpy, which sometimes can happen by human mistake, one host will be included twice in host_ids. convert it into a set might be more robust and efficient.
|Done
|oh, it is down below BUG=chromium:406434
|Done
|oh, that's right. moved to init function.

but note that get_sheriffs is currently broken
as we've moved to rotation.googleplex.com. I haven't figure out a way to let chromeos-test access our rotation site.
|Done
|Done
|yeah, it is a bit messy. But I'd like to keep this template string within this class as we've got other types of bug class as well and each bug class has a unique template. I tried to use ''' within the class but ''' doesn't seem to work with indentation.
|I tried to use ''' but that doesn't seen ti work with indentation.
|Done
|Done
|Done
|Done
|Done
|chromium:462819
|Could you describe the test flow in more detail?
|how about get_num_special_tasks_local?
and please add a docstring.
|the code here repeats the logic in get_host_special_tasks.
Could you refactor?
|why need to change this from host_id to host?
|put start_time, endtime in a new line or have the next line align with (
|get_host_queue_entries will call inject_times_to_filters which seems not necessary. can we just keep the old code?
|why renaming host_id to host? i feel host_id is more informative if it is really an integer.
|For better performance, I guess you could preprocess &quot;queue_entries&quot; to a dictionary like
  entry_map = {id: queue_entry} 

And here get rid of the for-loop and just do
   job_dict = entry_map.get(task['queue_entry']['id'])
|Could you add docstring for the params and return.
|an -&gt; a
|Could you add some explaination in the docstring about why some special task may lack the detail of its associated job?
|same question here
|this doc might need an update
|we already have run_with_retry in db.py, why that one doesn't work?
|nvm, run_with_retry only applies when executing a sql query, not connection time.
|close the quote in one-line
|can fit in line line?
|sorry i got many dumb questions. I don't quite get how directories are moving around.

  &quot;source&quot;: &quot;/etc/resolv.conf&quot;,
  &quot;target&quot;: &quot;/etc/resolv.conf&quot;,

  self.tmp_append = CONTAINER_BASE/usr/local/ssp_append
  target = CONTAINER_BASE/usr/local/ssp_append/resolve.conf
  target_dir = /etc

  so 'source' (/etc/resolve.conf) will be copied to   
  &quot;CONTAINER_BASE/usr/local/ssp_append/resolve.conf&quot;.

how does it inside the container link /etc/resolve.conf to &quot;CONTAINER_BASE/usr/local/ssp_append/resolve.conf&quot;?
|I am confused why some processing need to happen in &quot;pre-start&quot; and some in &quot;post-start&quot;

could you add some description what 
_deploy_config_post_start and
_deploy_config_pre_start are doing and why?
|seems should be **kargs
|if a user doesn't have the access to a path, it will complain

ls: cannot access /PATH/TO/CHECK: Permission denied

this will also lead to CmdError?
|put { in a new line, and indent by 4.
|name this file as ssp_deploy_config.json
|add a trailing comma after 400
|source will here will look like
source = usr/local/ssp_append/resolve.conf
without a prefixing &quot;/&quot; before 'usr'. And I assume attach_run knows the CONTAINER_BASE, is that right?
|oh, i see.
|remove this extra line.
|by &quot;temporary&quot;, do you mean it will be replaced sometime?
|60 secs? put 60 in a constant?
|do you mean you can't use
ClActionTable.objects.filter(build_id__in=build_ids)?
|FAKE_HOMEDIR is already a string, no need to convert?
|the problem might be that all() sas used together with filter. I think the following one might solve the problem

build_entry.annotationstable_set.filter(deleted=False)
|Done
|good catch. done
|Done
|moved credential path constants to cbuildbot/constants.py
so in the new patch, this code stays and it will pass the paths to GmailServer()
|moved to cbuildbot/constants.py
this class doesn't use default settings anymore.
ptal
|Moved the constants to cbuildbot/constants.py.
The default values will be passed to this class in tree_status.py
|Done
|Done
|Done
|why not also catch empty string and be more robust here?
|good idea. done
|Smtp is the easiest/standard way to send email if the server allows it. Might be useful for other customer to reuse our infra, for example, when security is a concern or gmail api not accessible for some reason.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|yeah, you are right, 1518 is for frontend jobs which already enforces hqe to exist. 1513 sounds the right place.
|Can we add the filter here, i.e.
  hostqueueentry__isnull=False

This might be more efficient. If you use exclude, it will result in a query like this:

NOT ((`afe_jobs`.`id` IN (SELECT U0.`id` FROM `afe_jobs` U0 LEFT OUTER JOIN `afe_host_queue_entries` U1 ON (U0.`id` = U1.`job_id`)

The above will join the the full table of afe_jobs and afe_host_queue_entries.
|Do we still need above two lines?
|if you'd like to check for suffix, probably add it here.
|this is how we do logging in this module.
|could you add this to unittest as well?
|make 1 as an option input from the command line. So that in case we need to manually run this script we can be flexible.
|match.groups(1)
match.groups(3)
|make &quot;an hour ago&quot; a variable
|return True or False. None is a little ambiguous.
|remove the ending comma
|aha, my problem was due to the ending comma which makes tasklist to be a tuple instead of a QuerySet.
|The first arg of prepare_rows_as_nested_dics is &quot;A Django model query object with a select_related() method&quot;.

Seems tasklist is of type list but not a query.

And why we need to select queue_entry here?
|please ignore my question about queue_entry...the other part of the comment is still valid.
|in status_history.get_status_tasks, it says
   return tasks[0:1]
Looks like it is returning the one entry instead of the query object which prepare_rows_as_nested_dicts expects.

on my local machine I got
  AttributeError: 'tuple' object has no attribute 'select_related'
|changed from
LockFile /var/lock/apache2/accept.lock 

LockFile is deprecated
|Removed
  Include /etc/apache2/httpd.conf
which doesn't exist on newer version of apache.
|changed from 
  Include /etc/apache2/conf.d/
which is renamed in newer version of apache
|thanks for catching this. retested and made sure the module is actually disabled.
|we also have some other statuses like ERROR. 
How about check for if test.status != 'GOOD'
|here is a comment, guess the new option need to be a string type.
|need to do the same trick for &quot;options.offload_failures_only&quot;
offload_failures_only needs to be a string rather than a boolean.
|fyi, we use chromite.lib.parallel in gs_offloader. seems working well.
|Please add [autotest] at the beginning of the title
|replace the tab with spaces
|-&gt; GitResetError
|four space indentation
|The current logic handles the situation where
proxy goes down in the middle of a run and the job_id is seen in output. There are some other cases need to be handled here. I list the possible cases below:

1) GOLO proxy was down at the beginning, we get code PROXY_CANNOT_SEND_REQUEST(11). In such case no suite has been created, no job_id seen in output. We can retry with original cmd without -m.


2) GOLO proxy went down in the middle of a run, we get code 
PROXY_CONNECTION_LOST(12)
   if job_id seen in output:
     while (getting PROXY_CANNOT_SEND_REQUEST or
            PROXY_CONNECTION_LOST):
          retry with -m
   elif job_id not seen in output:
     fail the stage
     (or call abort_suite and retry without -m)


3) PROXY_TIMED_OUT(13) anytime during a run,
   usually not indicates a golo flake, probably don't retry.
|drones should use the default conf; and drones are in &quot;prod&quot; as well. So the naming &quot;prod&quot; might not be very accurate. But I don't have a better name. so just an FYI.
|but maybe it doesn't hurt for drone to have sso, would be safe if you could test this.
|might be better to use
self.tmpdir (which got cleaned up automatically after the test finishes)
|Done
|The google api is built on httplib2 and there is a doc says it needs httplib2.Http().
http://google-api-python-client.googlecode.com/hg/docs/epy/oauth2client.client.OAuth2Credentials-class.html#authorize
|I found httplib2 is not by default installed with GCE base image. Should I be concerned that some bots might not have it?
|btw, I also need to install google-api-python-client and put a oauth2 credential token on the golo bot. How could I do that? (unfortunately it seems that gmail doesn't support using service account)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The docstring of &quot;authorize&quot; says it accepts an object of An instance of httplib2.Http() or something that acts like it. I am not sure how I could do it with https.
|Done
|Done
|Done
|I can do this. But changing the interface means that we are not back-compatible. I can grep the callers in chromite, but not sure whether it is used by code outside chromite.
|I kept it here for safety as some slaves don't have httplib2.
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/mixed-c-pre-cq/builds/7863
|I tried to use ~ directly, but for some reason it doesn't work for me if I don't use expanduser (I am using python 2.7.6).

  fdeng@anthill ~ $ ls
  ...  chromeos-stats-cmd-history ...

  fdeng@anthill ~ $ python
  &gt;&gt;&gt; import os
  &gt;&gt;&gt; os.path.exists('~/chromeos-stats-cmd-history')
  False
  &gt;&gt;&gt; os.path.isfile('~/chromeos-stats-cmd-history')
  False
  &gt;&gt;&gt; os.path.isfile(os.path.join(os.path.expanduser('~'), 'chromeos-stats-cmd-history'))
  True
  &gt;&gt;&gt;
|gotcha. Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|get_chromeos_release_version by default looks at /etc/lsb-release
why need to pass the content to it here?
|make the summary fit in one line.
|Currently the logic lives in provisioning.

Ideally, any code that reimages the dut should take care of creating the label and re-apply the label. The problem is reimaging happens in both machine_install and autoupdate_EndToEndTest, the only code path they share is autoupdate module.

One idea is to provide &quot;preinstall&quot; and &quot;postinstall&quot; functions. Every code involve reimaging a dut are supposed to call them. There would be no code enforcement though. If we really want to enforce it, we have to put it in the code path that all reimaging will share, which is harder.
|This CL provides an opportunity to detect and correct a &quot;label-mismatch&quot;, but can't guarantee that the problem is 100% gone. 

More important, I think we need to prevent this from happening in the first place by ensuring every re-imaging flow apply the label properly.
|cool, I understand it now.
|this check and the next check can be done using one check
  '^[\d]+.[\d]+.[\d]+(-rc[\d])?$'
|same here
|Done
|Gmail api doesn't support service account. So I couldn't use &quot;scopes&quot;, had to use a token.
|Done
|Done
|I am following the other two similar methods _SetupCIDB, _SetupTreeStatus. I thought RunCommand was used for a reason, though I am not sure about that.
|Done
|Done
|Made the script be compatible with the usage of /bin/mail.
We can try replace /bin/mail with site_utils/gmail_lib.py in nagio config.
|I found this (search for '/bin/mail' in the page)
https://access.redhat.com/documentation/en-US/Red_Hat_Storage/3/html/Console_Administration_Guide/Configuring_Nagios_to_Send_Mail_Notifications.html

Seems that by default it uses /bin/mail to send email, but you can change it to any arbitrary command. I'll need to change the interface of the the script so that it takes a stream of text instead of a file.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|added a comment
|Done
|Done
|Need to load the token and authorize everytime a email is sent as the http authorization might expire.
|Done
|required doesn't check for empty string. just in case
|replace with sys.stdin
|Done
|Done
|Done
|Done
|Done
|Done
|rephrased. ptal
|Done
|It is None in unittest
|add a docstring
|I wonder whether logging is better than print?
|How will drone refresh work with autoserv pid file inside container?
|The logic here doesn't seem to be able to handle case like

/usr/local/autotest/results/2032-chromeos-test/chromeos1-rack5-host6

os.path.basename(options.results).split('-')[0] will return 'chromeos1' instead of 2032?
|how could _get_job_id_or_task_id be replaced by basename and split?
Will the format of &quot;results&quot; change?
|if only need once, how about
   if machines:
|paths_to_replace.get(arg, default=arg) might be easier to read
|resolve the TODO?
|In autotest, usually upper case for constants.
But since hostname is not a constant anymore, I am using a lower case.
|The original logic here is actually what we want, no need to add the change here.
SERIALIZATION_LINKS_TO_KEEP indicates that even if we don't follow the foreign key, please store the value anyway. If you do something like


HostQueueEntry.objects.get(id=234).serialize(), you'll find host_id has already been serialized.


So our problem being that, although the shard_client is able to serialize host_id, the master won't pick it up. The logic you want to look at is in 
&quot;update_from_serialized&quot; in model_logics.py, which blindly ignores all foreign key. To fix it,  I suggest 

  - add a new field UPDATE_FROM_SERIALIZED_LINK_TO_KEEP (just like SERIALIZATION_LINKS_TO_KEEP)
  - make update_from_serialized read it and update any thing specified in this field.
  - HostQueueEntry specify UPDATE_FROM_SERIALIZED_LINK_TO_KEEP=['host']


Let me know if I am misunderstanding anything.
|got it. sorry that I somehow thought you were adding &quot;include_dependencies&quot; instead of removing it.
|Please make sure job/host pages on both shard and master function properly.
|host queue_entries are created on the master and sync'd to the shard, and sync'd back to master once it finishes. With that said, for dut_status, i think it is okay that it hits the master.
|we don't want to block this on shard. The frontend relies on this method.
|same here, we don't want to block this on shard.
|There are some possiblities:
1. filter_data has host_id=X
2. filter_data has host_id__in = [X, Y, Z]
3. filter_data doesn't have host_id nor host_id__in, but some other filters.

In the case of 2 and 3, it might involve hosts on both shard and master or multiple shards. I am not sure how the frontend Java code is using this rpc. Could you please check?

I suggest we either fail loudly when 2,3 happen so that we don't run into mystery bugs, or we support case 2 and 3 here.
|why put in a separate function? seems we are not reusing it anywhere.
|Please see my comment in last patch, I don't think we need to query shard for hqes.
|You are right. I was thinking currently these statuses were only for human consumption and dut_status won't care about these transient statuses, so maybe we can save some traffic here. But on a second thought, I think it might be good to fix this to avoid confusion.
|See crbug.com/462819, I think this CL is a good opportunity to fix that one.
|Can we do something similar to fanout_rpc here for get_special_tasks? It would be nice that dut_status, master frontend, shard frontend can call the same method &quot;get_special_tasks&quot;.

Some thing like
def get_special_tasks():
   if utils.is_shard():
        return objects from local db
   else:
        tasks_on_shards = []
        for each shard:
            tasks_on_shards += get_from_shard('get_special_tasks', filter_data)
        tasks_on_master = read objects from local db
        return tasks_on_shards + tasks_on_master

No need to check host_id or host_id__in or even filter_data if we assume one host can only present on one shard. Master has all hosts but won't have their special tasks, which ensures no duplicate record in the result.

This will solve the case 2, 3 I mentioned earlier.
And as an extra benefit, we get master frontend automatically show all special tasks (including shards').

How do you think?
|Performance is not an issue today but would become a concern if we got 100 shards. Given that, I am okay with not supporting case 3. But I feel case 2 is easy enough to support if we can go over the host_id__in list and hit each shard we need to.
|I think it needs to say &quot;if not result&quot; as result might be empty list.
|got it. could you please add a comment here for this?
|Here are the places which I found also call this method.
1. frontend/client/
   also calls 
     get_host_queue_entries_and_special_tasks
     get_num_host_queue_entries_and_special_tasks
2. server/cros/dynamic_suites/
3. site_utils/gs_offloader
4. site_utils/diagnose_util

2 and 4 are sensitive to performance. 1 and 3 are fine.

And you are right, we don't sync back host_id from shard to master. It looks like update_from_serialized in model_logics.py blindly ignore all foreign key. One way to fix it is to let update_from_serialized handle a setting like UPDATE_FROM_SERIALIZED_LINK_TO_KEEP, and have HostQueueEntry specify it.

Could you move the hqe related changes to a saperate cl? Let's get special task to work first.
|how about set shard_hostnames in each branch, and call pack_in_list(get_from_shards(...), results) with shard_hostnames ouside the if-elif-else clause?
|Does the frontend work without problem?
|Need to handle a corner case.

If 'id' in kwargs or 'id__in' in kwargs:
    return results

Task ID is not universally unique, the id passed in would only be applicable to local db.
|sg.
|nit: no need to convert to list, all() returns an query set that is iterable.
|need to recompile the frontend. Maybe move the frontend java/html change to another cl.
|why can't we set the default to &quot;True&quot; here but have to use None?
|Could you please add some comment on the complication of True/False/None here?
|same question, can we avoid the None case complication here?
|Got it. Maybe add a comment for it.
|please run a dummy suite and make sure the bug we saw doesn't reproduce after the change applied.
|&quot;that need the label&quot; needs to be updated.
|I think the docstring needs to say &quot;The hostnames of hosts that need to remove the label from&quot;
|In short, host-scheduler on the shard needs to read suite jobs' keyvals &quot;suite_min_duts&quot; for scheduling purpose. But since suite jobs are not synced to shard, their keyvals are not available on shard currently.

The following doc describe how host-scheduler uses &quot;suite_min_duts&quot; 

https://docs.google.com/document/d/1aMkb3CgiW1teTumkdNl05DJPdRf46fs-zieH0EuclD4/edit
|def __init__(self, afe, hash)

if t is the hash, where is the afe? i am a bit confused..
|SpecialTask's constructor seems to take two args &quot;afe&quot; and &quot;has&quot;, but here we pass in 't'. How does this work?
|ah, actually, no -m here, this is for kicking off the suite.
(Updated the build name which I actually used)
|I ran the alter statement on a backup prod db copy of 15 million rows in afe_jobs. It took 1 hour 20mins. The current db has 20million rows. You may want to schedule a minimum of 2 hour downtime.

The rest look good to me.
|yeah, we have a many &quot;do&quot; and &quot;don't&quot; in the architecture that'll be a headache in the long run. The doc sounds a good idea. Not specific to this problem, I am also thinking maybe we can add some periodically db consistency checking.
|i gave it some thoughts.
this code replies on the assumption that we call deserialize host/job only on creation of a host and job. If you try to modify a field of a host on master, and call deserialization outside the normal heartbeat, the attributes and keyvals will be lost.

Given the assumption is true with our current implement (I believe), I am willing to accept it. My reasons are here:

- Most host attributes/job keyvals generated/updated at runtime on a shard, like job_repo_url, we can afford losing them. (need_collect_crash_log may need some special treatment). And we won't face the problem as long as we don't break the above assumption

- If we don't clear the existing attributes, we'll risks on having incorrect (outdated) attributes be associated with a host when a host is deleted and re-added, which would be pretty bad.

how do you think?
|Done
|core_filters defines how one model is related to the other model in a 1-to-many relationship.
e.g. Host vs HostAttribute
The value of Host.objects.get(id=20). hostattribute_set.core_filters equals {'host_id': 20}
From core_filters, we know Host 20 related to its attributes via field host_id=20

The goal here is to find all the related objects (host attributes in this example) and delete them.

I added some comments. Let me know if it still confusing.
|good catch. i wanted to move it class Job but ended up copying it.
|PFQ runs bvt-cq and bvt-inline in parallel. i change this to 3 so that they will take 6 in total.
|yeah, that's fine because locked and invalid columns only exist in afe_hosts tables.
|right, that's intentional. s.Running is referred in the second sql. all the states in &#124;states&#124; is referred in the first sql
|log the skipped test?
|Will logging an empty string result in a blank line?
I would suggest return None here and make the caller do not print the link if retry link is None
|I guess you need to pass in testname=v.get_testname() here?
|this needs to be changed to default_database
|Done
|The suite will still run if we have less than 10 available.
This is 'preferred' minimum number of duts, but not a hard restriction.

The suite will aggressively grab up to 10 duts if there is availability. Once it gets 10, scheduler will deprioritize giving it more duts and try to feed other suites with lower priority(pfq/canaries), so that canaries/pfq won't starve.
|sorry i missed this,
it needs to be changed to &quot;autotest_stats&quot;
See: https://chromium-review.googlesource.com/#/c/246428/5
|the above line can be removed, timer can be reused.
|same here, timer can be safely reused.
|is measuring &quot;local&quot; necessary?
When &quot;serialize&quot; is called on a model, all data of its fields have already been pulled from db. Thus I'd expect &quot;serializing local&quot; would just mean assigning couple of fields in a dictionary in memory, which should be super fast.
|you may save a couple of lines with the following
timer = stats.Timer('deserialize_latency.%s' % ...)
with timer.get_client('local'):
  ....
|same here
timer = stats.Timer('deserialize_latency.%s' % ...)
with timer.get_client('local'):
  ....
|tested on my local autotest setup by running the scheduler and scheduling a dummy suite. works fine.
|Could you add
DEPLOY=apache, scheduler, host-scheduler.
We now have auto-push, just in case for debugging purpose.
|it needs to say &quot;==tot&quot;
|Done
|Done
|right, this behavior is not garanteed if more than 1 dep is provided. We could make the sorting more sophisticate to take account of the order of deps as they are listed in &#124;preferred_deps&#124;. Currently the cros-version is the only case, so I think it is okay to go with the most dumb sorting for better performance. I added some clarification to the docstring.
|I cherry-picked this cl and did the following test:

- Run a dummy suite, observe metadata about host_history are properly stored
- Run stats.Timer(metadata={job_id: 1234}); stats.start();stats.stop()
   Observed the stats works well and metadata are properly logged
- Run ./collect_suite_time_stats.py --suite 6162 --verbose --cron_mode
   The script works fine.
I think these should cover most code paths.
|the docstring needs an update after refactoring.
|please add &quot;import common&quot; here
|The following line will not work without import common.

my understanding is this file would be an autotest-side wrapper and would not be a part of chromite?
|please add docstrings for the three methods.
|this one can be removed now.
|create_range_query-&gt;_compose_query
|please add a docstring here
|the carbon server and port are not used anymore. could you take the chance deleting them?
|you are changing the interface of &quot;add_label&quot;. Things like server/frontend.py will fail. There are also some reference in cli/
Please grep the repo and update any caller.
|oh, you are right. I missed the fanout_rpc part that calls it.
|Could you make this method private if you don't expect any caller outside this file? 

And the docstring summary seems express the same thing as the label_add_hosts, please update. Maybe we should choose another name that makes the distinction more clear.
|Is Fanniout a typo?
|you may also want to rebase this cl, it is conflicting with tot
|Add deploy=apache
Please restart local apache and run a dummy_suite with a build that is different from current build of your dut. Make sure the provisioning flow is not broken.
|there are callers in the codebase that depend on create_label rpc. please update the callers.
|should it be name=label.name?
if `id` is an integer, I guess we will have problem.
|add a docstring.
|Done
|Done
|just to emphasize that I am quoting the parameter. It is not a coding standard.
|I believe conditions in one exclude have the relationship of 'AND'. We need a 'OR' logic here, so a chain of 'exclude' is used.
|good point, I think they can overlap if one manually put a label, say, 'board:x86-mario' when creating the job. Change to set.
|Done
|Done
|Done
|Just figured out how to import site_utils.
|Done
|Ok, I'll just leave it as it is.
|I am getting &quot;ImportError: No module named autotest_lib.client.common_lib&quot; here, any quick idea on what's going on?
|still not work.. I put a &quot;todo&quot; here.
|Done
|Done
|Done
|Function is moved to common_lib/site_utils.py, this comment is addressed there.
|Done
|Done
|Done
|I agree. I removed the check here.
|Currently, compare_multiple_traces is implemented in a way that if the expectation for an input perf value is not defined in the expectation file, it simply skip checking it (see Line 165-167) instead of raising an error. To make the behavior consistent,  &quot;no data in an expectation file&quot; here means that &quot;we want to skip everything&quot;. 

Is doing this way good? any better idea on how to deal with missing expectations?
|I am trying to load the the expectations for a specific combination of (board, test) and filter others. For example,  if we have defined the following expectations and initialized the expectation_checker with board = 'lumpy' and test_name='test_1', we will only load the first two expectations in the following list rather than all of them:

&quot;lumpy/test_1/trace_1&quot;: {....}
&quot;lumpy/test_1/trace_2&quot;: {....}
&quot;lumpy/test_2/trace_1&quot;: {....}
&quot;lumpy/test_2/trace_2&quot;: {....}

&quot;stumpy/test_1/trace_1&quot;: {....}
&quot;stumpy/test_1/trace_2&quot;: {....}
&quot;stumpy/test_2/trace_1&quot;: {....}
&quot;stumpy/test_2/trace_2&quot;: {....}


In this way compare_one_trace will be able to search in a smaller set of expectations(2 expectations in this case) rather than a set of 8. 

Does this answer you question? Please let me know if I misunderstand your question and you are talking about something else.
|I adopted this checking logic from chrome tree. I think they use regex to ignore wrongly formatted perf_key. If not using regex, I think I'll put the following. I feel it is little verbose in this way, but maybe add some readability? How do you think?

keys =  perf_key.split('/')

if len(keys)!=3
    continue

perf_board, perf_test, perf_metric = keys

if not perf_board == self._board or not self._test_name == perf_test:
  continue
self._expectations[perf_metric] = all_data[perf_key]
|Done
|Done
|Done
|Done
|I think it depends how we want to deal with those cases when trying to check a perf_value for which an expectation is not defined.

The way Chrome does is that when an expectation is missing, it simply note the result as &quot;MISS_EXPECTATIONS&quot;, is that what we want or we need something different?
|Done
|I think they are not equal. Assuming that we have only two options for the value of 'better' which are &quot;higher&quot; and &quot;lower&quot;, then we have:

if perf_data.get('better') !='higher' 
is equal to
if (('better' in perf_data and perf_data['better'] == 'lower') or
   'better' not in perf_data)
We are missing the condition 'regress &gt; improve' compared to the original.

The checking sequence is that first check the value of 'better', if not defined, try to determine by comparing the values of 'regress' and 'improve'. 

The code is adapted from Line 275-295
https://cs.corp.google.com/#chrome/tools/build/scripts/master/log_parser/process_log.py&amp;sq=package:%5Echrome$&amp;q=perf_expectations.json&amp;type=cs
|Done
|Waiting for reply for the comment on Line 122
|I manually calculated these thresholds for perf.ScrollTest
I used recent performance values (stumpy-R23-2813.00) for these metrics and introduced 15% tolerance manually. For example,
The recent performance value for stumpy/desktopui_PyAutoPerfTests/FPS_ScrollBlankPage is 361.36. The 'improve' I've input for its expectation is calculated as &quot;361.36 * (1+0.15) = 415.564&quot;.
|I don't quite understand, by a helper function, do you mean something like below?

def process_perf_comparison_result(result):
   if result['regress']:
      raise error.TestFail(...)
   if result['improve']:
      raise error.TestWarn(...)
|Yes, do we want to distinguish these two then?
|Hold for now until we get an consensus on where to put the checking logic.
|At the end of each perf test, add this piece of code to check regressions.
|moved to client/common_lib
|I added a page here and some instructions. Current content is just a draft, it is subject to change.
http://dev.chromium.org/perf-regression-detection
|As discussed offline, for the first step we will manually input the values of improve and regress. see next patch.
|Each expectation is an entry in a dictionary.
The key is &quot;board_name/test_name/trace_name&quot;
The value is a dictionary that represents the details of an expectation.

For &quot;lower is better&quot; case, if the actual performance value is lower than the value of &quot;improve&quot;, improvement is detected.

For &quot;lower is better&quot; case, if the actual performance value is higher than the value of &quot;regress&quot;, regression is detected.

&quot;better&quot; indicates whether it is a &quot;lower is better&quot; case or the opposite.

builda and buildb represent two build numbers. Ideally, there will be another script(make_expectations.py, not implemented yet) which takes these two numbers as input, looks up the performance history in autotest database, and then automatically reasons the value of &quot;improve&quot;/&quot;regress&quot;. I haven't implemented  this feature yet so they are just two place holders. Currently, we need to manually specify &quot;improve&quot; and &quot;regress&quot;. 

&quot;sha1&quot; is supposed to be used by make_expectations.py too to detect any changes in &quot;builda&quot;/&quot;buidb&quot; or &quot;better&quot;  so that it can regenerate &quot;regress&quot; and &quot;improve&quot; if needed.
|removed
|I am following along the doc at http://www.chromium.org/chromium-os/testing/collecting-stats-for-graphite

I was a little confused by the names of different metrics &quot; count_ps, mean_90, upper_90...&quot;. What does &quot;_90&quot; mean? 

Also, are these results calculated based on a &quot;10-second&quot; period? I see a 10-second window is used for &quot;Counters&quot;. Does &quot;Timers&quot; work in the same way?

It would be a lot easier to understand graphite results if the doc could explain the metrics :)
|Done
|Done
|Is there a better place to put this url? It looks like buildbot/constant.py stores various constants. But I am not sure whether I should have cros_build_lib.py depend on buildbot/constant.py
|Please ignore my comment. I just saw cros_build_lib.py already has imported constants.py.
|1. Done
2. I moved the method to a new python file. The new file initiated a logger (logger = logging.getLogger('chromite') ) and uses it in the method.
|Done
|Done
|It looks like there is a bug preventing us to use timer.get_client.

In graphite/stats.py, the constructor of Timer doesn't have an arg called &quot;connection&quot;

class Timer(statsd.Timer):
    &quot;&quot;&quot;Wrapper around statsd.Timer.&quot;&quot;&quot;
    def __init__(self, name, bare=False):
        super(Timer, self).__init__(_prepend_server(name, bare), _conn)


But in client.py:get_client(..), it tries to construct a new timer with a &quot;connection&quot;. An exception is raised when call get_client via an instance of stats.Timer

        return class_(
            name=name,
            connection=self.connection,
        )

I'll create an other cl to fix it before modifying the code to use get_client.
|I've moved most of them except for the last two steps. Please take a look. 

The results are sent with different namespaces.

'scheduler' for methods in site_monitor_db

'drone_manager' for methods in site_drone_manager

'host_scheduler' for methods in host_scheduler

'scheduler_models.Host' 'scheduler_models.Job' and 'scheduler_models.HostQueryEntry' for methods in correspoinding classes in scheduler_models
|I saw the time stat for tick() is written in SiteDispatcher. So for each method of BaseDispatcher called here, I added a wrapper in SiteDispatcher and a time stat around it. 

For other steps which call methods in _drone_manager , email_manager, django.db, I just added the time stats in tick()

Another way is to put all time stats for each sub task in tick(). I am debating on which way makes the code more clean.
|As mentioned in the discussion in issue 196392, this maybe a place we are interested in measuring.
|Done
|Done
|Done
|Done
|If we use  &quot;with...as queue&quot;, we lose the control of the maxsize of the queue. I saw the comment above, it looks like we would like to keep it small so that it wont take too much memory and too long for a graceful exit. Does their concern still exist?
|Done
|Is there a reason we keep the references to each thread in a pool? The threadpool seems never got referenced in the code.
|Alex, I haven't fully understood it yet. Would you please point me to the code where they sidestep pickling the function as you said?
|This is interesting and good to know. Thanks for the example. I'll come up with a new patch.
|I tested the script locally by having the the results uploaded to a test google storage folder. It didn't throw an error and looks like it was able to pass the function between processes. I haven't had an explanation for why it works yet given the fact that a function can't be dumped using cPickle. I am still trying to figuring it out.
|If the current script works without problem, do we still want to change it to use BackgroundTaskRunner? What else will we benefit from the change?

Will there be any side-effect if we introduce an dependency to chromite.lib in this script?
|According to python doc, when a process exits, it attempts to terminate all of its daemonic child processes. I think it can prevent any spawned process from becoming an &quot;orphan&quot; if for some reason the main process terminates. How do you think we keep it?
|Another CL is coming for changes in chromeos-admin repo
|The option &quot;--threads&quot; doesn't accurately reveal what the script is actually doing after we switch to use multiprocessing. But changing it may lead other code depending on it breaks. Do we want to change it in this CL or leave it as it is?
|Decide to go for the original solution after all discussions.

I dug through the following code:
- rpc_util: get_host_query, extra_host_filters
- model_logic: query_objects, smart_get(called by extra_host_filters)

Here's what I found:

1. models.Host.query_objects has already been returning an empty result set when no matched host are found. It is implemented to use &#124;filter&#124; function of models, which returns an empty result, rather than &#124;get&#124;, which raises Host.DoesNotExist.

2. The only case that Label.DoesNotExist is raised is when &#124;get_hosts/get_host_query&#124; is called with arg &quot;multiple_labels&quot;. The error is actually raised by &#124;smart_get&#124; that is called by &#124;extra_host_filters&#124;.

With above said, I belive we are not introducing a new return type in this CL, but just handling the exception gracefully.

I double checked all places in the autotest repo where get_hosts gets called. I confirmed that they wouldn't be affected by this CL.

For the case brought up by beeps@, 
def get_info_for_clone(..):
   ...
   host_dict = get_hosts(id=host.id)[0]
   ...
I believe it shouldn't be affected by this CL for two reasons:
- It doesn't use multiple_labels arg, and therefore, Label.DoesNotExist won't be raised in any case.
- It is using a host id to retrieve the the host. As long as the id is valid, we should get exactly one host.

host_dict = get_hosts(id=host.id)[0] naturally introduces a risk of raising IndexError as it refers to index 0 without checking, but I feel that is a different problem and maybe we file another issue for it?

Please correct me if I understand the code wrong.
|It is good to know the original design consideration. I am thinking building a whitelist of exception types and make RetryingAFE do not retry calls when the exceptions fall in the whitelist. 

Do you remember what exceptions other than URLError we want to retry?
|These imports do not get used.
|proxy doesn't get used.
|Another thing, stop has a default arg subname='total', is it a good idea to allow customizing it? Otherwise we will have a sub directory called &quot;total&quot; in graphite I think?
|Looks like a dot at the end of the name doesn't matter in fact :)
|I am not sure what will happen if we pass an empty string to subname. Will it result in a final name looks like &quot;schedule.tick.&quot;
(with a dot at the end)?

I saw in site-package/statd/client.py, it uses '.'.join to create the final name. 

    def _get_name(cls, *name_parts):

        def to_str(value):
            if isinstance(value, unicode):
                value = value.encode('utf-8', 'replace')
            return value

        name_parts = [to_str(x) for x in name_parts if x]
        return '.'.join(name_parts)
|Hi Alex, I moved the check to _prepend_server() and tested. PTAL.
|Done
|Done
|Why is self.connection set to None here?
|Why do we need overload _valid_connection?
|The first two still work. I commented out the others that don't work and keep the call in main.
|This test fails as chromeos2-row2-rack3-hostbs, chromeos2-row2-rack3-hostbs2, chromeos2-row1-rack7-hostbs1 are not on chromeos2-row2-rack3-rpm1. Should we do something about it?
|Done
|An issue about cleaning the rpm code is following
|Filed a bug about the code cleaning job.
https://code.google.com/p/chromium/issues/detail?id=248844
|Done
|Done
|Done
|I modified the tests in the new patch. They are now mocking pexpect.spawn.read_nonblocking() which returns output stream from the switch.

I also mentioned that we should change Sentry rpm tests in the rpm-code-cleaning issue.
https://code.google.com/p/chromium/issues/detail?id=248844
|Done. 'rb' is not necessary, removed.
|This has something to do with the formatting of the csv file we are going to use. In the csv file, I am having a placeholder for each interface which currently doesn't have a servo attached to it (in which case servo_hostname == ''). I feel including such ports will make future modification to this file easier and help avoid duplicated input for a port.

The csv file looks like following, as noted in docstring:

chromeos1-rack5-host3-servo,chromeos1-poe-switch1,fa15

,chromeos1-poe-switch1,fa16

,chromeos1-poe-switch1,fa17
|Done
|Done, I also re-order the imports as I see in the CODING_STYLE imports using 'from' should appear after regular imports.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Thanks for catching this. I'll fix it in the new patch
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Add a helper function _EnterConfigurationHelper in the new patch.
|In the case when the mapping file is out of date, &#124;dut_hostname&#124; may refer to a servo name that is not recorded in the mapping file. Thus, _get_rpm_controller won't be able to create a CiscoPOEController for it, I make it return None in this case. I'll update the 'return' section in the docstring of _get_rpm_controller.
|Done
|both front_server and rpm_dispatcher use this function. I created a new file, any better place I may place this function?
|Done
|After we send line &quot;show interface description&quot;, 
it will show a long list looks like:

fa32         chromeos1-row4-host1-servo

fa33         chromeos1-row4-host2-servo

.....
And we need to hit space when we see something like &quot;More &lt;space&gt;&quot; to continue. 

We need to hit 'q' when we find what we want and stop browsing the list.
|Hard coding the interface in the mapping file has a benefit. Currently the interface labels are manually maintained by the lab admin. The are hard coded in the switch. If in the future we change the switch, our code will break until the lab admin re-labels those interfaces in the new switch. By hard coding the interface in this file, our code can work with the new switch right away without relying on the lab admin to redo the labeling work. 

After discussion with scottz, we though it would be better to leave the interface hard coded in this file. I am going to revert the changes in this file to include interfaces.
|Done
|I move this piece of code to the subclass SentryRPMController so that POEController can reuse the rest of the code in this method.
|Sometimes when program has errors, it may not log out properly and connections are left open, I feel it won't hurt to force the ssh to close.
|Done
|Done
|Done
|rpm_controller does not need to read the mapping any more in the new patch. It will figure out the interface dynamically. 

rpm_dispatcher and frontend_server read the mapping file. I add a check on the last modified time of the mapping file, if it changes, the file will be reloaded. Please take a look at these two files.
|Done
|the '-l login_name' option of ssh doesn't work here, so we have to send user name via sendline.
|Done
|The work flow to set an outlet state, e.g. set it to 'ON', is:

User Name: &lt;input user name&gt;

Password: &lt;input password&gt;

chromeos1-poe-sw1#configure terminal

chromeos1-poe-sw1(config)#interface fa36

chromeos1-poe-sw1(config-if)#power inline auto

chromeos1-poe-sw1(config-if)#exit

chromeos1-poe-sw1(config)#exit

chromeos1-poe-sw1#show power inline fa36

....

Port Status:   Port is on .....

....

chromeos1-poe-sw1#exit

fdeng@anthill$

The following code goes through the process and loops until the port status is the expected one or time is out. 

The login part is done in _login.
|I add the logic to figure out the interface dynamic. please take a look.
|Done
|We are getting email alerts on error-level logging messages.
|Done
|Done
|Move the logic to _verify_state and explain in the doc string that we need to retry.
|exception messages are now logged in each helper function.
|Done
|Done
|I picked two unused ports and labeled them with two fake hostnames. John helped to plug two unused devices to the two ports(we have to have something connected to the ports otherwise we can't turn the ports on). The integration tests in the new patch should be fine now.
|remove unused import
|unused import
|Done
|Forget to test it again after a restructuring. Thanks for catching it.
|Done
|Done
|Please take a look at the new patch, it now figures out the interface dynamic.
|The format is
&#124;servo&#124;, &#124;switch&#124;, &#124;interface&#124;
A row without a servo name means that the corresponding interface is currently empty. I keep the records for empty interfaces to make later updates easier.
|Since we are adding ':' after returns, do we want to capitalize the following sentence? Same thing for @raises

@returns : A list of ....
|Remove spaces before &quot;&quot;&quot;
|Looks like there are two spaces after &quot;bits.&quot;, remove one
|remove space before colons
|remove colon before colons
|Why is self.mox.VerifyAll() not needed for these tests?
|add a space after &quot;0==1bit,&quot;
|typo &quot;ibts&quot; -&gt; 'bits', and add a comma after '1==1.5bits'
|add a space after sel_val or remove spaces after mux and mode_val
|add a space after each comma, the same for (0,1,2) below
|No need for line continuation with '\'
|a docstring might be helpul
|&quot;Gets&quot; or &quot;Get&quot;? We may want them to be consistent. The same for &quot;Opens&quot;/&quot;Closes&quot;/&quot;Creates&quot; above.
|self._capture_active is initialized as an integer but later assigned with a bool value. Thought bool and int can be converted to each other, will a consistent type be better?
|Add a period.
|By &quot;when servo is invoked it typically does a bunch of control initializations&quot;, do you mean when the &quot;Servo&quot; object is initialized at client side?

The scenario of the usage I image is that, at client side, it calls &quot;health_check&quot; to verify everything is working. If health_check reports error, we try to repair the beaglebone by rebooting and verify it by calling &quot;health_check&quot; again. If it is still not working, we try to power cycle the beaglebone and then call &quot;health_check' again .

I feel it would be cleaner and more efficient that we have a dedicated method do all the sanity checks than relying on a successful Servo.__init__ every time. (The fix for 255645 is a workaround as we don't have the servo verify/repair procedure yet.)

Such a method can sit in either servod or at client side. I thought servod should be able to tell its own health state and be a black box to client. What would be the drawbacks/concerns of having it at server side?
|Thanks for the explanation. It makes sense to me and I think that's a valid point. After a offline discussion with other reviewers, I decide to abandon this change and merge it with crosreview.com/66891
|I am trying to find a sanity check, if passes, will give us some confidence that the servo is responding, not only the xmlrpc server. We've seen incidents where it can connect to the rpc server, but when trying to interact with the servo, the call hangs and beaglebone stops responding. Unfortunately echo is not sufficient for detecting this error. 
chromium:255645

Any better way we can know servo is working without actually running a command like pwr_button?
|225932 is one symptom that indicates the usb is going wrong. We had some workaround but the root cause of 225932 (possibly a kernel bug) is still unknown and no guarantee it will not happen again. The idea here is to detect errors as early as we can. 

This cl serves as part of the servo/beaglebone repair feature(crbug.com/245320).
To make our servo/beaglebone more reliable, we may, in the future, have some more sanity checks. I am seeking a place for them. Any better place where we should put them?

Richard, this error was seen on servo V2 right? Our hope is that V3 won't have the same problem, but it is unknown yet.
|Done
|Done. use os.path.exists, more readable
|Done
|ah, i see. changed it to use shell command.
|Done
|Usb sometimes goes into a erroneous state. I added some comments about why we need to check this.
|My thought is to only rely on exceptions for error detection. However, because it is a rpc method, I have to add a dummy return value as it doesn't allow me to return None. I'll add a comment to the &quot;Returns&quot; in the docstring in the new patch. Does it help?
|the variable &#124;incomplete_tasks&#124; is not referenced after definition?
|Hi Scott, would you please take a look and see whether this is the right place? If so, should I add a parameter &#124;num&#124;?
|Done. Thanks for catching this.
|Done
|Done
|I think the doc suggests we use is and is-not for checking of None. I believe we will run into problem if we use is/is-not for string comparison. Please take a look at my code example in last patch.
|Done
|Yes, I think constants are better here.
I changed to use constants in the new patch. I accidentally submit this patch in the middle of addressing comments, so this patch is not finished yet.... Sorry about that.  Please take a look at the new patch.
|I change the word 'host' to 'servo' in the new patch to make it more clear.
|This piece of code is adopted from autotest: server/cros/servo/servo.py with some modifications. I think the person who wrote this must see some errors when switching the usb direction without powering it off, but I am not sure what the error is. So I think it is safer to leave the comment here to just make people be aware of potential problems.
|Done
|I get rid of this code after adopting richard's comments. 

But I am not convinced that we should use 'is' and 'is not' for string constant comparison, see the following example.

if __name__ == '__main__':

   val = ''.join(['servo', '_sees_usbkey'])

   check1 = val == 'servo_sees_usbkey'

   check2 = val is 'servo_sees_usbkey'

   print check1

   print check2

Output:

   True

   False

If I just want to check whether &#124;val&#124; equals 'servo_sees_usbkey', using 'is' will give a wrong answer.
|Done
|The reason we want to switch to 'dut' here is that we want to make host unable to see the usb disk. I thought when &#124;original_usb_power&#124; == off, we don't need to care which side usb_mux_sel1 is pointing to, because the host won't see the usb anyway. In other words, we only need to switch usb mux when the power is on *and* it is pointing to dut, because this is the only case host can see the usb, does this sound right?
|Done
|that makes sense. removed the checking in the new patch.
|Done
|Done
|Yes, I feel the restructured code is better. Change is made in the new patch. Thanks.
|In addition to avoiding unnecessary &quot;set()&quot;, the logic can avoid unnecessary sleeping time after the operation. I feel this is helpful and plan to keep the logic here.
|Done
|Done
|Done
|Done. Thanks for the advice.
|Done
|Done. Change is made in get_usbkey_direction() in new patch. Please take a look.
|Done
|Done
|nit: &quot;help=...&quot; looks not aligned, and same below.
|@param record
|I am debating about the idea of having email_handler as a variable here or as an attribute in frontend_server (and may be pass it to set_up_logging as an arg). As I feel the initialization of email_handler might be better to happen when set_up_logging is called at runtime. The current way makes them separated. Not a big problem. I'll leave it up to you. Other than this, the patch looks good to me.
|Done
|Done
|Oh, yes.. you are absolutely right. Thanks for the explanation. I'll go back to the old list without StageBuildFailure
|I tried to create a new class that inherits from CrosDynamicSuiteException. But then I realize we have a problem.  In ./frontend/afe/json_rpc/proxy.py:BuildException(), we translate JSONRPCException to CrosDynamicSuiteException. CrosDynamicSuiteException.__subclasses__() is called to retrieve its subclasses. Unfortunately, __subclasses__ does not recursively get all subclasses, but only gets the direct subclasses.

If we apply the proposed change, subclasses of  ControlFileException would not be parsed properly.

On a second thought, I think maybe we could just catch CrosDynamicSuiteException. I feel we may be also interested in filing bugs for other types of dynamic exceptions as well. How do you think beeps?
|Done
|Done
|I'll wait for your change. Please poke me when that cl is going out.
|Done
|@beeps, I am changing this method so that we have the option to get only lab sherrif. Would you please take a look?
|Done
|I am separating lab sheriff from others, so that we can cc some bugs to only lab sheriff.
|lab sheriff is cc'd on the failure in suite_scheduler.
|Any reason why unittest.main is not called in this file? I am adding it.
|I added the check to create_bug_report.
I keep the check for tracker in Reporter.report as we still need it.
|whom should these bugs be assigned to?
|Done

Please see the new patch
|I am filing bugs for exceptions raised by create_suite_job. For other exceptions, we will still get emails. Do we also want to include other types of exceptions?
|two spaces before Must
|I feel a concrete example for each parameters would help me understand what the method expects.
|Sounds good to me. I've been confused about hanging indentation for a long time, just want to know whether this counts for hanging indentation. Looks like I am not the only one that is confused.. ;-)
|I know hanging indentation needs 8 space in autotest. Is it a hanging indentation?
|As discussed offline, is adding a timeout here (in &#124;set&#124; as well) an option? what would be the complication to do so? I am happy with the current change though.
|remove comma and space after 'pwr_button'?
|how about updating this docstring to mention that we are parsing perf values?
|load_perf_values is only defined in subclass. Maybe add something as following to this class(similar to what we have for load_iterations)?

def load_perf_values(...)

    raise NotImplementError(' XXX Not implemented...')
|I feel a tag &quot;@returns&quot; mentioning that an empty dictionary will be returned when it fails to parse the json file would be helpful
|maybe it doesn't matter, but since you already use 0.0 in mean_and_standard_deviation, maybe also use 0.0 here.
|nit: add a summary line for this method.
|looks like this line has been moved to _restart_ui. do we still need it here?
|Good to know, added to the new patch, thanks
|Done, use `import` in new patch
|crbug.com/273843 filed.

Currently we can only use create_host to create chromeos host. ServoHost will subclass SSHHost statically; Existing packet_capture creates a SSHHost instance directly. There are also many other places where SSHHost instances are created directly. If we fix crbug.com/273843, they can all use create_host.

What is &quot;factory&quot;?
|I'd like to rename site_host to cros_host, and the class SiteHost to CrosHost as well. &quot;site_host&quot; and &quot;SiteHost&quot; are referred at many places which need to be updated. How about I create a bug for this renaming and cleaning work and address it in a separate CL?
|bug filed - crbug.com/273833
|We have two ssh host implementations, SSHHost and ParamikoHost. My thought is to mix SSHHost or ParamikoHost with SiteHost(future CrosHost) in create_host at run time.
If I make SiteHost(future CrosHost) subclass SSHost statically, how can we deal with ParamikoHost?
|Done
|As discussed offline, we reached a consensus that SiteHost will be subclassing AbstarctSSHHost in the new patch, so that SiteHost.make_ssh_command can override AbstractSSHHost.make_ssh_command.

The way we mix SiteHost and SSHHost looks like the following:

classes = [SiteHost, SSHHost, ...]

host_class = type(&quot;%s_host&quot; % hostname, tuple(classes), {})

If SiteHost was *not* subclassing AbstractSSHHost, &#124;make_ssh_command&#124; in AbstractSSHHost would be executed if someone accidentally put SSHHost before SiteHost.
|I heard from dennisjeffrey@ that you were able to test your change with run_remote_tests.sh by informing it with the suite name? If so, would you please describe it in the TEST field?
|I think we should remove max_run_time docstring as it is not used.
|-&gt; raise error.TestError(...)
|nit:please put the docstring in one line.
|The above line is commented out. Is this intentional?
|nit: please put the summary line in the same line as the quote for consistency.
|Sleep enough time for the dut to come back from rebooting. Without it, a following crashdumps job sometimes fails.
|Done
|Yes, it won't hit this code if the test is run using provision_FirmwareUpdate/control. But when our scheduler schedules provisioning job, it uses control_segments/provision, which doesn't accept &#124;servo_args&#124;.
So I am thinking keep the code to catch servo errors when it uses control_segments/provision
|Done
|Done
|Thanks for the note, yeah, it works. I tried

./site_utils/run_suite.py -b link -i link-release/R30-4537.0.0  -s faft_dev -f False --bypass_labstatus

it schedules provision_FirmwareUpdate. I have to comment out the real firmware update logic in run_once because most recent firmware builds may break the device.
|I think this cl is not sufficient to turn on firmware update provisioning job. My understanding is that to trigger provision_FwUpdate, we need to teach dynamic_suite to add &quot;fw-verions:XXX&quot; to a job as a dependency, the similar as what we did to add 'cros-version:XXX' label in suite.py:create_job.

I couldn't find any place where &quot;fw-verions:XXX&quot; is assigned to a job as a dependency. Did I miss anything?
|Done
|Done
|according to client/common_lib/test.py, it seems that &#124;initialize&#124; runs once for each job, while &#124;run_once&#124; runs for each iteration or runs for a period of time repeatedly until test time is out. For this particular test, it won't make a big difference if we only need to run it once. But I am debating on whether we should keep the code consistent with the original idea of having &#124;initialize&#124; do initializing job? How do you think?
|use _get_board_type_from_afe() for now. added a TODO comment above.
|Done
|if the build name is invalid, the test hangs here for a very long time. what is the best way to handle it?
|Done
remove gs:// and file:// stuff
|the gs:// and file:// cases will be removed.
|Done
|Done
|Done
|Done
|I think I still need self._hostname and self._build because _clear_version_labels/_add_version_label use them. I feel &#124;initialize&#124; might be a better place if a provisioning job does have instance variables. How do you think?
|Would you please also update the call to &#124;create_bug_report&#124; in suite_scheduler/deduping_scheduler.py?
|Done
|Done
|ProjectHostingApiException is caught. Do we expect other possible exceptions?
|Done
|Moved it to site_utils/phapi_constants.py
|Done
|only_open is not used. I removed it. Let me know if we still need this feature to be added.
|Done
|Done
|Done
|Done
|Done
|Done
|Added the check.

When we reach here, the new issue haven't been created, so we don't have an id to feed the first '%s' in the logging msg.

And I think we may also want to add a similar logging message before the last line of this method. How about we use a break here instead of &quot;return None&quot;, so that both cases can share one logging message? Please see the new patch.
|Done. 

This file looks like a library, so I was debating whether we want to introduce a dependency on a file in server.cros.dynamic_suites, a module which uses this library.
|Done
|I am thinking change 'only_open' to something like 'search_mode', which can be 'open_only', 'open_with_dup', and 'all'.

Currently, the logic is a little confusing. If only_open is False, I would expect it to search through all issues rather than opend and duplicate issues.

or any better way to solve this?
|Done
|Done
|Done
|nit: missing a space before `request['dut']`
|Please remove spaces before the word 'param'
|or 'jsonrpc_connect'?
|Done. Created a cleanup bug and added a TODO here
|Done. Removed the TODO and try/except block.
|it is confusing..I rephrased the docstring in the new patch. Please let me know if you have any better idea on how i can improve it.
|Thanks for catching this. Verified new patch.
|Done
|The logic of automatically detecting that a servo is attached to a DUT is moved to _create_servo_host.

Calling get_servo_args and getting a servo object via `host.servo` is currently the only guranteed way to get a good Servo object for a servo in the Lab, otherwise, the test wouldn't work in the lab (please see crbug.com/266418). This is not the best solution, but for all existing tests that require servo, I think we can assume it is true.

In the long run, we'll need a way to inform CrosHost that a servo is required or not.
|Done
|Done
|Missing a blank line before quote...will address in next round
|Done
|Done
|Following Richard's comment in patch 6. The try wrapper was here when not all beaglebone servo hosts supported get_board(). I think the TODO has been fixed.

From the perspective of xmlrpc call,  till the point when it creates a servo object, it should have made through the verify/repair process successfully. If we still get an exception here, that is unexpected and I think we should let it fail.
|that sounds more robust. I added the try clause back and raised the exception.
|Done
|Done
|Done
|Done
|It is called in the rebooting code in its base class. Added a comment.
|I am trying to override make_ssh(scp)_command in AbstractHost to customize the value of several ssh options.

What do you mean by &quot;abstract classes methods&quot;? Do you mean make_ssh(scp)_command in abstract_ssh?
|Done
|Done
|I agree, I'll create a bug for this.
|Done
|Done
|Done
|system and system_output are re-factored. localhost will be dealt with by servo_host in the new patch.
|I made system/system_output call self._servo_host.run when servo host is not 'localhost'. With this change I get rid of some code in __init__, but introduce some complexity in system/system_output. Not sure whether it worth it or not. Thoughts?

The above two lines come from utils.system_output.
Since previously it calls utils.system_output, I feel it would be better to ensure that we still get the same output as before.
|system and system_output are re-factored. localhost will be taken care of in ServoHost.run in the new patch.
|I tried to convert both program_ec and program_bootprom. It turned out the code became complicated. _scp_image formats the destination path and returns it. We would have to repeat the work of formatting destination path if using send_file() directly. So I say we don't convert them. How do you think?
|Please see comments above
|localhost is allowed. Removed &quot;&quot;Must be a REMOTE host&quot;
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I did some refactoring. _reinitialize_lab_servo was removed. I added a new method create_healthy_servo_object to servo_host. Please take a look.
|Done
|Done
|fwupdate was deleted in another cl
|fwupdate was deleted in another cl
|Done
|Moved to client.common_lib.error. Made it subclass AutoservoError
|Done
|Done
|Done
|I haven't done the refactoring yet. Will do in next round.
|One way to do this:

1) pass a ServoHost object as an arg of Servo.__init__, store it in self._servo_host

2) Modify Servo.system_output and Servo.system:

- call self._servo_host.run(...) when servo host is a remote device;

- call local sudo commands when servo host points to &quot;localhost&quot;

3) In Servo class, change all self._server to self._servo_host.server

One ugly part is that we have to create a ServoHost object (which is supposed to be a remote device) pointing to &quot;localhost&quot;, because a Servo object need a ServoHost object to call rpc methods. Any better idea?
|thanks for pointing this problem out, I didn't notice that. After looking through the repair flow again, I think we are good with the current logic in repair_with_sysrq_reboot and repair_full.

In repair_with_sysrq_reboot, self.reboot will ensure that the servod goes up after rebooting. It then sleeps for 10 secs, which is defined in self.REBOOT_DELAY. repair_with_sysrq_reboot will be followed by another verify(), which checks the servod for the second time.

I increased self.REBOOT_DELAY to 20 seconds in the new patch. 20 seconds plus 60 seconds for actual rebooting seems to be very long, is that ok?
|Done
|Done.

This code is moved to _check_servod.
|Do you mean not to catch generic Exception?
I did some refactoring of this method. In the new patch, specific exceptions are caught for rpc call. (This code is moved to _check_servod)
|Done
|Done
|Done
|Done
|I'd like to have something imply that we are (re)initializing &#124;self.servo&#124;. I change it to _reinitialize_lab_servo, how does it sound?
|self._servo_host.verify() will also call -&gt;abstract_ssh.verify_connectivity which raises other types of exceptions. I see repair_full attempts to repair on any exception happening in verify. So I am thinking keeping the same logic as repair_full does. How do you think?
|Done
|I'll try to make every Servo object include a ServoHost object and do some more refactoring in servo.py in the next patch.
|Done
|Done
|Done
|Would you please also remove this line, since it will default to running hwtest? (added by my CL 63923)
|nit: I generally prefer to having a message for NotImplementedError. If it was converted to a string, logged, etc, it would be easier to triage with a message rather than an empty message.
|Previously, `SerialHost.host_is_supported` calls `SiteHost.check_for_rpm_support`. When SiteHost doesn't exist, it falls to `base_classes.check_for_rpm_support`. Since I am going to remove SiteHost and make `SerialHost.host_is_supported` call `CrosHost.check_for_rpm_support`, I think we can safely remove this method from base_classes.
|What is the best way to test with SerialHost?
|Done
|Done
|I can change it to four in next patch. It is not quite clear in our CODING_STYLE.
|I'll leave it as it is then..
|Done
|Applied the second idea. A time stamp is recorded and checked. If the threshold is hit multiple times within 24 hours, only one email is sent.
|I tried to use:
stats.Counter(....).increment()/decrement()
It looks like Counter doesn't really make sense because it is used to plot how frequent the value changes.

I tried to use:
stats.Gauge(...).send(..., cls._num_running_processes),
I got negative numbers shown on the graph which don't make sense to me because the minimum value should be 0. Why is gauge doing with the numbers?

I tried to use stats.Raw, but I couldn't find the resulted graph in graphite.

Any suggestions?
|Done
|I am leaving it as it is then. Let's change it if performance actually becomes an issue.
|a little unconformable to call _reset_last_notified_time_if_necessary here, because this is a instance method and the method might be called too often.
But I haven't found a better place. better ideas?
|board: some explanation # Optional
|Add board to self._str
|Looks like we may also want to add a property method for self._boards
If so, I suggest change argument `board` of __init__ to be plural.
|nit: indentation
|alphabetical order
|Which module(s) have to come after 'driver'? Maybe say 'import driver before...to force circular import order.', not sure whether this is correct in grammar. I am ok with the current wording. leave it up to you.
|alphabetical order
|not done? :P
|Initialize the variables priority and timeout outside the 'for' loop, so that if this 'if clause' is not executed, the following 'return' statement won't throw an exception.
|the same here as previous cl, add _priority and _timeout to _str
|That makes sense.
|the same here as previous cl, add property methods for _priority and _timeout
|alphabetical order
|Interesting python syntax...I thought it was the reverse.
|With this change, are we still missing a case where it goes into the `for` loop but none of the klass.KEYWARD equals &#124;keyward&#124;, (e.g. we have a typo in 'run_on' in our config file, although this should rarely happen)?
|nit: return -&gt; @returns:
|Done
|Done
|Sounds a good idea. Done.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think monitor_db.py:ProvisionTask can take advantage of this change too. I'll create a bug and address both of them later.
|created crbug.com/295226
|Capitalize the first letter after ':', apply everywhere
|Mention that it can return None in case of timeouts.
And add a @raises
|return None explicitly
|is there a need to check &quot;parse_output is not None&quot; before referencing it?
I am thinking of the cases when _adb_run calls super(ADBHost, self).run and it has some problem with ssh to it and couldn't get adb command output.
|add a period
|add a note saying that it overrides the method from AbstractSSHHost.
|mentioning that we are ignoring warning_timer
|I think there is no need to store a private hostname variable. hostname should be accessible via &#124;self.hostname&#124;.
|if timeout is &quot;None&quot;, end_time and current_time will not be defined. It will raise an error at Line 256. Looks like we have a bug in wait_down of the base class too.
|warn_time is not defined.
|how about specify the relax factor '3' in a constant?
|Or how about adding a  'usb_boot_timeout' arg instead of 'relax_timeout' to allow customized usb boot timeout?
|I think not passing &#124;servo_host&#124; here should be allowed, it defaults to 'localhost'.

Even if we don't want to allow 'servo_host' to be 'localhost' , checking it here might not work.

If this test is called from the lab, we won't have &#124;servo_host&#124; in &#124;args&#124;. In such case, cros_host._initialize will unconditionally connects to a lab servo and ignore &#124;servo_args&#124;.
|Use single quote.
|To make it a little simpler, you can use 'with' statement and drop timer.start/stop:

timer = stats.Timer('servo_install')
with  timer.get_client('usb_boot_timeout_%s'  % usb_boot_timeout):
    ...

with timer.get_client('install_timout_%s' % install_timeout):
    ...
|I see, that makes sense.
|nit: add a period.
|nit: indentation/alignment.
|nit:indentation/alignment of arguments
|add a docstring
|add a docstring
|Add a blank line before @param argv.
|a question: If we use :lab:, do we still want to enforce it is invoked inside the chroot? Looks like _main_for_lab_run will work outside chroot?
|Done
|* _CollectKeyval reads: test_that_results_6N7ivT â”€&gt; results-1-dummy_Fail â”€&gt; dummy_Fail.Crash â”€&gt; results â”€&gt;keyval

* _CheckExperimental reads: test_that_results_6N7ivT â”€&gt; results-1-dummy_Fail â”€&gt; keyval

They are different files so it will not repeat parsing the same keyval file. 

_CollectKeyval is designed to parse perf/attr keyval. The parsing logic deals with `keyword` and 'uniquifying duplicate keys' which are unique for perf/attr keyvals. I think reusing it would be tricky.

@alex, I feel it would make sense to keep them separate? How do you think?
|Please see above comment.
|Done
|Done
|Done
|Done
|_powercycle_to_repair and repair_full are pretty much the same as they are in CrosHost. I have a bug created for merging repair_full. I shall add _powercycle_to_repair to the list too. For now, I'll leave this logic as it is and will address any issues in the merged version.
|Done
|Done
|Done
|I found autoserv won't complain the directory already exists if there are no 'control.srv', 'status.log', '.autoserv_execute'. So we are cool here.
|Given that we also have paramiko ssh host, I suggest we respect the value of SSH_ENGINE here.
|This method might be called by our repair/verify control file.
It is possible that ssh to the device might fail.
Firstï¼Œ I think we need to catch and handle the exceptions raised by `run`.
Then, a follow up question is which host we are going to use if it fails to run 'which adb'ï¼Ÿ thoughts?
|If you decide to follow the comment below, can you also rename base_host_type to something indicating it is used for connection? 

'base_host_type' is a little confusing to me because we are not really creating a new type of host class using &#124;base_host_type&#124; as a base class in this method.
|Would it be cleaner if we refactor to something like

if SSH_ENGINE == 'paramiko':
    from ... import...
    connectivity_class = paramiko_host.ParamikoHost
elif SSH_ENGINE == 'raw_ssh':
    connectivity_class =ssh_host.SSHHost
else:
    raise...
classes = [_detect_host(connectivity_class, hostname), connectivity_class]
|Ah...I just realized ADBHost was made to innherit from host.SSHHost. I believe we want it to inherit from AbstractSSHost. Otherwise, we'll have some problem here. I should have caught it in the review of the ADBHost CL. sorry :-[
|If the problem is caused by a hostname like '127.0.0.0:XXXX', can we fix it by moving Line159-Line166  to the beginning of this method and passing 'args' to _detect_host? (server_utils.parse_machine is the one that handles the format of hostname.)

I kind of prefer the old way because it focuses on one thing (i.e. detecting the host type) instead of developing the classes list partially as well as creating an instance.
|Done
|Done
|Currently the board label in the afe does not include the prefix 'board:'
An side-effect of it is that if a test has an dependency like 'board:lumpy', it will never be satisfied. Do we want to keep this behavior or fix it?
|Done
|It took about 0.8s using my local setup. But anyway, it is an easy fix. In the new patch, I made it only detect labels when it is a suite.
|Done
|the indent seems to be off here.
|I see, great, done!
|Done
|I kind of prefer a HELP variable at the begining. I feel if I move the entire help text block to here, the while loop would become super long and not very readable imo.
|I was trying to avoid '\n' by using heredoc suggested by alex. What would be the correct syntax to allow me not using 'cat' and avoid from adding a bunch of '\n'? I couldn't figure out the right syntax.
|Done, removed cat.
|Done
|Done
|removed -z
|Done
|I am afraid this CL will not work as we wanted it to :-(

If we set ignore_deps=True here, dependencies will be ignored by Line 126: my_suite.schedule(..). As a result, none of the dependencies will be respected.

Note that the entire block from Line110-Line124 doesn't do anything real but logging. It would be very tricky to ignore only detectable dependencies, because the real logic of ignoring the dependencies is hidden in my_suite.schedule(...), which is out of the control of test_that.
|Done
|Done
|Yes, both would work. get_client is just a simpler way to sends stats under the same namespace, so that we don't have to append the prefix &quot;servo_host_repair&quot; every time.
|We also have the children &quot;RepairNA&quot; and &quot;FAILED&quot;.
|Done
|In the new patch, I moved most of the keyval parsing logic to read_keyval in base_utils.

However, the parsing of 'units' remains here because the format &quot;units_metricname&quot; is specific to to this test, not all tests follow the rule.
|Checked Dennis' code in tko/perf_upload.
It turns out it has the feature of aggregating of results from multiple iteration and calculating avg/std for them.

I ran the test with iterations=3, the output file 'perf_measurements' can be found here

http://anthill.mtv.corp.google.com/results/1025-fdeng/172.22.75.76/platform_BootPerfServer/results/perf_measurements

I manually checked the json data sent to the dashboard, it only sent the avg/std of the values of three iterations for each metric. 

I'll leave output_perf_val in each iteration. The use of base_utils is removed
|To correct, not HTTP404, but

HTTP Error 403: Forbidden
|Our tko parser will try to upload the the perf data regardless it is running in the lab or on people's desks. But I got a HTTP404 error when uploading. So I think it depends on the dashboard server side to deny un-authorized uploading requests. (will confirm this with dennisjeffrey)
|A boolean flag upload_perf is passed from control file to indicate whether it should upload perf data.
|this change will be reverted in the new patch
|Done
|Please see comments in new patch.
|Confirmed with Paul Covell that we are going to use ChromiumPerf for now.
|Hi pthammaiah, I put ChrimiumPerf for now. Please let me know if we need to change it
|I didn't use 'with' here because I couldn't figure out how to fix the unit test to deal with  __exit__. The unit test seems using a special mock framework.
|I am happy with the current code.  I feel 2 and 3 are very much impacted by how quick human intervention takes place.  I haven't seen many cases where a DUT can automatically come back after a few failed repair tasks without outside intervention.
|I am confused. Does this code got run every time a repair task fails? If so that means we are filing bugs on every repair, isn't this true?

and, our goal is to find the problematic test, why should we care how many repair tasks were run?
|the fix is here, allow empty value by using '*' instead of '+'
|Add a new test
|We now have three possible types of output

1) None, None

2) None, 0

3) bug_id, 1

It probably won't matter much, but do we expect 1) and 2) to mean the same to the client?
|Ah, actually there is a fourth type of output

4) bug_id, any number that is &gt;=1 when bugs are updated.
Line 640-643.

yes, I think 0 would make more sense than None for bug_count given the fourth case.
|https://chromium-review.googlesource.com/#/c/175650/ is still in commit queue. This cl needs to be cherry-picked to autotest repo to properly run telemetry_Benchmarks locally.
|spaces
|Would you please also test with a POE request?
|This method in the base RPMController only applies to two of its sub classes, SentryRPMController and WebPoweredRPMController. It doesn't applicable to CiscoPOEController. For the long run, we need to refactor the code here because the root problem is that a poe device is just not a rpm(I remember I've got a bug created for it). But for know, I think the easiest solution to make things work is to override get_next_rpm_hostname  in CiscoPOEController and just return None.
|10 is hard-coded. read from user input?
|I agree with your comment in the last patch about arg_to_dict. I don't feel very strong about which is the better way to go. Just thought it is consistent with other tests. Leave it up to you. Just make sure that the two comments are consistent with the required format. (The other comment in the test file)
|four spaces
|Unfortunately, pylint doesn't work very well with autotest coding style:( Woud you please move &quot;If telemetry...&quot; before @param? (see  _cleanup_perf_string in this file for example)
|It might be good to mention in the docstring we only intend to run this test on lumpy and parrot.
|I saw other control files are using utils.args_to_dict to parse the args to the test. 
It is not as powerful as the parser library but looks like it is a standard way to go. It forces the the args to be in the form of key=val or key:val

Can you check whether we can use it here?
(here is an example, server/site_tests/telemetry_Crosperf/control)
|If run in the lab, will our lab servers have write access to the bucket? On our lab servers, gsutil is running using a non @google.com account
|Is there a specific reason for filing against Hardware-Lab?
|If this test is only applicable for lumpy board, you may enforce it by checking the value of run_host.get_board() 

Note that it returns a board name with a 'board:' prefix, e.g. 'board:lumpy'
|According to https://github.com/autotest/autotest/wiki/ServerControlHowto

It looks this way is more robust to handle a case where we may have multiple machines.  If running on multiple machines would result in a critical error, I'd say just call 'job.run_test', otherwise we can keep it as it is.
|There is a doc at https://github.com/autotest/autotest/wiki/AddingProfiler  

It looks to me that job.profilers.add(profiler, profiler_args) says &quot;use this profiler for the following tests&quot; and job.profiler.delete says &quot;do not use this profiler any more&quot; (seems only matter if there are more tests to be run).

I think for this case it wouldn't matter much as we don't run more tests after deleting the profiler. But I would recommend keeping this code for completeness.
|The coding style now suggests put the summary line in the same line with the first &quot;&quot;&quot;
|Capital H, i.e. Host
|I think we should call super(...., self).initialize()
|I don't quite understand how this workaround address the problem? Would you please explain? or maybe add some comments here.

and we certainly do not want to call sudo in the test. is it possible to workaround it without calling sudo?
|Will this work in our lab? It seems to assume a chroot environment?
|Please move _parse_args before its caller.
|use single quote
|Would you please add a doc string for the parameters?
|align with 'Failed to..'
|add a space after ','
|Please convert the comment to a docstring.
|Do the following to save a line.
telemetry_args = []
if self._devserver:
    devserver_hostname = ....
|Add 4 spaces for an 8-space indentation.
|merge the above two lines into one.
|This block is getting large. How about putting it into a method something like _build_telemetry_args(script, test_or_benchmarks)?
|Done.
|Done. there was a bug where desc was referenced as a dictionary key after its value got changed. I was trying to avoid that. Made it cleaner in the next patch.
|ah, got it.
|This is not introduced by this cl. But why are we using the string 'True'/'False' instead of using action='store_true' like we do for --bypass_labstatus?

parser.add_option(&quot;-l&quot;, &quot;--bypass_labstatus&quot;, dest=&quot;bypass_labstatus&quot;, action=&quot;store_true&quot;, help='Bypass lab status check.')
|This file is still in this cl with some modification. Do we want to override it with the new one?
|add a space before/after *
|@returns:
|did richard mention in lab chat that we will have timestamp file in subdirs which might be different from the timestamp in the parent? Will the timestamp in subdirs be ignored by this code?
|looks like we just want to populate timestamp_dirs? If so why do we need  my_walk to yield values instead of just have the for loop under get_all_timestamp_dirs?
|in this case, exit with code 1?
|I see there is a sys.exit(1) above.
so here, have prune_builds return an exit code and exit it with it?
|return None explicilty
|os.walk()?
|Could you also add an example of the 'dev-channel'/'cannary-channel' case to this comment?
|This two-layer for look is a little confusing as it deal with both regular build directories and special directories like 'XX-channel'. I wonder whether it would be better to some thing like the following to separate the searching for directories and actual prune logic

def get_all_build_directories(root): # root = 'images/'
    return [ images/dev-channel/x86-alex, 
                 images/dev-chanel/falco......
                 images/x86-alex-release, 
                 images/lumpy-release, ....]
     # this is actuallly all eligible values for 'actual_build_dir'
     # in your original code.

def prune_builds_and_labels(actual_build_dirs):
    for build_dir in actual_build_dirs:
          # deal with 'keep'
          prune_builds

def main():
     all_build_directories =get_all_build_directories('images')
     prune_builds_and_labels(all_build_direcotires)

I  haven't think too much whether there are any logic flaws.
|The list looks good to me currently.
|general crash collection question:

How did we end up having orphanded .dmp files in '/var/spool/crash' on the DUT?
|Yes, please in the bug mention that we need to fix generate_test_report.py and come back to remove the the following code.
|how will the test report generated by generate_test_report be further consumed? Will the report just be read by human or by other scripts?
I'd like to know this because that'll have some influence on how we shall fix generate_test_report.py.
|src/scripts/build_library/test_image_utils.py previously calls 

    emerge_to_image --root=&quot;${root_fs_dir}&quot; chromeos-test-init

To add authorized_keys, we would need to do

    emerge_to_image --root=&quot;${root_fs_dir}&quot; chromeos-test-init chromeos-test-testauthkeys


We thought it might be cleaner to put everything that needs to be done for rootfs in a single package, so that we can do

    emerge_to_image --root=&quot;${root_fs_dir}&quot; chromeos-test-root

if we need to install more stuff to rootfs in the future, we don't need to modify test_image_utils.py and keep appending to the list.

Meanwhile, other packages that only depends on chromeos-test-testauthkeys can still use it separately.

How do you think?
|Done
|Done
|Rephrased the description in the new patch.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|nit: please avoid using \ by doing
code, response = self.send_request_and_wait(
        arg1, arg2 ....) # 8-space indentation before arg list
|use single quote
|+1
|Would you please put an example command you tested with?
|Done
|Done
|Done
|As a reader who is not familiar with the bug we are trying to fix, I feel I could get the point of the workaround faster if the comment explicitly told me &quot;we don't want to use e.message because it is useless and hides the real message&quot; :)
|single quote
|Maybe just me feeling lost, but I like this :) Thanks!
|say we have 150 hosts, will it take 60 * (150/10) = 900 minutes to re-verify all of them?
|If everything runs ok, there should be a file called perf_measurements in the &quot;results&quot; folder. 
You could manually check whether its contents look correct. The data in this file will be uploaded to the perf dashboard.
|Hmm, you are already using a graph name here..
My concern was that we would be adding too many entries to the first dropdown box (&quot;Select a test suite&quot;) on the perf dashboard if you want your test name to show up in that box.

Do you think make 'tag' as a part of the graph name would work for your need?
|How about this?
Add &quot;dashboard_test_name&quot; : &quot;network_WiFi_AttenuatedPerf&quot;
to each entry. And in the tests, use different 'graph' names, e.g. output_perf_value(graph='ht40_ch001'), output_perf_value(graph='ht40_ch006')...

This way, on the dashboard, you'll go 'network_WiFi_AttenuatedPerf' -&gt; 'ht40_ch001' -&gt; 'metric1'
|how about just using &quot;counts&quot;?
|Could you please manually check the &quot;perf_measurements&quot; file in the test's result folder and see whether it looks correct? The data in this file will be uploaded to the perf dashboard.
|units may only contain letters, numbers, periods, dashes, and underscores.
|ChromiumPerf is a very general name we use for tests that do not have a clear owner. Could you make it more specific if you know which team owns the test?
|You could drop &quot;dashboard_test_name&quot; if it is the same as &quot;autotest_name&quot;
|sorry, I missed this in previous patches. Is there a particular reason you are converting testrating to string?
currently, only float type is supported.
|nit: but if you are uploading another patch, would you please remove comma at the end to keep consistency?
|If we are going to change the name, we'd better change it now, otherwise we will have performance data show up under two different names which will be confusing...
|Because it is spelled wrong, all data know are showed under &quot;ChromiumPerf&quot; category (this is the default category), once this cl lands, everything will start being uploaded under ChromeOSVideo.
|I was thinking reading it from the keyval file which has &quot;CHROME_VERSION=xxxx.xx.xx&quot;. But after reading the code, I realized it would not be possible because the system info will be pulled from client to server after a test has finished, but not available during the test. So I'd +1 to simran's solution.
|duplicate words &quot;specific host&quot;, remove one
|Could you add a doc string for request/api_call and a concrete example of their values?
|cool, I am ok with leaving it as it is now.
|I see. I'd vote for using yield at both places if it doesn't hurt.
|why is acquire_hosts implemented as a generator but get_hosts is not? anything special about acquire_hosts?
|Do we expect to build up the subclass list of RDBRequest in the future? If so, would it make sense to create a new file and start separating these subclasses of RDBRequest from other basic data structures?
|typo:through
|please add a doc string.
|add @returns
|Could you provide more explanation for what this function is for in comments or docstring? 
How does it &quot;adds an RDBServerHostWrapper&quot;? The same question for batch_get_hosts.
And what we are validating for?
|What is the different between validation requests and require_hosts_requests? Is the only different between them is that a validation request has &quot;host_id&quot; and the other one does not?
|You could run unittest under tko/perf_upload
It has sanity checks for the json format.

However, currently there is not an easy way to test the entire  uploading flow unless you have a full cautotest server environment setup.
|Why do we want &quot;media.chromeOS.tough_video_cases&quot; to upload to the dashboard with test name &quot;media.tough_media_cases&quot;? 
&quot;media.chromeOS.tough_video_cases&quot; and &quot;media.tough_media_cases&quot; seems to be two distinct bencharks.
|Would you please order the config in alphabetical order?
|Just curious why it will end up in two instances of the profiler and how your workaround fix it? Could you point me to some related code if you've already figured it out?
|Hi Luis,

Thanks for figuring this out. This sounds like a reasonable feature that we should support. Could you please create a bug for it and maybe copy-paste your comments to that bug? And also include the bug id here in the code comments if you do so. Even if we don't fix it now, it would be helpful for people to keep this issue in mind when using profiler. 

I don't have more questions. (I saw simran has one more comment)
Thank you very much!

Fang
|self._host is not referenced anywhere? what is this for?
|Including &quot;not self.servo&quot; in the &quot;if&quot; condition seems problematic.

Assume 1) this is a repair job(required_by_test=False). 2) we have a servo with a wedged usb.

So, in servo_host._initialize(), it goes through verify().
verify assigns servo_host._servo with a Servo object. However, verify will still fail because the wedged usb.

And when we reach here(Line 977) in cros_host,
&quot;not self.servo&quot; evaluates False, so we pass the following section that calls &quot;self._servo_host.repair_full()&quot;.

It looks like, as a result, a bad servo with wedged usb will not be repaired either here or in servo_host._initialize(). 

Please correct me if I misunderstand the code logic.
|In the case where an exception is raised, why do we still call self.servo=self._servo_host.get_servo()
Are we going to try to use a bad-state servo instead of disabling it?
|Could you add some comment here, saying something like &quot;If we were able to initialize a Servo without any exception, we are good and we don't need the sanity check in _check_servod&quot;
|just to be safe, how about reset &quot;self._servo=None&quot;
to make sure self.get_servo() will not return an old cache of self._servo, which is in a bad-state
|we are still using &quot;required_by_test=(servo_args is not None)&quot; below, seems not addressed?
|Yes, we rely on the assumption that &quot; servo_args is not None&quot; == &quot;servo is required&quot;. unfortunately we currently don't have a better way to check this.

And yes to the second question, I believe we ignore the value of servo_args when it is a lab machine, but we still care about the evaluation of &quot;servo_args is not None&quot; to tell whether servo is required or not, even if we ignore its value. This is confusing..I know.. the comments above were trying explain this logic..
|I am a little confused. If it is a dut with servo in lab, required_by_test will always be false, regardless whether the test actually need servo or not?

I guess we want something like:

required_by_test=(servo_args is not None)

return ServoHost(servo_host=hostname, required_by_test)
|This is the case for dut on people's desks.
With this change in, we will be repairing servos on people's desk, whereas previously we don't do that. Just wanted to bring this up and confirm whether this is desired.
|We need a check of &quot;if self._servo_host is not None&quot;, so that host without a servo will not hit a NoneType error.
|hmm..that is correct, but I would still prefer that we check it just to make the &quot;No servo&quot; case explicit to people.
|I think the logging here is not necessary because if it was a repair job, repair_full would attempt to repair the servo.
|replaced is a little confusing. use &quot;verified&quot;?
|The &quot;@raises&quot; part of the docstring needs an update.
The list is kind of long though..
|ah, here, if a servo is not in the lab, e.g. on people's desks, do we want to repair it?  We don't repair it currently. Do we want to change this behavior?
|move _verify_servo to above its caller _create_servo.
|Is this patch meant to address richard's comments in previous patch? It sounds like what Richard suggested was  refactoring the logic of &quot;creating a healthy servo&quot; into the method &quot;def verify_software&quot; so that servo creation will be magically taken care of when verify() is called. Did I miss some offline discussion?
|As mentioned in previous patch, we will be repairing servo on people's desks. Need to confirm whether this is desired.
|yes, but is that desired for servos on people's desk?
|Please take a look at the new patch.
|verified by the run_suite log. I updated the TEST filed to mention that in the next patch. I'll just inherit your approval since no code has changed.
|Actually, the following change was the culprint

db.insert_job(jobname, job, commit=True)

I should do
 
db.insert_job(jobname, job)
db.commit()

Fixed in the new patch.
|After I use django models. I found the parser took significant long time(some times 5 or more seconds in total) on &quot;orig_test.save()&quot; and &quot;retry.save()&quot;

Any idea on how I can optimize it?
|Done
|Done.
|Done
|In dynamic suite, I defined it in dynamic_suite.constants.
But i am not quite sure whether we want to introduce a dependency on dynamic_suite module just for a constant. So I put it at the top of this file in the new patch.
|Done
|ah, right. removed
|This could happen when the base job failed in some situations. For example, the dut went offline since the beginning of the test.  we will only have 'SERVER_JOB' in tko_tests for the base job.

Added some comments to the code
|It does have. but since we are using django model below, we need to finish the current transaction first to avoid deadlock. So I am forcing the commit to happen here. I added some comments about it.
|Done
|Done
|Done
|thanks ;)
|tested on our drone. the entire parsing took 0.4s. seems not a big deal.
|Compared to direct db queries, the total time spent on parsing increased from 0.2 second to 0.5 second for dummy_Fail. Is that normal/acceptable?
|Done
|what would a verify_type/cleanup_type/repair_type look like? Do they have to contain a &quot;:&quot;?

I am thinking some use case like:

_verify_types = {&quot;bluetooth&quot;:'verify_HaveBlueToothTest'}

Then can_verify(&quot;bluetooth&quot;) will return True.

Is that the case we'd like to support here?
|could you add an example of a valid string or say something like &quot;job labels separated by comma&quot;?
|s/cleaned/verified
|what are these for? where do we use them?
|should this arg be called &quot;q&quot;?
|Add a @param for the new arg.
|Done, and I'll just inherit your approval since no code has changed.
|&lt;just copying my comment from last patch&gt;

ah..i meant adding a &quot;continue&quot; after Line 284 so it looks like
try:
     if any(query in comment for comment in issues. comments):
        matching_issues.add(issue)
        continue    # &lt;---add  it here
                      # make sure in this case we will bypass the following
                      # &quot;if issue in matching_issues&quot;
                      #  otherwise, the newly added issue
                      # will always be removed
except (AttributeError, TypeError)
     pass # &lt;--- keep this 'pass' here
if issue in matching_issues:
    ...
Let's keep the 'pass' in except-clause so that non-matching issue can be properly removed.
|add a docstring
|why labels.issuperset(issue_labels) here?
if arg labels = ['Hardware-Lab', 'mylabel'] and issue_labels = ['Hardware-Lab'], we do not consider the issue as a match, is that right?
|ah, i meant adding a &quot;continue&quot; after Line 284 so it looks like 

try:
     if any(query in comment for comment in issues. comments):
        matching_issues.add(issue)
        continue    # &lt;---add  it here
                      # make sure in this case we will bypass the following
                      # &quot;if issue in matching_issues&quot;
                      #  otherwise, the newly added issue
                      # will always be removed
except (AttributeError, TypeError)
     pass # &lt;--- keep this 'pass' here
if issue in matching_issues:
    ...

Let's keep the 'pass' in except-clause so that non-matching issue can be removed.
|Add a &quot;continue&quot; after Line 284 inside the if-clause, because it passes the current &#124;query&#124;, otherwise, &#124;issue&#124; will be removed at Line 290.
|typo: /va/log
|powercycle_to_repair attempts to power cycle for 6 times and BOOT_TIMEOUT is 60s. That is to say, it would cost at least 6min for dut with a bad image to be repaired.
Does that sound too long? What is the rationale behind &quot;6 times&quot;?

bring up this question as we will be running _powercycle_to_repair more often after this cl lands.
|oh.. cleanup doesn't have this benefit i wanted..
|just to clarify, does the &quot;job&quot;  here refer to the job that runs the test, or the cleanup job?

Does cleanup put logs back to its the test job's result folder?
|is it any better to put host.cleanup() in an &quot;else&quot; clause so that we don't move to cleanup if any previous step failed (keeping the old behavior)? 
I mean
try:
    ....
except Exception as e:
    logging.error('Collect ...')
else:
    host.cleanup()
|if we have 6 device, each ran 30 jobs within 2 hours,
we will have 180 logs, each with a long list of labels, does that sound too much?
|I am thinking the case where every job keeps running but we just don't have enough duts to run them quickly enough, so that too many jobs are queued on the same dut. e.g. release branches compete with canaries.

Not a big deal. we can come back and add some limit later if it becomes a real problem.
|how about an option --no-diagnose-pool so that people can turn this feature off?
|this will convert to whole hour,  will that make the the timeout not accurate enough? why do we need to convert?
|using 'hour' makes sense. I guess what I am suggesting is using '60.0', a float number so that we don't convert 90 min to 1 hour, but 1.5 hour. Otherwise if timeout=90min and suite finished at 80min, run_suite would think it timed out but in fact it didn't.
|I did a git --rebase, the code under this 'except' clause was picked up from crosreview.com/192867
|Ok, I'll use an else and put return job within it.

And for the second comment, do you mean remove 
  else:
       logging.error('Failed to schedule test....')

When 'ignore_errors==True', we won't raise an exception,  so I am thinking keeping the else for logging purpose.
|Any concerns on deprecating test level retry entirely? Are people still using/relying on it? If no, I'll do a cleanup after this cl to remove the old retry

If yes, I am agree with renaming it to test_retries to remove any ambiguity.

I'll create a bug to track the work here.
|Done
|Done
|Yes. If we want, we could thread the setting from run_suite to dynamic suite. The caller of run_suite (buildbot, suite_scheduler, people) can then easily turn it on and off.

I renamed it to job_retry in next patch, and threaded the setting from dynamic_suite.reimage_and_run -&gt; dynamic_suite.SuiteSpec-&gt;suite.Suite
|Done
|Done
|Done
|Done
|Done,
I put this logic in a has_following_retry method that captures all cases we don't want to file a bug.
|Done
|We need to deal with the following cases:

For a given job id,
1. no retry map entry -&gt; file bug
2. has retry map entry
    2.1 already_retried=True -&gt; don't file bug
    2.2 already_retried=False
          2.2.1 retry_max == 0 -&gt; the last retry job, file bug
          2.2.2 retry_max &gt; 0
                   Have we failed in scheduling a retry job(e.g RPC error)?
                   Yes -&gt; file bug
                   No -&gt; don't file bug (We only reach this state if we call should_file_bug before the retry logic)

I added a new retry state 'ATTEMPTED', to express the situation where we've made an attempt to schedule a retry, but scheduling was not necessary to be successful.

It is also used to prevent us from repeatly scheduling retry in case we hit rpc error continuously, though this might be a
rare case.

Open to better/cleaner ideas.
|That is correct. I added some comment in RetryHandler's class docstring and should_retry's docstring in next patch
|Done
|ah, I meant to say 'aborted'. No retry will be scheduled if aborted before the job starts running, either due to timeout or user.
|Done
|Done
|Done
|Done
|Done
|Done
|I added some code to log the number of retries it has gone through in this method, since in RetryHandler it doesn't have access to test.job_retries -- the total number that is needed to compute how many retries have occurred.
|Yeah, I gave some thoughts on the deprecation of the old retry mechanism. After the new retry CLs are done, I am gonna work on cleaning up all the legacy code related to the old retry (if we decide to kill the old feature)

Just to be safe, I'd like to leave all the cleaning work to a later cl and make sure I don't break anything with this cl.
|Done
|I moved the common logic into a new method _schedule_test. Please take a look and let me know if I can do a better job here.
|what i need here is a mapping from 'test' --&gt; 'jobs' that have run the test.

self._job_info[job.id] = {'control data': test, 'retries': 0} would give the 'job' --&gt; 'test' mapping, but not the other direction that I need here (i.e. 'test' --&gt;'jobs').

I couldn't think of a way to solve this problem without having to compare ControlData objects. But your concern totally makes sense. How about I override '__hash__()' and '__eq__()' of ControlData to make sure ControlData objects can always be compared/hashed as we expect?
|Thanks for the draft. Yeah, that looks a better idea. Working on the re-factoring.
|Done

Catching two rpc errors here. We can expend the list if we later find more types of error worth catching here. (also moved the exception handling to _schedule_retry)
|When I modified job_status.wait_for_child_results to make it accept new jobs, I thought it made sense to allow accepting multiple jobs at a time rather than only accepting only one job on each call of &quot;yield&quot;. This way the feature of accepting new jobs would be more generic and would not be limited to the scenario of retry. Might be useful in the future? How do you think?
|Yeah, that is why I put a &quot;continue&quot; after &quot;results_generator.send([new_job])&quot;, so that it skips bug filing if a retry job was successfully created.

I didn't use &quot;elif&quot; next line because there is a corner case where a) retry is required, and b) it failed to create a retry job for whatever reason(exception raised). In this case, even though should_retry returns True but we still want to file a bug.

The code is little confusing. I re-factored it a bit in the next patch. Let me know if it doesn't make sense to you.
|Regarding the TODO, I can make it file a bug for the base test.
If later a retry is kicked off and complete, we could update the old bug -- mark it as invalid if retry passes or update the bug with retry job's info if retry fails.
How does that sound?
|I need to make it an OrderedDict because the unittests below will rely on the order of items in the dictionary.
|will add CQ-DEPEND=CL:191002 in next round.
|I meant to not retry on WARN. Thanks for catching this. Fixed in next patch.
|If we ever reached such a wired state, it would be a bug. I guess we can just let the suite fall. Removed the check in the new patch.
|Makes sense. Done
|Done
|Makes sense. Removed.
|Moved the check to should_file_bug.
|I guess I could re-poll in each iteration for a set of child jobs and then calculate the set difference against the previous screenshot of the set to figure out new jobs. Just feel using &quot;send&quot; could avoid some overhead with fewer lines of code. And in the following &quot;wait_for_results&quot;, we don't have a parent job to poll children from anyway. 

Added some comments in the new patch. PTAL
|huh, no idea..removed.
|yeah, that is correct.
|Done
|Yeah, I think you are right. test_executed is already checked above.
I'll just keep this sanity check of job_id just in case wired things happen. Removed the comment in new patch.
|yes, I'll make sure CQ-DEPEND be added to these cls.
|In this patch,  instead of simply using 'job_id-owner' as subdir, I generate the actual result directory of a test from its &quot;job_tag&quot; and 'subdir' retrieved from tko_test_view_2
|I figured just using &quot;job_id-onwer&quot; is able to handle the retry scenario, but isn't sufficient to solve all problems.
Someone could run the same test twice but with different 'subdir_tag'

job.run_test('dummy_Fail', tag='Fail', subdir_tag='subdir_1')

job.run_test('dummy_Fail', tag='Fail', subdir_tag='subdir_2')

We need to distinguish the two runs in dynamic suite's status log. Please see the updated commit message for more explanation.
|added a new test in job_status_unittest for this
|Checked the code. Looks like that the result directory string &quot;1132-fdeng/172.22.33.55/&quot; which contains a job id comes from autoserv, and is threaded from autoserv -&gt; server_job -&gt;base_job. With that said, base_job does not generate it and has no idea what this string looks like. It simply append it to the front of what is returned by build_tagged_test_name.
|Add a copyright comment here and anywhere else in this cl that is applicable.
|where is drop_hosts used?
|add a docstring please
|oh, this is &quot;AndReturn&quot;. CanArm doesn't have a return value. It is confusing though. :p
|Keep ['host1']? CheckHostsExist returns a list of host names, right?
|remove  comma
|https://chromium-review.googlesource.com/#/c/191002/5/site_utils/test_that.py

is in commit-queue. It changes the lambda to be &quot;lambda log_entry, log_in_subdir=False:None&quot;

Could you use the new lambda here? (maybe add a cq-depend on that cl just in case?)

And  I guess you might need to rebase over that one also.
|as mentioned in patch 1, if we don't want people to use this method to collect random things, how about just make it collect_var_logs? currently the name is a bit misleading (tho maybe on purpose).
|move this method to abstract_ssh.py?

This method looks independent on how we do ssh (either using python lib or command).
|Please see comment on https://chromium-review.googlesource.com/#/c/198284/
|Done
|Done
|Done
|Done
|I am trying to find the length of the longest 'display_name'  among views. max_width is a running variable that records the currently-seen-longest length. At the end of the for-loop, max_width is supposed to be updated with the length of longest 'display_name'. I meant to have Line 721-722 do for this purpose, looks right?
|Done
|good catch. I meant to have None represent the status 'unknown' but forgot this edge case here.
|ahh... this should be self._test_views.
will fix in next round.
|the same here, could you pass tag='quick' to run_test?
|please use single quote here and other control files as well
|could you pass tag='quick' to run_test?
So the test name will become 'hardware_MemoryIntegrity.quick', which matches 'NAME' field above. This is to assure that different tests get unique test names in a suite.
|you probably need to remove '.quick' here too to work around the bug mentioned in my other comment.
|I believe the cq failure is due to a known issue in the lab crbug.com/326294, where experimental test failure are not handled properly.
A cl (crosreview.com/193726) that fixes it is still under review and probably will not land in 1~2 weeks.

As a workaround, you could remove '.quick' from NAME for now and added back once 193726 is landed.
|confirmed. yeah i think you are right. added some comments here.
|Done
|Done. please take a look.
|nit:single quote
|drop @returns None?
|reboot now could raise AutoservRebootError. unsure whether we need handle it here.
|please add a docstring for this method.
|nit: use lower-case 'c' here
|I guess P1, P2, P3 are priorities? could you clarify them in the note?
|replace comma ',' with ':', the same applies below
|Could you please add a note here that 'func' must return a list of hosts to be cached?
|shold -&gt;should
|i see. I am ok with leave it as it is.
|do we want to decorate some of the following methods as abstract methods using abc?
|Looks like this is the only place we remove an entry from the cache. Do you have any insight on how large the cache would grow if we don't restart scheduler for a long time? or shall we have any cache cleanup mechanism?
|== None -&gt; is None
|add spaces around '='
|It would be safe to apply the schema change while the lab is closed. Last time I chatted with alex, looks like we are planning db cleanup for this weekend. If that's the case, how about we cherry-pick this cl on weekend and deploy the schema change, and I'll land it next week after everything has settled?
|oh, i missed this comment. ya, sounds a good idea. will put the run_suite change in another cl.
|Re beeps' comment about merging &quot;run() and output_results()&quot; into &quot;wait_for_results()&quot;.

I am trying to give the caller the control on when they'd like to output different types of results. Currently the collector has output_results() and output_buildbot_links().

Since it looks like output_buildbot_links has to sit out there as a public method, I am leaning towards keeping output_results also as a public method so that it is consistent with output_buildbot_links.
|Done
|Done
|Done
|I guess I could check KeyError for this case too. But I figured I can save one level indentation for the main logic this way ;)
|Done. The new patch should implements the idea in the doc, except for the retry case. will take care of retry in a separate cl.
|lab_is_down will fall into the category &quot;SUITE_FAILURE&quot; which covers the case lab is down or any issues resulting in the creation of the suite. Could you make cl 199941 reports code 4-SUITE_FAILURE?
|Done
|This will be taken care of by dshi's cl 199941
|Done. I make it log failure reason when it returns SUITE_TIMEOUT and INFRA_FAILURE. ptal
|Yes, it throws StageBuildFailure when staging fails.
create_suite_job also throws ControlFileEmpty, ControlFileNotFound, NoControlFileList. They are all subclasses of error.CrosDynamicSuiteException.
I'll add CrosDynamicSuiteException here in the new patch.  I think that'll cover all the cases.
|Done
|Could you do a sanity check on the format of &#124;build&#124; using a regular expression, so that if we get wired error message (like crbug.com/370089), we won't treat it as a valid build string?
|this condition doesn't work anymore, we need take care of the case when build is not None but regex doesn't match ;)
|you may save the second re.match by using a tmp var for read() and only assigning it to &#124;build&#124; if the tmp var is a valid build string. not a big deal tho ;)
|could you add a comment about this setting?
|in what circumstance we will end up having an hqe that is assigned with an unleased host?
|the arg name and docstring of &quot;acquire_hosts&quot; might need an update.
|where are we going to call this method?
|just curious, is it our plan to set up a second scheduler any time soon?
|Since you are refactoring the logging code, could you add docstring to this class and its methods?
|I notice the base class already has a copy of this method?
|the same question about this method
|Please update the description
|you'd also need to add an entry for your test in perf_dashboard_config.json (for the perf value to show up on the dashboard)

http://www.chromium.org/chromium-os/testing/perf-data#TOC-Specify-presentation-settings
|Are you trying to display the perf values on chromeperf.appspot.com?

Adding an entry to this file is not sufficient for this purpose, your test also needs to call output_perf_value (see http://www.chromium.org/chromium-os/testing/perf-data)

Also I noticed the control file computes the &quot;tag&quot; on the fly. That might cause some problem. autotest_name must include a static, complete name including the tag, e.g.
  platform_CryptohomeFio.1m_write_plain-1
  platform_CryptohomeFio.1m_write_plain-2
  ...
|The output_perf_value looks good.
Just that the tag would still be a problem. As I mentioned, for the perf value to show on the dashboard, all possible values of 'tag' need to be explicitly listed out.

Please see the network_WiFi_Perf case above.
|Yeah, that sounds good.
|I'd generally recommend not specifying dashboard_test_name (defaults to the same value of &quot;autotest_name&quot;), since it would make it easier to correlate the perf graphs to the autotest.

Is there a specific reason you'd like to specify a different name?
|is this a newly supported supplemental columns?
|Done
|Done
|There is only one case we modify the view dictionary.

When a test was aborted before it got a chance to run. In such case, view['reason'] will be None.
To make it more clear, view['reason'] will be updated with 'Timed out, did not run.'
|Done
|Done
|Done
|Done
|Done
|The retry counts is now logged with test info and buildbot link in the new patch.
But it only shows the final retry count. Showing the failure reason for each failed test in the chain is a bit tricky. For example, given the following
retry chain (job3 retries job2 which retries job1): 

  job1 (test views: SERVER_JOB[GOOD], dummy_FAIL[FAIL]) -&gt;
  job2 (test_views: SERVER_JOB[ABORT]) -&gt;
  job3 (test_views: SERVER_JOB[GOOD], dummy_FAIL[FAIL])

In the database, the field 'tko_tests.invalidates_test_idx' for dummy_FAIL of job3 will be NULL because job2 was aborted so that there is nothing to invalidate. Thus from dummy_FAIL of job3, we can't easily trace back to  dummy_FAIL of job1 using invalidates_test_idx.

It can be done if we do the test_name and subdir matching. If this is desired, I can do it in a separate cl.
|Yeah, i think that is cleaner. I did some refactoring and put things that modifies/checks a single view to a new class TestView.
|Done
|for a retry, we will print something like

  dummy_Fail.Fail   [ FAILED ]
  dummy_Fail.Fail     FAIL: always fail
  dummy_Fail.Fail     Retry test in job 2151

I am debating on whether to include a pointer to the failing job. I can remove it if this leads to more confusion than clarity.
|please see my comment above
|Done
|Done, fixed code
|need a fix here. will include the fix in next round
|Done
|i think it is a good idea. we might still lose logs if the test had put them in other directories (like /tmp/profilers), but I guess collecting /usr/local/autotest/results is the best effort we can make.
|please see my comment in the bug.
|is chaos lab in chromeos3?
|are rpms in chaos lab behind hydra? This only applies to rpms behind hydras.
|I removed the row restriction and add a todo for replacing this code with something dynamic. Could you take another look at the new patch?
|Done
|I only ran unittests. I am not sure how I can further test it.
|the following test failed, but it also failed on a clean branch on my machine. seems not related?

buildbot/cbuildbot_metadata_unittest.py
ERROR: testPaladinBuilder (__main__.__doc__)
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/mnt/host/source/chromite/lib/timeout_util.py&quot;, line 140, in TimeoutWrapper
    func(*args, **kwargs)
  File &quot;buildbot/cbuildbot_metadata_unittest.py&quot;, line 24, in testPaladinBuilder
    full_version = cbuildbot_metadata.FindLatestFullVersion(bot, version)
  File &quot;/mnt/host/source/chromite/buildbot/cbuildbot_metadata.py&quot;, line 644, in FindLatestFullVersion
    return gs_ctx.Cat(latest_file_url).output.strip()
  File &quot;/mnt/host/source/chromite/lib/gs.py&quot;, line 378, in Cat
    return self.DoCommand(['cat', path], **kwargs)
  File &quot;/mnt/host/source/chromite/lib/gs.py&quot;, line 569, in DoCommand
    raise GSCommandError(e.msg, e.result, e.exception)
GSCommandError: return code: None
[Errno 2] No such file or directory
|was trying to follow the convention of other options. I saw file_bugs and wait_for_results both default to None. Shall I change it to &quot;False&quot;?
|it currently defaults to false
|please add docstring
|please log the message (instead of print)
|could you first check &quot; if 'suspend_cmd' not in dargs &quot;, and generate the command only if the condition is True (similar to what 'reboot' function does)?
|180-&gt;120?
|could you define a constant for '120' and use that constant?
|Is this a cros-host specific restriction? If so, could you move the check to CrosHost.suspend()
|'restart' -&gt; 'reboot'
Actually, could you use OP_REBOOT or base_classes.Host.OP_REBOOT here?
|does this method apply to all types of devices including non chromeos devices?
|One more thing, I'd like to confirm with you that none of the suites I am going to enable retry for is running under &quot;fire-and-forget&quot; mode.  Run_suite will report error if --no_wait=True.

I noticed there is a async field, but seemed not used? It is currently set to True for pgo.
|sgtm.

Turn on retry is a two step things:
1. add --retry to run_suite
2. add JOB_RETRIES to control file

So to clarify, based on the comment, here is what I think we will have:

  PFQ:    diabled
  PGO:    
       perf_v2 - enable, need add JOB_RETRIES to tests
       pyauto_perf -  enable, need add JOB_RETRIES to tests 
  CQ:
       bvt_cq, enable
  Default: 
       au - enable, need add JOB_RETRIES to tests
       bvt - enable
       qav - disable, looks like qav has been failing a lot,
             I am thinking not enable retry for it.

Looks correct?
|I am not sure whether retry is desired for PFQ and PGO.
There was a discussion on how PFQ should handle retry failure, seems no conclusion is made yet. Do you have any idea about this?
|ok, will add one
|if both are used, run_suite will error out complaining invalid options. 

I am uploading a new upatch which will turn off retry for PGO[perf_v2, pyauto_perf]
|I mean to turn on retry for all canaries, is this the right thing to add?
|Could you handle the case where dargs.get('board') == None?
This is a possible case since we only add 'board' to dargs in cros_host.
|There are scheduler/frontend/rdb/host scheduler changes. Looks like we need some DEPLOY elements.

DEPLOY= scheduler, apache
I am not sure about the deployment for rdb and host scheduler, maybe confirm with beeps?
|Richard has recommended: &quot;Can you break the &quot;migrate graphite&quot; part of the change into a separate CL?&quot;

+1 to breaking it into a separate cl;)
|confused.. if dut can't send stats, what is the point of moving graphite to client/common_lib? maybe I am missing some context...
|remove extra spaces?
|I recently added this. &quot;JOB_RETRIES = 1&quot; is the field for turning on the new retry. &quot;RETRIES = 1&quot;, without the &quot;JOB_&quot; prefix, is what you are looking for ;)
|Could you name the title
    [autotest] Migrate graphite blablabal...

just a convention to follow, so that we know this is an autotest change.
|as mentioned in the other cl, you'll need to add
  DEPLOY = apache, scheduler, host_scheduler
because there are changes to frontend, scheduler, and host scheduler.

This tells lab sheriff to 1) restart apache, 2) restart scheduler 3)restart host scheduler, when deploying this cl to our prod server.
|There are two complexities here:

1) At the time the unittest runs, it doesn't have a way to know which tests will be uploading data to the perf dashboard. 

2) Test names in the config file need to match the test names generated at runtime. For example some tests may use
   job.run_test('dummy_Fail', tag='Error')
The test name in the config file should be 'dummy_Fail.Error', matching the final name generated at runtime. Unittest is not able to know the final test name without actually running the test.

I know this is confusing. Actually there is an easier way to check whether data has been uploaded to the dashboard or not, which is checking the &quot;.parser.log&quot; file in the result directory.
Logs will say whether there was a failure in uploading or not.

In the long run, we shall make such error easier to surface (maybe automatically file a bug or something).
|This control file already have JOB_RETRIES set to 1. I think that is sufficient if the goal is to rule out infrastructure level flakiness.
|This control file already have JOB_RETRIES set to 1. I think that is sufficient if the goal is to rule out infrastructure level flakiness.
|Hi Rohit, just fyi, currently JOB_RETRIES are respected in the following cases:
1) bvt, bvt-cq running by cq builders (thos paladins)
2) soon in bvt running by canaries, release builders, pgo builders

suites kicked off nightly by our suite_scheduler do not respect the retry request.

We might later turn on retry for qav.
You are welcome to add JOB_RETRIES now. But please note that this control file will probably not be retried because we haven't turn retry on for qav.

And could you set the number to 1 (the same for other control files you are modifying)? Usually that is sufficient to rule out a infrastructure level flakiness.
|Since retry is very expensive so we are doing it very carefully.

Currently qav timed out very often. It looks like we very often don't have enough resource to run the suite. Retry won't help in such case but will possibly make the situation worse by adding more load, this is what I am trying to avoid. I think we need to reach a point when the stage is green for most of the time before we could turn on retry.
|which are the control files that correspond to platform_CryptohomeFio.16k_write and platform_CryptohomeFio.surfing ?
|are you going to upload a change to control.stress?
|I expect the view to be read-only outside the class and I kinda want to enforce that.
|Done
|There are two types of aborts:
1) a job was aborted because suite job has timed out
   in such case, the status could be &quot;ABORT&quot; or &quot;RUNNING&quot;
2) a job was aborted because it hits its own time out

We've seen many cases where a job was aborted with RUNNING which leads to an exit code of ERROR but was actually a case of 1) above. 

&quot;aborted_by&quot; was used as the first guard to make sure that the test was actually aborted.

This is a bit hacky so better idea to determine timeout is welcome ;)
|This is the only case where we modify the view to add more clarity for timeout. I am trying to make TestView read-only outside the class, so I moved this logic to TestView.__init__.
|double checked. there is no other place that overrides v['reason'] outside the class TestView, it should be ok.
|silent the case where a test was aborted but has not hit its own timeout. I think unless a user aborts a job, this would mean suite have timed out.

Or any other way we can effectively tell whether a job was aborted due to suite timing out?
|need some update here ;)
|remove local_devserver?
|is this exception still applicable?
|I am confused about the part of passing a code segment to client_at.run()
client_at.run() seems accept a control file?
|I haven't seen usage like this. How does autotest ensure that the code of 'power_SuspendStress' exist on the dut? Do we have better way to do this?
|oh, it accepts an open file-like-object. if you've run the test and it passed, it is probably a valid usage. nvm
|-&gt; introduced
|JOB_RETRIES is most helpful for the case when  the dut in the lab flakes or some other lab flakiness. Usually retry once will solve such problem from my observation of bvt in canaries and cq (because the next retry will get a new machine).

In the case where au need to be rerun for 2-3 times, did the au test actually failed continuously for 2-3 times? or were the au tests aborted without being executed (mostly likely we are lacking for duts in this case)?

Adding retry means doubling the turnaround time for a true failure. I'd suggest only bump the number to 2 if we do see a lot of au have failed continuously for 2-3 times, otherwise 1 is more preferred.
|Done
|Done. removed.
|Done. PTAL
|apache needed for afe/models i think
|How do you think make &quot;_testMethodName&quot; as a &quot;graph&quot;?
So that we don't have too many entries in the first dropdown on https://chromeperf.appspot.com/report

For example, 
1) in the first drop down we select &quot;image_test.DiskSpaceImageTest&quot;
2) in the second drop down we select board, say &quot;cros-alex&quot;
3) in the third drop down we select &quot;TestRootFS&quot;
|the current handling sgtm. just wanted to make sure the perf uploading error will not be critical to the stage.
|The dashboard sometime may not be reachable, e.g down for maintenance. I am not familiar with how retry_util works, it will handle the exception if perf uploading fails right? just wanted to make sure perf uploading failure won't fail the stage.
|i saw perf values are uploaded in image_test, do we want to specify an entry for image_test here?
|this looks like a workaround for telemetry tests. I think we can drop the handling of &quot;ref&quot;
|the handling &quot;_by_url&quot; looks lile a workaround for telemetry tests. i think we can drop the first replace. but keep replace('/', '_').
|can we prepend a suffix to the test_name here, something like &quot;cbuildbot&quot;. So that all perf results can be easily distinguished from other results from chrome and autotest.

so the final test_path would look like
   cbuildbot.image_test ....
|why does Timer use self.name while others use subname?
|nit, summary in one line
|Another consumer of &quot;logs_to_collect&quot; file would be cros_host (or the crash collect flow). 

how do we in cros_host figure out the absolute path using &quot;dev_image/autotest/results&quot;? Or do we have to make it a special case and hard code it to read &quot;/usr/local/autotest/results&quot;?
|sg. let's do that. and please add some explanation about why we are having two paths for autotest results.
|I imagine &quot;logs_to_collect&quot; be a place where people can add any new log file they want to collect generally.

crash collect flow will read from /mnt/stateful_partition when reimaging happened. But when reimaging did not happen (say power cycling the dut brings the dut back online), we want to refer  &quot;logs_to_collect&quot; as well to figure out what files to collect. In such case, i guess &quot;dev_image/autotest/results/&quot; is not a valid path that we can collect from? can we somehow infer the right path?
|DEPOLY=scheduler
for scheduler_model change?

not sure about the rdb_host change. 

@beeps: do we need deploy &quot;host-scheduler &quot;?
|I didn't quite get the problem we are trying to solve here. Could someone explain in what circumstance we can't pipe through the value of &quot;local&quot; by calling test_that with --arg?
|could you shorten the summary and make it fit in oneline?
|generally logging is more preferred if applicable. but since this is a test util, not a high priority thing.
|is there a specific reason to use print, replace with logging?
|I guess 'query' should have the same indentation as &quot;fields&quot;?
|please add some clarification about when it will be returning None
|please return None explicitly, same applies to create_range_eq_query
|please put the number in a constant
|how do you think raise a exception with the message?
the same applies to create_range_eq_query_multiple

If the caller for some reason doesn't pass either a equals_key or a range_key, the caller is calling the method in a wrong way that should be fixed I think?
|why is beeps@ here? does he want to be notifiedfor every bug? :)
|tf_interval_end -&gt;t_interval_end
|what is the &quot;new host history function&quot;? not implemented yet?
|could you elaborate what ti, tf dbg_str represent for,?
|looks like es_test_utils is not only used by test, might be better to rename it to something else.
|i'd suggest more meaningful names for variables and args. That would be lot more readable than &quot;t&quot; &quot;ti&quot; &quot;tf&quot;.

And probably more comments along the line explaining how we are getting the final stats step by step.
|could you rename the function name to get_stats_string or format_stats_string or something that starts with a verb?
|Could you fit the summary line into one one and add a more detailed description below of how this method works?
|ti, tf do not refer to the incoming arg  ti and tf right?
please use different variable names if that's the case.
|could you print &quot;lock_start&quot; instead of &quot;ls&quot;?
the same for others.
|please initialize with a string message
|pass task_caches, suite_start_time, suite_end_time to _get_special_tasks?
|is not None
|might be cleaner if we wrap the logic related to reading/updating the cache in a class?
|add a docstring
|add a doc string
|yeah, i thought about it but i was unsure about the side effect.
|If the exception happens, will we hit a NoneType error in calculate_total_times?
|If the exception happens, will we hit a NoneType error in calculate_total_times?
|get_host_history can return &quot;None, None, None&quot;, do we want to handle it here?
|could you raise a specific type of exception?
And do we want any exception that is raised by get_history_details to be a subclass of RPCException?
|Could you also include this example in the USAGE part of the script? that would be helpful
|can you mention that a string type will be returned if some attribute is missing?
|the same here.
|The term &quot;other metadata&quot;  is used many times and is a bit confusing to me what it refers to. I guess you mean all other metatdata than &quot;status&quot;? Could you please explain here in the docstring?
|do we want to initialize self.metadata_dbg_str with empty string here? so that we can make sure record_state will not fail due to missing attribute
|Done
|Done. the factory method in added in crosreview.com/212349
|Done
|it just changes the memory used to hold the cache.
one cache entry is about  64bytes, so 1000 would be 64KB, which isn't much. Moved the setting to config file and set it to 1500 for now.
|good catch. I'll make this thread safe.
|Done
|Done
|missing t... Fixed
|Done
|Done
|Done
|Done. added in __main__
|Done
|Done.
|Done
|Done
|it will throw away the least recently used item. The most recently used item will always be moved to the end. So with &quot;last=False&quot;, we will be removing the very first item, i.e. the least recently used one. The unittest ensures this is the case.
|Done
|Done
|Done
|Done
|Done
|Done. we don't need this message anymore.
|yeah, i think that's reasonable. i'll merge them to one.
|Done
|Done
|i mean keep this setup code for labels.
|do we still want to label the outlet with hostnames? If so, i'll keep this labels.
|Done
|i agree it is less understandable this way.  i was debating between passing in the object and passing in two args &quot;dut_name and outlet&quot; and chose the latter for better extensiblility. 

Currently we have CiscoPOEController overriding this method. If in the future we add a new type of power management device that requires more args than outlet, we only need to add more stuff to powerunit_info and limit the change within _change_state. Otherwise, the new class would have to override the caller methods of _change_state as well. how do you think?
|oh. shoud be removed.
|here is some hard tabs, but I am not sure about the coding style in chromite.
|why is this needed?
|Please add copyright
|i'd recommend move package shard/ to scheduler/shard.  it looks more related to scheduling.
|please doc-string this class and its methods.
|Could you explain your concern on mocking things and gs_offloader a bit more? I didn't quite get it.

I am thinking something like the following in the module level:

  def get_shard_config() //Or one method for each attribute.
  def is_shard()

  def get_shard_client():
      # call get_shard_config() to get configurations from global_config
      # error out if is_shard() == False
      heartbeat_client = ShardClient(shard_hostname, pause_sec, afe_hostname)
      return heartbeat_client
 
   def main():
       _heartbeat_client = get_shard_client()

With something like above, we will still be able to easily mock out &quot;get_shard_config&quot; if we want to, is that right? or are you trying to take care of other cases?
|Can you do the check out side the class since we only need to check for once?
|How about pull out _setup_afe, _get_my_shard_hostname, _get_pause_sec out of ShardClient and pass afe, hostname, tick_pause_sec as args to __init__? 

I don't feel very motivated to tie the class to the configurations in global_config. We can have a module-level method like get_shard_client() and put configuration loading and check (_ensure_running_on_shard) there if we want to ensure the scrip is run on a slave. How do you think?
|please pass a message string to the exception.
|If we move ensure_running_on_shard and is_shard out of the class and do the check one level up, we do not have to check _ensure_running_on_shard in every tick.
|argparse is more preferred.
|add copyright
|import shard_client from autotest_lib?
|please docstring this class.
|import os in a separate line.
move import common to after python packages.
|remove one blankline
|please add docstrings for these methods
|looks like there are three blank lines here, remove one
|looks like there are two blank lines above, remove one
|looks like there are three blank lines here, remove one
|please provide docstring for these methods.
|sorry i mean provide docstrings for the test methods in this class
|This patch only has one file, could you please check?
|sort alphabetically (error goes before global_config, autotest_lib.server goes before autotest_lib.shard)
|8-space indentation from last line.
|we should continuously check &quot;is_staged&quot; in finish_download right?
|i see. i'll just remove the timer.
|I'll just add it ;)
|Done
|Done
|Done
|it should look like &quot;172.11.22.333&quot; without port and http://
i changed the variable name to server_name to be consistent with naming in devserver_healthy
|sure, working on refactoring.
|I find that get_latest_build_in_gs already has the decorator. Looks like we are already running with nesting wrappers. I added the decorator to call_and_wait and removed the decorators from stage_artifacts, trigger_download, and finish_download. I tested it by chaging the default timeout_min and add some unittests. Thing seems to work fine ;)
|Moving the decorator around seems more complicated than I thought.

stage_artifacts makes calls to self.translate and self.call_and_wait, so does trigger_download and finish_download. If I were going to apply remote_devserver_call to &quot;call_and_wait&quot;, i have to also apply it to &quot;translate&quot;.

However, I can't decorate &quot;translate&quot; because many other functions, which calls &quot;translate&quot;, are also decorated by remote_devserver_call&quot;.

The granularity of &quot;call_and_wait&quot; and &quot;translate&quot; seems too fine to be decorated. Can we handle the Timeout error one layer up as an alternative solution (i.e. dynamic suite and other code that calls dev_server functions)?
|Done
|do we care about finish download and trigger download timing and count? let me know if i should also record them for these two functions.
|sure, i added some stats around trigger_download. ptal.
|Done
|Done
|Done
|Done
|Done
|Sure. Done
|finished_on can be None if the hqe was aborted,  i think we need a check here
|why changing the operator? getting latest time means we keep whatever value that is bigger right?
|Can we reuse &quot;is_slave_shard&quot; here? 
If not, could you elaborate the comments a bit more to make the distinction clearer?

The word &quot;moblab&quot;  might be a bit confusing to people since usually that refers to the mode running by our partners (In that mode, we don't want tko to use global db configuration). Can we use something else, like slave_mode?
|i saw shard related configurations are in a [SHARD] section
https://chromium-review.googlesource.com/#/c/212725/21/global_config.ini

you may want to rebase over that cl
|you may also want to change here.
|add
BUG=
TEST=
|nit: use single quote for consistency.
|remove a duplicate s.
|i am not sure why get_host_queue_entries is calling it **data, but seems that **dargs is more common.
|how about make a list of (upstart_job, error_msg) and iterate through that list and check?
|please avoid modifying a list while iterating through it. it can mess up the iterator sometimes.
|add a doc string
|Done
|@kris, please let me know any special cases where this rule doesn't apply.
|I verified the mapping rule currently applies to all chromeos3 duts in cautotest. 

According to @kris, some existing outlet names in the rpms may be wrong. we can change our db directly if some host&lt;-&gt;outlet mappings are updated later.
|@kris, the same here, thanks
|if server=None, by defaults AFE uses the server in global_config, I modified the help message to reflect that.
|Yeah, there is. Done
|need image for create_metadata?
|do we want to run test_importer on cautotest and cautotest-cq?
|nit: space before/after *
what is this 0.000001 for by the way? maybe add a comment
|add something like &quot;ignored when --last is used&quot;
|add something like &quot;ignored when --last is used&quot;
|where is time_utils? can't find it in my codebase, is it new?
|fix the todo?
|ensure that the attr is not callable?
|how about default=datetime.datetime.now()
for end?
|nit: remove '-v' in the help message
|how about make options.end default to now in argparser. And here only deal with &quot;if not options.start&quot;?

so that if i only give --start without --end, my --start will still be effective.
|aligns
|Done
|would be nice if something like 'only_hosts' can be part of the dump file name.
|I agree there is benefit of automatically correcting the string. But here are my arguments not doing so:

- I think it is reasonable for a developer to assume that the dashboard would show text they've passed in here. It might cause confusion if the assumption is broken. As one may wonder &quot;why I put xy+z, it gave me xy_z&quot;? We don't know if the special character would mean something special for the test writer. I'd prefer to leave it to their own judgement on how to replacing it.

- we will be correcting the string over and over again at runtime, which is a waste. I'd prefer we could fix the test in the first place.
|sounds reasonable and 2) sounds a big win.
|How about get rid of the if-cluase and just do:

  replacement = '_'
  description = re.sub('[^-\.\w]', replacement, description)
  units = re.sub('[^-\.\w]', replacement, units) if units else None

And may also make &quot;replacement&quot; an argument, so that it is customization by the tests.
|thanks for catching this case.

might be more readable to do:
  if not replacement or re.search(string_regex, replacement):

no quote needed for if-statement if fits in one line
|nvm, thought you wanted me to add it. done.
|2-2 is already in the list? was it disabled in shadow?
|Done
|yeah, i realized after i chumped it..i'll put notes below revert line in the future.
|I guess these will go away after rebasing.
|we can easily make get_shards to support filter by passing **filter_data (default to {}). Just something nice to have.
|remove '\' and use next sentence as summary line.
|there is a coding-style in the root of autotest.  Some code from upstream autotest doesn't follow, but I think we want all new code to follow the coding-style.
|How is this done?
will models.Job.objects.filter(shard=shard).update(shard=None)
ensure we are getting non-finished jobs?
same question for hosts
|Thanks for the explanation. 

As for jobs, what about the completed jobs? Do completed jobs already have &quot;shard=None&quot;? or will models.Job.objects.filter(shard=shard).update(shard=None) assign &quot;shard&quot; to None for all completed jobs?
|maybe update the docstring to reflect the fact that &quot;the shard will be removed from all jobs&quot;? currently it says &quot;jobs that haven't been reported finished yet&quot;
|do we have a mechanism that disables a shard (but not removes it from database)?

And could you explain the big picture of how failover will work?
|thanks for the explanation. I get the idea: manually detect bad shard and delete it, for v1. that's fine. Just wanted to know what is our current plan for failover.
|what about non-chromeos hosts?
I suggest phrase this as an assumption than a fact.
|&quot;this&quot; refers to the fact that &quot;repair will always at least reboot the device once&quot;.

When we delete a shard, we plan to schedule a Repair to all hosts that were previously owned by the shard, and we are hoping reboot will clear all the processes leftover on the hosts.
|@mkryu: with the new crashcollect flow, this will still be true right? just wanted to confirm since the new sharding architecture will rely on this.
|not sure whether there will be any race condition here. Ideally we want to update the shard=None, and then schedule the repair task.
|put something like manually test in a local setup of autotest
|i think only one '%' is needed.
|could you use ( ) for line continuation?
|ah, I took a look at readonly_connection. looks like it has some magic taking care of closing the connection automatically. we don't need to take care of it here.
sorry about the confusion.
|thanks for confirming this and working out the the solution.
|My understanding is that this will only affect cross-site http request.

It won't limit the general visit to cautotest afe from an origin other than localhost and corp.google.com right, will it?

Could you confirm? Because we have moblab server that are used by our parterners outside google, we don't want to break their use flow.
|In the tests you run for

localhost (GOOD) 127.0.0.1 (BAD) evil.com 9BAD) localhost.evil.com (BAD) good.corp.google.com (GOOD) google.com (BAD) dhcp-172-22-67-244.corp.google.com (GOOD) dhcp-172-22-67-244 (BAD) wkbox.mtv (BAD) wkbox.mtv.corp.google.com (GOOD)

are these direct visit from above origins to the cautotest web interface from a browser? If so, this might break moblab...
|Could you please verify the change? 

One way to do it is to setup an autotest instance.
There is a script that automated this process
http://www.chromium.org/chromium-os/testing/autotest-developer-faq/setup-autotest-server

Let me know if you need help here.
|Are we open the door to all origins?
How are the rpc caller authorized?
I am not quite sure about this part. can someone chime in here?
|could you remove '\' and add a docstring for this method?
@param cursor: ...
@returns: .....
|could you please add
@param job_labels: ....
@returns: ...

and remove '\' (this is old coding style)
|use IF (s.word=='GOOD', s.word, 'FAIL') to save some chars.

If you could switch to tko_test_view_2, then s.word becomes 'status'
|change to LIKE 'CLIENT_JOB%'
|all right, sounds performance is the issue.

If we are going to use sql, i think we can query over &quot;tko_test_view_2&quot; which already does the join.
|The model test view have all of the joins here. 
  tko_jobs.label is selected as &quot;TestView.job_name&quot; 
  tko_status.status is selected as &quot;TestView.status&quot;;
  tko_tests.test is selected as &quot;TestView.test_name&quot;;

I recommend something like:
    models.TestView.query_objects(job_name=JOB_NAME, status='GOOD', ~Q(test_name='SERVER_JOB') ....).count()
I think with django feature we can achieve the same goal. FYI, https://docs.djangoproject.com/en/dev/topics/db/queries/
I'd like to avoid direct SQL whenever we can, since that's one point we are using django for ;)
|please close the cursor once we are done with it.
|shorten this line and following if-else to :
    status = 'passed' if result['status'] = 'GOOD' else 'failed'
|change the above if-else to:
   summary = summaries.setdefault(label, {})
|why do we need distinct here?
|sg. just curious. good to know.
|is_slave_shard is still referenced here.
|as discussed, please add some comments or docstring here about how the &quot;shard&quot; field works
|&quot;if not hostname&quot; may be safer, to cover the empty string case
|just wanted to confirm, why the old one is less equal than 37, is that intentional? same for wifi perf weekly
|Done
|-&gt; history
|space after comma
|could you put  'machine_utilization_rate' as the name of the Gauge? the same for 'mar'.
|space after comma
|just wanted to make sure that total_time_not_utilized and total_time are float type right?
|please change the test name and the test directory name
to platform_Crounton, to follow the naming convention of other other tests.
|please import one module per line
|two lines between methods and classes
|i think &quot;self.tmpdir&quot; is available for use and automatically cleaned, no need to create a new one.
|two lines, the same below
|remove host, not used
|remove the space after resultsdir
|space is the default delimiter. no need to pass it if split by space

use extend for better performance 
   args.extend(self._runargs.split())
|if you use self.tmpdir, this is automatically cleaned
|hi, could you explain how this function would be used (in your client side)?

Is it part of the solution to the issue of &quot;finding subjobs of a suite job&quot;? If so, I thought we were planning to retrieve the subjob &lt;-&gt;suite job relationship from afe rpc interface at client side. But maybe I am misunderstanding something.
|ah i didn't notice  &quot;only_hosts&quot;/&quot;only_shards&quot; is already a part of the path and i didn't saw them in the bucket so got confused. as long as we can distinguish them, I am cool with it.
|would be nice if the file name could show if this is a &quot;host dump&quot; or a &quot;shard dump&quot;.
|Done
|Done
|Done
|Done
|this is not necessary actually because we won't be ever comparing invalid_options with other codes
|that makes sense. Made new patch catch TestLabException (NotEnoughDutsError is a subclass of TestLabException)
|server side also has a cros package, so I slightly prefer &quot;client_constants&quot; over 'cros_constants'
|pass timeout self._CHECK_HOST_UP_TIMEOUT_SECS
|add logging.debug and log the crash_job
|add logging.debug after _collect_crashlogs
|add logging.debug here remove set_host_attribute
|add logging here about remove prior log
|set a time out to is_up, e.g. is_up(timeout=15)
I think the default is 60 seconds, which is too long. set the number as constant like CHECK_DUT_UP_TIMEOUT_SECS
|fit the 'e' in the above line
|to same two lines:
    return attrs[0].value if attrs else None
|add &quot;skip collect crashlogs&quot;
|add &quot;for gs_offloader to consume&quot;
|can the above three lines can fit in one?
|use debug for crash collect logging. so do other places
|fit 'src' and 'e' in the above line
|how about refactoring crashcollect::get_crashinfo_dir() a bit so that 'crashlogs' and 'crashinfo' can be passed to it as an argument, and just reuse thit method in cros_host?

The only places get_crashinfo_dir is called is inside crashcollect.py, so the re-factoring won't be to much.
|I think you could do:

  dirname = os.path.dirname(sub)
  return os.path.join(base, dirname.strip('/'))
|how about 
  os.path.dirname(sub.rstrip('/'))
  return os.path.join(base, dirname.strip('/'))
|put &quot;.crashjob&quot; and host attribute name 'need_crash_logs' in a constant. We'll also need to read them in gs_offloader and scheduler code. 

I propose we create a server/constant.py that stores contstants at server-side.
|put the code related to adding a new rpc method in a separate cl.
|we can put this constant in client/cros/constants.py, maybe somewhere close to &quot;# LOGS to collect from DUTs&quot;
|just to clarify, I am thinking moving _PRIOR_LOGS_DIR to client/cros/constant becasue this is a path on the dut and there are already some dut-side paths in client/cros/constant about crash collection.
|how about
os.path.join(common.client_dir, 'common_lib', 'logs_to_collect')

I think common.client_dir point to &quot;AUTOTEST_ROOT/client&quot;.

and use () for line continuation.
|please see my comment at Line 1103
|os.path.join(_CRASH_LOGS_DIR, 'prior_logs') is more preferred
, same for .crashjob
|might just use _SAFE_WAIT_SECS and remove the comment #in seconds.
|this extra check for LAB_MACHINE_FILE really makes the flow complicated and hard to understand to other people. on a second thought, I think we could just not cover this special case. Just let it always move to the first repair function. This is also desired by https://chromium-review.googlesource.com/#/c/218294/8/server/hosts/cros_host.py
|yes.
|could just do: return attrs[0].value if attrs else None
|Could you provide more details about the flow? assuming the reader is someone who knew little about crash collection.

Might be helpful to make it clear under which &quot;condition&quot; we are collecting from &quot;where&quot;, and the reason behind it.
|add @param job_id: ....
|yeah, i think self.job.resultdir would point to whatever -r points to. It is safer to use self.job.resultdir than relying on &quot;current directory&quot; of the os.
|we need to put _CRASH_LOGS_DIR in the job's result directory. crashcollect.py::get_crashinfo_dir is an example. or maybe you could reuse it.
|log a message when we failed to collect the logs.
might be easier to search through the logs if we have some prefix to all crash collect related messages, e.g &quot;crash collect: found XXX&quot;
|Looks like there are couple of places where collection can fail
- self.collect_logs()
- self.run('rm .. ')
- self.collect_system_logs()
- self._AFE.set_host_attribute can fail if cautotest frontend goes down.
- self.path_exists

currently exceptions are caught at different places (this method, _try_collect_crashlogs and collect_system_logs). It might be cleaner if we have a central place to handle all possible exceptions and let other methods not worry about exception handling.

We also need to think deeper about some edge cases. Some subtle cases:

- if collect_logs passes but self.run('rm..') throws an exception, we may want to create the marker file; but if collect_logs failed, we don't want to create the marker file
- if set_attribute failed, but self.run('rm..') succeeded, the next repair will think crashcollect is needed and might collect from system directories, which is undesired.
- and is it possible that &quot;prior logs&quot; were not successfully removed for some reason and might be wrongly picked up later?
...

Let's give these edge cases some thought. Even if we might not be able to handle them all elegantly, it is good to know how things can go wrong.
|else:
    # log a message saying we didn't collect because
    # the dut was manually re-installed without --lab_preserve_log
|I think we need to ensure that we only leave the job_id marker when logs have been collected.
|how about create a method in server/site_utils just which parse _LOGS_TO_COLLECT_FILE and return a list of paths. And make this method iterate through that list and call collect_logs on each file. This way we can separate the parsing and collecting logic.
|run_suite will raise a devserver error if build is &quot;ad_hoc_build&quot;. But I am fine with let run_suite take care of that.
|Can we not mixing the logic of filtering locals and splitting locals from foreigns? The effect of the flag is not very straightforward if I don't read the code. 

Consider move the filtering to its caller (deserialize)
or make this method return three lists:
- links_to_local_values_no_update
- links_to_local_values_update
- links_to_related_values
|please update the docstring to reflect the new change
|please add this DEPLOY=shard_client to the document
at https://sites.google.com/a/google.com/chromeos/for-team-members/lab/autotest-server-admin
|DEPLOY = apache
|guess it will fit in one line if you do the &quot;return ... if pools else None&quot; syntax
|if host.shard and ...
|can we have this routing functionality built into a decorator? So that we just apply that decorator to any function that needs to be sync'd to slave?

we sort of mention this in &quot;8. Sync&quot; in 
https://docs.google.com/a/google.com/document/d/132WFtDCb5EKBqb9zHIZ2ytmoYAImQQget7_5CZoYlSE/edit
|how about other rpcs like host_add_labels/host_remove_labels, delete_host ...? Do they need to be sync'd to slave?
|would be nice if you could test the flow when there is an rpc error, e.g. shard is down.
|8 space indentation
|this is a bit long. how about &quot;forward_single_host_rpc_to_shard&quot;
|if the client is using an RetryingAFE to make a call to the master, it will be retried at an upper level.

if the client is using a non-retrying AFE, the shard should probably respect that.

So we don't need RetryingAFE here right?
|do we want to add testing_exceptions (probably with an empty value ) to global_config?
|&quot;Will return from run_suite ...&quot; will print twice.   The first one is here print together with &quot;Reason&quot;. I am fine with printing it twice. just fyi
|i think this needs to handle fallback as tko/db.py does.
|could you explain the difference between None, False in the docstring?
|i see, missed the line below.
|once the code is committed. people will use the same key. will that be a problem?
|see my comment from the other cl. i think we need to check the SHARD:: shard_hostname here as we did in tko/db.py. so i'd suggest move that logic to global_config. it might be a bit wired global_config needs to be aware of shard. if you have better idea, that would also be great.
|I guess this is commented out intentionally to make sure that &quot;no connection has been created in settings&quot;, is that right?

I read your post on the bug. I don't quite understand this part --
&quot;Write a router that doesn't need all the imports&quot;  Did you previously wrote a db router that needs &quot;import connection&quot;? why was it needed before and what makes it not needed now?
|you'll need the same logic for the django model. can we move the logic to global_config.global_config, something like

get_config_value_fallback_if_not_shard

Or any better idea how we can reuse this logic?
|need the same care here.
|add apache
|add spaces around =
|if not fallback_section
|Please mention here we use fallback because our sharding business.
|this clause is useless since msg is not used anymore (it should have gone with earlier changes I guess).
|Done
|Add a line
DEPLOY=apache

This tells the lab sheriff to reload apache, needed by the frontend rpc change
|this might not apply without the context of CL:219999,
you can test it by 

  AUTOTEST_ROOT$ python
  &gt;&gt;import common
  &gt;&gt;from autotest_lib.server.cros.dynamic_suite import tools, frontend_wrappers
  &gt;&gt;afe = frontend_wrappers.RetryingAFE(timeout_min=5, delay_sec=10)
  &gt;&gt;afe.get_attribute(...)
  ...
|add a ':' after &quot;attribute&quot; and host_filter_data
|put this example in docstring of the script
|put his as docstring
|This comment doesn't match the code. I think the code says a period of &lt;start=a_date_of_X_days_back, end=a_date_of_X_days_back + 1 day&gt;

I actually feel the code makes more sense.
|how are we going to use this script?
 - if called by people, start_date and end_date might be easier so that I don't have to count days_back for a specific date.

 - if called by script, do we want to use logging instead of print?
|change these to &quot;is None&quot;
|change this and below to 'is not None'
|replace the hard tab with space
|query_host_history can be removed?
|i guess you are using get_intervals_for_host as a backup?
please add a comment explaining why this is needed.
|need to pass intervals to this call
|looks like there are two cases:
  1. intervals is None or empty:
      need to 'query_host_history', compute intervals for the host
  2. intervals not None and not empty
      in its caller (get_report), need to &quot;query_labels&quot;, and compute intervals for each host, and pass in &#124;intervals&#124; to this method

Computing the intervals at two different places is a bit confusing.
It might be more clear if you could refactor out &quot;query_host_history&quot;/&quot;query_labels&quot; and &quot;compute intervals for each host&quot; into another method, something like

def get_intervals_for_hosts(hosts, pool, board):
   if hosts:
        query_host_history
        compute intervals for each host in hosts
   else:
        query_labels
        compute intervals for each host in hosts
   return {host: intervals_for_the_host}

If you do that, here in get_host_history_intervals it always takes a non-empty &#124;interval&#124; as an argument.

Just some thoughts, feel free to push back if it doesn't make sense.
|add spaces around + sign
|-&gt; str(e)
|You could run the script by passing a machine that doesn't exist in cautotest. And confirm the thrown exception is of the right type (RemotePowerException, not xmlrpclib.Fault).
 ./rpm_client.py -m chromeos1-fdeng --state ON
|The exception in the bug:

&lt;Fault 1: &quot;&lt;class 'autotest_lib.site_utils.rpm_control_system.rpm_infrastructure_exception.RPMInfrastructureException'&gt;

is of type xmlrpclib.Fault.  (anything after &quot;&lt;class .... is pure text )

So I think the fix should be in 
rpm_client::set_power(), make it catch xmlrpclib.Fault and convert it to RemotePowerException.
|create a bug and put the link in the bug, refer to the bug here.

The link may expire after a couple of months i think, so please paste the error to the bug.
|gerrit confuses me.  CL:221018 is reverted, but seems this patch doesn't contain all the changes in CL:221018 but  depends on CL:221018?
|add @param hints, same for others.
|Done
|Done
|Done
|Done
|Done
|Done
|this paragraph is removed, as suggested in above comment
|Done
|Done
|good point. I changed it. and will change the mapping.
|yes.

An alternative way I was thinking was to use stats.timer. but we have to decode the suite name and use it as part of the key, it is a bit complicated and less flexible. so i think using a cron job is a better choice.
|Provisioning/Restting/GatheringParsing will all fall under &quot;job_time_breakdown&quot;.

For example, in autoserv, if --reset is set, we will send metadata like

     metadata = {	
                'job_id': queue_entry.job_id,
                'hostname': host.hostname,
                'status': 'Resetting'
                'duration': 20 }
      es_utils.ESMetadata().post(
                type_str='job_time_breakdown', metadata=metadata)
|we are still querying index_old here. is it intentional?
|guess they should be exactly the same right? if so, use !=
|Done
|If it is something like &quot;123-owner/&quot;, something wrong is happening, i kind of prefer to treat it as no match (which is consistent with the old behavior of get_afe_job_id). I'll make the docstring more clear about this.
|The old get_afe_job_id does require the presence of hostname right?
the old get_afe_job_id uses:  '^([0-9]+)-.+/.+$'

  &gt;&gt;&gt; print re.search('^([0-9]+)-.+/.+$', '123-fdeng/hostname')
  &lt;_sre.SRE_Match object at 0x2436d50&gt;
  &gt;&gt;&gt; print re.search('^([0-9]+)-.+/.+$', '123-fdeng/')
  None
  &gt;&gt;&gt;

The new method simply added a second (), so it should not change whether there is match or not i think
|+1 to a new type maybe suite_time_breakdown
logging &quot;suite name&quot;, &quot;build&quot; may also be helpful.

you can also log the total number of child jobs, just for sanity check in the post-process script to ensure no child job is missing.
|Following beep's comment, I've moved the metadata part and constants to a module called job_overhead in the other cl.
|moving this part to job_overhead sounds good.  suite job is also a job ;) i think that's fine.
|A separate type is more preferred, and this type don't really has any &quot;breakdown&quot;. So maybe just &quot;suite_job_time&quot;
|currently there is no plan to report to a different type. i am not opposed to removing type_str from both methods.
|_fetch_test_views_of_child_jobs also calls self._afe.get_jobs.  How about calculating num_child_jobs there and store it as local variable, so that we don't have to hit the db twice?
|Done
|Done
|Done
|sounds a good idea. created a new module job_overhead. ptal
|tried the first solution. it works.
|Looks like get_directory_size_kibibytes_cmd_list in gs_offloader is doing it. so I assume I can skip it in autoserv. Dan, let me know if you still want it here.
|sure, which type shall i use? shall I create a new one?
|in the new patch, i created a autotest_lib.client.common_lib.host_states (since we already have host_queue_entry_states there). And I made code in afe and job_overhead depend on that one. please take a look.
|host_queue_entry_status doesn't have &quot;Repair&quot;. Only models.Host.Status does. It become confusing when I tried to use host_queue_entry_status and host status together. And it is also a bit wired for autoserv to import autotest_lib.frontend.models (which involves import django ...)
|Done
|Done
|schema_051.sql is a base script, looks like it is some hack they put in so that they don't have to start from scratch every time from 001_XXX. 
https://github.com/lcapitulino/autotest/commit/7c71a57872b48f291fe2549684a7b986d81b8dcc

My understanding is that it can either start from 001_initial_db, or start from a base script.

If starting from a base script, the flow should look like
    at version 0 -&gt; schema_server_db_001.sql -&gt; at version 1

rather than the following where version 1 is skipped.
   at version 0 -&gt; schema_server_db_002.sql -&gt; at version 2
|It is confusing that you'll have to start from version 2. Can you solve the problem by just adding the following in def  migrate_to_version(self, version) at line 256:

    if current_version == version:
          return
Then i guess we can start from version 1 here.

Actually, we might not need to start from a base script at all.
I think it will also work if you move the &quot;create table&quot; stuff from schema_server_db_002.sql to 001_initiali_db.py and get rid of 'AUTOTEST_SERVER_DB' entry here and schema_server_db_002.sql
|Looks like events are missing often, not only for lock event. 
crbug.com/426969
|sort the imports
|when enable_gateway=True, will we run bootstrap twice? How would that work?
|My understanding is that in the case of a vagrant cluster, we will run this script on db server A2, so the first bootstrat would grant A1_user@A2? Why do we need this?
|i am ok with this as a short term experiment.
but if we decided to go down this way for long term, maybe we can do a better job on how we shards. The existing line drawn between bvt-inline and bvt-cq was for other reason, it may not be the best choice for sharding.
|Starting them in parallel is also preferred if we are going to move everything to a single pool:critical. So I am all for it.

just curious, was it one of the original considerations that bvt-inline is more critical so that we can save time by not running bvt-cq if bvt-inline failed?
|move 
  Line 130: job_info_dict[job_id][hit['status']] = float(hit['duration'])
to above 
   Line 124: if hit['status'] == 'Queued':
And remove Line 134.
|Find someway to not hardcode so many states. I suggest something like the following.

  s= host_queue_entry_states.Status # Use the constant from hqe states
  states =[s.QUEUED, s.RESETTING, s.PROVISIONING, ....]
  state_count = {} # e.g. {'Queued': 3, 'Resetting': 4 ...}
  sum_runtime = {} # e.g. {'Queued': 38secs, 'Resetting': 50secs}
  for info in job_info_dict.itervalues():
      for state in states:
            state_count[state] = 1+ state_count.get(state, 0)
            sum_runtime[state] = info[key] + sum_runtime.get(state, 0)
  result = {}
  if state_count and sum_runtime:
        result = {state: sum_runtime[state]/float(state_count[state]) if state_count[state] else 0
                      for state in states}
  # Add suite_overhead and num_duts
|No need to list out all states? how about

stats_samples_dict =  stats_dict.setdefault(key, {})
stat_samples_dict.setdefault(key, []).append(suite_runtime)
for key, val in suite_stats:
    stats_sample_dict.setdefault(key, []).append(val)
|same here can you avoid iterating a hard-code list? like
     for state, value in stat_samples:
         stats.Timer(key).send(state, mean(value))
|the child jobs are run in parallel. we need to do the calculation discussed in 

https://docs.google.com/a/google.com/document/d/15joW20ZYGbwELU86ZhMwCARSpe4Jdg4OzEo3lUuMQR0/edit

there is some discussion in the &quot;Measuring Scheduling Overhead&quot; section.
|how about grouping stats by
   board.build_type.branch.suite_name.metric_name
i.e. the stats key will be something look like
  suite_time_stats.lumpy.release.39.bvt-cq.scheduling_overhead
  suite_time_stats.lumpy.release.39.bvt-cq.child_jobs_runtime
  suite_time_stats.lumpy.paladin.40.bvt-inline.scheduling_overhead
  suite_time_stats.lumpy.paladin.40.bvt-inline.child_jobs_runtime
|explain how stats is calculated (e.g. what data is pulled from where) and our definition for scheduling overhead. Include important considerations we have made in the design doc. The goal is for anyone who hasn't read our design doc to know what we are measuring in this code.
|any way we can batch these metadata db query, i.e. query multiple jobs with one query instead of one query for each job?
|batch the query for multiple jobs into a single query to reduce  hits on database, e.g.
  tko_models.Job.objects.filter(afe_job_id__in = jobs)
|running -&gt; Running
not sure whether it matters but just keep it consistent with what we use in the scheduler.
|move this function to server/site_utils.py
and make both run_suite and this file call that function.
|return float(sum(l))/len(l) if l else 0
|to save some lines:
  stat_samples_dict = stat_samples_dict.setdefault(key, {'suite_runtime':[], 'overhead':[]})
|How about just the raw data to graphite? that way spike won't be averaged out.

If sending raw data, stats_dict can be simplified as a dictionary of tuples {(key, suite_runtime, overhead), (key2, suite_runtime2, overhead2) ...}
|makes sense. good to know
|can you pass _cron_mode to analyze_suites as an arg and avoid using global variable?
|I don't get the point of the if-else here. why is 24 special?

Can we just do

  end_time = time.time()
  start_time = end_time - 3600 * span

This should give us the epoch time for both start and end right?
|add some description here
|It also include Parsing Gathering. Your code has already counted them, just update description here and in the file's docstring above.
|remove @return as this method doesn't return anything.
Make it clear that this method will modify the input &quot;job_info_dict&quot;.
|add a doc string
|since _options is now a module-level variable, no need to make it global?
|add collect_crashinfo to the list?
|Please add. 
CQ-DEPEND=CL:228780

which has a db change that is needed.
|please explain the None case here.
|theoretically case 4 should never happen right?
(a dut should not change status while it is locked)
|How can I play with this cl?
|I saw VagrantProvisioner has _box_name, do we want to get box name from the VagrantProvisioner when generate the template?
|Could you explain what the purpose of the two templates(
CoreClusterTemplate and VirtualBoxTemplate) and how they work together?

I didn't see CoreClusterTemplate used anywhere, is that something we plan to use later?
|Could you add some comment on the network fowarding stuff?
|where do we get this box?
|can just do
   return version.endswith('.0.0')
|could you move the check of cros_version here? I think it makes  sense to skip all the rest of the code in this method if we are not going to upload the data.

cros_version comes from test.attributes.get('CHROMEOS_RELEASE_VERSION', '')
(Line 271) in the current code.
|will add a cq depend
|Done
|yeah...the hydra mapping is defined in
https://docs.google.com/a/google.com/spreadsheets/d/1BPJjOrhf5bHkD9kz7aFcFZ-INh5FaB2TWA7zw48Q-44/edit#gid=3
|Done
|I am leaving the name as provision_actionables.py for better clarity. currently it is intent to be only used by provision. we can change later if that assumption changes.
|Done
|Done
|Done
|Done
|looks like the second &quot;are&quot; should read &quot;or&quot;, could you fix it
|+1, i feel the above methods can be merged.
|how will dashboard code deal with a_hardware_identifier?
|how is hardware_id generated?
|It is in HostScheduler.__init__ -&gt;SuiteRecorder -&gt;__init__ -&gt; self.job_query_manager.get_suite_host_assignment()
|This is a bad example. Removed it. I think what I really want to say is that: we need to querying the db for the latest 
completed job that has run on a host, which is slow.
|right,  I don't really need the second part of the example. This is not a good example actually, i rephrased what i want to say in the next patch.
|good to know. i wanted to give an estimation on how big the map is. if the order of number of host grows significantly, we'll know we need to fix it. I updated the comment, please take a look at the new phrasing. I am holding an implicit assumption that the integer is an id in the database with type int(11).
|i tried sys.getsizeof(123345), it returns 24.
I was unsure how the underlying calculation was done by python. but 24 should be a safe estimation, if it was 4 or 8 like in Java, then it is even better!
|Done
|yes, this should never happen. schedule_host_job should ensure the hqe got a host. removed.
|Done
|good point. I add some notes in the docstring of this file.
If this causes too much trouble, we may consider to store the state in db.
|Done
|Done
|Done
|there could be new suites created each tick. I need to at least query for the new suites.

I considered:
  - maintaining a map &quot;self.suite_to_minduts&quot;.
  - figure out which suites are new and just query for those new suites and update self.suite_to_minduts.

If I do so, I have to keep an entry &lt;suite_id, 0&gt; for those which didn't specify &quot;suite_min_duts&quot;. It is very tricky to figure out when to remove such entry from memory. Ideally, it should be removed when the suite is completed, but that requires db query which I wanted to avoid in the first place.

I also considered removing the entry &lt;suite_id, 0&gt; from &quot;self.suite_to_minduts&quot; when the suite holds 0 duts. But &quot;holding 0 duts&quot; doesn't always mean suite completion, it can mean the suite hasn't got any duts yet or suite got one but has released it, I have to tell these cases apart. I am leaning toward not adding the such logic as I feel it might get confusing.

How do you think?
|Done. Tested. and updated commit msg
|Done
|Done
|Done
|Done
|Done
|we can watch how many provisions happen per host in run_suite. For CQ, this number should be low (ideally 1 provision per host). For lower priority suites, the number can be a bit higher, because it needs to sometimes give a dut to a higher priority suite and later get it back.  It won't directly tell us how frequent the exchange happens, but at a bottom line, the number of provisions per suite should not be too crazy.

anyway, I'll try to fix it later.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|more logging is a good idea. I added some logging in host-scheduler, PTAL that cl

Stats:

I added a gauge stats for the min dut acquisition rate (count_acquired/count_required). The stats key is like
  -  rdb.min_duts_acquisition_rate.CQ
  -  rdb.min_duts_acquisition_rate.BUILD
For all priorities, we should expect min_duts_acquisition_rate be high, ideally 100%, meaning that suites at least got some duts to run.

I didn't go with the calculation of how many extra duts it is able to get each 
cycle, as i am concerned that we will see a lot 0s in the graph 
(maybe my definition of &quot;extra duts&quot;is different from what you meant?).
Say there are two suites are running in a pool with 10 duts,
suite1 has suite_min_duts =5, suite2 has suite_min_duts=3, we will see

  begining: suite1 hold 0, suite2 holds 0
  tick 1: suite1 gets 8 extra duts (holding 8),
             suite2 gets 2 extra duts (holding 2)
  tick 2: suite1 gets 0 extra (holding 8),
            suite2 gets 0 extra (holding 2)
  tick 3: suite1 gets 0 extra (holding 8),
            suite2 gets 0 extra (holding 2)
  .... (a lot of 0s above)...
  tick 10: suite1 release 1 permanently when only 7 jobs left
            suite1 gets 0 extra (holding 7)
            suite2 gets 1 extra (holding 3)
  .....
With the current algorithm, the allocation is pretty much determined in the first tick. 
&quot;Number of extra duts a suite can get in a tick&quot; will remain 0 for both suites until a point (tick10)
when the very last jobs in suite1 is about to finish.
|These tests seem fit in the rdb_integration_test better. So I moved them and make them do end-to-end host acquisition via rdb_lib.acquire_hosts.
|Done
|Here core_cluster means a core_cluster image?
Could you clarify what &quot;core_cluster&quot; refers to in the docstring, as well as the loop from puppylab-&gt;core_cluster-&gt;vm-&gt;puppetlab?
|put this in a constant?
|what if the key doesn't exist? will it throw an exception?
|put cmd after job_name
|labelname -&gt; label name
|yeah...i mean current
|in the file name
correct -&gt; currect
|WEVER -&gt; SERVER
|Looks like the code will try AUTOTEST_WEB first, if not specified, then fall back to &#124;default&#124;.
|it would be nice the naming of this table can follow the same convention, i.e. starting with &quot;server_&quot;
and then in the db_router, you'll check whether the table starts with &quot;server_&quot; instead of &quot;server&quot;. not a big deal tho, leave it up to you.
|I suggest we break server_roles into two tables
  server_servers_roles (id, server_id, role_id)
  server_roles (id, role_name)

this would work the same way like afe_hosts, afe_labels, and afe_hosts_labels.

IMO we should still be able to create a role, even if we have 0 servers. And each element in ROLE_LIST can be one row in server_roles, so that it won't be harded-coded in this class. Should we add a new role, we can just update the db.
|okay, we probably won't expect to too many servers like we do for labels, one table would work.
|If we can break the server_roles table into two like i mentioned earlier, create server with a given role would become one db call and new role would be created separately with a different command. how do you think?
|yes, that's right
|how will this method be used?
|make it a one line description, and put the raise in @raise
|might be helpful to give a full example, not sure what are the possible input and how they should be verified. maybe it'll be straightforward when i see the caller code
|do we need to modify setup_django_environment, and setup_test_environment for adding the new db?
|we are repeating a lot of code here. Can you take the chance to merge them with a loop through ['default', 'global', 'readonly', 'server']?
|the call_command for readonly looks redundant?
|Why shard's hostname is localhost for vm in a cluster? Doesn't the vm of a shard have its own address?
|And by the hook, do you mean we won't run host scheduler on the master, so the job won't start?
|Why do we want to forbid creating job against host on shard? would the job be automatically synced to shard?
|the case &quot;atest server replace&quot; is missing from the description, what is replace for?
|Can you clarify what table is for? The help message is not very informative.

From get_server_details, i saw it seems to related table view and detailed view. could you please explain the difference?
|can you use the failure recording method: topic_common.failure() ? the same in other classes

Looks like atest have built this dedicated to handle errors.
|-&gt; is not None

same below
|If  in the db, I already have two servers:
 - &quot;server1, role=scheduler, status=primary&quot;
 - &quot;server2, role=NULL, status=backup&quot;

Now i call _add_role(server2, role='scheduler'), looks like it won't allow me because there is server1, even if server2 is just a backup?
|i see, didn't realize this is a print
|still asumme I already have two servers:
 - &quot;server1, role=scheduler, status=primary&quot;
 - &quot;server2, role=NULL, status=backup&quot;

say i wanted to delete role=scheduler from server1,
it won't allow me and will say &quot;role scheduler is required, please add the role to another server&quot;

then following the recommendation I tried to _add_role(server=server2, role=scheduler). It still won't allow me because there is already server1 (the earlier example). Will this situation happen? Please correct me if i misunderstand the code.


seems that the right way to achieve this is

 _change_status(server1, role=backup)
 _delete_role(server1, role= scheduler)
 _add_role(server2, role=scheduler)

This sounds a bit confusing. I am afraid the sanity checks in each modification method might get users into unexpected loop that they can't get out of easily without knowing much about the code.
|is not None
|The name of this method is a bit confusing. verify_server_exists sounds like &quot;server must exists&quot;. How about?

def verify_server(exist=True) 

 exist=True, check server exist
 exist=False, check server doesn't exist
|lowercase (V)erify
|the filter below only get actual incompleted jobs, i didn't get which completed jobs we are &quot;pretending&quot; here?
|why is this change needed?
complete=False implies shard must has a value (not null), becuase shard will be set to null only after complete bit is set. is my understanding incorrect?
|please make this comment say if the value can't be found in AUTOTEST_SEVER_DB, will fall back to AUTOTEST_WEB, if AUTOTEST_WEB doesn't specify it, will use default.
|add as a comment?
|can we use int 0/1 for disabled? With 'False' as a string, we have to be careful about typo and capital 'F'.
|the above three lines are repeating in if-clause and else clause, can you move them out of the if-else?
|why not the setup_test_environment? how is lite different?
|i see.
|would it be more efficient to query for the server with the given hostname and then check whether it has the role and status==primary?
|we are safe to use &quot;if not allowed_users&quot; to cover the case allowed_user is mistakenly set to empty?
|Done
|Done
|Done
|Done
|Done
|Done
|why delete role here? If the server had the role, it would have raised an error at Line 53?
|how about ENABLE_ACTIONS_AFTER_ROLE_APPLIED
|if I add two drones or remove a drone and add a new one, seems it will be restarted twice?

I feel changing service on the fly while changing the db is kind of hard to solve this problem. If one makes multiple changes, like remove a server and add a new server to replace that role, which  i think are common cases, the better way to go seems to consolidate all necessary service change at the end and do them smartly. 

If we prefer to do service change on the fly for some reason, i recommend have some sort of protection, e.g. warn the user and let the user confirm by typing &quot;yes&quot; before proceeds, or 'no' to skip, or add an option to atest to indicate whether action should be performed.
|How about DISABLE_ACTIONS_BEFORE_ROLE_REMOVED
|same here
|How will the code look like here? I think the logic can differ a lot for different roles.

also if I am gonna add one drone, before restarting scheduler, the drone needs to be added to the scheduler's shadow config. Will that logic happen here?
|as this module become more complicated, I think I am gonna agree with beeps suggestion on restructuring the stuff in this module into classes. The logic of role/status modification and actions are intertwined. They look good candidates to be encapsulated by classes. A clear separation between them would be helpful to understand what event would trigger what change.
|logging.Formatter(&quot;%(asctime)s;%(levelname)s;%(message)s&quot;)

If we use the above here, we can get the timestamp automatically i think
|I am wondering can we use the logging module's default time formatter?

%(asctime)s mentioned in 
https://docs.python.org/2/library/logging.html
|i intentionally make it a dot, and use &quot;tag=double&quot; below in run_test.  This way the NAME (used by dynamic suite) and the test name in tko (used by run_suite) will end up the same. They have to match so that run_suite can correctly load the id of the bug that dynamic_suite has filed.
|I would prefer adding it to bvt-cq or bvt-inline :(
But I couldn't do that because we are sharding tests between boards (some boards only run bvt-cq while others only run bvt-inline while link runs both).
|added the discussion to the docstring.
|Done
|looks likes so. removed.
|yes, sanity suite only contains one test (dummy_Pass), so only 1 dut is needed. For cq suite,I chose 20 as it is the current size of &quot;board:wolf pool:tot-cq&quot;. that means cq suite would take minimum 20 duts (or even more if canary is not using them). i am open to better ideas of resource allocation here.
|6 is the current size of pool:canary
|looks like only one of {provisiion, reset, cleanup, verify} would be scheduled. Could you move reset/cleanup/verify case into &quot;elif&quot; clauses?
|could you also put cleanup and verify in elif clauses?
|ah, you are totally right.
|Done
|Done
|you mean add a timer? added a timer in the new patch.
|Done
|probably need to rebase over https://chromium-review.googlesource.com/#/c/237321/
|i mean to verify that the cros-version label exists in afe. I'll update the message to be more specific.
|use instanceof ?
|might be better for clarity 
  for name, ratio in rations:
|make 10 as an argument passed from test_that
|Done
|yeah, this is not related to servo change. I'll put it in a separate cl.
|Done
|Done
|i can rename it back.

There is a case when
   servo_args == None and try_servo == False, we won't create servo host (won't even try). my original intent was to find a name that can express this.
|@richard, Here is what we discussed:
  if servo_args is None:
      if try_servo:
          create servo (lab args)
          ignore failures
       else:
          Do not create servo.
  else:
      if servo in lab:
          create servo (lab args)
      else:
          create servo (servo_args)
      pass failure to caller

I found the code gets a bit duplicated if i follow  the above logic strictly, as there two branches both &quot;create servo with lab args&quot;.

So I still keep most of the original code. But the outcome should be same. How do you think?
|We were talking about fail loudly here in the case where &quot;required_by_test=True&quot;. But I am afraid that this will change the old behavior, it might break some callers. I am leaving it as it is. Let me know if fail loudly is preferred.
|Done
|Done
|ah, will fix this.
|It would be nice we can default skip_servo to true as servo check is expensive (maybe it should be named as &quot;use_servo&quot; then). The only reason i default it to false is to be safe that I won't break anything.

As for servo_args,
we have been using &quot;servo_args&quot; as a hack to determine whether a test 
needs servo or not. This makes the code logic complicated and less
strait-forward, and will become more complicated with the new arg.
Say we default skip_servo to true, without changing any test code,
we will end up the following cases to deal with 

  1) servo_args is not None and skip_servo==True  (come from test that uses servo)
  2) servo_args is None and skip_servo==True (come from test that doesn't use servo)
  3) servo_args is None and skip_servo==False (come from special task like repair, reset which use servo, we explicitly set it to False)

I found it wired that case 1) says skip_servo==True, 
but we still need to  initialize the servo. 
So I would vote for changing the tests to explicitly say &quot;skip_servo=False/use_servo=True&quot;, 
rather than figure it out based on servo_args behind the scene like we do today. 

We have 130 create_host calls, all in server side control files, 90% are 
firmware tests. A simple &quot;sed&quot; could do all the changes. We can coordinate 
with yusuf and make sure nothing breaks. How do you think, Dan and Richard?
|Done
|Done
|max_retries could theoretically be set to 0, thought it shouldn't be a common case. For consistency, I wanted to make 0 means 0 retries and None means unlimited retries, so it needs to explicitly do the comparison with 'is not  None'
|missed this comment.  will change it.
|ah, thanks for catching this.  removed.
|add @param prefix
|hi keith, &quot;drone&quot; is not the device that the test runs on. I think you may want to use 'test.machine'
|Please make sure that the output of the old script and the new script are identical. And better to test on cbf as it got more history data.
|how about rename it to host_status?
|afe was initialized with a server name, i guess afe_server is not needed here
|same here
|where is this method called?
|Looks like HostJobHistory contains functions fall into two categories

  1. functions that calls afe at client side
   get_histories_by_names, get_histories_by_board_or_pool, _get_history

  2. functions that afe calls at server side
   last_diagnosis

The mixing makes the dependency relationship very confusing.
Could you refactor so that they are not mixed in one class?

Some thoughts:
  # Put the following three as module-level methods, called  at client-side
  get_histories_by_names(afe, ...)
  get_histories_by_board_or_pool(afe, ..)
  _get_history(afe, host_job_history)
  
  # module-level method, called by server
  las_diagnosis(job_events)


  # HostJobHistory accessed on both side
  class HostJobHistory
|add @param job_events
|_get_history is not called? so in this patch self._history is of no use?
|space around -
|determining vm based on whether hostname contains &quot;localhost&quot; is a hack. I'd rather not adding more hacky logic on top of normal code. putting it at a designated method makes replacing the hack logic with something long term easier.  client/bin/site_utils.py:is_vm sounds the right place to go.
|how about just add another method is_testing_vm?
|is_puppylab_vm will probably be just one line of &quot;return server in _LOCAL_HOST_LIST&quot;. That sounds fine to me. If you do so, please move the big chunk of comment in rpc_hostname()
(&quot;TODO: Figure out ....&quot;) to the new method.
|remove ':'
|how do we make sure that a data point won't be retried forever, is there a guard or limit?
|please avoid using . in the metric name, unless it is on purpose. The name will be broken into two levels.
|timer = autotest.stats.Timer('shard_heartbeat')
  with timer.get_client('find_hosts'):

  with timer.geT_client('find_jobs'):
  ...
|Done
|yes, e.g. from the frontend, one can create a job and specify two hosts, that will result in two hqes. And the huge job (the one job that ran on 1300 hosts which caused our gsutil to fail) is another example.
|rephrased to be more accurate.
|These filters are very slow, as it is translated to

afe_jobs`.`id` IN (SELECT U1.`job_id` FROM `afe_host_queue_entries` U1 WHERE (U1.`active` = True  AND U1.`job_id` IS NOT NULL))

which grabs all active hqes.
|it can't be NULL, you are absolutely right. This is some leftover from the django raw sql translated from hostqueueentry__isnull=False. will remove
|yeah, that's right. thanks for catching this.
|please refer to crbug.com/490485 for the original raw sql.
These two sql are optimization on top of the original ones.
The major difference is how afe_host_queue_entries are handled.
The search results should remain the same.
|I put some notes on the bug.
|for frontend, we are looking for jobs
- without meta_host (this is why t3.id IS NUL)
- with a host
- one of the host' labels matches a shard's label

actually these outter joins are overly complicated by django. I'll simplify them in the next patch.
|Done
|good point.
|add a space after :
|make the summary oneline
|I vaguely remember that --image is dead (scheduler is not using it) and this is the only option in this file.
since we are getting rid of site* gradually, can we add the option in autoserv_parser.py?
|add a space after :
|the two control files might need to be put in a separate cl.
the control file will be effective immediately but rpc method change won't be able to support &quot;builds&quot; and &quot;test_source_build&quot; until next push to prod
|Done
|Done
|still needed by parent class. won't work if i removed it.
|Done
|Done
|Done
|sg
|Done
|great, good to know.
|Done
|i believe there is a bug. as in InsertBuild we have build_id=len(self.buildTable), which starts from 0. Then there is no point of -1 here.
|Done
|sounds good. i'll get the IOError check back.
|I expected the same, but actually id1==0 and id2==1
this is coded in fake_db:InsertBuild, where id is set to len(buildTable).
I thought this was a bug as db index is supposed to start from 1?
bug apparently i can't change InsertBuild as there are other tests already adopt the behavior.
|dut and host are synonyms, how about run_remote and run_local
|put it in a constant
|nothing wrong with the test. it is just that perf data (perf_measurements) are uploaded by another process running on our drone server, and perf dashboard only accepts data sent from our drone server in our lab. No data from outside the lab are allowed. You are welcome to keep the code this way so you still got data in per_measurements. Just an fyi that you won't see it on dashbaord.
|if run local, i assume it is run via test_that on people's desktop?
if so, output_perf_value won't be able to send any perf data to dashboard.
|When a devserver is very overloaded, one loop might get longer than STATS_INTERVAL. How about calculating the time difference between last check and now?
|oh, you are right. my issue was somewhat different -- I had the main thread blocked by the child but in this case we don't.
|I remember i had to add some logic to handle the control-c signal as it can only reach the main thread. Just want to double check we can still control-c it.
|yes, but if the main thread is dead, the child will be left orphaned and can't exit properly. http://stackoverflow.com/questions/1635080/terminate-a-multi-thread-python-program
|+1
|add copy right header
|inherit from object?
|raise a specific type of Excepiton
|close the quote in one line
|do we want a log file for the log server?how do we debug the log server if it crashes.
|add space around *
|can we move this out of the method? seems we don't need to load the value every time the method got called.
|no
|remove parentheses
|add @returns
|it seems easy to make the method generic to cover other server types.
how about put it in as an arg
  get_least_loaded_devserver(devserver_type=ImageServer)
|sg
|what's the overhead of spawning 10 processes (10=num of devservers) for every devserver check? on our drone, this means 10 processes per test at least?
|can we convert _compare_load to a comparator and call sorted(loads, key=_compare_load) here? might be more readable
|they are similar but somewhat different. my understanding is that primary and backup would have the same setup (configurations), so we can swap one with the other freely; and primary doesn't need to know the existence of the other.

on the other hand, a db master and db slave 

* have different mysql configurations; we can't simply swap a master with a slave as we do for drones, they need to be &quot;rotated&quot; -- provisioning a master as slave and the slave as master would require a relative complicate process. 

* they need to be aware of each other.

* slave should probably be treated as in service as well,  people usually tend to care less about the state of backup machines, but in this case they should.

** if a slave is down and out of sync with master for over 15 days (configurable), the slave can't be used again, as 15 days is the maximum length that slave can catch up with master. 

**  we have the option to route non-critical read-only traffic like wmatrix pumping to slave if we want.


i hope a dedicated role would help people realize they are different.
|yeah, i'll do the documentation some time next week.
also plan to automate mysql via puppet (crbug.com/427980). can't cheat with sam any more ..
|this reminds me why we have scheduler,host_scheduelr.. but not apache?
|where is verbose referenced?
|move this to a constant
|add spaces before and after + and after :
|seems inventory can fit in one line with _generate_board_inventory_message
|what's the difference between ro and rw?
|I guess this should say RO firmware?
|add a blank line after the summary.
|add @param for request and @return
|single quote, same below.
|can we remove space in &quot;, &quot;?
|It only affect suite scheduler bug like this 
https://code.google.com/p/chromium/issues/detail?id=506259

Previously the anchor looks like

ANCHOR  SuiteSchedulerBug(chameleon_hdmi_e2e, daisy_freon-release/R44-7077.66.0, &lt;class 'autotest_lib.client.common_lib.error.ControlFileNotFound'&gt;)

With this cl, it will look like 

ANCHOR  SuiteSchedulerBug(chameleon_hdmi_e2e,  &lt;class 'autotest_lib.client.common_lib.error.ControlFileNotFound'&gt;)


ANCHOR is used to dedupe bugs -- bugs with the same anchor will be merged into one thread. So previously, each build will have a new thread, now we dedupe them into one as there are lots of noises if we file one for each of them.
|I assume getting rid of the check for shard is the only change here?

why do we need to get rid of the check for shard?

   if server_utils.is_shard():
        return
|guess it doesn't hurt to check here, in case if any caller forget to check, we can avoid it from going into a wired loop.

or we could move the caller check to here, so that we have less &quot;if server_utils.is_shard&quot; in the code.
|since this method itself will ensure label exist (create one if not), I think it is safe to drop the check (ensure label exist) in site_utils/provision_AutoUpdate/provision_AutoUpdate.py
|does this cover your ips?
|is there a bug tracking this?
|please test the following cases outside moblab. -w cautotest will point to our real server. I picked the following jobs from daisy_skate paladin.

1. a passing job 38026510
run_suite.py --build daisy_skate-paladin/R46-7318.0.0-rc2 --suite_name bvt-inline --board daisy_skate -m 38026510 -w cautotest 

2. a failing job 
--build daisy_skate-paladin/R46-7311.0.0-rc3 --suite_name bvt-inline --board daisy_skate  -m 37897189 -w cautotest 

And also try --json_dump with the above cases.
|nit, change it to 
error_msg= 'BoardNotAvailableError: %s' % e
output_dic['return_message'] = error_msg

we can drop the &quot;Can not run suite&quot; string.
|same here.
|nit: It is clear that this is an exception, so just do
output_dict['return_message'] = error_msg
|The return_msg_udpated logic is getting complicated.
I'd prefer we keep get_return_msg as a private method in ResultCollector, as some of the reasons won't make sense out of the context of the collector. For example

  if code == RETURN_CODES.INFRA_FAILURE:
        return 'Suite job failed or provisioning failed.'
INFRA_FAILURE means &quot;suite job failed or provisioning failed&quot; _only_ inside collector. If you got INFRA_FAILURE because of TestLabException, you should not use the msg provided by this function, but instead, you should convert the exception to a string and use that as your return message. 


I recommend writing a separate function, e.g. update_return_message to be used in main.
|For each of the exception caught here, we want the return message to be the string representation of the exception, i.e str(e) rather than the string provided by get_return_msg.
|add an extra blank line
|we have another concept of test attribute in autotest, which differs attribute here. Could you rename the function? maybe get_control_file_attributes()
|I think it is important to include self.return_code and self.return_message in the json, which are part of the result.
|sounds good to me. In addition to &quot;code&quot;, you also want to bubble up the return message.
|Yes _buildbot_links is a subset of _web_link.
But there are some logic in link.GenerateBuildbotLink() which will determins the actual url that will be shown in the output, it is not always link.url, it could be a link to bug tracker. Currently, we are missing all the bug links I think.
|somewhere in the method above, you'll need to take care of the links in buildbot links which will point to the autofiled bug. Each failed test will have an entry in self._buildbot_links, not passing tests.
|you also want to take care of the wmatrix link
|it would be nice the json can include which autotest instance was used as lab people checks it very often.
|cbuildbot needs to be aware of the pool health bug filed.
|How do you deal with the case when exception are raised?
Do we want to pass the exception message via json as well?
If you are silent all logging, you will have mystery failures with no logs.
|It would be nice that the suite job id is included in the json.
|Either cbuildbot or the proxy has some I/O timeout so we had to keep logging something otherwise cbuildbot will think run_suite dead. So I think this message is still necessary.
|The return code and return_message got updated in the above code. If you are including return code and return message in the json, you will need to update the json accordingly.
|I didn't quite get it. Our current cbuildbot logic first calls run_suite without -m and then the second call is with -m. It is the second call (with -m) that is long running and waiting for result.

I do see it is possible that we move the polling while loop logic to cbuildbot, i.e. run_suite will always return immediately when calling by cbuildbot.
|but you probably still need to keep logging something, given the fact that we have a I/O timeout.
|oh, do you mean we run it three times
first time: run_suite --create-and-return
second time: run_suite -m JOB_ID --&gt; it waits here
third time: run_suite --json-dump -m JOB_ID --&gt;no wait

that should work.
|if you expect no logging, exceptions here need to bubble up to cbuildbot in json.
|+1, we have been calling for this feature for a long time.
It would open the door for adding more useful information.
|Move my comment in previous patch here.

It is true that _buildbot_links is a subset of _web_link.
But there are some logic in link.GenerateBuildbotLink() which will determin the actual url that will be shown in the output, it is not always link.url, it could be a link to bug tracker. Currently, we are missing all the bug information I think.

Actually the fix would be quite easy, maybe you just need to include the bug url in test_info, like you did for wmatrix
|the &quot;return_message&quot; has been very useful. If you got a return code 3, it can mean many things, it could be a bug in dynamic suite, or it could be suite timing out. I think we should added to the output_dict, or bubble up to main and let main write the message to json.
|this needs to say actionables.TestActionable(....)
|could you change it to distinct(t1.id)? I found there were many duplicates because job-label are 1-to-many mappings. though the network traffic saved is minimal, it is nice to have.
|same here, add distinct(t1.id)
|The result sets SQL_SHARD_JOBS_WITH_METAHOST AND SQL_SHARD_JOBS will have a big overlap I expect. So I am proposing merging the two sql into one:

    SQL_SHARD_JOBS = (
        'SELECT t1.id FROM afe_jobs t1 '
        'INNER JOIN afe_host_queue_entries t2  ON '
        '  (t1.id = t2.job_id '
        '   AND t2.complete != 1 AND t2.active != 1 '
        '   %(check_known_jobs)s) '
        'LEFT OUTER JOIN afe_jobs_dependency_labels t3 ON (t1.id = t3.job_id) '
    # LEFT OUTER to ensure that a job that doesn't have a label 
    # will still be included after the join. 
        'WHERE (t3.label_id IN  '
        '  (SELECT label_id FROM afe_shards_labels '
        '   WHERE shard_id = %(shard_id)s) '
        '  OR t2.metahost IN   '
        '  (SELECT label_id FROM afe_shards_labels '
        '   WHERE shard_id = %(shard_id)s))'
    # It is annoying that we have to repeat the subquery,
    # but I am hoping if the first half of &quot;where&quot; before OR is 
    # evaluated True, the second half won't be executed.
        )
|I guess it is very likely that metahost_objects and dependencies both contain the the same label, like &quot;board:link&quot;?
so we may end up with duplicates here.
|do we want to create some indexes to make the query faster?
|tko_jobs currently doesn't have parent_job_id, so you'll need to get that one fixed first?
|maybe merge the three &quot;create index&quot; statements with the alter table statement?  It sounds to me that create index is essentially mapped to alter table and will then require creating a temp table. I guess merging them into one might save some time.
|I saw logic about results_host and archive_host are removed. If we are going to deprecate logic of results_host and acrhive_host, it is probably preferable to do it in a saperate cl together with pieces in other modules. otherwise we are leaving a broken feature here.
|do we want to check &quot;shards&quot; in the config file if we are not using server db?
|over 80 chars.
|could you split the minor bug fixes to a separate cl? It took me a while to guess &quot;why this change has something to do with creating shard with multiple board labels&quot;.
|sg
|what does the parse do here?
|so without the change, all shards will always be listed. And with this change, one can show specific shard by specifying its name, is that right?
it doesn't seem to be related to supporting multiple boards per shard. Please clarify the minor bugs you are fixing here in the commit message.
|i see. good to know.
|I didn't quite understand what label_info is for.
I cherry-pick your cl, remove the code about label_info here, it seems I can still run shard_create without any problem.
So I am wondering what's the purpose of the code.
|why does the code do here? I remove this piece, it seems still working.
|-&gt; Must provide one or more labels
|Done
|Done
|could you remind me why the results folder has the owner of root but not chromeos-test?
|just curious, why didn't we create a user chromeos-test inside the container, any complication there?
|fix unittest?
|good point, i think we can skip
|rename this to something more accurate, probably _get_known_jobs_and_hosts.
|saw your other cl.
|what are the possible extra servers we may have?
should we expect everything be specified in the server_db?
|how about put the login code in another function.
|Done
|What do you mean by &quot;Deafult to None to use the ChromeOS build&quot;? There is no default? And this should never be None in the first place, is that right? It seems that you want to keep &quot;build&quot; like you did in the caller

And please keep the example.
|I think this query is sort of slow. Can we add a constraint on &quot;created_on&quot;? e.g, a cut off that is two-weeks would be pretty safe.
|i guess this means where the test code would come from, but could you elaborate the term &quot;test_source_build&quot; and &quot;ChromeOS build&quot; here to make it more clear?
|out of curiosity, why rimware update need this customized repo_dir?
|It also doesn't make sense to specify cros_build_spec when &quot;brach_specs==tot&quot; or specify firmware_rw_build_spec when &quot;branch_specs==firmware&quot; right?

Could you make this more clear or maybe add some checks below?
|what other value can firmware_rw_build_spec have?
|can we move the check here to Task.CreateFromConfigSection()?
|so if this is a firmware_build, we don't care firmware_rw_build_spec? could you provide some context?
|should firmware_rw_build_spec be a boolean type instead of a string. Do we really care its value or we only care whether it is set or not?
|max_elapsed_secs might be more strait forward.
|can we remove these site business?
|Done
|Done
|Done
|Done
|Done
|yeah..I have to hack the task_run.json file to reject the task. For long term, would you consider make on_before_task be able to do more things? It would be nice that
 - it can accept &quot;manifest&quot; as an arg
 - we can have the option to treat Exception in on_before_task as critical issue and fail the task.
|Done
|Done
|Yes, as mentioned below, this is a modified version of bot_config.py in https://github.com/luci/luci-py
I am not quite sure how LICENCE works. I modified the disclaimer in the new patch. PTAL
|Is it okay I put this customized version of bot_config in our source tree?
|@maruel, how can i whitelist a list of commands that should be allowed to run while forbid other commands?

This method doesn't give me access to the task.
|in launch_bot
|Done
|Done
|Done
|Done
|Done
|tried. looks like add_parser doesn't expect &quot;required&quot;
|I didn't quite get your question. could you clarify?

I intend to make kill and launch_parser as two separate commands (i.e. subparsers). &quot;kill&quot; and &quot;launch&quot; will have different set of options.
I am planning to add more options to kill and launch.
|Done
|Is there a way that I can kill a bot more gracefully?
|@marule and @vadimsh
|Yes, using PID is better. I plan to add more features around managing a single bot given the bot id (restart, kill, launch). I'll implement together in a separate CL. I'll put a TODO here for now.
|Done
|Done
|oh, i see, removed.
|Done
|Done
|great!
|Done
|Done
|yes, http:// doesn't seem to work.
|please make sure the new change is exercised.
|put the command you've ran here.

run_suite.py --pool='' --board=peppy --build=peppy-paladin/LATEST --suite_name=dummy --json_dump

I expect the builder will call run_suite.py with &quot;-m EXISTING_JOB_ID&quot;. I recommend you find the following suite jobs and call run_suite with -m against these three jobs.

- suite job that fails due to infra error
- suite job that passes 
- suite job that with retries
- suite job that fails
- suite job that fails with retries.
|I recommend add unittests for changes to ResultCollector.
You can refer to the example in ResultCollectorUnittest in run_suite_unittest.py
|Test the branch here when exception is raised. You can do it by specifying a unknown board.
|Done
|No, this just changes the script that kicks off run_suite.
Previously it uses _AUTOTEST_RPC_CLIENT.
If use_swarming_proxy=True, it will use _SWARMING_PROXY_CLIENT.

The change should not interfere with any run_suite arguments, including subsystem.
|this shouldn't be a hard-coded index.
|will do
|Done
|Done
|yeah, that makes sense. Done
|removed this class.
|Done
|got it. and following you comment above, i removed this class.
|That CL modifies manifest-internal/full.xml to pin chromite/third_party/swarming.client to the latest version.

https://chromium.googlesource.com/external/swarming.client

The original swarming.client in chromite was too old which don't support many options we need to use.
|i decided to use the same server for debugging mode. if --hwtest is specified and we are in debugging mode, we would still want the request to reach the lab i guess.
|Done. I don't think we need staging server. I am just going to inject None if we are in Debug mode, and a fake address if we are in Mock mode.
|This task summary json is a swarming thing. run_suite stdout will be dumped to this json file. We can't directly use stdout from swarming_client.py as stdout from it is mangled. It is generally a good idea to read &quot;outputs&quot; field from the json to get the original output from run_suite.
|we can retry on internal_failure, e.g. when a bot died. I'll add the retry in an other cl after this one has been proved to work in production.
|refactored.
|I refactored how the args were generated so that we don't have to hard code the index of --suite_name at
https://cs.corp.google.com/#chromeos_public/chromite/cbuildbot/commands.py&amp;l=992
|Done
|Done. it is a path.
|Done
|Done
|Done
|Done
|Done
|Done
|I saw len(devices) is checked in _initialize, when it has &gt;1 device, _initialize will raise an exception. Why do we need to check len(devices) here?
|to be more robust, use site_utils.ParseBuildName(self.build)
It will return a four-item tuple, you just need the first item
board, _, _,_ = site_utils.ParseBuildName(self.build)

catch site_utils.ParseBuildNameException in case it is a malformed named.
|'BOARD_PLACEHOLDER' maybe more clear.
|You can run a dummy suite with --file_bugs and see if the bug was filed correctly. You can copy /usr/local/autotest/bug_filing_oauth_credentials.dat from chromeos-autotest.cbf to your local autotest root dir.

and put the following in your shadow config.

[BUG_REPORTING]
project_name: autotest-bug-filing-test
username: bugdroid1@chromium.org
password: b350tted-droid
credentials: /usr/local/autotest/bug_filing_oauth_credentials.dat
|what does %% means in mysql?
|I suggest delete X number of rows at a time. X can be an option with a default. There is a limit for how many items you can put in &quot;WHERE id in (%s)&quot;. Also, by any chance the query is slow, we won't be locking the table for too long.
|return 1?
|How about make version constraint as a enum that has
(EQUAL, GTE, GT, LTE, LT)
|How about move these logic to determine version constraint into a method, and let that method return a enum, as I mentioned above
|Done
|Done
|followed paul's suggestion, moved to a loop. 
It is clearer now:)
|remove 'r' before &quot;&quot;&quot;
|I am confused why replacing ' with \'' but not with \'
|we use that for the same repo as well.
It makes sure this one won't be picked up by CQ before 295440 is picked up.
|please add CQ-DEPEND=CL:295440
|hmm, we can't just add an extra arg, as it needs to be consistent with the base class's interface. How about making the template say

&quot;Automatically generated to track the&quot;...
don't mention if it is a bug or email. I don't see much value of conveying it in the summary, if it shows up as a bug, we know it is a bug, if it shows up in a email, then we know it is an email :)
|send_email --&gt;use verb
|this is very hacky. I would change the code who sets the summary, rather than manipulate the summary here.

At least, you could change it to 
  the problem has been automatically reported to xxx
|we only use this to setup master db for testing clusters, not for production db.
|please guard this with an option.
I'd prefer not having people's local db be accessible by all other googlers.
|can we build the to_set incrementally with valid data instead of insert None/'' into it and relying on filter?

the code would be more readable.
|i'd vote for readability if it is just a couple of more lines. other people may also get confused by filtering on '' and None.
|this is running run_suite.py locally and not going through the proxy. I think there is no point of create-and-wait here.
|return bool(re.match(regrex, suite))
|what do you mean by &quot;owner is myself&quot;

and why file_bug=False? I with file_bug=False, you code won't be triggered as should_report will return False.
|should be 'bvt-.*', 'paygen_.*' (dot after -)

-* means zero or many '-'
|I thought the plan was for bvt, we are going to keep filing bugs. And for other suites, which are *currently file bugs*, we are going to switch to emails.

If that's the case, I'd recommend not modifying this method. but add new method def get_report_format(suite_name)
|how about return an enum type
ReportStates = enum.Enum('NO_REPORT', 'BUG', 'EMAIL')

return ReportStates.BUG
|Actually, I would recommend not modify this method, but have a new method. determine

def get_report_format(suite):
   if suite is bvt:
        return ReportStates.EMAIL
   else:
        return ReportStates.BUG
|it seems that for a test failure, if _file_bugs is false , we will always send email. This doesn't sound right. 

I think here is we want

 if self._file_bugs == True:
    if bvt:
       file bugs
    else:
       send email.
 else:
    nothing should be reported.
|sigh, tko/parser.py sets autocommit=False, so it'll bypass this. 

https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/tko/parse.py&amp;l=466

Looking at the code, we can't turn on autocommit for it.
we may need to special case parse.py.
|self._commit()
|self._db = None doesn't close the existing db connection. so we may be leaking db connections if we keep retrying this method.

self._db.select will go through self._db.run_with_retry and retry any OperationalError when db is initialized with autocommit=True. So i guess we can just change Line 152 to self._db=db.db(autocommit=True) to enable retry, which handle the close of connection already.
|commit_with_retry should call _init_db() to refresh the connection.

It would be nice db flake, connection refresh and retry are handled inside tko/db.py. Otherwise we have to duplicate the code at every caller.

I think stats can be added in run_with_retry. That'll give us an overall idea of how flake the db is. I don't quite get why we need to care about suite.wait particularly? It is orthogonal to the db flake problem.
|oh, i know what's happening, it is self._db.commit() is not guarded by run_with_retry.

I suggest we add a new method in tko.py:db_sql
  def commit_with_retry():
      self.run_with_retry(self.commit)

and replace self._db.commit() with the new method.

tko/parser.py also call db.commit() directly. So we'll need to apply the same treatment there as well.
|seems that autocommit is default to True. I don't understand why didn't select() go through https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/tko/db.py&amp;l=252
|the problem is that the server/control_segments/provision does not pass servo_args when calling hosts.create_host, leading require_by_test to be False.

Maybe we can force a verify/repair in provision_FirmwareUpdate?
|there is a reason for this condition.
For tests that don't require servo (e.g. a login test), we don't want it to though repair_full() if servo is found bad, as that will take very long time.
|instead of two loops here, would sorting them be more straightforward? we would also avoid calling cls.get_devserver_in_same_subnet(host_ip) multiple times.
|+1 I think we should sort devserver by subnet and pick the first one that's healthy.
|i overlooked the &quot;if not host_ip else ...&quot; part, get_devserver_in_same_subnet will actually be called once. well, it is a bit confusing ;)
|all right, seems like it has to be the way it is.
|Done
|Done
|Done
|do you mean a line is missing? added a new line.
|Done
|autotest has a different coding style which leaves two lines between functions. It wasn't quite clear to me whether that includes functions inside a class, but all other code has been stick to the rule, so I followed the convention.
|Done
|changed to pgrep, and removed shell=True.
|tried. seems that the machine can't access https://swarming_proxy/swarming/api/v1/client/bots
without oauth authentication. I'll need to install oauth dependencies and credential to the machine that runs this script, which would require much more change. I think I'll punt it for now and add it later if there is need.
|Done
|Done
|If the pid file was removed by another file, that should be a bug and we want it to fail aloud. Also if for some reason, the pid file has a wrong permission and the script failed to  remove it, we should also catch that. So I'd prefer we make OSError non-forgivable.
|it can be reliably reproduced, with a simple loop that starts long running sub-processes and exist without waiting in the end. The last subprocess always missing, even though I already got the pid in the parent process.

There might be some race-condition in the subprocess.Popen code.
|Done
|good point. Done. PTAL
|some description is preferred.
|Done
|can we check in this code in chromite/compute/lib?
|Error is a built-in type. Please use some other name. like GceError
|Can we call it GceManager?
|I think this is not needed. I can create instances without this in my other project
|no need for readonly since you already have https://www.googleapis.com/auth/compute
|please add doc string for the args.
|For this class to be more generic, this class should be as stateless as it can. could you make zone an arg for the function that needs it, rather than store it as a class variable. that way the instance of this class can be reused to talk to different zones.
|Can we move the authentication out of this class?
potentially, this can be shared by code that accesses other Cloud APIs.
|move default to a class constant.
|same here.
|add docstring.
|I think the caller should handle delete. or have an arg delete_on_fail to control the behavior. I thinking making this class very dumb to only do one thing per API would make it easier for it to become a generic library.
|docstring for argument
|don't we get 404 &quot;not found http error&quot; if no instance found?
|docstring
|timeout should be a class constant.
|there is also a third type, region operation.
can we get rid of the two and just use an arg to control the scope (zone, global, region)?
|this is a private class?
|why changing from p12key to json
|zone or self.zone
|same here
|save two lines with for _ in range(BULK_POST_RETRIES):
|raise a specific exception type.
|you don't need to check self._servo_host.required_by_test right?  if self.servo is not None, we are safe to return regardless the value of required_by_test
|I don't think we need to care about required_by_test in this method. If a test is calling this method, it already indicated &quot;I want a working servo&quot;. So just force setup servo when self.servo is None?
|mention the trybot test your ran and how you the expected results. That is a good reference for other people to understand the outcome of the CL.
|Let's make HWTestCreate private as well.
|mention the bug id.
|Please test with the change with
  cbuidlbot --remote -g &quot;302135 302100&quot; --hwtest lumpy-release

Observe the following facts:
- HWTest stage 
  start command should have: --retry=True --max_retries=10 -c
  wait command should have: --retry=True --max_retries=10 -m JOB_ID
  both start and wait cmds should not have --no_wait=True

- AsyncHWTest stage
  start command should have: --retry=True --max_retries=10 -c
  start cmd should not have --no_wait=True
  wait command should not run
|make this method private -&gt; _HWTestWait
|you need to accept &quot;debug&quot; arg here. If debug==True, simply print
  logging.info('_HWTestWait would run: %s',
                 cros_build_lib.CmdToStr(wait_cmd))
|also remove this one
|thanks for catching this.
|this means provision failure will always be followed by a power wash?
|assume the above two functions will remove the marker file, so that we don'r run into a loop.
|ah, should have put it as a comment. Done
|okay, makes sense.
|after correction, do we want to try deleting again?
|User-rate limit is hit when we submitting request too fast. There is a 250 requests per second limit. We sent about 500 emails today. As long as we don't try to send over 250 emails in one second, it will succeed.

This is the suggestion given by the API.

&lt;HttpError 429
when requesting
https://www.googleapis.com/gmail/v1/users/me/messages/send?alt=json
returned &quot;User-rate limit exceeded.  Retry after
2015-09-24T14:31:39.229Z (Mail sending)&quot;&gt;
|good idea. Done
|Done
|+1 maybe _original_suite_name
|how about put this logic in a helper function 

def get_original_suite_name(suite_args)
|For a server that has 3 devices attached, e.g. 1 shamu, 2 hammerhead, I think we wanted to apply three board labels:

board:android-shamu-1
board:android-hammerhead-1 
board:android-hammerhead-2

sbasi@ is this still the plan?
|it took me a while to realize singleton_prefix is a list with only 0 or 1 element. maybe add

singleton_prefix = singleton_prefix[0] if singleton_prefix or None

to make it more obvious. and just use singleton_prefix below
|call &quot;test  -f file&quot; instead of using []
|will power wash cleanup &quot;/var/log&quot;?
|it doesn't seem to download anything, update comment?
|done.
|Please use RunSwarmingCommandWithRetries like _HWTestWait did.
|would be nice if you put the description of how you ran trybot here. That way, people can always see it when they ran &quot;git log&quot; without having to find it in comments in this CL.
|An instance of named tuple RunHWTestSuiteResult...
|Maybe it is clearer to be a noun instead of a verb, e.g. HWTestSuiteResult.
|If put &quot;subsys_dict = None&quot; outside the try-clause or just after line 920, we can safely remove Line 927 and LIne 931?
|swarming_args was used to emphasize these args will be consumed by the proxy command swarming.py, not the proxied command (e.g run_suite). Is there a reason we have to rename it to **kwargs?
|could you put the &quot;key&quot; name here for message_type/message_subtype/message_value, so that people don't have to go to the definition of InsertBuildMessage to figure out what these arguments means.

e.g.
InsertBuildMessage(build_id, message_type=constants.SUBSYSTEMS,
message_subtype='used_subsystems', message_value=...)
|I think 'used_subsystems' deserves a constant.
|Please add docstring for Return.
|maybe put the string in a bracket, (Exception raised from ..)
|I remember paygen also calls RunHWTestSuite. So if you move the logic to the caller, you'll need to take care of the other caller.
|+1 to mike's comment. The old code handles lab_warning_codes, infra_error_codes, timeout_codes,  board_not_available_codes,  proxy_failure_codes. I think we will need to convert them accordingly to exceptions out of failures_lib.
|add **kwargs to docstring
|It is very hacky to rely on substring of the message of an exception. I think the code should be refactored to avoid this. Also the code handling should belong to RunHWTestSuite as there are other caller of RunHWTestSuite

One way (might not be the best way) you can do is to let RunHWTestSuite catch and handle the RunCommandError exception, make RunHWTestSuite returns a named tuple (exception_to_raise, subsys_dict)
return (exception_to_raise=None, subsys_dict=None), if not exception occurs.
|Specifically, I think I am proposing something like

RunHWTestSuiteResult = namedtuple('RunHWTestSuiteResult', ['exception', 'subsys_dict'])

def RunHWTestSuite(...):
   try:
    ...
    return RunHWTestSuiteResult(None, subsys_dict)
   except RunCommandError:
       # Handle everything here
       if some_condition:
          subsys_dict = GenerateSubsysResultDict(result, subsystems)
       if result.returncode in lab_warning_codes:
          exception_to_raise = failures_lib.TestWarning(
              '** Suite passed with a warning code **')
       return RunHWTestSuiteResult(exception_to_raise, subsys_dict)

def PerformStage():
   run_hwtest_result = commands.RunHWTestSuite()
   subsys_dict = run_hwtest_result.subsys_dict
   if run_hwtest_result.exception_to_raise:
      raise run_hwtest_result.exception_to_raise
|You should not have to use ast.
&gt;&gt;&gt; import json
&gt;&gt;&gt; json.loads('[&quot;foo&quot;, {&quot;bar&quot;:[&quot;baz&quot;, null, 1.0, 2]}]')
[u'foo', {u'bar': [u'baz', None, 1.0, 2]}]

https://docs.python.org/2/library/json.html
|I think for loading json into dictionary, you don't need ast
|yes, correct, $? is deemed to be 0 but i still need to update download_exit_code.
|seems to work for me. manual tested with 

#!/bin/bash
download(){
  ls /x
}

if download; then
  download_exit_code=$?
else                                                                                                                                                                                                         
  download_exit_code=$?
fi

echo ${download_exit_code}

and a more complicated one
https://x20web.corp.google.com/~fdeng/test_retry_pass.sh
|Done
|do you think set+e before the command and then set -e after, will work?
|is there a way i can work around this?
|Done
|Done
|I didn't quite get the syntax here. what does this mean
 **kwargs:BuildRetriableRequest(...)
|remove comment
|For HttpError, you may want to parse the error code. It is quite common to get 500, 502, 503. Those errors should be retried.
|I think you'll get 404 error (resource not found) when image does not exist?
|You can try it on https://cloud.google.com/compute/docs/reference/latest/instances/get

https://screenshot.googleplex.com/6z1pu5mnFx5


404 OK
 
- Show headers -
  
{
 &quot;error&quot;: {
  &quot;errors&quot;: [
   {
    &quot;domain&quot;: &quot;global&quot;,
    &quot;reason&quot;: &quot;notFound&quot;,
    &quot;message&quot;: &quot;The resource 'projects/android-treehugger/zones/us-central1-f/instances/non-exist' was not found&quot;
|Different operations may require different timeout. e.g. creating an instances may take longer than creating an image.

Could you make timeout as an argument, and allow the caller to pass in a timeout, so that we can tune it for different operations?
|add a docstring
|can this fit with the line above?
|can  this fit with the line above?
|remove a line
|can we use a namedtuple instead of a class?
|put 'Success' as a constant?
|can we change to raise an exception instead of assert?
|can this line fit with the line above?
|add @params and @returns
|all of those look like 500's error?
|this is just to build get a Resrouce object locally.
I believe the errors in the doc happened when &quot;execute()&quot; is called.
|I see. looks like when build the service, it also send an http request.
|and same here, only 500 codes should be retried

here is the python doc that might be helpful
https://google-api-python-client.googlecode.com/hg/docs/epy/apiclient.http.HttpRequest-class.html
|i think you don't need to retry here, the retry should be made when we call &quot;execute()&quot;. That's when it actually made the request. There is a standard way to retry these api call. You can refer to this CL
https://chromium-review.googlesource.com/#/c/311833/4/lib/gce.py
|I think we still need to add num_retries=NUM_RETRIES here
and other places where api got executed.
|It is better to use the built-in retry function. As that will only retry by chunk instead of retrying the whole downloading.

https://google-api-python-client.googlecode.com/hg/docs/epy/apiclient.http.MediaIoBaseDownload-class.html

next_chunk(self, num_retries=0)
source code 
Get the next chunk of the download.

Args:
  num_retries: Integer, number of times to retry 500's with randomized
        exponential backoff. If all retries fail, the raised HttpError
        represents the last request. If zero (default), we attempt the
        request only once.
|what are the known errors we need to retry?
If we do have a list, it is probably good to maintain a list of specific exceptions we want to retry on. And should new types of exceptions needed to be retried, we can keep expanding the list.

And could you use the chromite retry lib? 
https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/site_utils/gmail_lib.py&amp;l=172
|I forgot this was devserver repo. If we couldn't use chromite directly, maybe  make a copy of GenericRetry function? It would be nice to have a retry logic here so that future code can use as well.

as for error, you mean &quot;from apiclient import errors&quot; will fail?
|And this will only 500's code which is more appropriate.
|User -&gt; Use
|to be robust, if no board_labels or multiple board labels, we should either fail loudly  or fall back to platform.
|that sounds good
|This could be &quot;no board&quot; or &quot;multiple boards&quot;
so probably WrongBoardLabelError or something that can cover the second case?
|maybe move LATEST to a constant
|please remove this.
|please remove this
|might be a good idea to keep timeout_min, delay_sec and debug?
|please update TEST field.
|wanted to make sure that \n won't confuse our parser since our parser relies on indentation
|Done
|Done
|By false-positive, do you mean non-restricted users being wrongly identified as restricted?

we assume the user is not restricted if
 - REMOTE_USER is not set; or
 - REMOTE_USER is set and REMOTE_USER is in the &quot;restricted_groups&quot; specified in shadow config, checked by server_utils.is_restricted_user

I'll put &quot;restricted&quot; ldap group in shadow config, and only TVCs should be in &quot;restricted&quot; ldap group.
|sorry non-restricted user condition should be:
- REMOTE_USER is not set; or
- REMOTE_USER is set but REMOTE_USER is **not** in the &quot;restricted_groups&quot; specified in shadow config
|&quot;request&quot; here coming from cgi which is of different type from &quot;request&quot; in frontend/apache_auth.py that comes from django middleware. It doesn't contain META field.

with the change in apache/conf/site-sso-directives
REMOTE_USER will exist in os.environ
|what is the &quot;False&quot; for?
|Done
|ah, right.
|the logic is

 - type: server_db -&gt; only backup chromeos_lab_servers db
 - type: only_hosts,  only_shards -&gt; only backup chromeos_autotest_db: host table or shard table
 - type: others: -&gt; back up all databases.
|there is an interesting red dot between l and st 
what is it?
|nit add a blank line here
|remove trailing space.
|could you take the chance to update the docstring
|do we have to have them as two methods?
why can't we keep get_hosts(include_current_job=False)
but default include_current_job to False?
|maybe we should confirm that without this scope, can our bot still be able to access gerrit?
|need to add this to gitignore.
|oh you already did, never mind.
|remove the raise :)
|can also be &quot;release&quot; now?
|in _set_ids, when we populate self.host_ids, looks like we have a chance to save the hostnames. 

I mean:
   def _set_ids(self, host=None, queue_entries=None):
        if queue_entries and queue_entries != [None]:
            self.host_ids = [entry.host.id for entry in queue_entries]
            self.hostnames=dict(
                  (entry.host.id, entry.host.hostname )
                  for entry in queue_entries
                  ) #  a new host_names dictionary
            self.queue_entry_ids = [entry.id for entry in queue_entries]
            
        else:
            assert host
            self.host_ids = [host.id]
            self.hostnames = [host.hostname] # a new host_names dictionary

if this works, we can save a trip to db for every host, how do you think?
|can we use &quot;if filtered_drones&quot; here?
|I am adding a new check to ensure that json_dump_dict is not None. 

otherwise, trybot could fail when Line 310 tries to access it.
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/2002/steps/HWTest%20%5Bsanity%5D/logs/stdio
|not needed. removed.
|Done
|maybe in the log mentioning that the exception is ignored and lock modification will be enforced.
|you are right. i confused it with &quot;get&quot;
|as discussed, call kwargs.pop('force_modify_locking') here
(no need to specify None, None is default.)
|same here, make it clear that the exception is ignored and we are forcing the lock modification.
|same here, move the pop to outside the try-except.
|how about a shorter name &quot;--force_lock&quot;?
|I did not quite get why we are popping force_modify_locking here. Could you add a comment here?
|add # Optional?
|is it possible that the suites was not scheduled fast enough (e.g. delayed because a temporary AFE downtime, or AFE rpc is very slow like what we had before) and when they are scheduled, they already missed &#124;current_hour&#124;?
|when will test_source_build be provided?
seems that run_prod_code is conflict with test_source_build,
to avoid surprises, do we want to raise an error if both are specified?
|can we log the error?
|+1 to wiley's comment. I don't think AbstractSSH should know any of these. 

and if we need to share something between ADBHost and CrosHost, we may want to consider adding a separate layer.
|looks like after this cl lands, we will be checking the weekly event everyday, is that right? could you please add some comments on how it works?
|to answer myself, weekly_param doesn't exist anymore and it seem to be a global config that was not customize-able for individual suites.
|just curious, what is weekly_params for and why aren't we using it?
|3. In the next cycle (suite scheduler checks all events every 5mins, plus the handling time of each event), say around 3:40AM, nightly tasks at 2AM will be handled, and deadline moves on to be 3AM.

Is this true? Looks like at the end of each cycle it calls
RereadAndReprocessConfig, where config will be reloaded and even will be merged. So at 3:40AM, the 2AM deadline, before it got handled, will be replaced by a deadline of 4AM?
|I think you can do

pgrep -fc &quot;apache&quot; 

pgrep -fc &quot;python.*telemetry&quot;
|just curious why what is apache running on devserver for? 
and can we also add maybe telemetry count?
|-&gt; Connect
|the variable &quot;successful&quot; might not be needed.
You are already logging a message in &quot;except&quot;.
Just move logging.info('succesfully get response from servo host') to after the call of ready_test. I think it would do the same.
|why on moblab we need to use &quot;sudo&quot;?
on our lab servers, everything run as chromeos-test, don't we need to use sudo as well?
|The try-except here doesn't have any effect.

How about create a specific exception type like SshTunnelCheckFailure and raise it? And then in retry, only retry on this specific exception.
|same here, will chromite still be able to import oauth2client?
|oh, here it is. ignore my comment on the other cl.
|we might be failing on deduping if &quot;reason&quot; contains special characters. Could you put a #TODO here and refer to the bug you filed
|do we still want mysql-server in this case?
|add a space before &quot;Default&quot;
|this script should always setup mysql right?
|setup_db.sh is a very risky. If someone accidentally run it, it may destroy their local setup or if it was on a server, we lost all lab data. We should definitely prevent it. 

The convention for handling &quot;interactive mode&quot; is to use an option (e.g for apt-get, -q means quiet and select &quot;no&quot; to all questions, -qq means quiet and select &quot;yes&quot;). we can do the similar here.
|-y might be a good name.
|we should only ask this question when db exists.
can setup_db.sh ask the question itself?
|scratch my comment, -c already does the job. sorry about the confusion.
|Done
|I am thinking later on maybe we can revive the db cleanup on master after we drop tko tables.. cleaning up afe with a couple of months data may not be too bad. Need to do some experiments about the performance.
|nit add a space after :
|Done
|Done
|sure
|I have a question:

what happens if the tunnel flakes? e.g. SSH connection dropped out. How do we handle it?
|nit: looks this line can be merged with above?
|nit: looks this line can be merged with above?
|in this if-branch perf_values is a dictionary, in the else-branch it is a list, would that work?
|we were aggregating the data from multiple iterations of the test. How does the iterations get handled in the new world?
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

lgtm w/ two nits
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

yes, all exceptions in this file should be converted to phapi_lib.ProjectHostingApiException. And it will be caught in higher level here https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/server/cros/dynamic_suite/reporting.py&amp;l=352
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(12 comments)
|Uploaded patch set 4.
|Patch Set 4: Verified+1

ptal.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1:

(9 comments)
|Patch Set 1:

(4 comments)
|Patch Set 1:

I'll be OOO tomorrow and next week. 
Dan, may I leave the rest to you? Or maybe Richard is interested since he recently touched some of the special tasks rpc.
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(9 comments)
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(5 comments)
|Patch Set 5: Code-Review+1
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: -Code-Review
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Patch Set 2: Verified-1

some import error
|Patch Set 2:

(6 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

@prathmesh, ptal.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4:

(3 comments)
|Uploaded patch set 7.
|Patch Set 6:

(4 comments)
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Thanks for review.
Inherit approval.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

thanks for working on this :)
|Patch Set 3:

(2 comments)

yes, need to +1 cq again.
|Patch Set 4: Code-Review+2
|Patch Set 1:

(4 comments)

some nits
|Uploaded patch set 1.
|Patch Set 3: Verified-1

This cl might be breaking moblab test. Take it off CQ

https://uberchromegw.corp.google.com/i/chromeos/builders/stumpy_moblab%20paladin/builds/4657
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1

thanks!
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

also need to mark commit-queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

The new servo inventory test can replace sheriff_servo I think
|Patch Set 4:

looking
|Patch Set 4:

(2 comments)
|Patch Set 4: Code-Review+2

just nits
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

fixed nits. inheriting lgtm
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

gentle ping before we hit the next rpc storm...
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Re using gmail in golo: Yes, I think that's possible.  Need to install the google api packages and credentials like I did for GCE. Prathmesh, do you know how packages/credentials are manged in golo bots?
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(13 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(8 comments)
|Uploaded patch set 6.
|Patch Set 4:

(1 comment)
|Patch Set 6:

Thanks Mike for review.

Waiting for my three pre-cq trybots to finish.

- golo slave can send email smtp
    https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/mixed-c-pre-cq/builds/7936

- gce slave can send email via gmail
    https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/mixed-c-pre-cq/builds/7937

- gce slave without google api installed should not fail
    https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/mixed-c-pre-cq/builds/7938

will +1 verified/CQ after I confirm these cases.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 1:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2: Code-Review+1

lgtm. if no one +2 by EOD, i'll do it.
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Patch Set 2:

I am re-testing my new image on wolf-paladin. will +1 verified/CQ once it finishes
|Uploaded patch set 3.
|Patch Set 3:

prathmesh, I added the dpkt package requested by Thieu
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1

remove dpkt change. tested on mixed-c-pre-cq
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

added a unittest, inherit lgtm.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

has merge conflict.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

rebased. re-ran unittests.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1

oh, thought this one has landed.. rebased and rerun tests.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

this change should not cause vm faiure
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(16 comments)
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(6 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Verified+1
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Added a None check so that unittest can pass. Inherit approval.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

(1 comment)
|Patch Set 3:

(3 comments)

I am still going through this cl. will finish by eod
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+1

(2 comments)
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

I am changing it from WARN to INFO. I'd like to pipe the log to a file in cron job and it would be handy to see info-level message so that I know the script actually runs.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1:

(5 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 3:

(2 comments)
|Patch Set 4:

(3 comments)

looks good. a corner case to handle and a nit.
|Patch Set 5: Code-Review+2
|Patch Set 4:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 3:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

scheduler sorts existing suites from highest-priority-earliest-created to lowest-priority-latest-created. It then tries to feed each suite with a number of duts defined as &#124;suite_min_duts&#124;.

In a case where we have 6 duts in pool:bvt, and assume the suites were created in the following sequence.

10:00:01 created paygen_au_beta (suite_min_duts=4)
10:00:02 created bvt-inline(suite_min_duts=6)
10:00:03 created paygen_au_stable (suite_min_duts=4)
10:00:04 created bvt-cq (suite_min_duts=6)

At the beginning, paygen_au_beta will get 4 duts, and bvt-inline will get 2 and the rest will get 0. 

Assume paygen_au_beta finishes first, bvt-inline will grab all 6 duts.
Once bvt-inline finishes, paygen_au_stable got 4 and bvt-cq got 2.
Assume paygen_au_stable finishes next, bvt-cq will grap all 6 duts.

I chose number &quot;4&quot; for paygen as it usually has 4 or more tests. The number matters when taking PFQ into account, if there are only canary paygen and pfq suites left running, we want paygen be able to at least get 4 duts.

This is a relatively easy approach we chose to prevent suite starving. Details can be found at http://goto/support-dut-sharing-design-doc
|Patch Set 1:

I don't see that's a problem.

In the freon case, paygen will take all the 4 duts first. The other competing suites will still be scheduled and run with the left 1 dut and will take all 5 until paygen releases the 4.

Note that suite_min_duts and minimum_duts are two different settings. minimum_duts=4 we have today says there must be 4 working dut in the pool. The duts taken by paygen will still counted as &quot;working&quot;.

I prefer not use suite_min_duts=1 for paygen as when paygen is competing with pfq, assume we have 12 duts in the pool, pfq would take 11 and paygen would only take 1 and be starved.
|Patch Set 1:

When sharing duts between pfq/canaries, i feel the old setting minimum_duts doesn't quite make sense any more. All duts in the pool is busy doesn't necessary mean there is a pool health problem. Maybe the pool health bug should be filed in a different way, say, 30% of pool:bvt is dead.
|Uploaded patch set 2.
|Patch Set 2:

talked with richard offline, 2 might be a reasonable number to not slow down canary too much. (Note this doesn't guarantee that paygen won't take more than 2, but just reduce the chances)
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

fixed commit message.
and gentle ping, still need a +2.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2:

(1 comment)
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1

Will apply this on shard.
And only bump up the db version on master.

Tested
models.JobKeyval.objects.filter(job_id=63)[1].job
still works if job 63 exists.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3:

chumped. I've manually bumped the version to 99 on cautotest-mysql db.
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1:

Please rebase, it seems conflict with the tree.  Let's get this in soon
|Patch Set 1:

I'll +2 by EOD if no one has more comments here.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

I run the pool balance script this morning for link.
It can't see some Ready duts in pool:suites (which only in pool:suites).  I have to manually move 2 duts to pool:bvt. Will this cl fix that problem?
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified-1

hold on this cl. we may need to revive pool:bvt.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

hey Richard, this one is ready for review now.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 2: Code-Review+2

(1 comment)

I think we need come up with a deployment plan before submitting this cl.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)

Fixed a bug where deserializing with an existing id will override the old record.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

fixed a unittest.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: Id430e6d563345d39f55d2335da3ee5f2918da205
|Patch Set 3: Code-Review+1

other than dshi comments, lgtm
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 6:

(1 comment)
|Patch Set 9: Code-Review+1
|Patch Set 9:

django part lgtm
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Patch Set 3:

makes sense to first test on pfq and canaries. I have a new patch to do that.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Reverted

This patchset was reverted in change: Iad5e850c92f812318928d967473e8ac73e7c87da
|Patch Set 2:

(3 comments)
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2

(1 comment)

lgtm with a nit
|Patch Set 3:

(2 comments)
|Patch Set 3: Code-Review+2

lgtm. I think it is good to go after nits are fixed.
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1

not sure whether scheduler can understand '&gt;=tot'. let's make it &quot;==tot&quot; to be safe.
|Patch Set 1: Verified-1
|Patch Set 2: Code-Review+2

thanks!
|Patch Set 2: Commit-Queue+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Verified+1
|Patch Set 2:

gentle ping on this one, needed for rolling out dut sharing. got a +1, need a +2 ;)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

gentle ping on this one :) I'd like to get this out before rolling out dut sharing between canary and cq.
|Patch Set 1: Commit-Queue+1

thanks dan!
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 3:

(3 comments)

I am not done with reviewing yet. I think this CL worth more eyes since it touches many autotest pieces. I am tagging Dan for cc.
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+1

(4 comments)

Great work. Mostly looks good with some nit.
I'll give Dan some time in case he has any comment
|Patch Set 4: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

thanks!
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+1

(1 comment)

leaving +2 to dan
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

fixed a unittest. inherit approval
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Thanks,

Added a comment and an arg to be more clear.
Inherit approval.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(7 comments)
|Patch Set 3: Verified+1
|Patch Set 3: Verified-1

need to fix some unittests.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1

Thanks, I am gonna get this submitted as crouton test flow which uses &quot;atest create job&quot; is broken on their mario. I think this would fix their problem.
|Patch Set 1: Code-Review+2
|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)

Hi,

Please do not review it, it is not ready yet. Sorry for the spam. 

Fang
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)

Hi Nirnimesh, Dennis and Scott,

This is the cl about regression detection.
To add regression detection for a perf test, we will need to call the functions in expectation_checker.py at the end of that test. Expectations are specified in perf_expectations.py. I also added a page &quot;https://sites.google.com/a/chromium.org/dev/perf-regression-detection&quot; to describe the tool. It is a draft and the content is subject to change.

An example output is like:
INFO    : Test results:
---------------------------------------------------------------
desktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests [  FAILED  ]
desktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   FAIL: Pyauto perf tests regression detected: [('FPS_ScrollTextPage', 0.85300157731071025)]
desktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   FPS_ScrollTextPage                                44.128118
desktopui_PyAutoPerfTests/desktopui_PyAutoPerfTests   iterations                                        1
---------------------------------------------------------------

Would you please take a look and see whether the solution makes sense to you?

Thanks,

Fang
|Patch Set 2: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (21 inline comments)


|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Hi Scott and Nirnimesh,

I've addressed most of your comments and I still have two of them not handled.

Scott, I tried to copy client/common_lib/cros/common.py to client/common_lib/perf_expectations/ and import common in expectation_checker.py. I though this one should work for me but it didn't. I still get import error when I import site_utils

Nirnimesh, I didn't quite get what you mean by
&quot;Everything below this line should be done in the helper function.&quot; at Patch Set 4, Line 134. 

Do you mean something like below:

def run_once():
    ....
    checker = ...
    result = checker.compare_multiple_traces(perf_dict)
    self.process_perf_comparison_result(result)

# helper function
def process_perf_comparison_result(result):
   if result['regress']:
      raise error.TestFail(...)
   if result['improve']:
      raise error.TestWarn(...)

Please take a look. Thank you!
Fang
|Uploaded patch set 8.
|Patch Set 7: (3 inline comments)

Hi Nirnimesh and Scott,

I've addressed your comments. I figured out the ImportError with site_utils with Dennis help. Please let me know if you have more comments. Thanks,

Fang
|Patch Set 8: Verified; Ready


|Uploaded patch set 9.
|Patch Set 9: Verified; Looks good to me, approved; Ready

Inheriting LGTM from previous reviews.
|Patch Set 2: (1 inline comment)


|Patch Set 1:

Hi Richard,

I made the code log the exception. I am wondering how I can trigger the method _install_repair that contains my change?
It looks like an update-engine is involved.

Fang
|Uploaded patch set 2.
|Patch Set 2:

Hi Richard,

I tested my code and change the commit message as recommended.
Please take another look.

Thanks,
Fang
|Patch Set 2: Ready; Verified


|Patch Set 1:

Hi Richard,

I set the minimum space required by the encrypted stateful partition to 0.1GB. 

I test it with a normal case, i.e. enough space in /mnt/stateful_partition/encrypted and a case where I manually created a huge file that took up almost the entire partition to trigger the error. 

Successful host verification logs:
http://localhost/results/hosts/172.22.75.138/28-verify/debug/autoserv.ERROR

Failing host verification logs:
http://localhost/results/hosts/172.22.75.138/26-verify/debug/autoserv.ERROR

Please take a look and let me know any concerns/issues.

Thanks,
Fang
|Patch Set 1:

Hi Richard,
I set the minimum space required by the encrypted stateful partition to 0.1GB.

I test it with a normal case, i.e. enough space in /mnt/stateful_partition/encrypted and a case where I manually created a huge file that took up almost the entire partition to trigger the error.

Successful host verification logs: http://localhost/results/hosts/172.22.75.138/28-verify/debug/autoserv.ERROR

Failing host verification logs: http://localhost/results/hosts/172.22.75.138/26-verify/debug/autoserv.ERROR

Please take a look and let me know any concerns/issues.
Thanks,
Fang
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Hi Richard,

Your comments are addressed. And I also did a repo sync which brings in many changes from others.

Please take another look. Thanks,
Fang
|Patch Set 3: Ready


|Patch Set 3: Verified


|Patch Set 3: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Hi,

I found that in autotest_rpc_errors.py, there are several types of rpc errors.  I think three of them(PROXY_CANNOT_SEND_REQUEST, PROXY_CONNECTION_LOST, PROXY_TIMED_OUT) indicate a broken rpc bridge. Please let me know if you think other error types should also be included.

I modify HWTestStage to handle the three exit codes as warning. I tested it using a trybot where I forced RunHWTestSuite to throw an RunCommandError with an exit code 11 and observed it was handled as warning by build bot(See patch 3 for my experiment.)

Please take a look and let me know any thoughts.

Thanks,
Fang
|Uploaded patch set 5.
|Patch Set 5:

Hi Richard,

Bug= line is fixed.
I haven't figure out how to improve the comment. It does look redundant to repeat the returncodes. Do you have any suggestion?

And also, I realized the program may be confused by the code &quot;2&quot;, as it could mean run_suite.py exits with a warning or autotest_rpc_client.py exits with error &quot;CLIENT_HTTP_CODE&quot; encoded in autotest_rpc_errors.py.

Thanks,
Fang
|Uploaded patch set 6.
|Patch Set 6:

Hi David,

Thanks for your comments. I addressed them. Please take another look.

Thanks,
Fang
|Patch Set 6: Ready; Verified


|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: (1 inline comment)

Hi, 

I did some modifications to cbuildbot_stages.py and cros_build_lib.py to have the HWTestStage check lab status first before it attempts to call run_suite.py over rpc. The lab-down failures are handled as warnings. Please do a code review and let me know any feedback.

Thank you!
Fang
|Uploaded patch set 7.
|Patch Set 7:

Hi David,

Thanks for your feedback. I refactored the code and modify the new tests to use mock. Please take another look.

Thanks,
Fang
|Patch Set 6: (6 inline comments)


|Patch Set 7:

Hi Scott,

Does this patch look good to you? 

Fang
|Patch Set 7: Ready; Verified


|Uploaded patch set 8.
|Patch Set 8: Looks good to me, approved; Ready; Verified

Merge conflicts in cbuildbot_stages.py and cbuildbot_stages_unittest.py and inherit LGTM from Patch 7.
|Patch Set 8:

Resubmit to commit queue.
Merge conflicts in cbuildbot_stages.py and cbuildbot_stages_unittest.py and inherit LGTM from Patch 7.
|Patch Set 8: Ready

Resubmit to commit queue.
Merge conflicts in cbuildbot_stages.py and cbuildbot_stages_unittest.py and inherit LGTM from Patch 7.
|Uploaded patch set 3.
|Patch Set 3:

Hi Alex,

I added some logging statements to record the time queries take. Is this something experimental or we want the changes to go into the tree?

Thanks,
Fang
|Patch Set 3:

Alex and Scott, Would you please take a look and see whether I am measuring the right things?

Just had a discussion with Scott, we thought maybe we could output the stats as logs for now and let it run with the real server to see what we get before porting the results to graphite. How do you think Alex?

Fang
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)

Hi Alex,

I am picking up this CL again about chromium:196392. Would you please take a look at the new patch and let me know how you think?

Thanks,
Fang
|Uploaded patch set 5.
|Patch Set 5:

Hi Alex,

I've updated this CL to use the with statement in tick().
Please take a look.

Thanks

Fang
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 5: (2 inline comments)


|Uploaded patch set 9.
|Patch Set 9: Verified

Hi Alex,

I modified monitor_db:tick to use Timer.get_client. This CL will go after the other CL about fixing &quot;get_client&quot;.

Please take a look.
Thanks,

Fang
|Patch Set 9: Ready


|Patch Set 2: Looks good to me, but someone else must approve

Thanks for fixing this.
|Patch Set 1: (2 inline comments)

Hi Alex,

I'd like you to do a review of my changes. 

Thanks, 
Fang
|Patch Set 1: (4 inline comments)


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2:

Hi,

I've upload a new patch to use parallel module. Would you please take a look?

Another cl is published to update the upstart script in chromeos-admin. See
https://gerrit-int.chromium.org/#/c/35380/

Thanks,
Fang
|Patch Set 2:

Hi Alex,

Do you think it is in a good shape for submitting to the commit queue? 

Would you please also take a look at https://gerrit-int.chromium.org/#/c/35380/

Besides, how can I make sure these two CLs will be picked up at the same time?
Fang
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3:

Hi Alex,

Thanks for the feedback. I addressed your comments. Please take another look.

Fang
|Patch Set 2: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)

Thanks. I added it.
|Patch Set 4: Ready; Verified

Inherit LGTM from last patch.
|Patch Set 4: Looks good to me, approved

I see. Thanks :)

Inheriting LGTM from patch 3.
|Patch Set 4: Ready

Re-submit to commit queue.
|Patch Set 1:

Hi Scott,

Would you please review this CL?

Thanks,
Fang
|Patch Set 1:

Alex and beeps, Thanks for the feedback. I'll grep over the codebase to ensure every caller will function correctly.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)

Hi Scott,

After discussing with beeps, Aviv and Alex offline, I switch to another solution. I think RetryingAFE is catching too generic exceptions. I feel it might make more sense if it only retrying on network issues. I checked urllib2. Two types errors can be raised during a rpc call, HTTPError and URLErrror. And HTTPError is a subclass of URLError. So I made RetryingAFE retry only on URLError.

How do you think?
Thanks,

Fang
|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Patch Set 3:

Ah, I just found out I was misunderstanding the conversation with Aviv, beeps and Alex last week. We can't catch a specific type of exception I think that was what they meant. I'll talk with them again to see whether we can come up with a better solution.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)

Hi Alex,

Would you take a look at this patch? 
Thanks,

Fang
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 5: Ready


|Patch Set 1: Looks good to me, approved

Nice, I'll change my cl accordingly to use it.
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Abandoned

duplicated cl
|Uploaded patch set 2.
|Patch Set 2:

Hi Alex,

I am not sure how often get_client will be used with stats.Timer. Do we want to fix it? But if we do, here is a fix in my mind. Please take a look.

Thanks,
Fang
|Patch Set 2:

Another thing I don't understand is why decorators don't have problems with get_client. I see statd.timer.Timer._decorate also uses get_client...Hmm, I am trying to understand that.
|Uploaded patch set 3.
|Patch Set 3:

Hi Alex,

This patch is ready for a review. Would you please take a look?

Thanks,
Fang
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)

Hi Alex,

I address your comments. I tested with them. Everything works fine except for stats.Raw. There is no exception raised but just I couldn't find the result in graphite.

I tried stats.Raw in a clean branch, I still couldn't find the results anywhere in graphite, no matter whether I use get_client or simply just run:

stats.Raw('....').send('...', 100)

Is there anything special and interesting about stats.Raw I should know?

Thanks,
Fang
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 1:

Hi Alex,

I am trying to run monitor_db_unittest.py. The script raises an error and looks like it can be fixed by updating DatabaseWrapper of SQLite. Can I submit the fix?

Thanks,
Fang
|Patch Set 1:

Thanks Alex
|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2:

Hi Scott and Richard,

How about a change like this?

Fang
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 8: (2 inline comments)


|Patch Set 1: Looks good to me, approved

I am also curious about the answer to Dan's question.
|Uploaded patch set 2.
|Patch Set 2: (7 inline comments)

Hi Simran and Scott,

I added the POE support to our RPM server. Would you please take a look at this CL and let me know any feedback?

Thank you!
Fang
|Uploaded patch set 3.
|Patch Set 2: (22 inline comments)


|Patch Set 3: (2 inline comments)

Hi Simran,

Thanks for your feedback. I addressed them and please take another look.

Fang
|Patch Set 3: (1 inline comment)

Hi Simran,

I have some inline comments about the mapping file.
|Uploaded patch set 4.
|Patch Set 4:

Hi Simran,

I uploaded a new patch to bring back the hard-coded interfaces. Would you please take a look at the new patch?
Thanks,

Fang
|Uploaded patch set 5.
|Patch Set 3: (1 inline comment)


|Patch Set 4: (12 inline comments)

Hi Simran,

I addressed your comments and uploaded a new patch. Please take a look.

Thanks,
Fang
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 5: (13 inline comments)

@Simran, I addressed your comments. I also have a small fix in _verify_state in rpm_controller.py.

@Scott, I think this CL is almost done. Please let me know if you have more comments.

I am waiting for John to fix chromeos2-poe-switch6, so that I can populate the csv file for it.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 7: (10 inline comments)

Hi Scott,

I addressed your comments. Please take another look.

Fang
|Patch Set 9: (1 inline comment)


|Uploaded patch set 10.
|Patch Set 9: (1 inline comment)


|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

Hi Simran,

Hope you will feel better soon.

I addressed your comments, please take a look when you come back.

Fang
|Patch Set 12: Ready; Verified

Thanks Simran :)
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: (1 inline comment)


|Patch Set 2: (7 inline comments)

Mostly formatting nits.
|Patch Set 3: (7 inline comments)


|Patch Set 5: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6:

(2 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Abandoned

This CL is abandoned as we decide to implement the health check at client side (i.e. in autotest)
|Patch Set 1:

Ah, forgot to update the import in my last cl. Thanks for fixing it.
|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

I am adding num=3 as I saw FalcoBVT in suite_scheduler limits  num to 3. Please let me know if this is not what we want.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 1: Verified

oh, my bad, forget to click verified..
|Patch Set 1: Ready


|Uploaded patch set 2.
|Patch Set 2:

Hi Simran,

I make it to figure out the full path as config.py does. Please take another look.

Fang
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (7 inline comments)


|Patch Set 3: (4 inline comments)

Thanks for your comments beeps and Richard. Patch 3 was submitted accidentally when I was in the middle of addressing all comments. Sorry about that . Please take a look at Patch 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4: (2 inline comments)


|Patch Set 6: Looks good to me, approved; Ready; Verified

Address two typos and inherit LGTM from patch 4.
|Uploaded patch set 2.
|Patch Set 1: (11 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 3: Ready; Verified


|Patch Set 3: Looks good to me, approved

(1 inline comment)


|Patch Set 4: Looks good to me, approved

(2 inline comments)

LGTM. just two nits.
|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: (3 inline comments)

Hi alex and beeps,

Would you please take a look at the new patch? lab sherrif is now cc'd on the failure in suite_scheduler.

Fang
|Patch Set 2: (2 inline comments)


|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Hi, I am testing this patch on cbf server. I'll let you know when it is ready.
|Patch Set 5: (2 inline comments)


|Patch Set 7:

Hi,

This patch is tested and ready for a review. Bugs will be filed against Lab sheriff.

Please take a look.

Fang
|Uploaded patch set 8.
|Patch Set 7: (1 inline comment)

Yes, I should have split this CL into smaller ones. I didn't realize it as it is becoming huge..Will do in the future.

beeps, would you please take another look at this cl?
|Uploaded patch set 9.
|Patch Set 8: (4 inline comments)


|Patch Set 8: (1 inline comment)


|Uploaded patch set 10.
|Patch Set 10: Looks good to me, approved; Ready; Verified

Thank you both for reviewing this CL.
|Patch Set 10: Ready

Resubmit to CQ.
|Uploaded patch set 11.
|Patch Set 11: Looks good to me, approved; Ready; Verified

Add DEPLOY=suite_scheduler to commit message.

Inheriting LGTM from last patch.
Resubmit to CQ
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (3 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 2: (2 inline comments)

Add an inline comment mentioning what we've discussed offline. I am ok with the current change though.
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (4 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (2 inline comments)


|Patch Set 2: Code-Review+1
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (4 inline comments)


|Uploaded patch set 6.
|Patch Set 4: (1 inline comment)


|Patch Set 6:

Sure, I'll hold it
|Patch Set 6:

Thanks for letting me know. I'll do a merge with your code
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Hi Aviv,

Making ssh_verbosity_flag to pass down to a host object would require multiple changes in autoserv and server_job. I think it would be better if I address it in a separate cl. In this cl, I just apply the easy fix -- add GLOBAL_SSH_COMMAND_OPTIONS to make_ssh_comment. I'll come up with a new cl to replace GLOBAL_SSH_COMMAND_OPTIONS with an arg of host class.

Please take a look. Thanks,
Fang
|Patch Set 8: Verified


|Patch Set 8: Looks good to me, approved; Ready

Fix --ssh_verbosity and inheriting LGTM from Patch Set 6
|Patch Set 6: (1 inline comment)


|Patch Set 8: Ready

Resubmit, the dependent cl was merged.
|Uploaded patch set 9.
|Patch Set 9: Looks good to me, approved; Ready; Verified

Merge conflicts with CL:66136, and inherit LGTM from patch6, Retry commit queue
|Patch Set 9: Ready


|Patch Set 9: Ready


|Patch Set 9: Ready

cq failed due to security_OpenSSLRegressions_SERVER_JOB failed. it should not be related this cl.
|Patch Set 1: (2 inline comments)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: (4 inline comments)


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (16 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: (1 inline comment)

please take another look at the new patch that addresses the comments and a small fix(see inline comment).
|Patch Set 6: Ready; Verified


|Patch Set 1: (1 inline comment)

Would you please
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2:

Here is a link to the upstream fix.
https://github.com/autotest/autotest/commit/1e7d50b61474192a9bf5789e90668f9aee87ac14
|Patch Set 2: Ready; Verified


|Patch Set 2: Ready


|Patch Set 2: Not Ready

Why cq doesn't pick up this cl that was marked as Ready 5 hours ago?
Try to reset the Ready field
|Patch Set 2: Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 1: (6 inline comments)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(8 comments)
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(4 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue -Verified

Why doesn't CQ pick up this change? Try to re-mark it as &quot;Ready, Verified&quot;
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Rebase over [autotest] Create generic bug filer function.
Inherit approval from patch 5
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1

Looks like Pre-CQ Launcher is back. Retry.
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

ah..it broke the unittest. fixed. Inherit LGTM from previous patch. retry CQ.
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1

There was a CQ problem. Retry.
|Patch Set 4: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve

(2 inline comments)

LGTM with two nits and a question. Is it possible and worth it that in the future we refactor the two types of rpc logic into two classes such as JsonRPCHost and XMLRPCHost, and mix them with SiteHost on demand? Just a thought.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(17 comments)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)

I did some refactoring to servo.py/servo_host.py. Every Servo object now includes a ServoHost object, so that 

1) the code that connects to a servod server won't be duplicated, 

2) scp can be done via self._servo_host.send_file in servo.py, 

3) remote ssh commands can be run via self._servo_host.run() in servo.py. (But it also introduces some complexity, please see inline comments)

Would you please take a look?

Thanks,
Fang
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 6:

(19 comments)
|Patch Set 8:

(1 comment)
|Patch Set 8:

(1 comment)

- I'm worried about not automatically using servo for lab machines and expecting all tests that use servo to specify they are. Whats the reasoning behind this change?

To improve the reliability of servo, we'd like to ensure that whenever a servo is required, we can guarantee that a *good* servo object is created for the test to use. To achieve this, servo needs to be verified/repaired before being handed to the test. However, we don't want to waste a long time (2min or more) verifying/repairing servo if a test doesn't need a servo. This is why we need a way for the test to specify whether it needs a servo or not. We currently check it by checking the value of servo_args, but we certainly needs a better solution here in the future.

-And have you guaranteed repair via servo still works?

In CrosHost.repair_full(), a servo object is verified/checked before everything else, regardless the value of `servo_args`. 

I manually forced CrosHost._create_servo_host to return a valid servo host and forced ServerHost.is_in_lab() to return True. Confirmed that repair via servo still worked.
|Uploaded patch set 9.
|Patch Set 8:

(5 comments)
|Patch Set 9:

Hi, Richard,

how do think the re-factoring? Any more comments?

Fang
|Uploaded patch set 10.
|Patch Set 9:

(10 comments)

Thanks for the feedback! I uploaded a new patch and have some inline comments. Please take another look.

Fang
|Uploaded patch set 11.
|Patch Set 9:

(2 comments)
|Uploaded patch set 12.
|Patch Set 11:

(4 comments)
|Uploaded patch set 13.
|Patch Set 12:

(2 comments)
|Patch Set 13: Verified+1
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15:

Ah....Sorry, I accidentally uploaded an old patch from a different branch where I cherry-picked this CL.

Patch 15 should be the right one to look at.
|Uploaded patch set 16.
|Patch Set 15:

(1 comment)

Here is a list of issues that I came across through the review. Put here as a note for future references.

1. simply the code in CrosHost _initialize which creates servo_host and servo objects.
crbug.com/298432

2. A better way to detect 'servo is required'

3. decouple servo_host and servo objects.
crbug.com/298379

4. servo_host is now dealing with both remote host and local host. I think we can improve it.

5. consider move the pattern repair_full to base classes.
crbug.com/297035
|Patch Set 16: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1

i am happy with let this patch in and keep lab working
|Patch Set 1:

Does other reviewer have more comments or shall I +2 to it? I'd like this one to land as I have a bug that depends on it.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Patch Set 5:

Ping, any comments?
not urgent, but I'd be happy if I can land it before next iteration or move to next round of review this week.
|Uploaded patch set 6.
|Patch Set 6: Verified+1

Just rebased. Please take a look.
|Patch Set 6: Commit-Queue+1

Thanks!
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1

ToT autotest is broken. All local jobs fail. This is a tiny change that shouldn't break anything. Skip CQ.
|Change has been successfully cherry-picked as 276c5cc2042251a76c1f209aa4e39c79014f2d56
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Rebase over ToT, retry CQ
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

This is a better fix. I re-upload it in crosreview.com/168492
Thanks!
|Patch Set 1: Verified+1
|Patch Set 1:

Thanks, good to know!
|Patch Set 1:

The previous cl is closed... it doesn't allow me..=(
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

(3 comments)
|Patch Set 4: Code-Review+2

(1 comment)
|Patch Set 2:

(6 comments)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(9 comments)
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks! Confirmed test_that_unittest.py passed.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting lgtm from patch 2.
|Patch Set 1:

(1 comment)

&quot;adb_host kind of feels like you're trying to merge two different types of adb hosts together, those that are attached to the local system and those that you can talk to remotely, and end up flipping between if it's networked or not a lot in your code.
I haven't stared long enough though to figure out if it'd look cleaner if you split it into a LocalADBHost and RemoteADBHost though.&quot;

I think it is the same problem that ServoHost has (proposed in crosreview.com/66891), which needs to flip between localhost and remote host depending on whether 'hostname' is 'localhost'. When I wrote ServoHost, I was thinking to split XXXHost into LocalXXXHost and RemoteXXXHost, but I realized if so, we would have to potentially do it for every type of host class that needs to deal with 'localhost'. This sounds like something we want to fix in base classes as it starts to become a common problem.
|Patch Set 1:

(2 comments)
|Patch Set 8:

(7 comments)
|Patch Set 9: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1:

This CL is related to crosreview.com/170944
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Patch Set 3:

@Aviv, I looked at test_that and run_remote_test,
it looks like they are not using the exit code of generate_test_report. This cl makes generate_test_report exit with code 0 if the only failed tests are experimental. But since the exit code is not used further, how do you expect to make use of it?
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)

Addressed Simran's comment. PTAL. Thanks!
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 6: Reverted

This patchset was reverted in change: Iaf08c533bc013174dfa4d98127d87f22d2480a66
|Patch Set 1:

This CL is related to CL/170575
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)

After discussed with @milleral offline, we came up with this new idea that removes our concern on emitting keyval in autoserv while still being able to drop a keyval for generate_test_report to consume.

Would you please take another look?
Thanks!

Fang
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed unit tests...Inheriting LGTM from last patch.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

One more fix to the unit test: utils.write_keyval needs to be mocked out too. :/

Inheriting approval.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

this time suite unit test..
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 3:

(3 comments)
|Patch Set 5: Code-Review+2
|Patch Set 6:

Do we know what the root cause of the problem?
Is it because we didn't pass the &#124;**args&#124; when we initialized SSHHost/ParamikoHost in the last patch?
|Patch Set 5:

(1 comment)
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting LGTM from patch 2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fix unittest...inheriting LGTM from last patch.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Abandoned

problem not caused by this cl. no need to revert
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 03590af9d2dfbae4c543e81614f99bb6097b5374
|Patch Set 1: Code-Review+1
|Patch Set 1:

Comments in Patch 2 have not been addressed/replied?
|Patch Set 1:

This cl has been pending for quite a while..ping Richard?
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Addressed Alex's offline comment of using heredoc.
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 2:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting LGTM from last patch.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

That's fine. I re-uploaded mine :)
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks for review!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

I randomly pick 2 builds:

gs://chromeos-image-archive/parrot32-release/R31-4539.0.0/test_suites.tar.bz2

gs://chromeos-image-archive/parrot32-release/R31-4628.0.0/test_suites.tar.bz2

I didn't see the suite. Not all R31 have the suite?
|Uploaded patch set 2.
|Patch Set 2:

I changed it to R31. I am curious, do we have to explicitly backport the change to R31 for R31 images to have it? Assuming we haven't done that, how does it happen some of R31 images have it and some do not?
|Patch Set 2: Commit-Queue+1 Verified+1

Ah, right, that explains.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

I assume the point of having a 'tmp' dir is for other code to dump temporary files into it.
If that is the case, a read-only tmp dir would potentially be problematic because there are code somewhere will try to write to it and will fail.

I might need to understand what the server/tmp is used for in the first place.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Server test will create a temporary folder like XXXXX_TESTNAME under server/tmp when being initialized, implemented in client/common_lib/test.py. So theoretically all server tests are using it. In reality, not all server tests may need to create temporary files, but a temporary directory should be there in case there is a need.

So, we need to find a writable temporary directory for server tests. The candidates we have are

1) /tmp 
    Did you mean test_that does not have privileged to /tmp? I run a server test with test_that, it seems to have no problem writing to it.
    Do you know in what cases system /tmp won't work?

2) server/tmp

* I run a server side test platform_BootPerfServer with test_that, it has no problem creating a tmp directory at /build/lumpy/usr/local/autotest/server/tmp.
  Do you know in what cases test_that won't have privilege to create server/tmp?

* If those cases where test_that doesn't have privileged to create server/tmp, all server-side tests would fail. Simply creating a dummy text file under an existing server/tmp will not solve the root problem here. We need to figure out a right place.
|Patch Set 3:

Ah, interesting, my test_that is able write to /build/lumpy/usr/local/autotest/server..

Anyway, how do you think about the latest patch, using /tmp for server job? If /tmp works, which seems to be a better place, I can worry about why test_that has sudo privilege later.
|Patch Set 3:

I guess, for some reason, test_that does get root privilege. Maybe that's why we haven't been seeing server-side tests fail. I'll look into it.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

My autotest location was outdated. After running ./build_package, i can see that the user has privilege to server/tmp. That explains why test_that has not been failing server tests.

Thanks Aviv!
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed unittest and ran ./utils/unittest_suite.py.

Inheriting approval.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

Checked the HWTest failure, should not be caused by this cl.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(2 comments)

Hi Richard,

I added comments to the places that were changed from the other broken cl. PTAL.

Thanks,

Fang
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

should not caused by this cl
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

network test failure not caused by this cl
|Patch Set 1: Code-Review+1

where do we use these scripts to show perf data?
|Patch Set 1:

(1 comment)
|Patch Set 1:

Since I've already been playing with Telemetry, I can verify cl.
|Patch Set 1:

Hi David,

I found some failures in the following test. It looks like not related to this test but due to some. But Would you please confirm?


dromaeo.domcoreattr,
http://anthill.mtv.corp.google.com/results/1120-fdeng/172.22.75.76/debug/autoserv.DEBUG

dromaeo.domcoremodify
http://anthill.mtv.corp.google.com/results/1121-fdeng/172.22.75.76/debug/autoserv.DEBUG

dromaeo.domcorequery
http://anthill.mtv.corp.google.com/results/1122-fdeng/172.22.75.76/debug/autoserv.DEBUG

dromaeo.domcoretraverse
http://anthill.mtv.corp.google.com/results/1123-fdeng/172.22.75.76/debug/autoserv.DEBUG

media.tough_media_cases
http://anthill.mtv.corp.google.com/results/1125-fdeng/172.22.75.76/debug/autoserv.DEBUG

octane
http://anthill.mtv.corp.google.com/results/1127-fdeng/172.22.75.76/debug/autoserv.DEBUG

sunspider
http://localhost/results/1130-fdeng/172.22.75.76/debug/autoserv.DEBUG
|Patch Set 1:

(My last comment text was sort of broken...hit the button before I finished typing)
I meant those failure seems not related to this CL. But Would you please confirm?
|Patch Set 1:

Yes, let me sent them to your email.
|Patch Set 2:

sorry for the late request, but would you please also update the 'tag' to the new names mentioned in crobug.com/306657?

If this CL is landed before you see my comment, that's also fine, I'll fix them in a new cl.
|Patch Set 2:

to correct, crosbug.com/306657
|Patch Set 2: Verified+1

I'll address the tag problem in a follow up cl. Let's get this patch landed first.

+1 Verified, I was able to verify this patch locally.
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

fixed the benchmark name and confirmed it runs locally.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

set_board failure was not caused by this cl
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+1

once in a while, i have some folders named something like results-2013XXXX

I guess they are created by me running autoserv mannually?

Ideally, I'd like .gitignore to ignore them. But since this is a special use case, I don't care too much.
|Patch Set 2: Code-Review+2
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Ya, I'll do a rebase against the other cl once that one gets in.

There are code in the perf data uploading script depending on the 'tag' to generate the correct dashboard test name.

The old uploading script will soon be replaced by a new uploading mechanism. I think the tag can be safely removed by then.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Rebased. PTAL
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

au test failure not caused by this cl
|Patch Set 5:

(8 comments)
|Patch Set 6:

I published some comments on one file, but haven't done with other files yet. For you questions in the control file, I'll let you know once I got the right answer.
|Patch Set 6:

(8 comments)
|Patch Set 6:

(2 comments)

Hi Luis, I've talked with the lab team . And there are several things that we are generally concerned with

1. This code seems assuming it is run with test_that within chroot. We need to make it work in the lab environment if we are going to commit this cl.
2. This code only works with lumpy, which we need to fix
3. the code uses sudo. Anyone can run this code once committed, which poses risk to our lab servers.
|Patch Set 7:

(4 comments)
|Patch Set 7:

(1 comment)
|Patch Set 8:

(2 comments)

I don't have more comments except a nit. Just need to have it tested.

Btw, some comments in telemetry_runner.py in the last patch from simran seem have not been addressed yet
|Patch Set 12: Code-Review+1

LGTM. I'll defer +2 to simran in case he has comments.
Thanks for testing out the whole path.
|Uploaded patch set 1.
|Patch Set 1:

there is perf_value_iteration, representing a group of perf values that belong to the same iteration.

what do you mean by a tko model for perf keyval?
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

got verbal approval about the database change from @milleral.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1:

I haven't entirely figure out whether the retry should be implemented in dynamic suites or scheduler. But it is definitely good to have the option.

Alex, for retrying an individual failing test, why would retry care about the overall suite job's result?
|Patch Set 5:

(1 comment)
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 4: Code-Review+1
|Patch Set 6:

(5 comments)
|Patch Set 6:

(1 comment)
|Patch Set 7:

(1 comment)

LGTM except for the timestamp question. Maybe @Richard or someone else can comment?
|Uploaded patch set 1.
|Patch Set 1:

I still need to do a rebase over crosreview.com/176575.
|Uploaded patch set 2.
|Patch Set 2:

gently ping.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Rebased over cros/master. Inheriting approval.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed unittest. Inheriting approval.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

set_board problem is not caused by this cl
|Patch Set 1: Code-Review+1

(2 comments)
|Uploaded patch set 1.
|Patch Set 1:

I think we need to backport the change in server-side control file to R31 if we also want to see R31's perf data on the dashboard. Are we interested in seeing R31's perf data?
|Abandoned
|Patch Set 1:

(2 comments)

what do you mean by test_that cant find the resultsï¼Ÿ I thougt test_that only cares the exit code of generate_test_report.pyï¼Ÿ
|Patch Set 1:

yesï¼Œthe outputted file perf_measurements is in json file. Could you use that file for further processing? or you have to have the perf keyvals be shown via generate_test_reportï¼Ÿ
|Patch Set 1:

That makes sense. The work around looks fine to me.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(7 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

network test failure not caused by this cl
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

grep mod_for_test_scripts\/ssh_keys . -r

./archive_hwqual:  cp &quot;${script_dir}/mod_for_test_scripts/ssh_keys/testing_rsa&quot; \
./bin/cros_image_to_target.py:    self.identity = env.CrosUtilsPath('mod_for_test_scripts/ssh_keys/'


There are two other files refers to ssh_keys, do we want to leave ssh_keys there or move it to somewhere if it doesn't make sense to have ssh_keys inside the directory mod_for_test_scripts any more?
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 6:

A naming convention to distinguish these keys from others would make it easier for us to fix crbug.com/323219

  * kernel_to_chrome_main
  * kernel_to_signin_start
  * kernel_to_signin_wait
  * kernel_to_signin_users
  * kernel_to_signin_seen
|Patch Set 6: Code-Review+1

LGTM, leave +2 to Richard in case he has more comments.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 65386a16a852d41565e4e85c991eb78f7378796f
|Patch Set 2: Code-Review+2

This cl is still draft status?
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Thanks!

Inheriting approval.
|Patch Set 2: Code-Review+2

(2 comments)
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue Verified

Ya, the machine list simplifies things a lot. longer discussion = better fix :D
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1

(1 comment)

perf dashboard part looks good to me.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

John, thanks for updating this file. once submitted, we'll need to sync the change on the rpm server.
|Patch Set 1: Code-Review+1

Looks good to me from the autotest's point of view.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 3: Code-Review+2

+2 w/ two nits, no need for another round of review.
Feel free to inherit approval once you fix them.
|Patch Set 6:

(1 comment)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

I am waiting for https://chromium-review.googlesource.com/#/c/182548/ to be merged to do a rebase against it. Other than that, this is ready for review.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Rebased, inheriting approval.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

the cl should not cause unittests to time out.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

HWTest failure was not caused by this cl.
|Uploaded patch set 1.
|Patch Set 1:

If this cl was submitted, future data for ToT builds will start to show up under the category of ChromeOSVideo instead of ChromiumPerf.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1

(5 comments)

Overall looks good to me. I need more time to understand every detail. But that's probably will happen after Feb.9 when I come back, so don't block on me :)
|Patch Set 6:

(3 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+1
|Patch Set 1: Code-Review+2

Yes, we need to push the changes to our prod server. I'll request it tomorrow once the cl is landed.

And also, please contact chrome-speed-team@google.com with the test names (dashboard test name) and master name if you haven't done it yet.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

The warning is fine. Would you please update the &quot;TEST=&quot; field in the commit message?
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3:

Hi Luis,

I have a new comment in patch 2. Would you please take a look?

Fang
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3:

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 6:

(2 comments)
|Patch Set 6:

(3 comments)
|Patch Set 10:

(2 comments)
|Patch Set 10:

(2 comments)
|Patch Set 10:

(1 comment)
|Patch Set 11: Code-Review+2

+2 assuming Richard's comments have all been addressed.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

Just wanted to confirm that Media and Media4k results go to the same graph and that is desired.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Update commit message(TEST field). Inheriting approval.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(6 comments)
|Patch Set 5: Verified+1
|Patch Set 5:

any more comments on this one?
I'd like to land it together with the dynamic suite change(CL:190585)
|Patch Set 5:

thanks, I'll wait till tomorrow in case beeps would like to take another look.
|Uploaded patch set 6.
|Patch Set 5:

(3 comments)
|Patch Set 6: Verified+1

Hi beeps, ptal.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Added a related_name for invalidates_test. Inheriting approval.
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

fixed a unittest. verified by trybot http://chromegw/p/tryserver.chromiumos/builders/lumpy-release/builds/2052.
|Patch Set 1:

sorry I am busy with sheriff stuff today. I'll start reviewing CLs in this series tomorrow.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1

(2 comments)
|Patch Set 4: Code-Review+1

Add a CQ-DEPEND of cl 188453?
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(3 comments)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Added DEPLOY=stats_poller.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

this is a new file in site_utils, it should not fail cq
|Patch Set 3:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2

looks Richard's comments have been addressed.
so +2.
|Patch Set 1: Code-Review+2

Looks good to me! please address aviv's comment.

Thanks for adding this.

Fang
|Patch Set 2:

(3 comments)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2

+2, but feel free to wait for others' feedback
|Patch Set 4: Code-Review+1
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(7 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(5 comments)
|Patch Set 5: Verified+1
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 5:

(6 comments)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 6:

(12 comments)
|Patch Set 7:

(1 comment)
|Patch Set 7: Verified-1

there is a bug, fixing it.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 8:

Hi beeps,

PTAL. Let me know if I misunderstood your comment.
There was a bug in the last patch where when test warns, it won't retry and won't file a bug either. The new patch fixes it. A unittest is added to cover the case.

Fang
|Patch Set 8: Verified+1
|Patch Set 8:

gently ping ...
|Uploaded patch set 9.
|Patch Set 8:

(8 comments)

Hi beeps, please take an another look. thanks!
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 9: -Commit-Queue -Verified
|Uploaded patch set 10.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Update some outdated description in commit message.
Inherit approval.
|Patch Set 3: Code-Review+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4:

Hi beeps, could you take an other look please? I added a new test.
|Patch Set 4: Commit-Queue+1 Verified+1

Thanks!
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Fix a small issue in test_that. test_that uses a fake function as &quot;record&quot;. The fake function need to allow a second arg.

The change is minimal. I believe it won't cause any problem. I am inheriting approval.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

auto update failure should not be caused by this cl.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

failure not caused by this cl.
|Patch Set 1: Code-Review+1

(3 comments)

lgtm w/ several nits
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1

(2 comments)

lgtm w/ two nits
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1:

Hi keybuk,

The json file looks good to me. In order to make your test upload to the dashboard, you would also need to modify your tests to call the api &quot;output_perf_value(...)&quot; (the user guide has some how-to instructions).

Could you include the changes to your tests together in this CL?

Fang
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

good from my side. dummy_Pass works locally on a lumpy with iteration 2. +2, but feel free to wait for @wiley to confirm his use case.
|Patch Set 1: Code-Review+2
|Patch Set 4:

(2 comments)
|Patch Set 5: Code-Review+1
|Patch Set 5:

good from my side, i saw alex has a question above so I am leaving +2 to him.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(6 comments)
|Patch Set 3: Verified+1
|Patch Set 3:

beeps gives some refactoring/testing suggestions. i'll be working on it and will submit a new patch.
|Patch Set 4:

beeps... seems that you clicked CQ +1 for me... guess it was an accident.

I haven't got a chance to fix your comments and upload my unittests yet. But since this one has already landed and I have another small following up cl also about run_suite.py. Are you ok with me addressing your comments/adding unittests in the other cl that is coming soon? 

Alex also suggested test this script using -m over passed 1000 jobs and make sure the output match. I've not done 1000, but have done about 5 jobs that cover success/warning/error output. I think it should be fine. I can do more before next push.
|Patch Set 4:

Did a sanity check by running run_suite -m JOB_ID for 400 old jobs. Compared exit code outputted by old and new scripts. Confirmed the output match.
|Patch Set 3:

(2 comments)
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 5:

(2 comments)
|Patch Set 6: Code-Review+2

You could land it now. The other one has already been pushed to prod this afternoon.
|Patch Set 1:

hello, should be ok to land this cl now
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as a58be5312df9ba2b177332c9ca93f7170f8a5e1c
|Patch Set 4: Reverted

This patchset was reverted in change: I42410fa2e5923dfa5e83c0812f8a38b8981b2ff7
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 4d6c98c1ec269a2e7bc5aaa7c7b477d1d9d18b7e
|Patch Set 2: Reverted

This patchset was reverted in change: I47916708e7b49bbc2064370262e3f9e231f08efe
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

HWTest timing out should not be caused by this cl
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Build package failure was not caused by this cl
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

HWTest failure not caused by this cl
|Uploaded patch set 1.
|Patch Set 1: Verified+1

zeuthen@ for cc, dshi@ for review
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 3:

yes, it's on my list. will do it today/tmr
|Patch Set 3:

(10 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

moved run_suite changes to another cl 199173. will first land this one and later 199173 if everything with the db goes well.

inheriting approval.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

vm tests failure not caused by this cl
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Verified+1
|Patch Set 4:

oh, 1 min earlier beeps said he'd like to take a look today. so I will hold by EOD in case he is still interested in taking a look.
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1

This one was separated out from cl:198284, which already got approval. will land this one after the db changes in cl:198284 are deployed.
|Patch Set 1: Code-Review+2 Commit-Queue+1

inheriting approval from cl:198284
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Abandoned
|Patch Set 1:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 6:

Could you rebase over CL:199383? just easier to read the difference.
|Patch Set 6:

never mind..i was looking at a wrong patch.
|Patch Set 6:

(3 comments)
|Patch Set 7: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

Had a discussion with @davidjames earlier. To alleviate cq flakiness, we were planning to add &quot;JOB_RETRIES&quot; to all bvt tests.

Given that retry is expensive, I was thinking only turn it on for cq and canaries for now by adding --retry=True in cbuildbot.

We could do the other way by adding '--retry=False' to all other builders except canaries and cq. Which one is more preferable?
|Patch Set 3: Commit-Queue+1

i am keeping retry default to False for now since we are going to add JOB_RETRIES to all bvt tests and I'd like to avoid unnecessary retry caused by that. We could change the default later if our requirement changes.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

rebased. inheriting approval
|Uploaded patch set 3.
|Patch Set 10:

(1 comment)
|Patch Set 11: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue
|Patch Set 2:

sorry, my bad, the DEPEND cl should land and be pushed to lab servers before this cl can go in. Marked as not ready
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

david for cc, beeps for review.
|Patch Set 2:

if you haven't reviewed this cl yet, please hold on. I'd like to fold the fix for this one with the fix for crbug.com/375818, since they are pretty related.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)

Ready for review.
|Patch Set 3:

(1 comment)
|Patch Set 3:

I am taking beeps's advise on re-factoring manipulation on a single view into a separate class, showing retry counts, and some other changes. I am almost done. Will get a new patch after fulling testing it.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

The new patch mostly does
1) figure out retry count
2) some refactoring to encapsulate operations on a single view to a new class TestView.
|Patch Set 3:

(8 comments)
|Patch Set 5:

gentle ping.. this cl is blocking us on turning on retry for canaries and other builders. It'd be nice we can get this out soon.
|Uploaded patch set 6.
|Patch Set 5:

(7 comments)

Hi beeps, I addressed the comments and did a rebase, ptal.
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1

checked with john, chaos lab is in chromeos3 and not behind hydra, so we should be fine here. ideally, we would make the mapping configurable rather than hard-coded. this patch is just a quick fix as people are asking for it.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Verified+1
|Patch Set 4:

may i get a +2 if this patch look good? :)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

move a constant outside the class. inheriting approval
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

build package failure was not caused by this cl
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

changed the default value of job_retry to be consistent with upstream callers and updated unittest. inheriting approval
|Patch Set 2:

(7 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

Hi Richard,

Does the overall idea look good to you?

Fang
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Change has been successfully cherry-picked as 150bd85b0c6ee021357bfa20a163083fb72c8d20
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

Plan on turning on retry for canaries once CL:200520 landed.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

rebased. inheriting approval.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

build package error not caused by this cl
|Patch Set 3:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

sorry i totally missed the last update.
|Patch Set 1: Code-Review+2
|Patch Set 9:

(2 comments)
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

LGTM, thanks for fixing the bug
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(3 comments)
|Patch Set 1:

The field JOB_RETRIES give a test the ability to opt in/out of retry explicitly which might be useful in some situations. In a case where infrastructure wants to retry but the test doesn't allow retry, the test still won't get retried.
|Patch Set 1:

The line between infrastructure failure and test failure is sometimes blurred and hard to tell. So currently we just treat them in the same way. If we could find a better way to distinguish those two, it would be nice to automatically retry for infra failure, and for real test failure only retry when the test requests it.
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

(1 comment)
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

oops, this cl did not land...
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1

Yeah, currently we have job retries added to all bvt tests.
|Patch Set 1: Commit-Queue+1

thanks!
|Patch Set 3:

(2 comments)

sorry i totally miss this cl. just two nits.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 15:

(1 comment)
|Patch Set 15:

(1 comment)
|Patch Set 15:

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

i see.. it is sad we have to use retry to get away from a real bug. but seems the bug won't be fixed any soon.
|Patch Set 2:

Because the perf data is collected by hardware_StorageFio, so that the perf_measurement file will be in the result folder of hardware_StorageFio. And as a result, data will be upload under name &quot;hardware_StorageFio&quot;

See

http://cautotest-cq/results/896476-chromeos-test/chromeos2-row5-rack9-host7/hardware_StorageFio/results/

You probably don't want to upload perf results under name &quot;hardware_StorageFio&quot;. To do that, you will need to copy the perf_measurement from result folder of hardware_StorageFio to hardware_RamFio in hardware_RamFio.py. It is a bit hacky, but i think that will work.
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

finished_on is recorded in scheduler_models.HostQueueEntry._on_complete(self, status), which is called by HostQueueEntry.set_status

When HQE is aborted, _on_complete will be called because ABORT is one of models.HostQueueEntry.COMPLETE_STATUSES.

Tested by manually aborting jobs from frontend.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Verified+1
|Patch Set 4:

I didn't find any.
The hqe final status is set in postjob_task. We currently don't have any unittests for postjob_task. I checked moinitor_db_unittests. All the tests there don't reach a point where hqe completes.

I can add a unittest for scheduler_models.HostQueueEntry.set_status
As long as all code that changes hqe status go through scheduler_models.HostQueueEntry.set_status, we will get them covered.

How do you think?
|Uploaded patch set 5.
|Patch Set 5: Verified+1

i think it wouldn't harm to add a unittest that checks set_status will result in finished_on being set properly, so i just added one.
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)

Addressed comments on unittest. Also cover the cases of non-complete hqe statuses. ptal.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

fixed a unittest.
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 5: Code-Review+1

sorry about the late response, i was ooo last week. perf uploading part looks good to me.
|Patch Set 5:

Hi Rohit, what does &quot;client side test&quot; in your comment refer to?
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 9: Code-Review+1
|Patch Set 4:

(4 comments)
|Patch Set 5:

(1 comment)
|Patch Set 8:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 9: Code-Review+1

perf uploading part looks good to me.
|Patch Set 10: Code-Review+1

(2 comments)

a nit, it is fine if this cl has already made through cq.
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 4:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1

I understand we probably need to do the same modification for many telemetry tests.

But I am not sure a test_that option would be the best way to go. I think a test_that option should be a generic thing that are applicable to all types of tests, not just for one type of tests.

Let's create an issue and discuss possible solutions there if you are planing to bake it to test_that.
|Patch Set 1: Code-Review+2
|Patch Set 2:

(6 comments)
|Patch Set 2:

(1 comment)
|Patch Set 9: Code-Review+2

(1 comment)

LGTM
|Patch Set 4:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 5:

(1 comment)
|Patch Set 5:

haven't finished reading the latest patch. will make another pass soon
|Patch Set 5:

(7 comments)
|Patch Set 13: Code-Review+2

(1 comment)
|Patch Set 14:

I am actually curious when I was granted for +2 privilege explicitly..I didn't remember that happened.
|Patch Set 2: Code-Review+1

+1 as far as autotest is concerned.
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 8:

(6 comments)
|Patch Set 9: Code-Review+1

LGTM, defer +2 to beeps since he had some comments earlier.
|Patch Set 10: Code-Review+1
|Patch Set 10: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

(1 comment)
|Patch Set 1:

I am also confused why they (upstream autotest) decided to put it as the most sever status.

The order was used for overriding (as said in the comment). More sever one would override the less sever one.
So the only possibility I could think of is that they wanted TEST_NA to override all other statuses, which I don't know why.

We can change it, but more testing is probably good in case wired thing happens. tko parser might be impacted.
|Patch Set 5:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 1:

this is server side change. i think we don't need to back port to old branches.
|Patch Set 1:

yes, that's right. the change should already be effective
|Patch Set 48: Reverted

This patchset was reverted in change: I81fd554a910c8c5b7537b34ec13301fcf15be3fd
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 5:

(2 comments)
|Patch Set 5: Code-Review+1
|Patch Set 7: Code-Review+1

(1 comment)
|Patch Set 7:

LGTM, defer +2 to beeps since he has some comments earlier in patch 5
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Commit-Queue+1

thanks for catching the error.
|Patch Set 4: Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1

dynamic_suite.suite_unittest failure should not caused by this cl.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3:

oh, i totally missed simran's comment about the deletion of the tests. will address it. Thanks!
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

moved the deletion of the tests to this cl.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(10 comments)
|Uploaded patch set 5.
|Patch Set 4:

(4 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

dynamic_suite.suite_unittest failure should not caused by this cl.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

testCommitNewLKGM failure was not caused by this test.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

not sure if other reviewers will have more comments. but here is +2.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 21:

(12 comments)
|Patch Set 21:

(2 comments)
|Patch Set 25:

(3 comments)
|Patch Set 29:

(2 comments)
|Patch Set 30:

(3 comments)

looks good to me. just some nits
|Patch Set 30:

(2 comments)
|Patch Set 32: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(4 comments)

please take another look
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 5:

(3 comments)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Uploaded patch set 9.
|Patch Set 7:

(1 comment)
|Patch Set 9: Verified+1
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 9:

(2 comments)
|Uploaded patch set 12.
|Patch Set 12: Commit-Queue+1 Verified+1
|Patch Set 12:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

fixed unittest. inheriting approval
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1

this cl should not cause hwtest failure
|Patch Set 2: Reverted

This patchset was reverted in change: Ic1dc736e934ef90ec8001883e8a15c195be388bd
|Patch Set 2: Reverted

This patchset was reverted in change: I9036cca4d24daba4dbbe89569976cc8effb19732
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

leave +2 to Jay in case he has any comments.
|Patch Set 12:

(2 comments)
|Patch Set 12:

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 14: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 13: Code-Review+2
|Patch Set 14:

(1 comment)
|Patch Set 15: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2

lgtm, please confirm with dan about the timeout question.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

hold for new changes in oyster bay 2.0
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1

The layout is effective now. land the change. inherit approval.
|Patch Set 3: Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

from gs team's reply, it seems they aren't going to fix anything. so time to let this cl in?
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1

just saw dshi has a comment
|Patch Set 2:

(7 comments)
|Patch Set 4: Code-Review+1

Instrumenting the devserver in platform code can probably happen in another cl if we want to have it. Let's get this one in?
|Patch Set 5: Code-Review+2

(3 comments)

some nits.
|Patch Set 1: Code-Review+2
|Patch Set 1:

;) given that it has been broken for so long and seems no serious bad things happen, I am wondering who/what code is using this script?
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

yes, with host attributes, every host will be mapped to one rpm, which we will figure out beforehand, no need for searching.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

oh, forgot to publish it. thanks for noticing it Dan.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

(1 comment)

I see the reason for
|Patch Set 2:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 5:

thanks for working on it.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Added a todo with a bug id. inherit approval. will chump the change to make cq work.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

thanks for fixing it.
|Patch Set 2:

the cl was previously reviewed and approved at https://chromium-review.googlesource.com/#/c/217980

This cl has a fix. no need for a full review, so I just +2 to it.
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 4:

(5 comments)
|Patch Set 4:

(3 comments)
|Patch Set 6:

(1 comment)

cc mkryu since he is changing the repair flow.
|Patch Set 4:

(1 comment)
|Patch Set 6:

(2 comments)
|Patch Set 7: Code-Review+2
|Patch Set 7:

(1 comment)
|Patch Set 4:

(2 comments)

@dshi, could you help take a look at the apache part?
|Patch Set 4:

(1 comment)
|Patch Set 4:

(8 comments)
|Patch Set 5:

(4 comments)

Hi Moises, the rpc part looks good to me, just some nits. once you confirmed the apache config, it'll be ready to go!
|Patch Set 7:

+1 to Nick's comments
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2

thanks!
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 9:

(3 comments)
|Patch Set 10: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

fixed a nit, inherit LGTM.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2:

(5 comments)
|Patch Set 7:

(9 comments)
|Patch Set 9: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)

The board label is auto-detected. so the chance that a dut got a wrong label is very low. pool is a bit different, it is possible we have available duts but haven't been added to a pool (i see it once for a new board due to an accident, not very often though).
|Patch Set 3: Commit-Queue+1 Verified+1

np :)
|Patch Set 2:

(4 comments)

i am not done yet. will continue after lunch.
|Patch Set 2:

(12 comments)
|Patch Set 2:

(2 comments)
|Patch Set 4:

(1 comment)

not done yet. i figured the cl is quite large. The code related to adding a new rpc method can be put in a separate cl  .
|Patch Set 8:

(9 comments)
|Patch Set 9:

(1 comment)

Looks good to me
|Patch Set 9:

(1 comment)
|Patch Set 9: Code-Review+1

This cl is ready for other reviewer to take a look.
|Patch Set 10: Code-Review+1
|Patch Set 11:

(1 comment)
|Patch Set 13:

(6 comments)

looks good. might add couple of more logging for debug process. see inline comments.
|Patch Set 14: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

the cl was originally reviewed at https://chromium-review.googlesource.com/#/c/213901/

this one has a fix for django import.
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)

lgtm, will +2 once the comment in the commit message is addressed.
|Patch Set 1:

(2 comments)
|Patch Set 4: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 4: Code-Review+2

looks beeps' comments have all been addressed.
so +2
|Patch Set 4: Code-Review+2
|Patch Set 4:

btw the title of this cl is too long ;) Not have to fix it if it is already in cq.
|Patch Set 1:

I believe everything in frontend/perf-dashboard can be deprecated.
|Patch Set 2:

could you remove frontend/perf-dashboard as well?
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

let me explain. infra flakiness is one thing we hope retry would help. The JOB_RETRIES =1 will tell our infra to run the test on a different machine, thus it can help reduce noises caused by a bad machine, network flakiness, etc.
|Patch Set 1:

And in this specific failure, it looks like a network flake, where the dut dropped offline during the test. This is exactly the case retry would help by running the test again on a different machine.
|Patch Set 1:

autoserv doesn't have enough knowledge to distinguish a flakiness in network from a real bug (like a kernel bug that caused the network to go down). Retrying the test would give us more confidence whether this is a flake or a real bug. This is especially important to CQ, as a failure will reject all cls in a CQ. We wanted to reduce the chances that CQ being falsely rejected due to flakiness like network.
|Patch Set 1:

We do have suite-level control of retry. The configuration in control file is aimed at giving people the right to opt-out retry if they really want, and also the option to control how many times they would like to retry.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1

Yeah, I should have put a clearer message. Message udpated. Thanks!
|Patch Set 2:

could someone give a +2 :)
|Patch Set 4:

(3 comments)
|Patch Set 6:

(4 comments)
|Patch Set 7: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 6: Code-Review+1

(2 comments)
|Patch Set 7: Code-Review+1

looks good to me.
will +2 by EOD in case beeps has more comments.
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(1 comment)
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Fixed a nit and inherit approval
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2
|Patch Set 3:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2

(3 comments)

LGTM, just some nits
|Patch Set 2:

(2 comments)
|Patch Set 5:

(3 comments)
|Patch Set 7: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

DEBUG ONLY, DO NOT REVIEW
|Patch Set 1:

Are /build/daisy and /build/daisy.gcc4-9 pointing to the same place on your machine?
|Uploaded patch set 2.
|Patch Set 2:

can you try patch 2 and see whether that fixed your problem?
|Patch Set 2:

good, this patch is ready for review
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

yeah, i think the problem will be fixed by the mentioned cl. it would not hurt to have the change though, so leave it to richard to decide.
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

the dependent is out-dated, need a rebase?
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 6: Code-Review+2

i get what the cl is trying to do, but i have no idea whether it will break. So make sure we test it by running a bunch of suites (more than 1) on the testing server before push.
|Patch Set 6: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(3 comments)
|Uploaded patch set 4.
|Patch Set 3:

(7 comments)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

take it out of cq. i wanted to add time recorded to the metadata.
|Patch Set 4: Commit-Queue+1

oh, time recorded is by default added, nvm
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

rebased over 225236
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(7 comments)
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Verified+1
|Patch Set 5: Code-Review+2
|Patch Set 5: -Code-Review Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

forgot to upload host_states.py.  inherit approval.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

the merge request has been approved in crbug.com/426668. so +2
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 7: Reverted

This patchset was reverted in change: Ie115b90a2a74a8daca28ecfe1e164b38320f74aa
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)

leave +2 to richard since he has made the original change.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(10 comments)
|Patch Set 3:

(5 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

other than the couple of nits, I think this cl is in good shape. The individual reporting of Queued/Running/Parsing ..can be done in another cl. You can add other reviewers if you want.
|Patch Set 4:

(4 comments)
|Patch Set 5: Code-Review+2
|Patch Set 5:

cq +1?
|Patch Set 3:

I've upgraded to trusty yesterday and i just sent out some notes about apache.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3:

The other cl that this one depends on: https://chromium-review.googlesource.com/#/c/228780/
needs a change on a db table (alter table) which requires quite a long time to locking the table. I am waiting for time where the lab is not very busy to do that, so that I don't have to close the lab for the operation.

I'll +2 to this one as soon as the table alteration finishes.
|Patch Set 3:

Hi Ilja Friedel

I did an experiment on my local machine to alter the table to make higher_is_better allow null (ALTER TABLE tko_iteration_perf_value
MODIFY higher_is_better BOOLEAN DEFAULT NULL;).  It took 17 hours and locked the table. So to do it in prod db, we need to close the lab for it.

There is an planned lab outage on Saturday, 6 December 2014 (we planned to close the lab on Fri evening), I can take that chance to update the db. How do you think?   

Fang
|Patch Set 3:

cool, i'll do it then.
|Patch Set 3: Code-Review+2

I got a workaround the db alteration problem (https://chromium-review.googlesource.com/#/c/234250/). This one is ok to land now.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 3:

sync down was tested ;)

sync down: migrate.py sync 97
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Verified+1

thanks for catching this! tried migrate.py sync 96, and confirmed the db was synced down.
|Patch Set 4: Commit-Queue+1
|Patch Set 5: Reverted

This patchset was reverted in change: If3ed332ffc82e1e0c5a565fa26910a5139fa14cf
|Uploaded patch set 3.
|Patch Set 3:

DO NOT REVIEW.
|Abandoned

abandon the draft cl
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I added the three storm duts to pool:suites
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2:

needs a rebase over https://chromium-review.googlesource.com/#/c/229699
|Patch Set 5:

(5 comments)
|Patch Set 6: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 4:

(1 comment)

just one nit.

re quinten, yes, i think http://crbug.com/342552 won't happen again as it will stop sending data with -rcN to dashborad.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

i am gonna chump this and do a push.
|Patch Set 2:

actually no need for push for this change as it is a client test.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

We already have upload hook executed when we do 
  repo upload .
in autotest

Is this change purely to make cros lint work?
where is &quot;cros lint&quot; usually used?
|Patch Set 1:

My understanding is that autotest uses &quot;utils/run_pylint.py&quot; 
instead of &quot;cros lint&quot;. run_pylint.py understands the common package and stuff. It uses pylintrc in utils/. You can manually call utils/run_pylint.py FILE_TO_LINT

So not using &quot;cros lint&quot; seems intentional?
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2

how is this enforced -- &quot;These tests run only on boards with the relevant USE flag set (wifi_bootstrapping)&quot;?
|Patch Set 3:

(2 comments)
|Patch Set 3: Code-Review+2

are you planning to do 

'test': test_path + '/' + hardware_id,

in the future? i agree with Quinten, if there are too many different hardware_ids, it might become a problem. And I am not sure whether all people wants to separate them into different graphs, one per unique hardware_ids. It should be configurable imo.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(16 comments)
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Stats:
- added some stats in query_manager.py
- the other rdb cl is mostly counting requests. I think the existing timer
   for batch_acquire_hosts is sufficient to catch performance regression.

Bad cases:
- Updated docstring of host_scheduler.py to mention some bad cases.
- One thing that i was concerned is two suites can exchange duts which triggers unnecessary provisioning. I am thinking make rdb read host' label and prefer allocating a host to a job with the same label. I need to check the performance of doing so. Any thoughts here are welcome

DB inconsistency:
- The cl maintains everything in memory and doesn't change db,
   so i expect we will not see db corruption. A restart should bring everything to a good state. 

Job stuck in queued:
- To notice important job get stuck in queued, I think we can monitor the average queued time, e.g for bvt-cq on paladin (enabled by https://chrome-internal-review.googlesource.com/#/c/186387/)
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(11 comments)
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5.
|Patch Set 2:

(3 comments)
|Patch Set 5: Verified+1
|Patch Set 5:

looks like the max_count cl is in. i am gonna try out the puppy lab.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1

I did stress-tested in puppy lab.  3 suites (300 jobs) can work ok on a local 8G-memory vm (i turned off shard vm). 20 suites(2000 jobs) are mostly ok sometimes can hang. Seems mostly due to the disk bottleneck.

ok, I am gonna submit this cl. let's see how it is gonna behave in prod.
I'll keep an eye on host-scheduler tick.
|Patch Set 2:

(4 comments)
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+2

(1 comment)
|Patch Set 5:

(4 comments)
|Patch Set 5:

(4 comments)
|Patch Set 5:

(1 comment)
|Patch Set 7:

(2 comments)
|Patch Set 5:

(2 comments)
|Patch Set 5:

(2 comments)
|Patch Set 9: Code-Review+2
|Patch Set 3:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(7 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4:

(2 comments)
|Patch Set 6: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 4: Code-Review+2

just curious, why did we choose to use shard_id as a signal for deciding whether a job needs to be uploaded in the first place?  I felt a bool bit like &quot;uploaded&quot; in the db seems more strait forward and less error prone - client uploads jobs with &quot;uploaded=0, complete=1&quot; and then set &quot;uploaded =1&quot;.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(5 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)

thanks, will submit when the other two cls in this series are ready.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(6 comments)
|Patch Set 3: Code-Review+1
|Patch Set 3:

does anyone else want to look at this one? will +2 by eod
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Verified+1 Trybot-Ready+1

rebased and removed the associated unittest. ran the unittest. inherit approval.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified-1

Hmm, looks like freon boards still fail.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 3:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3:

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

found a way to workaround the problem.
Since no one really cares about the bit in autotest db,
I am gonna hold back the db alteration.

Even if someone does care about it, this cl didn't change the old behavior, previously, if higher_is_better was not set  by the test, it would default to True anyway (see crosreview.com/228374), now the &quot;default&quot; is chosen at the db level rather than the code level.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5:

this cl probably needs a rebase over https://chromium-review.googlesource.com/#/c/236943/
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Patch Set 1: -Trybot-Ready
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(2 comments)
|Patch Set 2:

Makes sense to me to put it in bvt-inline given that we are sharding suites between similar boards. will upload a new patch.
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

rebased. inherit approval
|Uploaded patch set 1.
|Patch Set 1:

will need to create a new pool:critical for wolf before this cl lands.
|Patch Set 1: Verified-1

will remove the bvt-provision suite.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Patch Set 2:

Hi David, could you take a look at this one?
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1

Hi david, 

I moved the majority code into two functions. Ptal 

Thanks,
Fang
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2

provisioning retry is handled by autotest scheduler. it is currently set to retry once. (i am actually debating on whether we should remove retry as provisioning is expensive, but i'll see how often it flakes.)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

updated a comment.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

merge request filed at: crbug.com/444109
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

merge request at: crbug.com/444109
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

will chump it.
|Uploaded patch set 1.
|Patch Set 1:

Prathmesh Prabhu I am adding you to review since you are the auther of https://chromium-review.googlesource.com/#/c/229076/6
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 1:

(3 comments)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

fixed and ran a unittest.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: Reverted

This patchset was reverted in change: Ieb4c00fd7e00b516cd23c685d8fa8ac13a72d1fa
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5: Verified+1 Trybot-Ready+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

revert this one, performance suite has been backported.
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

In provisioning, machine_install will remove cros-version and job_repo_url first always. It seems unnecessary to do that in test_push.

And the removing the cros-version won't force provisioning to start from scratch, because machine install checks lsb-release to determine whether to go with try_stateful_update or a full-reimaging, regardless cros-version.

With that said, I don't feel double provisioning can help identify the bug:444036...

But I am not opposed to adding to test_push to identify other bugs.
|Patch Set 1:

oh, looks like you got it covered in the commit message. great.

the ebuild i have it here
https://chromium-review.googlesource.com/#/c/235032/
not sure why it complains
|Patch Set 1:

I see, that's a good point.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thanks!
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Patch Set 4: Verified+1
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Verified+1

this patch is ready for review
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

fixed nits. inherit approval.

thanks!
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

thanks.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

thanks, let's follow the failure on the bug.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

fix nits. inheriting approval
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1

thanks
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

rebased. inherit approval
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

Don has some comment that seem to make sense. Maybe return the server objects as a json dict? leave +2 to don.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

need to wait for CL:238421 to be pushed.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Code-Review
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: -Verified
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

thanks dan.
|Patch Set 1:

(6 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue -Verified
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 3:

(6 comments)
|Patch Set 4: Verified+1 Trybot-Ready+1

i think i've done sufficient tests,  but please take a closer look at these queries...I hope I am not changing the result of the original queries.
|Uploaded patch set 5.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 4:

(2 comments)
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Patch Set 1:

(4 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

good to go after the minor cleanup
|Uploaded patch set 1.
|Patch Set 1: Verified-1

How can I test this one
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2: Verified-1
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Verified+1

(3 comments)

This patch is verified and ready for review. PTAL
|Patch Set 4:

(1 comment)
|Patch Set 4:

gentle ping on this one
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2 Commit-Queue+2 Verified+1

fixed a nit. inherit approval.
|Patch Set 5: -Code-Review -Commit-Queue
|Patch Set 4:

(1 comment)
|Patch Set 5: Commit-Queue+1
|Patch Set 2:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(6 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 1:

(4 comments)
|Patch Set 3: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

I'll do a manual update together with the db cleanup.
the update will take 2 hours.
|Patch Set 1: Commit-Queue+2 Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 4: Reverted

This patchset was reverted in change: I66044890e6adefbcc6d1052e33444f88aa2795a7
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4: Reverted

This patchset was reverted in change: Ibfa3601e558739ee9ef225b5c67351e36e790889
|Abandoned
|Patch Set 1: Code-Review+1
|Patch Set 3:

(4 comments)
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(4 comments)

just some stylish nits
|Patch Set 2: Verified-1

this cl might break the cq. taking it off cq
|Patch Set 2: Commit-Queue+1 -Verified

the other one is doubt. 
https://chromium-review.googlesource.com/#/c/283648/3/cbuildbot/config_dump.json

resubmit this one
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

I'd prefer keep the clarity and do better dedupe. The bug is very actionable, the deputy should go fix the config or go poke the owner of the suite. With this cl, there will be only one bug created per bad suite.

We've had issues where people have typos in the suite name, 
or people wrote bad control file that couldn't be parsed, or people expect the suite to run in tot-1 but didn't backport.

we've got enough questions from people asking &quot;why suite doesn't show up on wmatrix&quot;, silent the bug means deputy need to look for one more place, which not all deputy knows how to.
|Patch Set 1: Commit-Queue+1

Let's try this. If we still got a lot of spams, I'll work on a better solution.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+2

chromeos4-row9-rack5-host9 seems bad, not caused by this cl
|Patch Set 3: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Verified+1

Can you rebase and regenerate config_dump?

The CQ is failing

chromite-0.0.1-r1992:   File &quot;/mnt/host/source/chromite/lib/timeout_util.py&quot;, line 151, in TimeoutWrapper
chromite-0.0.1-r1992:     func(*args, **kwargs)
chromite-0.0.1-r1992:   File &quot;/mnt/host/source/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 47, in testDump
chromite-0.0.1-r1992:     new_dump == old_dump, 'config_dump.json does not match the '
chromite-0.0.1-r1992: AssertionError: config_dump.json does not match the configs defined in chromeos_config.py. Run bin/cbuildbot_view_config &gt; cbuildbot/config_dump.json
chromite-0.0.1-r1992:
|Patch Set 2: Verified-1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 4:

(1 comment)
|Patch Set 6:

(12 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 11:

(4 comments)
|Patch Set 12:

(1 comment)
|Patch Set 12:

(1 comment)
|Patch Set 13:

(3 comments)
|Patch Set 13:

(2 comments)
|Patch Set 14: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2

(2 comments)

one nit
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Will land monday after branching.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1

just two nits, feel free to inherit approval from dan.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

I'll hold untill setuptools is fixed, otherwise installation will fail.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2:

(4 comments)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 4: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1

lgtm except for the comment from mkryu.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1:

(3 comments)
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

thanks Dan.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

re paul, setup_dev_autotest.sh will call utils/build_externals.py which will install django and chromite to site-packages under autotest root.
You probably has setup autotest using this script so you already have the dependency. Most people don't have a local autotest so it fails for them.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

inherit approval.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3:

(4 comments)
|Patch Set 3:

(3 comments)
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

(12 comments)
|Uploaded patch set 6.
|Patch Set 4:

(9 comments)
|Patch Set 6: Verified-1

there is a bug in killing process.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Patch Set 8:

(1 comment)
|Patch Set 8:

(2 comments)
|Uploaded patch set 9.
|Patch Set 9: Verified+1

as recommended, removed the licence since it is implementation of APIs.
addressed some comments. PTAL.
|Uploaded patch set 10.
|Patch Set 10:

(4 comments)
|Patch Set 10: Verified+1
|Patch Set 10: Commit-Queue+1
|Patch Set 10:

thanks!
|Patch Set 10:

Hi Dan, what is the bug?
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: I155750de1d05b6e3f2625a4ae210622f748975f7
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1:

(3 comments)
|Patch Set 1:

it this one still causing problem? is there a bug?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

(1 comment)

inheriting approval.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Patch Set 6: Trybot-Ready+1
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

(1 comment)
|Patch Set 10:

A passing trybot run
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/206

An infra failure trybot run
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/paladin/builds/225
|Patch Set 10:

@aviv and @gabe, would you have some time this week to take a look at this CL?
|Uploaded patch set 11.
|Patch Set 10:

(13 comments)
|Patch Set 10:

(1 comment)
|Patch Set 11:

(6 comments)
|Uploaded patch set 12.
|Patch Set 12:

Running &quot;bin/cbuildbot -g &quot;*227126 293323&quot; --remote --hwtest link-release&quot;

will mark verified after this one passes.
|Patch Set 12: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(1 comment)

lgtm, just a question
|Patch Set 1:

sounds good! thanks Filipe.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 2:

(3 comments)
|Patch Set 5: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 5: Verified-1

looks like this cl is breaking cl
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

inherit approval.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)

thanks for the clarification. Leaving +2 to Richard.
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 3:

I learnt from wiley that CQ-DEPEND is not needed.
I haven't been uploading CLs in a stack before. sorry about the confusion.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4:

(2 comments)
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2

thanks for the fixes.
|Patch Set 6: Code-Review-1

looks like this cl might be breaking cl
|Patch Set 6: -Code-Review Verified-1

I meant to say verified -1
|Patch Set 6: -Verified
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: -Verified

will moved to another stage, do not review yet
|Uploaded patch set 3.
|Patch Set 3: Verified+1

ready for review.

verified in tryjob, forced it to abort a dummy suite.
cbuildbot -g '296190 296028' --remote --hwtest link-paladin

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/paladin/builds/296/steps/BuildReexecutionFinished/logs/stdio
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 3:

(1 comment)

one nit
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: -Code-Review
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2

thanks for the refactoring ;D
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

I plan to run this script every 10 mins as a cron job.
In case the autotest server restarts, or for some reason bots died, we will be re-launch bots automatically.
|Uploaded patch set 3.
|Patch Set 2:

(9 comments)
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 3:

(5 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 5:

(1 comment)
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

passed trybot
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/393
|Patch Set 3: Commit-Queue+1 Verified+1

merge-approved
|Patch Set 3:

merge-approved at crbug.com/528564
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

passed trybot:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/393
|Patch Set 1: Commit-Queue+1 Verified+1

merge-approved crbug.com/528564
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

this is contrib which shouldn't break anything.
hold for one more day in case lab folks have more comment.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+1

lgtm other than dshi's comment.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Thanks, inheriting approval.
|Patch Set 7:

(17 comments)
|Patch Set 11:

(3 comments)

cc davidjames since we are working on similar things for android.
|Patch Set 12: Code-Review+2
|Patch Set 12:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Patch Set 4:

Thanks for the refactoring Charlene.
|Patch Set 2: Code-Review+1

leaving +2 to richard.
|Patch Set 1:

(1 comment)
|Patch Set 3:

lgtm, will +2 after david's comments are addressed.
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+1

leave +2 to richard
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1

thanks for cleaning this up Charlene!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Merge approved in crbug.com/536133
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Reverted

This patchset was reverted in change: I03c3706c195167a53534cb8b1461d665156bb3e4
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 3:

vote for original_suite_name
|Patch Set 5:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

inherit approval
|Patch Set 2: Code-Review+2
|Patch Set 2:

Please get TPM to approve the changes before submitting.
see the instructions item 2,4
|Patch Set 1: Code-Review+2
|Patch Set 1:

Please get TPM to approve the changes before submitting.
see the instructions item 2,4
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+2 Verified+1

thanks!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+2 Verified+1

thanks!
|Patch Set 2:

(1 comment)
|Patch Set 4:

(5 comments)
|Patch Set 4:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 6:

(6 comments)
|Patch Set 6:

(1 comment)
|Patch Set 8: Code-Review+1

leave +2 to aviv.
|Patch Set 12: Verified-1

this is causing pre-cq to fail

https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/pre-cq/builds/11174/steps/HWTest%20%5Bbvt-inline%5D/logs/stdio
|Patch Set 12: -Verified

oh, i see. got an email alert, thought it was asking me to find the bad cl.
|Patch Set 12:

(1 comment)
|Patch Set 15: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+2 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Trybot-Ready+1

ptal
|Patch Set 3: Verified+1
|Patch Set 3:

(2 comments)
|Patch Set 3: Commit-Queue+2

thanks for review.

Trybot passed.
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/paladin/builds/488
|Patch Set 3: Commit-Queue+1
|Patch Set 3:

(1 comment)
|Patch Set 3: -Commit-Queue
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1

this should work
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)

ptal
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Verified-1

this cl maybe at fault, i'll manually test the failed board.

https://uberchromegw.corp.google.com/i/chromeos/builders/peach_pit%20paladin/builds/10610

11/09 17:00:32.400 DEBUG&#124;          ssh_host:0153&#124; Running (ssh) '/tmp/stateful_update http://100.107.160.2:8082/static/peach_pit-paladin/R48-7627.0.0-rc3 --stateful_change=clean 2&gt;&amp;1'
11/09 17:00:32.723 DEBUG&#124;        base_utils:0268&#124; [stdout] Downloading stateful payload from http://100.107.160.2:8082/static/peach_pit-paladin/R48-7627.0.0-rc3/stateful.tgz
11/09 17:00:35.741 DEBUG&#124;        base_utils:0268&#124; [stdout] 
11/09 17:00:35.741 DEBUG&#124;        base_utils:0268&#124; [stdout] gzip: stdin: unexpected end of file
11/09 17:00:35.741 DEBUG&#124;        base_utils:0268&#124; [stdout] tar: Child returned status 1
11/09 17:00:35.742 DEBUG&#124;        base_utils:0268&#124; [stdout] tar: Error is not recoverable: exiting now
11/09 17:00:35.742 DEBUG&#124;        base_utils:0268&#124; [stdout] Successfully downloaded update.
11/09 17:00:35.742 DEBUG&#124;        base_utils:0268&#124; [stdout] Missing var or dev_image in stateful payload.
11/09 17:00:35.747 ERROR&#124;           process:0274&#124; Process Process-2:
11/09 17:00:35.748 ERROR&#124;         traceback:0013&#124; Traceback (most recent call last):
11/09 17:00:35.749 ERROR&#124;         traceback:0013&#124;   File &quot;/usr/lib/python2.7/multiprocessing/process.py&quot;, line 258, in _bootstrap
11/09 17:00:35.750 ERROR&#124;         traceback:0013&#124;     self.run()
11/09 17:00:35.750 ERROR&#124;         traceback:0013&#124;   File &quot;/usr/lib/python2.7/multiprocessing/process.py&quot;, line 114, in run
11/09 17:00:35.751 ERROR&#124;         traceback:0013&#124;     self._target(*self._args, **self._kwargs)
11/09 17:00:35.752 ERROR&#124;         traceback:0013&#124;   File &quot;/usr/local/autotest/client/common_lib/cros/autoupdater.py&quot;, line 437, in update_stateful
11/09 17:00:35.753 ERROR&#124;         traceback:0013&#124;     raise update_error
11/09 17:00:35.754 ERROR&#124;         traceback:0013&#124; StatefulUpdateError: Failed to perform stateful update on chromeos4-row8-rack12-host3
|Patch Set 6:

Interesting, it sometimes passes

same board passes in earlier run
https://uberchromegw.corp.google.com/i/chromeos/builders/peach_pit%20paladin/builds/10609
|Patch Set 6: Commit-Queue+1 -Verified

makes sense. let me try again.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

added two lines of logging so that we can easily tell if we are running with the new change. inherit +2
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 7:

Aviv, this one does not participate in CQ HWTest. I am going to chump this and hope that will help with the provisioning failures.
|Patch Set 1: Code-Review+2
|Patch Set 4:

Bindu, why do you need to chump this CL?
Any changes in client/server path in autotest should go through CQ.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+1

(9 comments)

some nits.
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+1

are we going to add the decorator in this cl or in another one?
overall it looks good to me.
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

yes, that's a good idea
|Abandoned
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 7: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 5:

the check was a final guard to any bug that may be introduced
in machine_install. 

we've got a very mystery bug before where the cros-version label was not update. 

see crbug.com/444036
|Patch Set 5:

as of today machine_install is still depending on afe.
I definitely agree relying on afe as a workaround is a bad idea. But removing the check from provisioning is like removing part of the workaround without fixing it all, leaving the system in an unsafe condition where we might have to spend hours to triage such bug next time. Not sure if this is a good idea.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2

thanks for the info~
|Patch Set 1: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1

inherit +2
|Patch Set 7:

(1 comment)
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue
|Patch Set 3:

the dependent cls were pushed. this one can go now.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

inherit approval.
|Patch Set 3:

(1 comment)
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5:

fixed a unittest, inherit approval.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

nit fixed. thanks Dan!
|Patch Set 1: Code-Review+2

(2 comments)
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

ah. right, forgot to use -a when git commit
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3:

https://uberchromegw.corp.google.com/i/chromeos/builders/CQ%20master/builds/8702

could you take a look at this failure?
01:19:49: ERROR: Cannot find overlay: /b/cbuild/internal_master/src/overlays/overlay-setzer
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

okay, let's give it a try
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

:D
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Patch Set 1:

I am waiting for trybot to finish, the change should be at low risk ;) https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/1925
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 1:

(1 comment)

Inherit +2.

Tested with a couple of edge cases. I am finally satisfied with the change.

trybot for negative case 
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/2054/steps/HWTest%20%5Bbvt-inline%5D/logs/stdio

trybot for passing case
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/2055/steps/HWTest%20%5Bbvt-inline%5D/logs/stdio
|Patch Set 6: Code-Review+2 Commit-Queue+1
|Patch Set 6: -Code-Review -Commit-Queue
|Uploaded patch set 7.
|Patch Set 7: Verified+1 Trybot-Ready+1

i changed a bunch of stuff since patch 1. it is probably safe to get an another round of review. ptal
|Patch Set 7:

trybot passes:
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/2056/steps/HWTest%20%5Bbvt-inline%5D/logs/stdio

negative case was handled
https://uberchromegw.corp.google.com/i/chromiumos.tryserver/builders/release/builds/2057/steps/HWTest%20%5Bbvt-inline%5D/logs/stdio
|Uploaded patch set 8.
|Patch Set 7:

(2 comments)
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 8: Code-Review+2
|Patch Set 8:

inherit +2
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Trybot-Ready+1
|Patch Set 8: Commit-Queue+1

this code should not cause autotest unittest failure, unit test flakes?
|Patch Set 5:

(2 comments)
|Patch Set 6:

(4 comments)
|Patch Set 7: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 5:

(2 comments)

overall it looks good to me.
thanks for refactoring the afe stuff out to a util.
|Patch Set 6:

Is it safe to land all the files at the same time or do we need to break them into smaller cls for deployment purpose?
|Patch Set 6: Code-Review+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 1:

thanks for fixing this.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

approved in bug 569970
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+2 Verified+1

approved in bug 569970
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

dan@, does suite job use server-side packaging?
|Patch Set 3: Code-Review+2

we can wait this one to be pushed to prod. and then submit the chromeos-admin CL. we can force a puppet change. There might be a gap in-between push-to-prod and the puppet change, but that should not be too bad (a few suites might fail on filing bug).
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

(2 comments)

&lt;haven't finished yet&gt;
|Patch Set 2:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

inherit +2
|Patch Set 1: Code-Review+2
|Patch Set 5:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5:

(2 comments)
|Patch Set 5:

could you run this test via moblab
  ./platform_BootPerfServer/control.perfalerts
It will give us some confidence that the change would work for non-telemetry tests.
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

I decided to abandon
https://chrome-internal-review.googlesource.com/#/c/250896/
as according to the manual of debconf-set-selections, it is not recommended to call the following (seed it with an entry of mysql-server-5.6) on an existing server with mysql-server-5.5 installed.

echo 'mysql-server-5.6 mysql-server/root_password password autotest' &#124; sudo debconf-set-selections


I checked the default version of mysql-server is still 5.5 on trusty server. I am going to stick with 5.5 so that all of our servers are consistent.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

Yes, i think that's plan. For chromeos builders, we currently use trusty 14.04, I assume we will start with the same so that we know everything will work.

My understanding is that once we move to ccompute, they will set up a builder that build a &quot;golden&quot; gce image continuously from a base image. We should have the flexibility to decide the OS distro of that base image.
|Hmm the reason i want to suspend is because that is the purpose of the test, to test roaming after the device does a suspend resume. And am doing it in a thread because i wanted to deconfig the connected AP while device is in suspended state. 

Or may be i didnt understand your question right.
|Oh the thread is because i wanted to bring down the AP while teh device was sleeping and not after it did the resume. I thought the prior represents a more real case and the device after rsume would immediately fail trying to connect to first AP and fall back to the second one that is up. Also the suspend stress test doesnt use any thread.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The veryon* boards dont have wifi:&lt;module&gt; dependency. Only the preflight boards have it. So do u suggest that we add it and leave pool:wificell.

Also, in this case we should make sure we have only 1 device of this type. Else it'll run on all of them.
|Done
|Done
|Done
|Done
|Done
|Leaving it at this as per yesterday's discussion.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|For bcm and marvell, we decided to stick with pool wificell. wifi:&lt;module&gt; will be added to these.
|Done
|Done
|Same.
|Done
|Done
|Done
|hmm i think we decided that these, perf_bcm and perf_marvell should run on the actual devices, speedy, mighty, jerry as they are going to FSI.(Ref. patch 1 comments by you)
|Done
|Done
|Same.
|Done
|Done
|How long would this test take? Not sure if all of these should be run for wifi_release.
|Corrected this. It's weird that on speedy we see 4356 in chrome://system. They both use the same FW. I checked with Katie and she say's it's an error.
|Where can i get this string &quot;marvell_88w8897_2x2&quot; like in list_6 ?
|This will fail as it did in the past because we wont merge the suites into 41.
|Done
|Done
|Is the variant label yet to be added in cauto ?
|Done
|Not needed. As the parent method returns true by default.
|This is needed as westerndigi. supports visibility and inherits from ap_configurator
|This is a bug. Has to be implemented to set visibility. deepak is checking in this method.
|Is it that we can check either self.command_list or sorted_page_commands here ?
|This needs to be matched with the inner block. Sry my bad.
|No. This was fixed by https://chromium-review.googlesource.com/#/c/169950/
|We would log the same info for every ap in list. So can we log this once or dump the ap info we are scanning each time ?
|Can ap's be unlocked twice ?
|Can we also remove the temp directory in destroy_driver_connection ?
|Done
|Done
|wait_for_object_by_xpath() throws an exception when the element is not found. So we have to catch this exception and pass inorder to execute the loop. The other method just returns true or false. I can use the wait_for, if you still prefer that.
|Done
|Done
|Done
|Done
|Done
|Should be (disabled_item, popup) variable here too.
|xpath can be used directly.
|(wep_item, popup, wait_for_xpath=text_field)
|This can be removed coz it's called in the try block.
|Done
|Done
|Done
|Done
|Done
|Done
|This is a configurator problem and will be fixed with https://code.google.com/p/chromium/issues/detail?id=305887.
|Done
|There is actually a bug open for this https://code.google.com/p/chromium/issues/detail?id=305887.  Few AP's set WPA2 instead of WPA either because it doesn't support or because it was just coded that way. We plan to fix this. But will we have a control file for WPA2 if the AP doesn't support WPA ? this needs to be discussed.
|Done
|Do you mean the AP's with mixed security WPA/WPA2? or the dual band AP's that support both? For the dual band AP's we still would have 2 separate blocks(one for each ssid) with security WPA or WPA2.
|Done
|Done
|Done
|Done
|The change is there above, in set_using_ap_spec().
Yes , i will merge set_security_wpapsk &amp; set_security_wpa2_psk for now.
|Done
|Done
|Just added coz the other configurators have it and this one was missing.
|I think this should be wpa2 or wpa not mixed.
|Move ap.ssid below the quote.
|Done
|Done
|Done
|Done
|Done
|Yes but looking for the object again is magically making things work. If this is removed we fail with element not found.
|Done
|Done
|Done
|Yes that would be simpler. I used the WiFiClient since you made a suggestion to include the cleanup method in wificlient module. I will just use the host object instead.
|This should be daisy_spring.
|The build uses the same name as board. So --board='$board_path'.
|The board should also be daisy_spring. Here are the labels from AFE:
Other labels:board:daisy_spring, pool:wificell, wificell, cros-version:daisy_spring-release/R33-5116.45.0
|The board should also be set to x86-alex. Again from AFE:
 board:x86-alex,wificell,cros-version:x86-alex-release/R32-4920.76.0
|if board=spring how can board be equal to daisy. hmm
|Done
|Done
|Done
|Done
|Done
|Done
|Would it be better to change this to broken_pdus or it is fine to keep it generic in the control file ?
|Done
|We want the Finally block execute for both types of exception inorder to get the stack trace and post a task done.
|Done
|Done
|Done
|It is used in the cartridge and also the runner.
|Used in the runner.
|Done
|We want to have the broken_pdus list in the control file because we do not want to re-discovery the broken pdu's within each cartridge(we create a cartridge for each batch of 15 APs) or even between the different run's(for each spec in control file). Instantiating it within the cartridge wont help in that case. Hence putting it in the control.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Removed this class.
|Removed this class.
|Removed this object.
|Am using a list now and list.append is thread safe.
|Yes i think that would also achieve the same goal and reduce some complexity. Initially i thought i should have have both list of broken pdu and another lab status variable which would be True or False, that would give the general status, that why created the object. But looks like i can do all my job with just the list. I will get rid of the LabStatus object. Also, each cartridge had it's own labstatus object, which i want to change and make the labstatus global to the control file so that for any thread(across all cartridges, across all bands) can share the labstatus and any subsequent thread can make use of any previous status that was set by a different thread(so that they dont have to query the pdu again).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|value_of_css_property('background-image')) always returned OFF, irrespective of radio being on or off for this AP. Is it returning the correct state now ?
|Is the sleep still needed ?
|Or its actually fine. Not tough to figure that out.
|With this as tag, is there a way to know if the 2.4ghz failed or the 5ghz ?
|No the factory does not create the object again. The APSpec object is passed to it and it looks correct too. The issue we were seeing is that when we access the ap_spec.CONFIGURATOR_ANY(not to be confused with object.. it's the file '.' variable which is assigned to CONFIGURATOR_ANY = object() ) in ap_configurator_factory.py, it did not have the same address as before and we are using it for a comparison check. But we did not run into this issue running directly from the tree(../autotes/files/) instead of the autotest tar(/tmp/autotest). So atleast we confirmed that the code needs no change. There may be some difference in the python environment in both cases, not sure of python internals. But looks like when class loaded in the factory somehow it was loaded from a different address. Just speculating.
|Is the page_number no longer needed?
|No it should be &amp;&amp;. Or the logical expression will be incorrect and it may run if it is not 'Repairing' but 'Repair Failed' and vice-versa.
|Not sure why we have a print. Can we change this to logging or actually just remove it.
|Done
|Done
|Done
|Done
|Done
|If the page doesn't load the while condition should fail.  We have 3 other edimax ap's that have had no issues so far. So am not sure if that is needed.
|Wont this have the same effect as before ? If we want across batches should it not be within while batch_locker.has_more_aps():
|Done
|Done
|Done
|We need this because the screenshots show that the settings are saved but the page didnt refresh after applying settings. So if the page did not refresh and we are not duplicate admin, we just continue ignoring the stale page.
|Done
|Done
|Would be nice to have this class as DLinkDIR505lAPConfigurator.
|I think you meant it does not support modes without MODE_N.
|Same as above.
|Same as above.
|Move one space right.
|One space right.
|Done
|Done
|Done. Included main here.
|Done
|Done
|Done
|Done
|Done
|Done
|It is a list of pathnames.
|Done
|self.test_results_dir holds the test result directory to parse. The csv files will be created in RESULTS_DIR. Edited the logging.info to say the same.
|Done
|Done
|Done
|Done
|Done
|Done
|This was initially a method that could be called to create the csv after getting results from parser.  Since there can be multiple test dir's, doing it all in the parse method and calling it there now.
|Done
|Done
|Done
|Done
|Done
|Removed the connect_fail and config_fail. Need to retain total in order to get the total number of tests run in order to get the pass percentage.
|Yes it will. Do not have a smple status.log with PDU failures. Added a TODO.
|Why don't we pass the ap_locker object to this method in that case.
|Why are we again looping through the list of locked ap's to find the hostname ? Is'nt that what we pass from ulock_aps()method.
|Who would this method ?
|I mean who would call this method.
|How does the reboot take effect ? The unlock_and _reclain_aps() does not do a reboot.
|This only unlocks it. How does it return to the remaining batch of APs?
|What happens if the ping fails again during the test ?(after the conn_worked was found to be healthy ?
We are collecting logs from work client even now(old code) and also the in the parser this is not counted towards connection failure.
|Why did we move creating managed interface for scanning to here ?
|Because we created the interface here, we are having to call the remove_interface so many times from different places. Could this be consolidated under one error condition?
|list()
|Why cant we check the DUT health at the beginning of this loop so that we can reclaim AP's faster.
|That is the brand name on AP TP-Link. But i can get rid of the '-'
|Need to check AP.
|Done
|Done
|Done
|Need to check AP.
|This method still looks bit messy. May be we can move the following lines under this check into another method and call the method just passing the 'line'.
|Prefer another method for getting the config_pass_string and  connect_pass_string too.
|How about for ChaosLOngConnect ?
|Consider reducing this to '%s [\d.]+ ('([\w.]+)'
|Same as above.
|if not result_str:
|Should None be returned here ? sice you are checking for null in 332 for unknown FW version ?
|If not firmware_ver:
|Spaces around '+'
|Combining the lines with () does not seem to work.
|Yes that can be done.
|Yes it takes care of both cases(also because we return empty list in both cases). But would it not be nice to give the 'ssid not found' case also a second chance ? We dont see the 'ssid not found' happening off late though.
|I remember dup'ing these. Anyways, added both.
|But i think i remember we made this change because there were few APs that needed more time to come up. Would it not affect those ?
|The loop runs only for i = 0, 1 so the maximum time we give it is 4 mins ?
|Shouldn't the refresh be done when i == 1 ?
|You have removed the condition to check for networks == None:. I understand it doesnt matter but dont we want to log this since we are looking to gather information when this happens.
|Actually we can make this &quot;if self._ap_spec.security not in security:&quot;. Even if security is empty list the check will work. Sorry this is from my previous submission.
|So this should be 4 mins not 8 minutes ?
|This looks same as before am not clear how the old code ran the job twice.
|Ok got it. I was thinking in the context of the other job, incorrect security. Thanks for explaining that!
|I know it is redundant but we can have an explicit check like:
if self._ap_spec.security not in security and i==0:
Or
We can have a method define so that the code reads like:
if security_not_in_scan():
   
But again this is only for code readability.
|THis check seems bit confusing with just i ==0;
|If None is returned from iw scan, you are returning empty list. None is interface in bad state therefore we reboot(line 410). we look for None in-order to reboot. How can we combine the two ?
|Hmm i see this in the logs :
'kernel_version': '3.8.11',
   'wifi_firmware_version': 'Atheros AR9462 Rev:2'}
Therefore, used 'kernel_versoin'
|duh! i overlooked this.
|Use logging.info instead
|Why dont we print if &lt;8 ?
|line 42. to send the control keys to browser.
|Why ?
|Just curious.. we always had 15, did we have lot of failures offlate coz the ssid was not found ? Even with batch of 7 we still give the same time for each AP rit ?
|Ok. so we want to run 2 chaos tests in parallel now. Thanks for explaining.
|Just curious, what determines when we start testing a device on stable channel ?
|Done
|Done. But do we want to run it on builds &lt;40 ?
|It's probably not checking by default. Used it with --verify this time. Need to make this the default.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Not sure why pylint didnt detect this(same as last time). I will fix this.
|Same.
|Blame it on pylint..
|Done. 
cntc and cnta are different modules. The ChromeNetworkProvider is initialized thus:
self._chrome_testing = cntc
|Done
|Done
|Done
|Done
|Done
|Yes it is SHORT.
|Done
|Done
|Checked with Dan Shi. And he suggested that i use '_&quot; instead of the second '.'. So am changing it to &quot;NAME = would be network_WiFi_BeaconInterval.wifi_bintval_bcm4356&quot;
|Done
|Done
|Here, would it also help if we lock the device ?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Would attenuator_zeroed read better?
|i would prefer if its spelt as zeroes and zeroed
|i.Do you mean that if attenuation is set to 0 then False?
ii.typo-&gt; False
|Again what is &quot;zeros attenuator&quot; ? This is used in many places making sure i understand right before giving my comments.
|zeroed_linked_signal
|Same as above
|This block is missing return value of True if all looks good
|What is the criteria for choosing low power signal value ?
|typo -&gt; stuck
|This should be a new if else block.
|Re-arrange the imports in order.
|Change t to a meaningful variable like &quot;service_test&quot;
|Since you dont use match again, can it just be a if utils.system_output(grep_url_cmd) condition
|I would prefer this to be results_dir
|Same as above for variable 't'
|Same as above for variable 't'
|Does this not throw an error ? I prefer we access as as a class attribute. Is there a reason why you made this change ?
|This can go into the net constants file.
|Space after wifi,
|Space
|Agree. Modified the same.
|Honestly that was my first instinct. But i dono why i changed it prolly because default case had just a break. It's much better now. Thanks for your suggestion!
|Fit it into the previous line
|Move up
|MOve up
|MOve up
|Move up
|Roll over to the next line.
|Exceeds 80 characters
|Exceeds 80 character limit
|Exceeds 80 char limit
|Tien is removing them in a different CL
|This a endtoend test using chrome api. So i think it should be here. Matfunc has other roaming tests covered.
|Move this up.
|Move this up.
|See if you can move this line up.
|Move this line up.
|MOve this line up
|Move this line up
|I thought it'd be better to keep it separate for completeness. But does this mean that we never set bitmap for Intel ?
|Thanks Paul, that was a great idea. Done.
|This is super cool solution!
|Should this be wpa2 ?
|Is the security correct ?
|I dont think 10 mins is sufficient unless you have altered the suite and tested that it finishes in an hour.
|Same
|Same
|Same
|Same
|Remove space.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified+1

My comments are not getting posted. So putting ot down here:

Line 39:Done

Line 41:Yes the method does a non-blocking call and suspends the DUT before returning. No wait_down is not needed, the methos takes care of that.

Line 75:This timeout was to give client some grace period to fully resume and complete scan. Without this the test would fail with no wifi network found. But looks like even with this sleep the test fails sometimes. So i was doing some trial and error with different sleep periods and it turns out this is not needed. Instead, a long sleep after AP configuration resolved the issue.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1

Good catch. Done.
|Patch Set 2: -Commit-Queue
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2

Inheriting +2.
|Uploaded patch set 1.
|Abandoned

Incorrect change Id
|Patch Set 1:

No this whole upload is incorrect; hence abandoned I'll create another CL with ebuilds. You can use https://chromium-review.googlesource.com/#/c/259450/ for reviewing the test itself.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(8 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

I think with this matfunc &amp; atten. perf will run on 42 twice once a week. We dont want only tot everyday; tot-1 will also be needed. Correct me if am wrong.
Right now only wifi_perf is ==tot for nightly.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Patch Set 5:

(17 comments)
|Patch Set 6:

(2 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 6:

(4 comments)
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

http://cautotest/afe/#tab_id=view_job&amp;object_id=25537837
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

http://cautotest.corp.google.com/afe/#tab_id=view_job&amp;object_id=24614643
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Ready


|Patch Set 2: Ready


|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified; Ready


|Patch Set 1: Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 4: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Ready

Removed from the list temporarily due to the following bug.https://code.google.com/p/chromium-os/issues/detail?id=17380
|Patch Set 2: Verified


|Patch Set 2: Ready


|Patch Set 2: Ready


|Change has been successfully cherry-picked as aa79a75822f66c7bdcb060fd669b6dbcc0ec06aa
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Patch Set 1:

Tested manually
|Patch Set 1: Abandoned

Created a different CL https://gerrit.chromium.org/gerrit/#/c/44951/
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified

Verified by running the script as chronos.
|Patch Set 3: Ready


|Patch Set 1: Abandoned

Moved to different branch
|Patch Set 1: Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Patch Set 7: Ready


|Patch Set 7: Ready

Inheriting LGTM
|Patch Set 7: Abandoned

Moved to a different branch
|Patch Set 1: Looks good to me, approved; Ready; Verified

Carrying +2 from Ia3e59f6099bac7d88df5b10958ca495f212f62d7, manual test chumping
|Change has been successfully cherry-picked as ba42530b716e7a6f7c3ac43fa724ca7b52014b2f
|Patch Set 1: Verified

Ran unit test.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Inheriting LGTM
|Uploaded patch set 2.
|Patch Set 2: Verified

Ran the ap_configurator unit test for setting visibility and verified that AP gets value True when not implemented and False if AP does not support visibility and method is implemented to return False.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Abandoned
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Change has been successfully cherry-picked as 5733b58e67b09a7c219888dedb416977258fa21d
|Uploaded patch set 2.
|Patch Set 2: Verified

AP uses c0:c1:c0:8b:87:4f as bss and c0:c1:c0:8b:87:4e as mac
|Patch Set 3: Ready; Verified


|Change has been successfully cherry-picked as 46bf174eb7d1cddd0b6dc02f369d6801421b6bd8
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready


|Change has been successfully cherry-picked as 890d6ddcdb3c6ec883fc6b947e8cbfaac96dedde
|Uploaded patch set 2.
|Patch Set 1: Abandoned
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as e47cc2e2e08b7136e1d24cd8e115543a0acf2234
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified

Tested with wndr4300 and medialink.
|Patch Set 4:

This fix does not fully guarantee that connect always succeeds because the DUT sees the ssid. I have seen it with wndr4300 wherein even though bss is found initial 1-2 tries fail(for wndr4300). But for the medialink it always passed. Maybe chrome issue because now we can atlease be sure the AP was ready and beconing. Here's an example o/p:

16:35:26 INFO &#124; Waiting for the DUT to find BSS.. 
16:35:30 INFO &#124; Found bss in scan * Command: 
    /usr/bin/ssh -a -x  -o ControlPath=/tmp/_autotmp_Elj1lassh-master/socket
    -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o
    BatchMode=yes -o ConnectTimeout=30 -o ServerAliveInterval=180 -o
    ServerAliveCountMax=3 -o ConnectionAttempts=4 -o Protocol=2 -l root -p 22
    172.22.29.65 &quot;export LIBC_FATAL_STDERR_=1; grep 14:35:8b:00:76:48
    /tmp/scan.out&quot;
Exit status: 0
Duration: 0.0648579597473

stdout:
BSS 14:35:8b:00:76:48 (on wlan0)
16:38:17 INFO &#124; Found bss in scan * Command: 
    /usr/bin/ssh -a -x  -o ControlPath=/tmp/_autotmp_Elj1lassh-master/socket
    -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o
    BatchMode=yes -o ConnectTimeout=30 -o ServerAliveInterval=180 -o
    ServerAliveCountMax=3 -o ConnectionAttempts=4 -o Protocol=2 -l root -p 22
    172.22.29.65 &quot;export LIBC_FATAL_STDERR_=1; grep 00:8e:f2:fc:ff:8f
    /tmp/scan.out&quot;
Exit status: 0
Duration: 0.0290489196777
..
.
16:38:27 INFO &#124; Installation of autotest completed
16:38:28 INFO &#124; Connection try 1

16:39:31 ERROR&#124; TIMEOUT(assoc): ssid wndr4300_5_2_4GHz acquire 0.015 wpa_select 0.000 assoc 60.117 config 0.000 secs state failure

16:40:32 INFO &#124; Connection try 2
16:42:37 ERROR&#124; TIMEOUT(assoc): ssid wndr4300_5_2_4GHz acquire 0.265 wpa_select 0.000 assoc 60.153 config 0.000 secs state failure

16:43:38 INFO &#124; Connection try 3
16:44:42 INFO &#124; Connection try 4
16:44:47 INFO &#124; Connection try 5
16:44:50 INFO &#124; Connection try 6
16:44:53 INFO &#124; Connection try 7
16:44:57 INFO &#124; Connection try 8
16:45:01 INFO &#124; Connection try 9
16:45:04 INFO &#124; Connection try 10
..
.
16:46:05 INFO &#124; Installation of autotest completed
16:46:06 INFO &#124; Connection try 1
16:46:12 INFO &#124; Connection try 2
16:46:17 INFO &#124; Connection try 3
16:46:21 INFO &#124; Connection try 4
16:46:24 INFO &#124; Connection try 5
16:46:28 INFO &#124; Connection try 6
16:46:35 INFO &#124; Connection try 7
16:46:38 INFO &#124; Connection try 8
16:46:41 INFO &#124; Connection try 9
16:46:45 INFO &#124; Connection try 10
|Uploaded patch set 5.
|Patch Set 5: Verified

Tested with ChaosOpen tests.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Ready; Verified


|Change has been successfully cherry-picked as 6473f9ca8a72fddce76cb9b85703e189eac182f2
|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 1:

Ya  i did think of that. But i wasnt able to repro this issue when i ran and the bug does not have the screenshot. This will help if it is slow.
|Uploaded patch set 2.
|Patch Set 2: Ready


|Patch Set 2: Verified


|Change has been successfully cherry-picked as 87330193c8648cd9d75e8fa38e613aba1f19937f
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Change has been successfully cherry-picked as 05e42ffbfabdfa424eb09a9fef5b8aa2f85ebe18
|Patch Set 1: Verified

INFO    : Test results:

network_WiFiChaosPSK                                             [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.keebox_w150nr_5_2_4GHz [  PASSED  ]
Total PASS: 2/2 (100%)

network_WiFiChaosOpen                                              [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.keebox_w150nr_5_2_4GHz [  PASSED  ]
Total PASS: 2/2 (100%)
|Patch Set 1: Ready


|Change has been successfully cherry-picked as 981587f6e06257c56f88b1993ab646e2cb4ef9d2
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 8e215734afebec09c0f5ff4e6b51b5382675ac94
|Patch Set 1: Abandoned

Covered in https://gerrit.chromium.org/gerrit/#/c/59646/
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 3cb38e0c1e9b6e3066ab85c4dc2d519cb40dd60f
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified

Inheriting LGTM.
|Patch Set 3: Looks good to me, approved


|Change has been successfully cherry-picked as f992956cb88b91039bba5eb8d466a2ff64f2e7ce
|Patch Set 1: Verified

Sample output:
Tested with trendnet 731 by turning off the AP jus before scan.
 
12:01:08 ERROR&#124; These APs were not listed in scan:
12:01:08 ERROR&#124; Brand:trendnet 
                Model:tew 731br 
                Ssid:tew 731br_5_2_4GHz 
                Bss:00:14:d1:d9:ae:9b
12:01:08 ERROR&#124; Dumping command list []
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 87317342abb3147d2f604ee41f0ab37fae5d374b
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

(1 inline comment)

LGTM with one nit.
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as b198642282bdddb74d7f25c47c58183a894381bf
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Manually run. Chump.
|Change has been successfully cherry-picked as 0f3003f155b7f4d19ac14df50b3b7088c46e39d2
|Patch Set 1: Looks good to me, approved; Ready; Verified

Inheriting LGTM. Manually run. Chup.
|Patch Set 2:

Inherited @krisr's LGTM.
|Patch Set 1:

PSK:

17:29:48 INFO &#124; Connection try 1
17:30:51 ERROR&#124; TIMEOUT(assoc): ssid tew_432brp_5_2_4GHz acquire 0.014 wpa_select 0.000 assoc 60.098 config 0.000 secs state idle
17:30:51 INFO &#124; Connection try 2
17:30:57 INFO &#124; Connection try 3
17:31:01 INFO &#124; Connection try 4
17:31:04 INFO &#124; Connection try 5
17:31:12 INFO &#124; Connection try 6
17:31:14 INFO &#124; Connection try 7
17:31:17 INFO &#124; Connection try 8
17:31:20 INFO &#124; Connection try 9
17:31:23 INFO &#124; Connection try 10

OPEN:

17:34:42 INFO &#124; Connection try 1
17:35:00 INFO &#124; Connection try 2
17:35:05 INFO &#124; Connection try 3
17:35:12 INFO &#124; Connection try 4
17:35:15 INFO &#124; Connection try 5
17:35:17 INFO &#124; Connection try 6
17:35:20 INFO &#124; Connection try 7
17:36:23 ERROR&#124; TIMEOUT(config): ssid tew_432brp_5_2_4GHz acquire 0.243 wpa_select 0.000 assoc 0.179 config 59.868 secs state idle
17:36:23 INFO &#124; Connection try 8
17:36:34 INFO &#124; Connection try 9
17:36:40 INFO &#124; Connection try 10
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Change has been successfully cherry-picked as 84957a8d8a949431c96092b85aea54bd32bd5542
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Change has been successfully cherry-picked as a8c8f28783eb18b06bae83e1f3fcea609354c393
|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified

INFO    : Test results:
--------------------------------------------------------------------------
network_WiFiChaosOpen                                          [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.tew_692gr_5_2_4GHz [  PASSED  ]
--------------------------------------------------------------------------
Total PASS: 2/2 (100%)

INFO    : Test results:
------------------------------------------------------------------------
network_WiFiChaosPSK                                         [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_692gr_5_2_4GHz [  PASSED  ]
------------------------------------------------------------------------
Total PASS: 2/2 (100%)
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready

Manually run. Chumping.
|Change has been successfully cherry-picked as 409cccb5f97f43002a93567890afe1d78e70966f
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 33fecc3a6e1b5b74146b08446e6a18a5c91fc1af
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as cc956a8ef795603667b3495aed17cd9fa809bd05
|Patch Set 1: Commit-Queue+1 Verified+1

Run manually. Chumping.
|Change has been successfully cherry-picked as c340a07e06e00696e454f81177c1a8f45b9147f5
|Patch Set 1: Code-Review+2
|Abandoned
|Patch Set 1:

https://chromium-review.googlesource.com/#/c/167576/
|Patch Set 1: Verified+1

network_WiFiChaosPSK/network_WiFiChaosPSK.tew_691gr_5_2_4GHz [  FAILED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_691gr_5_2_4GHz   FAIL: 
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_691gr_5_2_4GHz   08/29 18:39:51.534 ERROR&#124;chaos_base:0127&#124; TIMEOUT(assoc): ssid tew_691gr_5_2_4GHz acquire 0.063 wpa_select 0.000 assoc 60.398 config 0.000 secs state failure
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_692gr_48_5GHz  [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_692gr_5_2_4GHz [  PASSED  ]
|Patch Set 1: Commit-Queue+1
|Change has been successfully cherry-picked as 3fab5e57588d97972568cb2adf7b57d0a4f72055
|Patch Set 2: Code-Review+2
|Patch Set 1: Verified+1

INFO    : Test results:
--------------------------------------------------------------------------
network_WiFiChaosOpen                                          [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.tew_654tr_5_2_4GHz [  PASSED  ]
--------------------------------------------------------------------------
Total PASS: 2/2 (100%)

------------------------------------------------------------------------
network_WiFiChaosPSK                                         [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_654tr_5_2_4GHz [  PASSED  ]
------------------------------------------------------------------------
Total PASS: 2/2 (100%)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3:

It was'nt needed. Inherited from base class AP.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 59b7632d3a425ad5c87bc5ce6bbdb2077fc45ff0
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

Covered in https://chromium-review.googlesource.com/#/c/169874/
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

network_WiFiChaosOpen                                           [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.tew_812dru_48_5GHz  [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.tew_812dru_5_2_4GHz [  PASSED  ]
---------------------------------------------------------------------------
network_WiFiChaosPSK                                          [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_812dru_48_5GHz  [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.tew_812dru_5_2_4GHz [  PASSED  ]
-------------------------------------------------------------------------
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 8e9498129cdaa75d28c550fbf07553e06308c772
|Patch Set 1: Commit-Queue+1 Verified+1

Manually run. Chumping.
|Patch Set 1:

Manually run. Chumping.
|Change has been successfully cherry-picked as 53eabb4a48a663a6bd99943286acfb03a5e83d72
|Uploaded patch set 2.
|Patch Set 2: Verified+1

INFO    : Test results:
-------------------------------------------------------------------
network_WiFiChaosPSK                                    [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.n600_48_5GHz  [  PASSED  ]
network_WiFiChaosPSK/network_WiFiChaosPSK.n600_5_2_4GHz [  PASSED  ]
-------------------------------------------------------------------
INFO    : Test results:
---------------------------------------------------------------------
network_WiFiChaosOpen                                     [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.n600_48_5GHz  [  PASSED  ]
network_WiFiChaosOpen/network_WiFiChaosOpen.n600_5_2_4GHz [  PASSED  ]
---------------------------------------------------------------------
Total PASS: 3/3 (100%)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1

THe wndr 4500 was fixed with https://chromium-review.googlesource.com/#/c/169950/. Also, i've added fix for asus n65u. Please rereview the CL.
|Uploaded patch set 5.
|Patch Set 5:

And with this we all AP's enabled. Yay! and hopefully fixed.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

Manually run.
|Change has been successfully cherry-picked as 81d6b5ad45c0b5ba0a6c09d2e1b850e4780769cc
|Patch Set 7:

(2 comments)

The chaos_runner is lot simpler and intuitive now.
Just one suggestion and a doubt.
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

INFO    : Test results:
------------------------------------------------------------------------------------------------------------
network_WiFi_ChaosConnectDisconnect.wpapsk                                                       [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpapsk/network_WiFi_ChaosConnectDisconnect.br6428n_n_ch5_wpa [  PASSED  ]

INFO    : Test results:
-----------------------------------------------------------------------------------------------------------
network_WiFi_ChaosConnectDisconnect.open                                                        [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.open/network_WiFi_ChaosConnectDisconnect.br6428n_n_ch5_open [  PASSED  ]
|Uploaded patch set 3.
|Patch Set 2:

(8 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting Kris's +2.
|Change has been successfully cherry-picked as 5016e78dd035043b187f50df7bd28b354acfbb45
|Patch Set 6:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

(4 comments)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Separate checks for open and psk is needed in the chaos_runner because we have ap's that set wpa2 for wpa. Without this it should just be a simple check.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(4 comments)
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 1:

(3 comments)
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(2 comments)
|Patch Set 7: Commit-Queue+1 Verified+1

Inheriting +2.
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 10.
|Patch Set 10:

Fixed the iw_runner unit tests.
Ran 8 tests in 0.001s

OK
|Uploaded patch set 11.
|Patch Set 11: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Manually run autotest.
|Change has been successfully cherry-picked as 16fca35ca7a6db29ea8cf4e7f2bd6e4396e22d03
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Abandoned

Moved to https://chromium-review.googlesource.com/#/c/175977/
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Merged set_security_wpapsk() and set_security_wpa2psk().
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)

Re-uploaded taking Jason's changes.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2. Manually run tests.
|Change has been successfully cherry-picked as ada34e33a27786604af7007600d99fbf2e4fc7f6
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Mnaually run tests.
|Change has been successfully cherry-picked as f4ec87fb54e8198ec6a56abb1c491f9949439a06
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Manually run tests. Chump.
|Change has been successfully cherry-picked as 618e213871d591fbea23a168af746a0a212dca41
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)

LGTM.Just 1 nit.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1

-----------------------------------------------------------------------------------------------------------
network_WiFi_ChaosConnectDisconnect.wpapsk                                                      [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpapsk/network_WiFi_ChaosConnectDisconnect.3700_a_ch149_wpa [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpapsk/network_WiFi_ChaosConnectDisconnect.3700_g_ch5_wpa   [  PASSED  ]
-----------------------------------------------------------------------------------------------------------
Total PASS: 3/3 (100%)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

Manually run tests. Chump.
|Patch Set 3: Code-Review+2
|Change has been successfully cherry-picked as 3370d8cab2a28129d68a1cd126afee6a1b001fbd
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1

Manually run tests. Chump.
|Change has been successfully cherry-picked as 952439ca397fde03ae444d90d69fede2e9493b31
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

Inheriting +2. Chump.
|Patch Set 2: Code-Review+2
|Change has been successfully cherry-picked as 895695adf1c4f07e48da57dc09d41ac237cd7664
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

Covered in https://chromium-review.googlesource.com/#/c/177948/
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

These 2 string are subsets of each other. I wanted to retain Mode-N in the string since thats what we are looking for and just accept alert instead of throwing exception.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Manually run tests. Chump.
|Change has been successfully cherry-picked as 906c2eb8d8bd1faad199798ccdd3ca480c01b6b5
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4:

(5 comments)
|Uploaded patch set 7.
|Patch Set 6:

(2 comments)
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Change has been successfully cherry-picked as b7d82c8a61da213dd34d2f0b23ba3bf371499358
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Change has been successfully cherry-picked as 9577109a6bd410d43e0a571d91f1016fb792e321
|Change has been successfully cherry-picked as c068c82cbd6977a34be2fbcf696675ebdfac850e
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5:

(2 comments)
|Patch Set 7: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

I will be uploading a new patch. Please hold off the review until then.Thanks!
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(10 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(11 comments)
|Patch Set 7:

(1 comment)
|Patch Set 7:

This patch is pylint-error free! :)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 7:

(6 comments)
|Patch Set 8:

(2 comments)
|Uploaded patch set 10.
|Patch Set 9:

(7 comments)
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13: Verified+1

Carrying +2.
|Uploaded patch set 14.
|Patch Set 14: Commit-Queue+1 Verified+1
|Patch Set 14: Code-Review+2
|Patch Set 14: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 17:

(1 comment)
|Patch Set 18: Commit-Queue+1 Verified+1
|Patch Set 18: -Commit-Queue
|Uploaded patch set 19.
|Patch Set 19: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as ca31191b5cf1564571eaef3b8c6071415c9988fe
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2 Commit-Queue+1

Inheriting +2.
|Change has been successfully cherry-picked as 03d80b7e8972580f8769426b921aeac8595280c0
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2

Manually run tests. Chump.
|Change has been successfully cherry-picked as b9d1ee5c6f9693d23f4b15da82da2e7bb77ad8ad
|Patch Set 3:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

I was trying to run the unit test when we saw that the configurator_type object's address was getting modified, and because of which _get_aps_by_configurator_type() was returning NULL. Ref. def get_ap_configurators_by_spec().

1.ap_spec.CONFIGURATOR_ANY=&lt;object object at 0x7f5b63aca1b0&gt;
2.spec.configurator_type=&lt;object object at 0x7f5b63aca1b0&gt; 

When the ap spec object was initialized it was set to #1 but somewhere down the line it changed to #2. 

So we tried changing the configurator_type to a constant, and that resolved the issue. This probably is just a work around; please give your inputs.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Kris and i did the whole exercise again on a clean source. Running the unittest still resulted in the same issue, object address mismatch. Hence we decided to settle down with constants for the above properties.
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

Manually triggered tests. Chumping.
|Patch Set 1: Code-Review+2

(1 comment)

Just 1 nit.
|Uploaded patch set 1.
|Patch Set 1:

The test failed because the DUT did not see it in scan, but this is the AP capabilities from the sniffer(which also run's a scan). Need to debug and verify. But you can use these details if you wish to try the test.
|Abandoned
|Restored
|Uploaded patch set 2.
|Patch Set 2: Verified+1

INFO    : Test results:
-----------------------------------------------------------------------------------------------------------
network_WiFi_ChaosConnectDisconnect.wpa2psk                                                     [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpa2psk/network_WiFi_ChaosConnectDisconnect.duck_g_ch5_wpa2 [  PASSED  ]
-----------------------------------------------------------------------------------------------------------
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Change has been successfully cherry-picked as 3be2cb952bf8088c60b530c76869a68fe7753c95
|Patch Set 4:

Manually run tests. Chumping.
|Patch Set 2: Code-Review+2

Ran with this CL and able to find the required AP.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Ran the Chaos WPA2PSK test.
|Patch Set 1:

@jabele:We have 'mixed' because some AP's do allow setting 'mixed mode' security.
The reason why we downgrade it to WPA2 in the runner is because we always configure AP's to wpa or wpa2(not mixed) and it turns out that some APs, though set to WPA2, broadcast wpa+wpa2 in security instead of just wpa2(rsn).

@krisr: what about the case where an AP is configured with wpa2 instead of wpa(configuration error) and it broadcasts both wpa+wpa2. Then wont we will go ahead and connect thinking it's wpa ?
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(3 comments)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as b7a30519a553e6f6bd7a6b4cfe9d7b6121dd3241
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Verified+1

Inheriting +2. Manually run tests.Chumping.
|Change has been successfully cherry-picked as 9273050ce965eb68c7f3a20be96caaa8532ee4b3
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting +2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting krisr's +2.
|Change has been successfully cherry-picked as d24b69d964c851a0f36562f844a2acbd3bab124a
|Patch Set 4:

Manually run tests. Chumping.
|Patch Set 4:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4:

Manually run tests. Chumping.
|Change has been successfully cherry-picked as 4632e2dd15129b29fde2280578b61687941d891a
|Patch Set 5:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

Test
|Patch Set 1: Code-Review+2
|Patch Set 1:

(6 comments)
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1

I was also a bit confused if it should be cros or mtv domain. But both worked for me.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

http://cautotest.corp.google.com/afe/#tab_id=view_job&amp;object_id=10625033
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I had tested appending to the csv file and it seemed to work. Forgot to update the output here. Here's a sample content from csv.I'll make other changes and upload.

butterfly,5792.0.0,dir_505l,WPA2,2.4GHz
butterfly,5792.0.0,dir_601,WPA2,2.4GHz
butterfly,5792.0.0,dir_632,WPA2,2.4GHz
butterfly,5792.0.0,dir_645,WPA2,2.4GHz
butterfly,5792.0.0,jnr3210,WPA2,2.4GHz
butterfly,5792.0.0,linksys,WPA2,2.4GHz
butterfly,5792.0.0,r6200,WPA2,2.4GHz
butterfly,5792.0.0,tl_wr841n,WPA2,2.4GHz
butterfly,5792.0.0,wndr3400v2,WPA2,2.4GHz
butterfly,5792.0.0,wndr3700v4,WPA2,2.4GHz
butterfly,5792.0.0,wndr3700v4,WPA2,2.4GHz
butterfly,5792.0.0,wndr4300_2,WPA2,2.4GHz

And this the config fail csv:
chromeos3-row2-rack2-host7,WPA2
chromeos3-row4-rack2-host4,WPA2
chromeos3-row4-rack2-host8,WPA2
chromeos3-row2-rack2-host7,WPA2
chromeos3-row4-rack2-host4,WPA2
..
|Uploaded patch set 2.
|Patch Set 1:

(6 comments)
|Patch Set 2:

Now this creates a csv file for each of the results* directory inside test_that result dir.
|Patch Set 2:

(10 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(6 comments)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Carrying Kris' +2.
|Patch Set 4:

(1 comment)
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Change has been successfully cherry-picked as 88ba8e12ced8dc0cddd0af3b009b0c66432ee9a2
|Patch Set 6:

This will be manually run. Chumping.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as b2a638e8081fda0464ca326c1826d1fbbc3c9549
|Patch Set 2:

Manually run tests. Chumping.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Patch Set 5:

Manually run script. Chumping.
|Change has been successfully cherry-picked as c2288073aa88db410ebab52ec5c62479a772eb6d
|Patch Set 2: Code-Review+2
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 4:

(1 comment)
|Patch Set 8: Code-Review+2 Commit-Queue+2

It would be nice if we had another quick way of getting the device heath than run the scan for each AP. But this is fine for now.
|Patch Set 8:

As we are saving a lot of time when the DUT fails.
|Patch Set 10:

(4 comments)
|Patch Set 11: Code-Review+2

(1 comment)

Just 1 nit.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Code-Review+2 Commit-Queue+1

Manually run. Chumping.
|Change has been successfully cherry-picked as 31c7b0a175b039fea967b17d835ff5ec8245d365
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Manually run. Chumping.
|Change has been successfully cherry-picked as 26e6bac91cc76a56543bdd40fe5c44852b8e67f4
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

Manually run tests. Chumping.
|Change has been successfully cherry-picked as 9f526bedee15b852341ee87fda92a89bd8057fa3
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1

Manually run tests; chumping.
|Change has been successfully cherry-picked as c3122181a6f6faf147c0ed3aa7113b432153155e
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Manually run; chumping.
|Change has been successfully cherry-picked as 41d67b66de1d4826be4a53b07fda4d2e79b1c5dd
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 2:

Unintended changes are showing up in file. Repo sync and upload changes.
|Patch Set 5:

(2 comments)
|Patch Set 6: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

INFO    : Test results:
---------------------------------------------------------------------------------------------------------------------
network_WiFi_ChaosConnectDisconnect.wpa2psk                                                               [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpa2psk/network_WiFi_ChaosConnectDisconnect.wndr_3700_v3_a_ch149_wpa2 [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpa2psk/network_WiFi_ChaosConnectDisconnect.wndr_3700_v3_g_ch5_wpa2   [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpa2psk/network_WiFi_ChaosConnectDisconnect.xwr100_a_ch48_wpa2        [  PASSED  ]
network_WiFi_ChaosConnectDisconnect.wpa2psk/network_WiFi_ChaosConnectDisconnect.xwr100_g_ch5_wpa2         [  PASSED  ]
---------------------------------------------------------------------------------------------------------------------
Total PASS: 5/5 (100%)

With a sleep of 30, there was a connect failure for the 1st  connection attempt. So thought 60 seconds was ideal, also this is only for the ones that fail security or ssid not found.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5:

Tried to make changes without having to loop in scan. Changes are minimal, just moved them out to separate methods.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 40a79916595b0b1cffa73fe5e5a10606c4e26173
|Patch Set 4:

Manually run tests; chumping.
|Patch Set 4:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(5 comments)
|Patch Set 2: Code-Review+2

(1 comment)

Just 1 nit.
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+2 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2

Forgot to +2.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Manually run script. Chumping.
|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 19801324c6dc398e9a448240878d8c4e96338ba3
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2:

Since the debug information with kernel and FW version are output only for connectin failures, there are chances that it will be empty in the config failure file if we did not have any connect failure at all.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1

Manually run script. Chumping.
|Change has been successfully cherry-picked as 5674f6382b4557db5d754154def2c969a5d2e9b1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2

Seems like print make copying easier from stdout.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1

Manually run tests. Chumping,
|Change has been successfully cherry-picked as 22c63ccb5c76af2a166457b25e85009a6e0d21e7
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

@krisr: Do you have any comments ?
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

Manually run tests. Chumping.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

Manually run tests. Chumping.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

Manually run tests. Chumping.
|Patch Set 2:

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2 Commit-Queue+1

Inheriting +2.

Manually run tests. Chumping.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Added the WAN MAC for Netgear R7000.
|Patch Set 3:

Inheriting +2. 

Manually run tests. Chumping.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Verified+1

Verified running on Samus:
http://cautotest/afe/#tab_id=view_job&amp;object_id=20126596

Locally run script. Chumping.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(24 comments)
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Patch Set 3:

I plan to refactor the chrome-end-to-end tests in a separate cl and restrict this one to roam-end-to-end. This does not affect the existing tests in chrome-end-to-end.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

I had to keep the Roaming test separate because the server-side configuration is very different compared to the other tests. The Chromeendtoend does a one time AP config and kicks off the client tests but the Roaming ones on the other hand go back and fourth between the server and client because we have to bring down an PA and configure another in between the test.
|Patch Set 4:

(5 comments)
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 7:

(2 comments)
|Patch Set 9: Verified+1
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

I will run the attenuator and router tests for host1-host3.

Tien, could you pls run them on host4-host6 using this file.
|Patch Set 1:

Results:
=========
Host1:

test_that --autotest_dir=../third_party/autotest/files/ --fast chromeos1-grover-host1.cros network_WiFi_VerifyAttenuator
/tmp/test_that_results_SG19OC/results-1-network_WiFi_VerifyAttenuator                               [  PASSED  ]
/tmp/test_that_results_SG19OC/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator [  PASSED  ]

Host3:
test_that --autotest_dir=../third_party/autotest/files/ --fast chromeos1-grover-host3.cros network_WiFi_VerifyAttenuator
/tmp/test_that_results_hULOMZ/results-1-network_WiFi_VerifyAttenuator                               [  PASSED  ]
/tmp/test_that_results_hULOMZ/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator [  PASSED  ]
|Patch Set 1:

Host2:

test_that --autotest_dir=../third_party/autotest/files/ --fast chromeos1-grover-host2.cros network_WiFi_VerifyAttenuator

/tmp/test_that_results_arDj9G/results-1-network_WiFi_VerifyAttenuator                               [  FAILED  ]
/tmp/test_that_results_arDj9G/results-1-network_WiFi_VerifyAttenuator                                 ERROR: Only positive attenuations are supported. (requested -5)
/tmp/test_that_results_arDj9G/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator [  FAILED  ]
/tmp/test_that_results_arDj9G/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator   ERROR: Only positive attenuations are supported. (requested -5)
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

I used a script to reliably modify each control file to add the new suite name and also check them manually for correctness. You may skip clicking on the 70 control files if you wish to :)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Inheriting Tien's +2.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2 Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

I have this CL ready for the ebuild: https://chromium-review.googlesource.com/#/c/232432/
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(3 comments)

Will submit in a different CL. Abandoning this one.
|Abandoned
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Taken care of comments in https://chromium-review.googlesource.com/#/c/234020/(Abandoned).
|Patch Set 1:

Totally agree! But seems like the only workaround for now. Created a different suite &quot;matfunc_preflight&quot; here: https://chromium-review.googlesource.com/#/c/230587/. But inorder to get all tests run on each of the devices, had to go this way.
|Patch Set 1:

We have a pool called wifi_preflight. The problem was that scheduling the suite(wifi_matfunc_preflight.control) against this pool still ran across all devices in this pool(we have 2 different glimmer-bcm and glimmer-marvell). Ok, i can retain 'wificell' and add the wifi:bcm/marvell in suite dependency instead of test dependency, then hopefully we can achieve what we want. Just to outline here:

suite:matfunc (unaffected)
pool:wificell (unaffected)

suite:matfunc_bcm + dependency on label wifi:bcm
pool:preflight

suite:matfunc_marvell + dependency on label wifi:marvell
pool:preflight
|Abandoned
|Patch Set 1:

Nope.. Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(11 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

Will hold-off submission until yuna is installed. https://code.google.com/p/chromium/issues/detail?id=444185
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1

Removed:
- pool:wificell from preflight boards
- suite name wifi_matfunc_preflight removed from all controls
No other labels to remove.
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 2:

(10 comments)
|Patch Set 1:

Thanks Mukesh!
|Patch Set 1: Code-Review+2
|Patch Set 2:

(4 comments)

I see that this CL does a connect in general to all the networks but where is the client side code that does verification after connection especially for the local radius and the proxy services.Have you forgotten to upload the client side test code ?
|Patch Set 5:

(5 comments)
|Patch Set 9: Code-Review+2

(1 comment)

Just one nit. Otherwise lgtm!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Patch Set 3: Verified+1
|Patch Set 3:

*Ping*
|Patch Set 3: Commit-Queue+1

Actually both! :)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1

Thanks Fang!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(4 comments)

Most of the files exceed 80 charter limit. Please fix this in all files.
|Patch Set 3:

(5 comments)

I look at few initial files and they all seem to have the same problem as below for ATTRIBUTS and/or SUITES lines. Will be better if you can take a look at all the files once.
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Just an FYI for Paul and Mukesh.
|Patch Set 1:

(2 comments)
|Patch Set 1:

I found a cl where Tien has added this to pre-cq. https://chromium-review.googlesource.com/#/c/302121/. I wont recommend adding it because it is servo dependent. We can remove it if we  decide to do so.
|Patch Set 1:

Yes it does pass, expect on devices with bad servos. But with this https://chromium-review.googlesource.com/#/c/304073/ and monitoring the pre-cq servo health, we have decided to keep RoamSuspendEndToEnd in pre-cq.
|Patch Set 1:

The connection failure you see is failing to connect to the device itself not a wifi connection failure. The servo error should be fixed now. I can remove this test from pre-cq here.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Carrying Kris' +2.
|Patch Set 1: Code-Review+2
|Patch Set 4:

Can you chump your changes ? i would like to kick off a test today.
|Patch Set 1: Code-Review+2
|Patch Set 2:

(6 comments)

In general, you dont need the parenthesis () is if it not a line continuation.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: -Verified

Also, i thought this method was called only for adb host.
Looking at the way wep properties is constructed, it may also have the same issue. I'll test that too and include in this cl if needed.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Thanks Filipe for your insights into the code. WEP cli property also had the same issue, i fixed it here. Please review.
|Patch Set 2: Commit-Queue+1
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Carrying Tien's +2.
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4:

No this patch is not responsible for the whirlwind failure. Infact this is only used by the interop lab that we trigger tests manually for. That is the reason i chumped after it failed the initial submit.
|Patch Set 2: Code-Review+2
|Patch Set 1:

This CL does not in any way affect whirlwind. We trigger these tests manually in the interop lab.
|Patch Set 3:

Verified. Thanks Roshan!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

(1 comment)
|Patch Set 4:

Re-joining the party here..
Since the base idea of this method is still setting the antenna bitmap, i would like to keep the existing method name. I would like to simplify the parameters though and have an adequate method description that explaining the new way of setting the bitmap. @Mukesh, what do you say ?
|Uploaded patch set 5.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 4:

Pls ignore the previous patch. Have more files to upload.
|Abandoned

Unable to upload/modify correctly. Hence moved to here https://chromium-review.googlesource.com/#/c/320424/
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Taken care of comments in the previous review.
|Patch Set 2:

You'r right that &quot;desired&quot; will not always be set because of h/w limitations. I think am pretty convinced with the earlier suggestion now to use &quot;disable_antennas_except()&quot; as the method name. As you stated, it removes ambiguity coming from enabling or disabling the antennas. It also makes sense to have a disable method that can be used along with the enable _all_antennas(i believe this was a recent change, was &quot;set_default_antenna_bitmap&quot; earlier.) Patch coming your way!
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

We discussed that you'll remove the hoofer. +2 with that change.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

No problem! :)
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

Please correct the indent. +2 otherwise.
|Patch Set 1:

Thinking of which, does it mean that it sometimes sees duplicate ssids in scan ? Could you also pls add logging for printing out iwbss.bss, and iwbss.ssid. So that if it happens again we have more information.
|Patch Set 1: -Code-Review
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

(5 comments)

Why do we need these many suites ? I think we did this in the past because we were dealing with variants but these are all different boards. You probably did it to run on different days; may be you should explore other methods to achieve this, maybe make the pools unique or something like that.
|Patch Set 2: Code-Review+2

Strange, we'r missing so many APs. wonder, where did they go?
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

These tests are exactly the same as the network_WiFi_SuspendStress/control.24HT40 and control.WPA2 with just changes to the number of iterations from 5 to 690. I think it will be better to convert the original test to run in the wifi_stress suite and remove it from matfunc instead of duplicating it.
|Patch Set 1:

We can have multiple suites in the same control file. It would be good a thing to investigate if we can determine which suite invoked us, so that we can make that tweak in iteration. If not i guess we have to go with this approach.
|Patch Set 2:

Ln 447 looks good. Leaving +2 to the rest of the reviewers.
|Patch Set 1: Code-Review-2
|Removed Code-Review-2 by Bindu Mahadev &lt;bmahadev@chromium.org&gt;

|Patch Set 1: Code-Review+2
|Patch Set 1:

Oops sry.. the -2 was a mistake. LGTM.
|We should deal with exceptions in _EndTest(), not here.
|Not sure what you were trying to say, but I meant you should rename &quot;p&quot; to a meaningful one.
|Patch Set 1: Abandoned

Wrong account.
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Patch Set 4:

(1 comment)
|Patch Set 1:

(1 comment)
|will do.
|Will add an error message print here and above.
|Following statement is from the QSPI IAS:
For successful operation at various freq combinations, min of 4-5 spi_clk cycle delay might be required before enabling PIO or DMA bit. This is needed to overcome the MCP between core and pad_macro. The worst case delay calculation can be done considering slowest qspi_clk as 1 MHz. based on that 1 us delay should be enough before enabling pio or dma.
|Will do.
|Yes, we add a 2 usec delay before Go bit is set.
|Sure, will do.
|There was an email from Laurent:
===
At what frequency are you trying to run SPI ? 
Please try below 25MHz otherwise it seems to require an extra HW change.
===

And, I tried to run it at 25Mhz, and QSPI won't work.
|The next Foster board will have a recovery mode switch. When we build for that board, there will be a statement in the #else clause to read the physical recovery switch.
|The other products based on T210 may not have CONFIG_COMMON_CBFS_SPI_WRAPPER defined.
|Will fix. Thanks.
|will fix.
|will fix it.
|Please revert this change. Spaces are purposedly inserted so this line and one above are aligned.
|What makes you to remove cpu_init() and l2x0_restart()?
|Why stop_critical_timings() is removed?
|same.
|Shouldn't you set both to the minimum of the two?
|data[0] equals data[1] already, 2nd and 4th checks are redundant.
|What if core &lt; NOMINAL, and cpu &gt; NOMINAL, what is the step?
You should have seprate steps for core and cpu.
|done
|done
|done
|done
|This structure defines the registers layout of an I2C controller.
The i2c_ctlr structure that I defined in the driver defines the registers that the driver actually uses. It is a subset of the actual registers. For example, packet_status and int_mask register are not used in the driver. So we can use the same structure.
|done
|originally copied from some other i2c driver.
Delete the attribute. done
|Please see my comment in tegra_i2c.h
|done
|mostly done, except that I need to pass FUNC_RSVD2 (instead of RSVD1) to DDC pingroup.
Need Simon's help to debug this.
|done.
delete the comment. The code should be self-explanatory.
|done.
I have to pass X15 of the rate to get what I want.
Need Simon to debug this.
|done.
Have to move i2c_reset_controller() routine before this routine.
|exactly 80 col. Is it not OK?
|good idea. done.
|done
|done
|I deleted reset_tx_fifo and reset_rx_fifo. They are not needed, like you said.
|routine is removed.
|done
|done
|Exactly 80 col. Is it not OK?
|done
|done
|done
|done
|done
|done
|will set flags, since = {0} is removed.
|Those are defined in seaboard.h. That file will be submitted in another CL.
Note: different board has different I2C PINMUX configurations.
|tpm_tis_i2c driver needs it.
|On i2c bus, i2c slave address is shifted left 1 bit, then bit 0 is used to indicate if the transaction is for write (bit 0 = 0), and for read (bit 0 = 1).
|done
|Some i2c devices don't work that way. Those devices operate at one address, one byte mode.
I provide i2c_read/write_data() routines for one address, many bytes device.
|my mistake. done.
|Same comment above in i2c_read().
|Will do.
Is there a convention to use big letters or small letters for hex numbers?
I will also convert those hex numbers to big letters to be consistent with others.
|Done.
|Done.
|Done.
|Done.
|I try to match the names as in Tegra TRM.
|I try to match the names as in Tegra TRM.
|Done
|Done.
|They are all gone. And, they are created when i2c_init_board() is called.
|I am not clear what you meant.
This routine is to select the pinmux group based on the pinmux_config. (I will rename the variable pin_mux to pinmux_config, so it reflects the purpose of that variable)
|Done.
|Done.
|I don't quite understand.
The routine is to activate or tristate the pins selected by pinmux_config.  (I will rename the variable pin_mux to pinmux_config, so it reflects the purpose of that variable.)
|Done.
|Done.
|Will change after the CL is approved.
|The routine is to prepare the 3 headers required by packet mode transaction.
|To be consistent, I removed the comments.
|Done.
|Done.
|Done
|Done
|I hope I have fixed it.
|Done
|Done
|Done
|Done
|Actually, chip refers to the i2c slave address, not the i2c controller.

The i2c controller to work on is based on a global variable, i2c_bus_num.

I can not use tegra_i2c_ctrl * for all 4 controllers, because dvc i2c controller's register offsets are different from the other three i2c controller's.
The 4 controllers are initialized in i2c_init_board().
|done
|cone
|done
|done
|done
|Will do.
|clock_disable() is already defined in arch/arm/armv7/tegra2/clock.c. I just &quot;extern&quot; it here.
|The idea was to have the i2c not consuming any power unless it is being accessed. So I re-init the controller for every transaction.

I will try to implement your suggestions: leave the device enabled and clocks running; and only re-init the controller when error occurs.
|done
|done
|I will use bit fields in struct to do bits manipulation.
|Removed those defines in warmboot.h
|The array is gone
|The assemble code will be in the next CL.
|done
|Anton,
I will work on your suggestion in the future commit.
|Removed here.
|done
|Let's keep the old way (use u8).
Reason: what I understand is that, if keeping them as u8, there will be 4 up-converting to u32 in sbox[tmpx] per loop; if change them to u32, there will be 4 up-convertions (cast to u32 in expkey[]) in the beginning of the loop, then another 4 down-convertions (cast to u8 at the end of the loop).
|Let's postpone this. I need to understand the code further to add comments. This piece of code was taken from fastboot, and is modified (by me) to conform to u-boot coding standards.
|I wish I have the knowledge to comment on the code. I need to understand the code to add any comments. This piece of code is taken from fastboot and I modified it to conform to u-boot coding standard. The original code is written by Karl malbrain, and is placed in public domain.
|done
|done
|The routine shifts one bit left (from high index element to low index element of an u8 array).
I have modified the code so it loops from high-index to low-index.
|done
|done
|I don't understand the difference between emrs and mrs, but from the original file: /// Specifies the MRS command to reset the DDR2 DLL, NvU32 EmcMrsDdr2DllReset;
|will do.
|I can #undef the other two, and remove the '1'.
But, if RANDOM_AES_BLOCK_IS_PATTERN is defined, it has to be defined with some value.
|done
|done
|done, except RANDOM_AES_BLOCK_IS_PATTERN is also used to be the pattern.
|done
|done
|well, it is from old fastboot code. Yes, you are right, I should improve it to get rid off the nv_fuse_hal stuff.
|Again, this is from old fastboot code.
I am changing it to return an u32 value, assuming that to get an u64 random seed is to call this (new) routine twice.
|Yes, it is in the crypto library.
I can not change it just here now.
I need to change the name in the crypto library first.
|Will use roundup().
|??
|done
|This piece of code is not executed by u-boot. U-boot puts this piece of code in the carvout area. Kernel will move it to a safe area, and stores that address in SCRATCH1 register.
When resuming from LP0, Bootroom will move the code addressed in SCRATCH1, move it to IRAM as specified in the header.destination , and start executing the code at the address specified in the header.entry_point.
As this code is executed in Bootrom, the code is executed by AVP.
I can not call other routines, as all codes must be in one piece (from wb_start to wb_end), and all must be in AVP codes.
|It is guaranteed 2 us. The branch instruction is &quot;ble&quot;, so it will wait until the current count (r2) is greater than the original count  + 2 (r3).
|Please see my comment above. I can not call subroutines here.
In the future, I like to write this code in C. But, I may need your help to generate AVP codes for this routine, and not to use local variables, as I don't know how Bootrom, which will execute this routine, will setup stack and frame registers.
|I can put it in tegra2.h. But I can not put it as a CONFIG parameter. Reason: the define is used in assembly code, and the assembler only likes certain C specific code, #define is one of them.
|Yes, they are all used in the warmboot_avp.S.
Even we have support for some of this stuff in power.c, clock.c, etc., I can not use them, as this is for assembly code.
Note that this .h file, included in warmboot_avp.S, should only have #define's, as assembler only recognizes #define.
|done
|done
|done
|done
|I will add:
/*
 * Defines the number of 32-bit words provided in each set of SDRAM parameters
 * for arbitration configuration data.
 */
|ok
|done
|done
|It is removed.
|done
|done
|Using #TEGRA_LP0_ADDR, for example, directly does not work. I get &quot;TEGRA_LP0_ADDR&quot; if I use that way.
As suggested by Anton, I got this QUOTE() macro from u-boot-config.git.
I have to use an extra indirection to force the evaluation of TEGRA_LP0_ADDR, then apply the # operator, then I get &quot;0x1C406000&quot;
|No, the &quot;lp0_vec=&quot; is needed.
To avoid the naming confusion, I will chagne this &quot;lp0_vec&quot; to &quot;lp0_args&quot;,and the one in regen_all.
|It works. Will submit a new patchset. Thanks.
|No. The old version one (on the left) is for Assembly code (for SOBJS). This time the warmboot_avp.o is for COBJS.
|Yes, I will deal with it.
|Could you be more specific? Are you suggesting to use bf_XXXX macros, instead of C's struct bit-field?
Last time I used bf_XXXX macros in the other file (warmboot.c), Tom's comment was that bf_XXXX may have problems upstreaming. So I changed to use C's bit-field in warmboot.c and apply the same approach here.

If both ways may have problems upstreaming, please advise a better way.
|The original assembly code checks if the warmboot code is running at the expected address, AP20_WB_RUN_ADDRESS. It is difficult to implement the same functionality using C only. Also, I don't think we need to do such strict check.

If no one disagrees, I will remove the FIXME.
|Will do.
|I can reduce to just one instruction. Will submit another patchset.
|Could you correct the grammar and spelling of this comment? Thanks.
|Is this line change related to this CL (turning off vbus)?
|You may want to clear the corresponding vbus_gpio field to 0 for these error conditions (failure on gpio_request and gpio_direction_output).
Same for the TEGRA_GPIO_USB1 case above.
|Why inline is needed?
|&quot;return err&quot; is sufficient.
I have been asked before to fix this kind of codes.
|To be completely correct, I think you should check the returned val with -1 first, then cast it with uchar, then do the bit OR operation. (But, you need to declare val as int.) This is to prevent that all bits read are all 1s.
|Do not use assignment in if condition. (If you run checkpatch.pl, you will see this ERROR.)

Also, could you pass the SMx parameter to this function to make it more general? Or, rename this function to pmu_set_sm1_pwm_mode()?
|Kernel will not use carveout (@0x38000000, as it is removed from physical memory). Also, it will not use lp0_vec (as it is reserved), and FB (@0x37600000, as it is removed from the bottom of physical memory).

From the kernel log (based on 10MB of FB):
[    0.000000] Tegra reserved memory:
[    0.000000] LP0:                    1c406000 - 1c407fff
[    0.000000] Bootloader framebuffer: 00000000 - 00000000
[    0.000000] Framebuffer:            37600000 - 37ffffff
[    0.000000] 2nd Framebuffer:        00000000 - 00000000
[    0.000000] Carveout:               38000000 - 3fffffff

And, the memblock with u-boot of &quot;mem=384M@0M, nvmem=128M@384M, mem=512M@512M&quot;:
# cat /sys/kernel/debug/memblock/memory
   0: 0x00000000..0x17ffffff
   1: 0x20000000..0x375fffff
# cat /sys/kernel/debug/memblock/reserved
   0: 0x00000000..0x00000fff
   1: 0x00004000..0x0067023b
   2: 0x1c406000..0x1c407fff
   3: 0x35ff4000..0x35ffffff

The memblock with &quot;mem=1024M@0M&quot; u-boot:
# cat /sys/kernel/debug/memblock/memory
   0: 0x00000000..0x375fffff
# cat /sys/kernel/debug/memblock/reserved
   0: 0x00000000..0x00000fff
   1: 0x00004000..0x0067023b
   2: 0x1c406000..0x1c407fff
   3: 0x35ff4000..0x35ffffff
|Are you worrying that since lp0_vec is currently inside that hole, kernel may start using it before tegra_reserve()?
It is a concern, but in reality, tegra_reserve() is called very early in kernel, and I am testing an u-boot that sets &quot;mem=1024M@0M&quot;, and lp0_vec is not been destroyed before tegra_reserve() is called.
|Will do in the next patchset.
|This is copied from Ventana's code.
I think this is because that the first 4k bytes are used by ARM's reset/interrupt vectors. By reserving the 4k, it is safer that kernel won't step into this range.
|Robert,
Should it be 1366, not 1368?
|tegra_lp0_vec_size and tegra_lp0_vec_stare are from cmdline &quot;lp0_vec=0x2000@0x1c406000&quot;, from the current u-boot.

The lp0_vec_size can only be specified by u-boot, because it creates the warm_boot code.
|Will do in the next patchset.
|Will do in the next patch set.
|I think we want to allocate a big enough framebuffer for all boards. Arthur has the most pixels (1366 * 910),so it is used for the formula. And, Robert just responded to my question about 1366 vs. 1368. His answer is that 1368 is divisible by8.
So I will change the equation to be 1368*910*4*2 in board-seaboard.c
|I did a rebase before the patchset #3.
And this is from the result of that rebase.
|See my comment in board-seaboard-panel.c

I will change the formula to 1368 * 910 * 4 *2.
|On the 2nd thought, I can not use memblock_remove. The lp0_vec is specified by u-boot, I can only reserve it, so the area won't be used by kernel.
|I think if we memblock_reserve it, we can memblock_free it later. Since we are not going to free it, I can try to see if memblock_remove works in our case.
|good point. Will do this.
|The new frame-buffer should be at 0x37680000.
Same for all .dts files.
|This line is redundant. Can you remove it?
Otherwise, LGTM.
|Nit: You do not need to purposely set this field to 0.
Same for the following xcvr_effect line.
|Could you put some comments here for setting it to 13?
|Nit: You do not need to purposely set this field to 0. Same for the following xcvr_effect line.
|add &lt;TAB&gt;.
|add &lt;TAB&gt;.
|add &lt;TAB&gt;.
And, add &lt;TAB&gt; to all other lines that you have deleted _ENABLE in your patchset #5.
|add &lt;TAB&gt; here too, such that all \'s are aligned.
|Combine these 2 lines.
|Combine these 2 lines.
|And, these 2 lines.
|Also, combine these 2 lines.
|These 2 lines too.
|Please add a &lt;TAB&gt; when deleting _ENABLE, so the texts are still aligned. Same to the following lines that you removed _ENABLE.
|What happened here?
They were corrected in Patch set 1, but in patch set 3 they were reverted back.
|-&gt; Modification
|Sorry for the nitpicking, please add &lt;TAB&gt; to align &quot;\&quot;.
|add &lt;TAB&gt; here too.
|Sorry for the nitpicking, please add &lt;TAB&gt; to align &quot;\&quot;.
|add &lt;TAB&gt; here too.
|I don't think I will change the names of these 2 registers back to _rst_* in this patch.

The changes will involve several C files, like,
  - cpu\arm720t\tegra114\cpu.c,
  - cpu\tegra-common\clock.c, and
  - cpu\tegra20-common\warmboot_avp.c

They are not related to this patch (T114 warmboot).

I will change those register names in this CL: https://gerrit.chromium.org/gerrit/#/c/50866/
|T114's warmboot code needs a very different header. This union thing is one of them that are different from T20/T30's header.
|I will move some #defines to clk_rst.h, pmc.h, or will reuse some #defines if those are already defined.
|will fix.
|I believe each arch-tegraXXX should have its clk_rst.h, because each soc has different clk_rst registers, especially newer soc tends to have more registers.

I will copy all #defines from arch-tegra/clk_rst.h to this file (in arch-tegra114 folder), and move some #defines for WB0 to this file also.
|will delete these *_RANGE #defines.
|will fix.
|will fix.
|Yes, this needs to be T114-specific.
For one thing, pmc_clamp_status register (offset 0x2c) is different for T114 from T20/T30. Also, there are more pmc registers in T114.

Please see my comments on clk_rst.h
|https://wiki.nvidia.com/wmpwiki/index.php/Tegra_T35/T114_Bringup/T114_Memory_Cfgs
|Should be from:
T40T E1611 Fab4 Dalmore A01P 1866 792MHz.
|Filename: E1611_Hynix_2GB_H5TC4G63AFR-RDA_792MHz_r403_v03.cfg
|I see other i2c drivers, like omap24xx, omap1510, sh_i2c, tsi108_i2c, etc., do one byte a time transfer also.
I don't remember what devices require this. But, this at least works for all devices at the time when we developed this driver, at Tegra2 time.

I can change the functionality of these 2 routines, but it may take lots of testing to make sure all platforms, including Tegra2, Tegra3, and Tegra4 based platforms, are still working.

Tom, what is your take on this?
|This is the behavior of our i2c_read/write functions. It increments    address for each byte access. I don't want to change the function to do multiple byte transfer because other drivers which call these functions may break.

So I create 2 new functions, i2c_read_mult and i2c_write_mult, to satisfy what tpm i2c driver requires.
|Which PMIC that does not work?
Any suggestions to workaround this issue?
|good idea. Will do.
Thanks.
|will fix it.
|I see other i2c drivers, like omap24xx_i2c, omap_1510_i2c, sh_i2c, tsi108_i2c, etc., use the same way (one byte one address approach).

I can use the #ifdef CONFIG_TEGRA_I2C compiler option to workaround this issue, but feel that it will become messy if we need to #ifdef CONFIG_DRIVER_OMAP1510_I2C, CONFIG_SH_I2C, CONFIG_DRIVER_OMAP24XX_I2C, CONFIG_TSI108_I2C, etc. for different drivers.
|Tegra has legacy i2c_read/write functions that DO NOT transfer multiple bytes with single address. So we create 2 new functions, i2c_read_mult() and i2c_write_mult() to satisfy tpm i2c driver.
|Yes, I did this way in case we ever need to build the u-boot without using DT.
|Will fix.
|I will add #ifndef CONFIG_OF_CONTROL around these.
|Please see my comments on CL 63475, that I repeated here:

I can use the #ifdef CONFIG_TEGRA_I2C compiler option to workaround this issue, but feel that it will become messy if we need to #ifdef CONFIG_DRIVER_OMAP1510_I2C, CONFIG_SH_I2C, CONFIG_DRIVER_OMAP24XX_I2C, CONFIG_TSI108_I2C, etc. for different drivers.
|will remove this property.
|I will add tegra, if this property will be approved.
|This is for i2c driver that needs to use i2c_read_mult() and i2c_write_mult() to do multiple byte accesses for a single address.

As for the device tree binding document, I will create tpm-slb96x5-i2c.txt in tpm folder, and describe the use-rdwr-mult property there.
|Do you need to change (or add) copyright year to this file?
|Done in patch set #2.
|will fix it.
|will fix it.
|My board has a STM32L151R8T6.
R8 has 64KB flash, and RB has 128KB flash.
I think if the code runs of 64KB flash, it should run of 128KB.
I will fix it to say it is an STM32L151R8T6
|pmu_tpschrome.h is required because charge_keep_power_off function is declared there.
|will do.
|Good catch.
Will fix.
Thanks
|WIll fix it.
|will do.
|The PMIC on nyan board requires a 9 seconds timeout.

Actually I am preparing a new file called chipset_tegra.c to replace chipset_gaia.c, which will not have #ifdef BOARD_nyan. The new file will solely be used by nyan.
|Correct, nyan does not use PP1800_LDO2.
But, since the signal (PA1) is tied high to +1.8V_STBY_KBC, so  it is always high. The code in chipset_gaia.c will not be affected if the signal is always high.
Otherwise, I have to #ifdef BOARD_nyan around the places that use PP1800_LDO2.

But, the bottom line is should I use chipset_gaia.c or not.
|XPSHOLD is used in nyan, and is named as &quot;HOLD&quot; in schematics.
It is tied to 1.8V_VDDIO.
|I will fix this by following the pit/ec.tasklist.
|yes, only if I am not using chipset_gaia.
|I don't know what is Gaia chipset.
nyan is following puppy, and for puppy, I was told to follow pit.

Anyone can suggest what file should I be using?
|The pmic (AS3722) that nyan uses needs 9 seconds to shut the power off.
I have tried 8 seconds, 8.5 seconds and they don't work.
|I will remove this line.
As for adding the tests to nyan, I will submit another CL after I learn how tests are performed.
|2013 copyright year
|2013
|2013 copyright year
|pmt_strap_opt_a is no longer here.
It is at 0x464 of PMC controller now.
|There are more/different registers in T124 PMC controller.
For example, scratch56 is changed from 0x340 (in T114)  to 0x600.
|This and MEMORY_TYPE_FORCE32 are directly copied from fastboot. They are not used in u-boot. I will remove them when I am ready to submit my WB0/LP0 code.

Tom, you can remove this file for now, as this file will be quite different for T124 WB0.
|See comment above. Will remove it.
|There should be gap (6 32-bit) between pmc_cntrl2 and pmc_io_dpd3_req.
|Good suggestion. Make it clear to read.
Will fix it.
|I forgot. Will fix it.
|I will file a bug to track this.
|Will update. Thanks.
|The previous for loop was mixing checking of STS_RDY and FIFO error inside the loop.Now, the loop is only to check for STS_RDY; and FIFO status is checked outside the loop. So it is fine to move the FIFO checking outside the loop.
|I think my equation is derived from the same equations you stated.
Also, it should not come here when bytes==0.
|I can move it down.
Do you want me to do the same to Venice.h? In another CL.
|I can remove them. Do you want me to do the same to Venice.h?
|It is hard to split this change.
I will come up with a better subject line.
|I will add the change in device tree binding.
It is not used in the kernel.
|I added #ifdef CONFIG_TEGRA_LP0 for defining of ft_system_setup().
|Coding wise should be fairly easy. It is the testing that may take lots of work such that I need to be sure that LP0 suspend/resume still works for all platforms.

For T114 and T124, testing should be easier. For T20/T30, I need to find working OS/kernel images.
|Ok, I will move the warmboot_prepare_code to board_late_init(), and check the warmboot codes for all platforms.
|Now I understand why I cannot use memalign, it is not because of relocation; it is because the call to prepare WB code is before initr_malloc() is called.
I will add a comment to explain this.
|will undo this.
|Good point. Will move it. Thanks.
|Yup, I see the growing lp0 vecs.
I will fix it.
Thanks.
|Will do.
|I can add a separate env. variable, but may take me extra time.

As I explained in the &quot;Add comment&quot;, this CL is just to bring the T124's lp0_vec in extra_bootargs to the same as in T114's.

The real solution is to add lp0_vec in the kernel's devicetree which I am almost done.
If you still want me to add a new enviroment variable, it will only delay the real solution.

Or, I can abandon this CL, and submit a new CL that adds lp0_vec in kernel's devicetree.
The drawback is that if kernel wants to use lp0_vec from cmd_line, there is none.
|I think the function that I intended to do is too specific to be put in the lib/string.c.
The function is to find a substring that begins with &quot;str2&quot;  and delete that substring from the &quot;str1&quot; string. The substring to be deleted begins with the &quot;str2&quot; header till the space that separates the next substring.
I should have put more descriptions to the comments of this function, and I will.
|will do.
|There are 2 reasons to delete &quot;lp0_vec=XXXX@XXXX&quot;. One is the growing vectors issue that Tom has pointed out that each time user does &quot;env save&quot;, the &quot;lp0_vec=&quot; will be saved to extra_bootargs. The 2nd reason is that the previous release has &quot;lp0_vec=0x2000@0xbdffd000&quot; substring already in the extra_bootargs variable. I need to delete this old one.
|This CL is to bring the T124 u-boot code for warmboot supprot to the same level as T114.
I do plan to have another CL that will change kernel's device tree to include the lp0_vec.
|Will do. Thanks.
|will do.
|No, I cannot.
The tegra_lp0_addr has to be determined before the relocation.
|I will change that. Thanks.
|Unfortunately that I have to do it this way.
The older arch/soc (T20/T30/T114) codes use &quot;TEGRA_LP0_ADDR&quot; and use it as a constant, and I have to use the existing codes in board/nvidia/common/board.c.
|This delay is no longer needed.
This delay is the main reason for this fix.
|You got the point.
I know that EC has the pull-up on CS line.
But I am not sure about the SPI ROM's CS line.
I will try to set the CS output high, then resubmit.
Thanks.
|Vadim, sorry. Our emails crossed each other.
NORMAL means no pullup, no pulldown. All SPI CS lines are defaulted to have NORMAL mode in our pinmux init settings.
Also, there is no API to read the pullup-pulldown state.
|How about T20/T30 boards?
|Do you need to worry about T20/T30 boards?
|How about NORRIN_ERS?
|You are right, although the next statement &quot;&amp;=3&quot; will do the same masking.
I will fix it.
|Done
|MASK has 4 bits.
ram_code[1:0] selects which sdram parameters to use in BCT.
Will add comment
|will add comment.
|You are right. Forget about T20/T30.
Will fix it.
|Will do.
|Done.
|Done.
|Done
|done
|done
|I will do the checkings of Manuf and Device in the next CL.
For this CL, I will add TODO of those checkings.
|Decided to add checking of manuf and device names to determine the battery type in the patchset #3.
|I will remove cut-off command from this CL.
I need to do more investigations on cut-off command.
It seems the cut-off command only exists to 3S battery.
|Decided to keep cut-off command in this CL.
|WIll leave it as is now.
Will have further discussions.
|I agree with the name of this CONFIG.
Will rename it to CONFIG_BAT_TEMP_RANGES_NON_CONST.
|Will use strcasecmp(). Thanks.
|You are right, will use the pointer directly.
It will require changes in battery_vendor_params() routine.
|Specifying INPUT is fine. It means the pin can be read.

From Tegra124 TRM, 
E_INPUT:
0: the pad’s input receiver is disabled.
1: the pad’s input receiver is enabled.
|Same here: it's better to check for EC_SUCCESS.
|It's better this way:
if (power_wait_signals(IN_XPSHOLD) == EC_SUCCESS) {
|There should be a do_encode_list() before do_pack_list().
|Is it possible that c(0, scratch10, 31:0) gets executed after any of these three s(...) statements?
Do you need a dmb() after c(...)?
|Do you need a dmb() here?
|If the first 3 entries do not apply to blaze, you should remove them.
|In nyan, cutoff means no voltage coming out from battery. So system is dead until AC adapter is plugged in.
|The last sentence (Multiplying by 2...) is not needed.
|Since m is getting bigger each loop, you can break the loop here.
|After reading it more carefully, diff cannot be negative. So, declare diff as u32 is fine.
|What if AP raises CS (SPI NSS) after here and before state = SPI_STATE_SENDING?
|What if AP raises CS (SPI NSS) after state is set to SPI_STATE_SENDING?

Same thing in the next routine, spi_send_response_packet().
|Same question here.
|According to our BootRom guy, BR does not set PLLP_OUT2_OVERRIDE bit, so PLLP_OUT2 is using an internal divider, which is a divided by 2 divider.
|I just asked our BR guy, he said sclk is programmed to use pllp_out2, which is 1/2 of pllp, and AVP is running at 204Mhz. So comment is wrong, should take out sclk.

SCLK_BURST_POLICY register:
6000:6028 = 20000040 (SWAKEUP_RUN_SOURCE=4=PLLP_OUT2)
|Actually AVP will resume after 20 ms then write orig_timer.

If you read the bug, you will see that &quot;this issue can be easily duplicated after suspend resumed and then let system enter suspend mode again immediately&quot;.

Supposedly, kernel should write 17 to cpu_pwr_good_timer before entering suspend if passed rate is not the same as tegra_last_pclk. (see set_power_timers() of kernel code.) And, I see that set_power_timers() is repeatedly called (about every 100ms).

I think what happened is that if system enters suspend again before orig_timer is written (in warmboot code) and set_power_timers() has not been called (in kernel code), the cpu_pwr_good_timer register is in wrong value. So when the system resumes, the wrong pwr_good_timer value is used.

By writing of orig_timer early, we avoid the situation that I described above.
|I just checked, our nvtboot code has this patch: nvtboot: Removed unneeded 20 msec delay.
And, that happened on May 22, 2014 5:10 AM.
|BC_SCLK_THRESHOLD has 8 bits (23:16). So it should be 0xff.
|What is the purpose of defining I2C_BUS_CLEAR_CONFIG_BC_TERMINATE_IMMEDIATE?
And defining it as 1 confuses people. TRM says BC_TERMINATE:0 = IMMEDIATE.
|Will do.
|Will fix.
|Now I know what is the purpose of the macro. Will fix it.
|I think that is fine. But, I will change it.
|There are several other places that have this kind of while loops without checking for timeout.
For &gt;1000 loops of cold reboot tests that I ran, I did not encounter one hang.
|Some are only used in this file. Some can use the same #define defined in addressmap.h.
|kernel before entering LP0 should set the re-start address in scratch register 41.
|BootROM will bring back sdram before jumping to our lp0_resume() routine (BR will verify if the digest in the header is correct, before moving the lp0_resume code 0x40020000).

AFAIK,BR already handles MTS related stuff.
|As Joseph Lo stated that he then switched CPU to EL1 before jumping into kernel's cpu_resume function.

We can discuss to have a more flexible way.
|I will discuss with Joseph.
|Yes, BR has restored sdram back, When I was debugging lp0 resume code, I briefly checked a few dwords to see if I can read/write memory. And, there is no problem.

Tom, I have a question. sdram_lp0.c handles memory types of NvBootMemoryType_LpDdr2 and NvBootMemoryType_Ddr3. And, your LPDDR3 bct is actually of NvBootMemoryType_LpDdr2. Do you think if LPDDR3 the same as LPDDR2?
|Larry told me that you want to talk to us about the lp0 flow in a meeting. We can talk about it in that meeting.
|This is the way I am aware of.
What's in your mind?
|This piece of code does not live in the BCT. This code is in the file system's /lib/firmware/tegra13x/tegra_lp0_resume.fw. Kernel will retrieve the resume fw before it enters suspend.
|That is basically the flow. Bit 0 of SCRATCH0 tells BR to do an LP0 resume.
And, SCRATCH41 tells lp0 resume code where to resume to kernel's space.

Also, in the cold boot path, coreboot will pack sdram parameters into various scratch registers (see sdram_lp0.c). So during LP0 resume, BR will then restore sdram parameters based on the saved scratch registers, then initialize the sdram.
|If VBSD_BOOT_REC_SWITCH_VIRTUAL is set to vb_sd-&gt;flags, the pressing of physical recovery button won't be recognized as an 'YES' in VbUserConfirms() function in vboot_reference/firmware/lib/vboot_api_kernel.c

		default:
			/* If the recovery button is physical, and is pressed,
			 * this is also a YES, but must wait for release.
			 */
			if (!(shared-&gt;flags &amp; VBSD_BOOT_REC_SWITCH_VIRTUAL)) {
				if (button) {
					VBDEBUG((&quot;%s() - Rec button pressed\n&quot;,
						 __func__));
	                                rec_button_was_pressed = 1;
				} else if (rec_button_was_pressed) {
					VBDEBUG((&quot;%s() - Rec button (1)\n&quot;,
					 __func__));
					return 1;
				}
			}

In kitty, there is no EC keyboard, so we have to use physical recovery button as a confirmation to enter DevMode.

Wait, I re-read your comment. Are you saying that in the else part I need to do the checking of CONFIG_PHYSICAL_REC_SWITCH?
Or, clear the VBSD_BOOT_REC_SWITCH_VIRTUAL if CONFIG_PHYSICAL_REC_SWITCH is set?
|Got it. Will change it.
Thanks.
|If VB_INIT_FLAG_VIRTUAL_REC_SWITCH is set, then VBSD_BOOT_REC_SWITCH_VIRTUAL is set in VbInit(), which causes the pressing of physical recovery button not been recognized.
|Will do. Thanks.
|Will do.
|good point. will do.
|Will clean up like you suggested. Thanks.
|Like I explained: the screen comes up about 5-6 seconds after reset. If we set it as 4 seconds, ctrl-u is missed by coreboot. (ctrl-u is sent from USB-KM232 cable.)
|As described in the comment, those devices without lid, should not shut down after EC reboots, so I think that adding the check (if has_lid) should not affect the functionality.

Do you have other suggestions?

BTW, I have a question about this function: so the function is to power on the device if lid is not open, but the actual lid is still closed, so the device will eventually be shut down, correct?
|To make the check less impacting to other devices, what if I check if the device is &quot;nyan_kitty&quot;?
|will fix.
|Actually no CLK_RST register is read. So, remove #include of clk_rst.h
|Will remove.
|Will remove.
|You're right. Will put it back.
|Will remove it.
|From T210 TRM. Will add comment.

8.9.1.2 Deep Sleep Exit
5.a. Set the E_INPUT bit of the PINMUX_AUX_GPIO_PA6_0 register to Logic 1.
|Will add.
|Let me investigate.
|Set ALLOW_TX_WR_ACCESS here also. Note shorten the names of these 2 #define.
|Let me study about register 1, and then update.

About VREG setting, currently kernel (BPMP actually) sets CPU rail to 0 (but keep GPIO5 on) before going to suspend.
I would prefer kernel keeps VREG, but clears GPIO5 to 0 to turn off CPU rail.

Joseph, please comment.
|Tom, good catch.
I remembered when I first debugged this, I knew GPIO5 was kept high by Kernel (and uses VREG to turn off CPU power) when entering LP0. But, decided to turn GPIO5 on resuming path anyway. I must have mis-typed the value.

As for other things done by pmic.c, kernel can do those things when it resumes. This code is just to bring up CPU.
|Actually, Joseph told me to only power up CPU0 (just like in coreboot when using ATF).
I am assuming we are using ATF.

If we are using secmon, we may need to bring up 4 CPUs.

Joseph, please comment.
|Shorten some names, so the line &lt; 80 chars.
|Joseph,
How does BPMP FW deal with this (different PMIC)?
|I debugged again (wrote the code long time ago), and both clocks are needed.
|will do.
The POR value of CPU_ACK_WIDTH is 0x200. HW recommends to use 0 for the CPU_ACK_WIDTH field.
|will do.
|will do.
|As explained above, this CL is to change the POR value of CPU_ACK_WIDTH. There is no need to change the POR value of NONCPU_ACK_WIDTH (which is 0x700).
|We don't know. But with this CL, we still see issues on EVT2 boards.
|Will do.
|It may seem redundant, but to be complete, can you also save the high part of BOMs?
|For this project, it is not important.
|Wondering if these defines are better placed in padconfig.h of  tegra210 include.
|Wouldn't it be better to use sizeof(int) instead of 4?

Or, just use (unsigned char *)TEGRA_APB_MISC_GP_BASE + 0xF4.
|The address becomes 0x70000c60 = 0x70000800 + (0x118 * 4), and that is not what you want.
|Consulted with Laurent, and will re-phrase the commit message. It is not leakage, it is to disable COMP circuitry.
|Tom,
While working on the same procedures for LP0 resume, I found that I need to make sure that writing to those SDMMCx registers has completed then SDMMCx clocks can be disabled.

I read SDMEMCOMPPADCTRL register back, then disable SDMMC clock.
|yes, they all return to 1.
|Tom,
I was playing with these bits yesterday, and found that if I reset these 2 clocks (SDMMC1 and SDMMC3), and un-reset these 2 clocks again, the VENDOR_IO_TRIM_CNTRL and SDMEMCOMPADCTRL registers are reset back to default values.

I think we need to ask SysEng if we need to keep these 2 clocks un-reset to have the SEL_VREG bit and PAD_E_INPUT bits maintained their values.
|1.25 should be 5.12
|The 50 ms delay that I added during the debugging was inside the power_off() routine, before calling this (chipset_turn_off_power_rails) routine.

And, 50 ms is too long. (That was used just to see if the PMIC_SHDN issued by EC theory was correct or not.) Now we set 3.3v at slot 2, and SOC and RTC at slot 7, so the max. delay is (5.12 ms * 5) ~= 26 ms.
|Can you clear the ONOFF_CFG2_SFT_RST_WK bit to 0 before we set CFG_SFT_RST? so we don't reboot the system.
|You can optimize it by ORing the 2 bits then ANDing with status.
|i2c_clock is already enabled in line 589.
|return with i2c_clock still enabled.
|You should call tegra_i2c_wait_for_config_load().
|We should use &quot;nvidia,require-cldvfs-clock&quot;.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Aaron &amp; Furquan,

This CL and the previous 4 CLs are my workarounds for TPM-less foster.
Unfortunately I still need to do a minor change to tis.c.

I tried to enable MOCK_TPM, and also use VBOOT_VERIFY_FIRMWARE (instead of using VBOOT2), and in all those cases, tpm_transmit() will be called, and code will hang at ASSERT(chip-&gt;vendor.send) statement.

The proper fix may be in some upper layers that should stop accessing TPM when tis_init() has failed.
But I am not that familiar with vboot_reference to make such changes.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned

Abandon this.
Use MOCK_TPM instead.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Abandoned

Abandon this.
Use MOCK_TPM instead.
|Patch Set 1:

Joseph,
I think you meant 210941, https://chrome-internal-review.googlesource.com/#/c/210941.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Patch Set 5 was rebased
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Abandoned

Already in current code.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1

Jimmy caught that in commit message the clock is set to 24 not 2.4 Mhz.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

(1 comment)
|Abandoned

As Tom suggested, code to set QSPI to 24Mhz is already in.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

I can create a new CONFIG_NO_TPM instead, and select that only for the foster board. So all other boards still work.

But, can a chromeos product run without TPM? I know the next foster board will have TPM.
So this CL is only a workaround fix so we can continue the work to load kernel.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

Aaron,
Cannot get MOCK_TPM=1 to work on my foster board. I think it is hanging inside setup_tpm().

Since this CL is a HACK (the new foster board will have TPM), I will add HACK to the commit message, so we know this CL won't merge to the tree.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 7.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 1:

I am wondering if this is t210 specific. Otherwise, why we don't need  to do this for t132?
|Patch Set 1:

I am wondering if this is t210 specific. Otherwise, why we don't need  to do this for t132?
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

add a missing secure_boot.h file.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 1: I would prefer that you didn't submit this

(4 inline comments)

The changes in suspend.c is riskier, and I do not understand about that. Maybe we will pass it on to Olof or Colin to review it.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

Talked to Jimmy, and we both feel that if we can keep clk_lock_save() and clk_unlock_restore() as macros, but move them to clock.h, then you don't need to change other source codes to add &amp; to flags. Also, it keeps the coding style the same.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(3 inline comments)

Your code does not differentiate T20 or T25. Do you intend to set 1.3v to core for T20 also?
|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Patch Set 1: (2 inline comments)

See my comments.
Will have another patchset coming.
|Uploaded patch set 2.
|Patch Set 2: Verified

Improve i2c driver to do initialize controllers only once at init time.
|Patch Set 2:

And, leave all controllers enabled, and clocks running.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 2: (34 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Verified

Rearrage tegra2.h as suggested by Tom. Also, reverted include/configs/seaboard.h to the base.
That will become a separate CL.
|Patch Set 4: (36 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified

In clock.c, I have to change the initialization of pll_rate[CLOCK_ID_OSC] (with a FIXME) so the i2c driver can run. Since i2c driver is the only one (currently) which is using CLOCK_ID_OSC, I think it is safe to change the initialization code.

Simon, since you are going to debug the clock_start_periph_pll(), please debug the setting of pll_rate[CLOCK_ID_OSC] also. Thanks.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Patch Set 7:

Rebased.
|Patch Set 7:

I thought I add dependancy so http://gerrit.chromium.org/gerrit/2169 (enable i2c driver) should be merged after this CL (add i2c driver).
|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 1: Abandoned

This is a test.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified

Please note that the actual warmboot code is in binary format (wb_code[] in warmboot.c). In the previous code base (v2010.09), the warmboot code is in assembly.
|Patch Set 3:

Simon,
I will submit separate commits for crypto and board.c/warmboot.c codes.

I am not clear about your comments about emc.h, fuse.h, warmboot.h, etc. Do you mean to have separate commits for each .h files?
|Patch Set 3:

Hi Simon,
The files, emc.h, fuse.h, and gp_padctrl.h, are used by warmboot.c. They are created so the warmboot code can access tegra registers that are defined in those .h files.

So, I will have 2 CLs, one for crypto first and other for warmboot code.
|Patch Set 3:

Hi Simon,
Maybe creating the emc.h and gp_padctrl.h file are overkilled.

warmboot code needs to save dram parameters to pmc scratch registers for Bootrom to use when resuming from LP0. Only one EMC register (fbio_spare) and two GP_PADCTRL registers (xm2cfga_padctrl &amp; xm2cfgd_padctrl) are used for this purpose. But, to be able to access these 3 registers using the latest method, I have to define all other registers. That's why you see these 2 big .h files. The majority of registers are only defined but not used.
|Patch Set 3: (10 inline comments)

I will abandon this CL, and submit a new one with just the warmboot code.
|Patch Set 3: Abandoned

Will submit a new CL with warmboot code only.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

A new one will be submitted.
|Patch Set 1:

Jordan,
This change will affect all boards. Is this what you want?
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (8 inline comments)

Patch set 3 is coming soon.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified

Rebased.
|Patch Set 4:

I am aware the build break, and working on a solution.
|Patch Set 4:

There is an out-of-tree build break because the Makefile in this CL does not create crypto subdir in the destination.
Vadim has a fix, gerrit/#change,2738, that changes the Makefile to fix this.
|Uploaded patch set 2.
|Patch Set 2: Verified

This is the new CL that has only the warmboot code.
|Patch Set 2: (26 inline comments)

Simon, maybe you can help me change the assembly code to C. I think if we can compile the C code to AVP code, and avoid using the local variables, then it is possible to convert the assembly code to C.

I will upload another patch set soon.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: (2 inline comments)

The reason that I am using the assembly code for warmboot code is that it was taken from fastboot.

I will try to convert the warmboot to C in the next CL.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Uploaded patch set 5.
|Patch Set 5: Verified

Did a rebase.
|Uploaded patch set 6.
|Patch Set 6: Verified

Move calling of warmboot_prepare_code() to board/nvidia/common/board.c
|Patch Set 5: (2 inline comments)

Oops! Forgot to publish my comments on this patch set.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified


|Uploaded patch set 5.
|Patch Set 5: Verified

Did a rebase.
|Patch Set 5: (2 inline comments)

Anton,
I have changed the &quot;lp0_vec&quot; (the first one, as in lp0_vec=lp0_vec=0x20000@0x1C406000&quot;, the second lp0_vec is not changed, as kernel needs that name), to &quot;lp0_args&quot; to avoid the confusion. Do you want me to submit the changes?
|Uploaded patch set 6.
|Patch Set 6: Verified


|Uploaded patch set 7.
|Patch Set 7: Verified

Rebased.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified

Move all files under crypto folder to under common folder, and change Makefile accordingly.
Also, chmod of crypto.c to 644 (was mistakenly set to 755).
Build passed with &quot;emerge-tegra2_seaboard sys-boot/chromeos-u-boot-next&quot;.
|Patch Set 1: Abandoned

Do not need this CL.
Vadim has a fix, gerrit/#change,2738, that changes Makefile to fix the build break.
The Makefile is:
http://gerrit.chromium.org/gerrit/#patch,sidebyside,2738,2,board/nvidia/common/Makefile
|Patch Set 1: I would prefer that you didn't submit this

You also need to change the LDO2 voltage range to 1300 from 1200; otherwise, dvfs set voltage for vdd_aon will fail if it tries to set vdd_aon to 1300 mv because the max. voltage of LDO2 is 1200mv.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned
|Patch Set 1: Restored
|Patch Set 1: Verified

(1 inline comment)

There is a FIXME in warmboot_avp.c. Please see my comment there.
|Patch Set 1: (3 inline comments)

Simon,
Yes, some codes are available in ap20.c. Unfortunately, I can not call these same codes from wb_start() routine, as wb_start() has to be in ONE piece.

I have implemented a embedded asm code inside wb_start() to find out the run-time address of wb_start(), and am testing the code now. Will submit another patchset soon.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

Agree with Jimmy. Let's wait for Olof to complete his clock works (3390, etc.).
|Patch Set 1:

Danny,
Please rebase, then re-submit. Thanks.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

You may need to remove seaboard from the commit message, since the change applies to all boards.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (2 inline comments)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2:

Dilan,
Can you explain why wm8903 registers can be modified if suspend_noirq()/resume_noirq() callbacks are used?
|Patch Set 2: Looks good to me, but someone else must approve

Steven,
Thanks for the explanation.
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned
|Patch Set 1: Restored
|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (2 inline comments)


|Patch Set 2: (2 inline comments)

Allen,
Please see my comment about the carveout/FB address map.

Robert,
Will implement your suggestions.
|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)


|Patch Set 3: Verified


|Patch Set 3:

patch set #3 new address map:

[    0.000000] Tegra reserved memory:
[    0.000000] LP0:                    1c406000 - 1c407fff
[    0.000000] Framebuffer:            37684000 - 37ffffff
[    0.000000] Carveout:               38000000 - 3fffffff

# cat /proc/cmdline
cros_legacy console=ttyS0,115200n8 lp0_vec=0x2000@0x1C406000 mem=384M@0M nvmem=128M@384M mem=512M@51

# cat /sys/kernel/debug/memblock/memory
   0: 0x00000000..0x17ffffff
   1: 0x20000000..0x37683fff

# cat /sys/kernel/debug/memblock/reserved
   0: 0x00000000..0x00000fff
   1: 0x00004000..0x0067025b
   2: 0x1c406000..0x1c407fff
   3: 0x35ff4000..0x35ffffff
|Patch Set 3:

Bryan,
What framebuffer address u-boot uses to match kernel's?
what is the size?
Do you also change the lp0_vec?
|Patch Set 3:

My u-boot (built with mem=1024M@0M) has already the fbmem.start = 0x18012000 setting, and the kernel (with this patchset #3) is running fine. I can suspend/resume with HDMI attached.

I am running on Seaboard. Which board are you running on?

If this u-boot/kernel transition is not smooth, I have other plan, that is to change lp0_vec to other places. I have tried putting lp0_vec at 0x18bfe000, and it works. That area is in between the current fbmem (0x1801200..0x1899167F) and the carveout (at 0x18c00000).
That will involve only u-boot change.
|Patch Set 3: (2 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 3:

Bryan,

&lt; To close that 128M hole, I tested a u-boot that sets mem=1024M@0. The kernel will not boot.&gt;

When you saw kernel not booting, did you apply this CL or not?
Sorry to ask, I just want to clarify. Thanks.
|Patch Set 3: (2 inline comments)


|Patch Set 3: (1 inline comment)

I still need to use memblock_reserve() to reserve the lp0_vec area specified by u-boot.
|Patch Set 3:

I can repro the kernel not booting problem that Bryan is seeing. I was using an old u-boot. That is why I did not see the problem.

Once I checkout c342c56771af4376c462a39a6721b5f70c603a13(Assign the frame buffer address as FDT one instead of u-boot one), and then use &quot;mem=1024M@0M) in u-boot, TOT kernel won't be able to boot, with or without my patches.

I need to change frame-buffer = &lt;0x37684000&gt; in board/nvidia/seaboard/tegra2-seaboard.dts, then kernel boots. &lt;0x37684000&gt; is the new frame-buffer address that this patchset allocates.

This indicates that u-boot and kernel have to be in-sync. Worse is that if we change the frame-buffer size, the frame-buffer address will change, and u-boot have to be changed too.
|Patch Set 3:

Robert,
Since the frame-buffer address changes as frame-buffer size changes, I want to use the correct frame-buffer size so I can fix the fdt's fb address in u-boot. I want to make sure that I can use 1368*910*4 (instead of *8) as the frame-buffer size.

Please confirm that. Thanks.
|Patch Set 3:

Bryan,
After making u-boot's frame buffer address matching with kernel's fb address, system can boot up. But, I do not see splash screen. Do you know why?
|Patch Set 3:

u-boot's board/nvidia/seaboard/tegra2-seaboard.dts:
...
	lcd {
		compatible = &quot;nvidia,tegra2-lcd&quot;;
		width = &lt;1366&gt;;
		height = &lt;768&gt;;
		bits_per_pixel = &lt;16&gt;;
		pwfm = &lt;&amp;pwfm2&gt;;
		display = &lt;&amp;display1&gt;;
		frame-buffer = &lt;0x37b40000&gt;;
		pixel_clock = &lt;70600000&gt;;
    ...
}

Kernel's dmesg:
[    0.000000] LP0:                    1c406000 - 1c407fff
[    0.000000] Framebuffer:            37b40000 - 37ffffff
[    0.000000] Carveout:               38000000 - 3fffffff

I only changed &quot;frame-buffer=&quot; field in tegra2-seaboard.dts, not other tegra2-xxx.dts files, because I am testing on seaboard.

Are there other things need to change?
|Patch Set 3:

Bryan,
Trying to debug why splash screen not showing up, I found that the frame-buffer address used in u-boot is still at 0x18012000  even I have changed seaboard's dts file to use the new frame-buffer address.
Do I need to do extra steps to build the new dts files?
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, but someone else must approve

With this patchset, the new frame-buffer address is at 0x37680000.
|Uploaded patch set 5.
|Patch Set 5: Verified


|Patch Set 5:

I did some experiments to try to understand the difference between memblock_reserve and memblock_remove:

By using memblock_remove on lp0_vec at the current location (0x1c406000), kernel hangs (not panic, just hang).

But if I move the lp0_vec to next to the frame-buffer, I can use memblock_remove, and system runs OK.

By using memblock_reserve on frame-buffer and carveout, I can not boot to kernel, system keeps rebooting.
|Uploaded patch set 6.
|Patch Set 6: Verified

Rebased.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

Bryan,
The new frame-buffer that kernel allocates is starting at 0x37680000.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve

(3 inline comments)

See my comments. Otherwise, LGTM.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 1: Abandoned
|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: Abandoned
|Patch Set 1: Abandoned
|Patch Set 5: I would prefer that you didn't submit this

(7 inline comments)

Please see my comments.
Also, do we need to change copyright year to 2012?
|Patch Set 8: I would prefer that you didn't submit this

(4 inline comments)

Please add proper &lt;TAB&gt;s in clk_rst.h. Also please change the copyright year to 2012 to all the files in this commit.
|Patch Set 11: (5 inline comments)

Sorry for the nitpicking. Please see my comments.

Also, what happened to the warmboot_avp.lds which was created in patchset #3, and was removed in patchset #9?
|Patch Set 1: Looks good to me, but someone else must approve

LGTM.
|Patch Set 2: Looks good to me, but someone else must approve

LGTM.
|Patch Set 1: Abandoned
|Patch Set 1: Restored
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified

Per Tom's suggestion, move crypto.c/crypo.h to cpu/tegra-common folder.
|Patch Set 2: Ready


|Patch Set 1: Abandoned
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1: (7 inline comments)

Please see the patchset #2
|Patch Set 2: Verified

In my opinion, register definitions (struct to define the registers and the bit field definition) should be in each arch-tegraXXX folder. So, arch-tegra1114/clk_rst.h and arch-tegra114/pmc.h inherit all #defines from their corresponding .h files in arch-tegra folder. Plus some of #defines in warmboot_avp.h are moved to these .h files also.

So most of #defines in warmboot_avp.h are distributed to each related .h files.
|Patch Set 2: (2 inline comments)

Tom,

I did build for seaboard and cardhu (and tested on Dalmore), and they built.

I have another CL (https://gerrit.chromium.org/gerrit/#/c/50866/), which is to change other T114 components to use the arch-tegra114/clk_rst.h and pmc.h.

I will enhance that CL to move arch-tegra/clk_rst.h to arch-tegra20 and arch-tegra30 folders, and change all codes that include &quot;asm/arch-tegra/clk_rst.h&quot; to &quot;asm/arch/clk_rst.h&quot;.

Also, I will rename register names of crc_cpu_cmplx_* to crc_rst_cpu_cmplx_*, as you suggested in this CL.
|Patch Set 2: Ready


|Patch Set 1: Verified

As needed by WB0 code.
|Patch Set 1: Ready


|Patch Set 1: Verified

All references to clk_rst.h and pmc.h are used to be included from arch-tegra folder.

Because clk_rst.h and pmc.h are created in arch-tegra114, change all tegra114 related C files that include those .h files to include from arch-tegra114.
|Uploaded patch set 2.
|Patch Set 2: Verified

I copied arch-tegra/clk_rst.h to arch-tegra20 arch-tegra30 folders, and deleted arch-tegra/clk_rst.h. Then, changed all files that have included asm/arch-tegra/clk_rst.h to asm/arch/clk_rst.h

I also copied arch-tegra/pmc.h to arch-tegra20 and arch-tegra30 folders, then deleted arch-tegra/pmc.h. Then, changed all files that have included asm/arch-tegra/pmc.h to asm/arch/pmc.h.

I have built the tree with seaboard, cardhu and dalmore.
|Patch Set 2: Ready


|Patch Set 2: Ready


|Patch Set 2:

I don't see any conflicts, and have set READY twice, but nothing happened.

What should I do next? Submit it again?
|Patch Set 1: Verified


|Patch Set 1: Ready

Thanks.
|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)

See my comments about where to get this .cfg file.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: I would prefer that you didn't submit this

Tom,

Sorry, after I +1 to your code, unfortunately, I just found out that this REPEAT_START does not work with the new tpm chip, slb9645.

Need more time to investigate.
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5:

Tom,

Is it possible to implement this on a device level so the repeat-start depends on a certain device, and affecting the whole bus?
|Patch Set 5:

Sorry, my previous comment should be &quot;and NOT affecting the whole bus&quot;.
|Patch Set 1: Verified


|Patch Set 1:

Tom,
I think the problem also exists on the first batch boards.

Occasionally I heard people with a standalone Venice (without servo board) saying they have to press power button several times to power on the system. I wondered if this issue is the reason for the randomness of powering up system.

Even for the second batch, I saw 2 boards (out of 5 that I touched) have no this issue.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified

This CL is from v2013g.
|Patch Set 1: Ready


|Patch Set 1: Verified


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1:

ok, I will create a bug to track this tegra_i2c driver re-write.
|Patch Set 1:

An nvbug #1340765 is opened to track the re-write of tegra i2c driver.
|Patch Set 1: Verified


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 1: Verified


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 1: (1 inline comment)


|Patch Set 2:

Vadim,
Thanks for you feedback.
We will discuss your suggestions (either change the i2c_read/i2c_write functions or add a function to provide read/write methods in tpm i2c driver) internally.
|Patch Set 2:

Since we agree to re-write the i2c_read/write functions in the future, and Vadim does not think this needs a devicetree setting, I will just use #ifdef CONFIG_TEGRA to call i2c_read_mult(), and abandon/resubmit the CLs that related to the &quot;use-rdwr-mult&quot; devicetree setting.

Do you guys agree?
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3:

I had the thought before, but slipped my mind.
Will debug with vboot. Although, it appeared that vboot is working (according to Jimmy).
|Patch Set 3:

Now I remembered: iic_tpm_write_generic() function combines the register address and data into one buffer, then uses i2c_write() with alen=0 to send out the buffer, which contains the register address and data.

That is why using i2c_write() works.
|Patch Set 3:

I did open an nvbug 1340765: task tracking: to rewrite u-boot tegra i2c driver.

Should I mention it in the BUG= clause?
I thought the BUG= clause is to indicate which BUG this CL intended to fix.
|Patch Set 3:

ok, I will add a TODO comment in the source to track the progress.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 1: Verified


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 1: Verified


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 3: Verified


|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 5: (1 inline comment)


|Patch Set 5: Looks good to me, but someone else must approve

Question on copyright year on one of the files changed.
Otherwise, LGTM.
|Patch Set 5: Looks good to me, but someone else must approve

Same copyright year question on chromeos-tegra.dtsi file.
Otherwise, LGTM.
|Patch Set 5: Looks good to me, but someone else must approve

Same copyright year question on chromeos-tegra.dtsi file. Otherwise, LGTM
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this


|Patch Set 1:

Tom,
This one is instead submitted to: https://gerrit.chromium.org/gerrit/#/c/60706/.

Abandon this one.
|Patch Set 1: Abandoned
|Patch Set 1: I would prefer that you didn't submit this


|Uploaded patch set 2.
|Patch Set 2: I would prefer that you didn't submit this

Fixed AP_RESET_L gpio to be output-high.
|Patch Set 2: Abandoned

Abandon this CL.
New CL is https://gerrit.chromium.org/gerrit/#/c/60561/
|Patch Set 2:

Tom,
Sorry, I should have abandoned this CL earlier.
Please see the new CL: https://gerrit.chromium.org/gerrit/#/c/60561/.
|Patch Set 1: I would prefer that you didn't submit this


|Patch Set 1:

Tom,

This is just a place holder to store bring-up u-boot codes, so people can easily get the patches and build their u-boot. It is not meant to be reviewed yet. That is why I gave myself a -1 so chromebot won't start doing its things.
|Patch Set 1: Looks good to me, but someone else must approve; Ready; Verified

Ok, I am marking it Ready.
Will do some fixes later on.
|Patch Set 1: Abandoned
|Patch Set 1: I would prefer that you didn't submit this


|Patch Set 1: Looks good to me, but someone else must approve; Verified


|Patch Set 1: Ready


|Patch Set 1: Abandoned

Tom,
I submitted another CL (60123).
Please review the new CL.
|Patch Set 1: Abandoned

redundant
|Patch Set 1: Looks good to me, but someone else must approve; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve; Verified

Fixed as Tom suggested.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Ready


|Patch Set 1:

Tom,
This is just a quick hack to test communication between u-boot and EC firmware. I will revisit the current 2013.06 branch and do a rework.

You can abandon this CL.
|Patch Set 1: Verified


|Patch Set 1: (2 inline comments)

Thanks, Bernie.

I will first split this CL into 2, except the flash_ec.
Jimmy Zhang will submit another CL just for flash_ec.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified

add CHIP_FAMILY to board/puppy/build.mk
|Uploaded patch set 4.
|Patch Set 4: Verified

removed power_led_task from puppy's ec.tasklist, because it is causing build break just for this CL.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified

add &quot;power_led_task&quot; to puppy's ec.tasklist.
|Patch Set 4: Rebased
|Patch Set 1: Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Rebased
|Patch Set 1: Verified


|Patch Set 1:

Tom,
What is the status of 2013.06?
I want to wait till everything else is stable, then introduce LP0. LP0 is not the most urgent thing.
|Patch Set 1: Ready


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: I would prefer that you didn't submit this

DON'T submit.
|Uploaded patch set 2.
|Patch Set 2: I would prefer that you didn't submit this

Don't submit yet.
|Uploaded patch set 3.
|Patch Set 3: I would prefer that you didn't submit this


|Patch Set 3:

Sync to ae3d91fce70be5f2a0d5ac09356bd22c533e1089, and cherry-pick this CL to build nyan.
|Abandoned
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this


|Abandoned
|Patch Set 1: Abandoned
|Patch Set 1:

Tom,
You are right, I missed that file.
I have submitted the changes to a new CL: 66850, with another TOT commit: 8c7a18616f216fe4c6df2d7fc2b3fc6319c385fd.
Wiki page is also updated with the new commits.
|Abandoned
|Patch Set 1: Abandoned

I screwed up on commit message. Abandon.
|Patch Set 1: I would prefer that you didn't submit this

This is temporary.
Please sync to 8c7a18616f216fe4c6df2d7fc2b3fc6319c385fd then cherry-pick this CL.
|Uploaded patch set 2.
|Patch Set 2: I would prefer that you didn't submit this

Removed CONFIG_BOARD_POST_GPIO_INIT and board_config_post_gpio_init().
|Abandoned
|Patch Set 1: Code-Review-1

This is my test comment.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Tom,
Can you see if my name is listed in the From field?
|Patch Set 1:

Tom,
I deleted myself (Yen Lin) from the Reviewer list then add &quot;yelin&quot; to the list.

Can you see my name now?
|Patch Set 1: Code-Review+1

Tom,
How about my name now?

Now I mouse over my name (it just became Yen Lin), it shows Yen Lin&lt;yelin@nvidia.com&gt;.
Your name is still twarren, and is an Anonymous.
|Patch Set 1: Code-Review-1

Actually this patch is not ready yet.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1

fixed board/nyan/ec.tasklist and test/build.mk.
|Patch Set 2:

(7 comments)
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4: Verified+1

I replaced chipset_gaia.c with chipset_tegra.c, and made the corresponding changes for the new chipset_tegra.c file.

Please review.
Thanks.
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review+1

(2 comments)

LGTM, except copyright year in some files.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)

LGTM, except the copyright year comment.
|Patch Set 1:

You should update copyright year on those files.
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)

Tom,
Please see my comments. Those are what I noticed recently.
We can merge your changes to chromeos-v2013.06 branch first.
Then, we can change those files later on.
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

As Tom and I discussed, I will make the changes as Simon suggested, and submit the changes as my CL, then Tom will abandon this CL.
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Verified+1

This is a re-submit of CL168473 (was submitted by Tom) with changes suggested by Simon.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Updated commit message as Tom suggested.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Changed based on Jimmy's comment.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Correct the commit message as pointed out by Tom.

I did rigorously retest on both Venice 1 and Venice 2 boards on SPI Flash and EC.
In terms of FIFO error debug messages, I did enable DEBUG but have never seen those error messages showing up.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Simon, I did some refactoring. Let me know what you think.
Thanks.
|Uploaded patch set 6.
|Patch Set 5:

(4 comments)
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

test
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Tom,
Agree that we should consolidate T114/T124 warmboot codes. Once this patch is approved, I will then change T114's warmboot code to be more like T124's, then consolidate both warmboot codes.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)

Besides the growing lp0 vecs problem, I found that this patchset breaks the venice (puppy) build.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

In this patchset:
1. created a CONFIG_RESERVE_TEGRA_LP0 #define just for Venice2;
2. fixed the growing extra_bootargs problem;
|Patch Set 2:

Also, did &quot;MAKEALL -s tegra&quot; to make sure all boards are built ok.
|Patch Set 2:

Tom,
CONFIG_RESERVE_TEGRA_LP0 is to solve the problem that the first patchset is affecting boards other than Venice2. CONFIG_TEGRA_LP0 is defined for all boards, and board_f.c, and board_r.c are also common files for all boards. But I want the reserving of LP0 to be only for Venice2, so I define CONFIG_RESERVE_TEGRA_LP0 only for Venice2.
|Patch Set 2:

(9 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Simon,
Hope you will like it this time.
I do have a CL in the work that changes kernel devicetree for lp0_vec. But feel that I should submit this CL first so both T114/T124 have the lp0_vec in extra_bootargs (although they will have different values), such that if kernel wants to use the vector form kernel's cmd_line. the vector is there.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 4:

(2 comments)
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Verified+1

Moved warmboot_prepare_code() from board_init(0 to board_late_init().
|Patch Set 6:

Simon or anyone,
Any comment?
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 7: Verified+1
|Uploaded patch set 8.
|Patch Set 8: Verified+1

I have implemented lp0-vec things to kernel's device tree things.
|Uploaded patch set 9.
|Patch Set 8:

(1 comment)
|Patch Set 9: Verified+1

To answer Simon's concern about TEGRA_LP0_ADDR not defined, I added #ifdef CONFIG_TEGRA_LP0 to define ft_system_setup().

Also, I deleted the lp0-vec property if there is error when adding/appending values to the property.

And, I restore the change of ft_board_setup() in boot_kernel.c. That change is in another CL (175802).
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Although I don't have a way to verify on Samsung's chromebook, but looking at the code, Samsung's must have passed vboot and cdata correctly to the ft_board_setup() function, so it would pass the test, then calls ft_system_setup().
My change is to call ft_system_setup() first, then do the checking. So the change should not affect Saumsung's code.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1

LGTM, and I also verified that the EC is working on Venice2.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Note that I have to use &quot;repo upload . --no-verify&quot;, because the script does not like the nvbug in BUG= field.
But I did run the checkpatch.pl script and it does not complain.
|Patch Set 1:

Can someone give me comments?
|Patch Set 1:

This is specific to u-boot DT.
And, the signal is pinmux, not gpio.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Pull-up CS line during reset.
|Patch Set 2:

Any comments?
|Patch Set 2: Commit-Queue+1

Thanks.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 5: Code-Review-1

(1 comment)

Tom,
I have a Norrin ERS that has the same CD line polarity as Norrin FFD's.
|Patch Set 6: Code-Review+1

Tome,

There is a rework to change the polarity on SD CD line.
Either we undo the rework or we change the DT in our private u-boot build.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

This CL and the other 2 CLs are not needed for bringup. They can wait.
I just want to stash here, so I don't lose them.
But, you are welcome to review them.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I have to use &quot;--no-verify&quot; when doing repo upload.
There are style errors/warnings, like &quot;spaces required around ':'&quot;, and  &quot;line over 80 characters&quot;. My opinion is that these errors/warnings, if I correct them, will not help the readability of the codes.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Simon,
Sorry for the delay. Was assigned to do other things.
Please review. Thanks.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I have to use &quot;--no-verify&quot; when doing repo upload.
There are style errors/warnings, like &quot;spaces required around ':'&quot;, and  &quot;line over 80 characters&quot;. My opinion is that these errors/warnings, if I correct them, will not help the readability of the codes.
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

fixed typo.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Found another 3S battery that has different DESIGN VOLTAGE (11.4V). Add checking of 11.4V for 3S battery.
|Patch Set 2:

Can anyone give me comments?
|Patch Set 2:

(4 comments)

Randall,
So I will wait for your CL (https://chromium-review.googlesource.com/178424) is approved, then submit my changes.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Verified+1
|Patch Set 3:

Can I ask you guys a favor to give me speedier review?
I am taking vacation tomorrow, and won't be on line for the next 2 days.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1

Thanks, Randall.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Louis,

Right now, the devicetree entry of &quot;nvidia,cs-pinmux&quot; is optional.

With your change, the &quot;nvidia,cs-pinmux&quot; entry becomes a MUST. We need to change the code in tegra114_spi_init() to fail the controller detection if &quot;nvidia,cs-pinmux&quot; is not entered.
|Patch Set 1:

(1 comment)
|Patch Set 2:

Louis,
Your changes in tegra114_spi_init() look good to me.

Can you also change 'Optional property' to 'Required property' in this file: doc\device-tree-bindings\spi\tegra1x4-spi.txt?
|Patch Set 3: Code-Review+1
|Patch Set 3:

Louis,
I don't have +2 right.
|Patch Set 1: Code-Review-1

(1 comment)

I found a problem with this CL. If I tap the POWER button while system is running, 10 seconds later, system will be powered off.
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1:

I don't think I can attach a file here.
So this is the content of the file (error-10183-0) that I think is useful (there are 8 other files):
===
cautotest_lib.client.common_lib.error
UnhandledTestFail
p0
(S'Unhandled ValueError: Invalid key: percent_cpuidle_CPU cluster off_time{perf}\nTraceback (most recent call last):\n  File &quot;/usr/local/autotest/common_lib/test.py&quot;, line 713, in _call_test_function\n    return func(*args, **dargs)\n  File &quot;/usr/local/autotest/cros/cros_ui_test.py&quot;, line 545, in execute\n    *args, **kwargs)\n  File &quot;/usr/local/autotest/common_lib/test.py&quot;, line 386, in execute\n    dargs)\n  File &quot;/usr/local/autotest/common_lib/test.py&quot;, line 275, in _call_run_once_with_retry\n    postprocess_profiled_run, args, dargs)\n  File &quot;/usr/local/autotest/common_lib/test.py&quot;, line 307, in _call_run_once\n    self.postprocess_iteration()\n  File &quot;/usr/local/autotest/tests/power_LoadTest/power_LoadTest.py&quot;, line 356, in postprocess_iteration\n    self.write_perf_keyval(keyvals)\n  File &quot;/usr/local/autotest/common_lib/test.py&quot;, line 151, in write_perf_keyval\n    tap_report=self.job._tap)\n  File &quot;/usr/local/autotest/common_lib/test.py&quot;, line 172, in write_iteration_keyval\n    tap_report=tap_report)\n  File &quot;/usr/local/autotest/common_lib/base_utils.py&quot;, line 542, in write_keyval\n    raise ValueError(\'Invalid key: %s\' % key)\nValueError: Invalid key: percent_cpuidle_CPU cluster off_time{perf}\n'
p1
tp2
Rp3
.
|Patch Set 1: Code-Review-1

(1 comment)

There seems missing a do_encode_list() function.
|Patch Set 1: Code-Review+1

Our HW guy confirmed that our tool to generate BCT will program swizzle_rank_byte_encode field correctly based on the contents of emc_swizzle_rank fileds. So we don't need the do_encode() function.
|Patch Set 2:

I asked around, and this is what I got.
When bit 11 of pllp_wb0_override is set, the pllm clock is muxed to use what's in PMC registers, PMC_PLLM_WB0_OVERRIDE_FREQ (at 0x1dc) and PMC_PLLM_WB0_OVERRIDE2 (at 0x2b0).
BootRom sets these 2 registers when it inits SDRAM.
Can you dump these 2 registers?
Are they programmed?
|Patch Set 2:

Julius,
Do you set bit 12 (PLLM_ENABLE) of PLLP_WB0_OVERRIDE register?
|Patch Set 3: Code-Review+1
|Patch Set 1:

I will work on this tomorrow (stayed at home sick today).

Yes, LP0 can make function calls as long as stack is setup and all routines (and other referenced stuff) are linked in one place. Also, BootROM will set stack pointer to IRAM (don't remember where, but somewhere in IRAM, but not in 0x40020000 page).
|Patch Set 1: Code-Review+1

Very nicely done.
|Patch Set 2:

(2 comments)
|Patch Set 2: Code-Review+1

Thanks for the explanation.
|Patch Set 1: Code-Review+1
|Patch Set 5:

With this patch, I see &quot;[charge force shutdown due to low battery]&quot; messages continuously shown (about 2 messages per second) on serial console when battery reaches &lt;3%.

That message should not be displayed after EC is going into hibernation.
|Patch Set 7: Code-Review+1 Verified+1

+1;
Also, verified on my board.
|Patch Set 1:

(1 comment)
|Patch Set 3:

Devin,
It seems your cutoff is not the same as nyan's cutoff. In nyan, cutoff means no power is coming from battery, so system is dead totally. To wake a nyan up, an AC adapter needs to be plugged in.
|Patch Set 1:

(1 comment)
|Patch Set 3:

Devin,
In nyan, after cutoff, I have to wait a couple of minutes then plug in AC to bring back the battery. Otherwise, battery stays dead. I guess there is some delay (in terms of minutes) required for battery to be fully discharged.
|Patch Set 3:

wait a few minutes, then plug in AC adapter.
|Patch Set 3:

Yes.
What was your original problem?
|Patch Set 3:

Devin,

Also, if battery can respond to I2C command, is there a command to 'turn on' battery?
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(3 comments)

Please see my comments.
I think we still have tiny holes to fill to make it perfect.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4: Commit-Queue+1

Queue ready for Joseph.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

The ram_repair adds about 34 usecs to the boot time.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R37-5978.B as commit 610d499c34361ee5b157e7ae0136fd3d822a7441
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

I think you are missing a boardid.h in mainboard/google/nyan_kitty folder.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Abandon this.
Will apply the changes to nyan branch.
|Abandoned

Will do this on nyan branch.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Ok.

I need more time to apply these changes to firmware-nyan-5771.B branch, and test.

Abandon this.
|Abandoned

Will do these on nyan branch.
|Uploaded patch set 1.
|Patch Set 1:

With this CL, I can cleanly apply future CLs that do not have KB_GPIO_OUT pins.
|Patch Set 1: Verified+1
|Abandoned

Kitty EC will be owned by Quanta.
Abandon this CL.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Kitty has no battery, no charger and no KB.
|Patch Set 1:

Tom,

I have already removed all keyboard, charger, battery supports from nyan. You can try this CL along with your coreboot/depthcharge changes.
|Abandoned

Kitty EC is owned by Quanta.
Abandon this CL.
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1

Do not review and submit.

The Patch Set 1 contains just the files copied from tegra124/lp0 folder.

In the next patch sets, I will add the T132 changes.

This patch set can be served to test 'emerge-rush tegra_lp0_resume' ebuild.
|Uploaded patch set 2.
|Patch Set 2: Code-Review-1

Note: Patch set #2 is not verified, and is not ready for review.

Joseph,

Patch set #2 has the changes for T132. You can cherry pick the changes to test LP0 resume. Let me know when your LP0 suspend code is ready.
|Patch Set 2:

Aaron,

Thanks for looking into this.

Basically, no major changes yet. I did remove these CLR_CPURESET2 &#124; CLR_DBGRESET2 &#124; CLR_CORERESET2 &#124; CLR_CXRESET2 &#124; CLR_CPURESET3 &#124; CLR_DBGRESET3 &#124; CLR_CORERESET3 &#124; CLR_CXRESET3 bits in clear_cpu_resets(). Don't expect those would make any differences.

Current status is that AVP has done everything and is looping at:
	// Halt the AVP.
	while (1)
		write32(FLOW_MODE_STOP &#124; EVENT_JTAG,
			flow_ctlr_halt_cop_events_ptr);

And, CPU is supposed to start at aarch64_trampoline, but it does not get there.

I have checked CPU related registers, everything seems correct.

I am now hooking up wires to see if CPU_PWR_REQ is on, and see if PPVAR_CPU has voltage.

Do you know if Palmas has been programmed to enable ENBALE1?
|Patch Set 2:

(3 comments)

Also, checked the CPU_PWR_REQ and VDD_CPU. They all look good. When we power up CRAIL power partition, I see CPU_PWR_REQ is on, and VDD_CPU is 1.0V.
|Uploaded patch set 3.
|Patch Set 3:

PatchSet3: 
 - change bug number;
 - Keep CPU1 in reset when un-reset CPUs.

Status:
 AVP has finished its job. But,
 CPU0 still cannot be started, it did not go to reset vector.
|Patch Set 3:

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 3:

Joseph's update:
* With the V3 of lp0 warm boot code, the system can resume back to kernel space.
* The CPU was in the EL3 and was needed to switch to EL1 before jumping into kernel's cpu_resume function.
* It's OK after enabling MMU (virtual address).
* But system crashed somewhere around syscore resume stage. Still debugging.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Code-Review-1

Patchset #4: has codes to enable debug UART controller clock.

Joseph found that without debug uart port clock enabled, resume may hang if initcall_debug=1, no_console_suspend=1 are set in kernel cmdline.

The code hard-codes debug uart port to be 0. Eventually, debug uart port should be dependent on odmdata. (pmc-&gt;odmdata has not been programmed correctly yet.)
|Uploaded patch set 5.
|Patch Set 5:

V5 of this CL: remove config_tsc() function.

AVP has no privilege to access SYSCTR registers. Besides, the contents of SYSCTR0_CNTCR and SYSCTR0_CNTFID0_0 registers are preserved during LP0.
|Patch Set 5: Commit-Queue+1 Verified+1

I am marking it verified and ready.

But, we still need the ebuild of tegra_lp0_resume for rush/ryu. Please see partner bug 31637: rush: need an ebuild to 'emerge-rush tegra_lp0_resume' for rush and its variants
|Patch Set 2: Code-Review+1

I also checked that avp warmboot code (tegra_lp0_resume.fw) can read the pmc_scratch20 register, and then determine the proper UART port to initialize.

Will submit the new tegra_lp0_resume.fw code once this CL is merged.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Penny,
Please share the patches to Andrew Chen.
Andrew Chen is not registered yet.
|Abandoned

Wrong branch.
Should submit to firmware-kitty-5771.61.B.
|Uploaded patch set 1.
|Patch Set 1:

Penny,
Please share the patches to Andrew Chen.
|Patch Set 1:

I am going to split this CL into 2 CLs.
First one is to add physical recovery switch support.
Second one is to enable MKBP keyboard input.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

We are still waiting the cable to arrive.
|Patch Set 1: Verified+1
|Abandoned

This CL is not needed.
We are using USB-KM232 cable to run FAFT tests, so no keyboard simulation from EC is not needed.
|Uploaded patch set 1.
|Patch Set 1:

Penny,
Please share the patches to Andrew Chen.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

Randall,
Thanks.
Can you also review my other CL, https://chromium-review.googlesource.com/#/c/227931?

BTW, do we have a different bitmap image of &quot;VB_SCREEN_RECOVERY_TO_DEV&quot; to show &quot;Press Recovery button to expose yourself ...&quot; instead of &quot;Press ENTER to expose ...&quot;?
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

This CL is needed only when we are using EC's keyboard simulation to run FAFT tests.
I am hoping that if we use USB-KM232 cable to run FAFT, we don't need this CL.
Still waiting USB-KM232 cable.
I won't put CQ ready yet.
|Abandoned

This CL is not needed.
We are using USB-KM232 cable to run FAFT tests, so no keyboard simulation from EC and no enabling of MKBP keyboard input are needed.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Increase firmware_screen to 7 seconds so firmware_SelfSignedBoot test can pass. It took about 5~6 seconds for dev screen to come up. With old value of 4 seconds of firmware_screen, ctrl_u is lost.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

Shawn,
Thanks for the suggestion. Will try it.
|Abandoned

This CL is not needed. As Shawn suggested, implement a lid_open() to return 'not_applicable' in servo_nyan_kitty_overlay.xml.
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Kary,

Please review.
Also, if test results are all promising, please +1 on Verified.
I will then invite Google engineers to review.

Note this CL is submitted to firmware-nyan-5771.B branch.
|Patch Set 1: Verified+1

Hi Google Engineers,

Do you have STM Engineer contacts that can help review this CL?
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

Tried to cherry-pick this CL to the master branch, and build/test for nyan. But, I cannot flash the newly built ec.bin, got the following error: (even with the TOT without my patches, I got the same error)

Waiting for the monitor startup ...Done.
NACK
payload 0 ACK failed for CMD44

Does anyone know why?
|Patch Set 2:

&gt; Tried to cherry-pick this CL to the master branch, and build/test
 &gt; for nyan. But, I cannot flash the newly built ec.bin, got the
 &gt; following error: (even with the TOT without my patches, I got the
 &gt; same error)
 &gt; 
 &gt; Waiting for the monitor startup ...Done.
 &gt; NACK
 &gt; payload 0 ACK failed for CMD44
 &gt; 
 &gt; Does anyone know why?

I filed a partner bug (issue 34558) for not able to flash EC image.
I hacked util/stm32mon.c (see the partner bug 34558 for details) so I can flash ec.bin to a Nyan board.
But, now the TOT ec.bin keep rebooting because of watchdog timer keep firing.
|Patch Set 2:

The watchdog timer problem has gone away after I unplugged the battery and AC.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch master as commit de5ff1e86ebaafdcb6976ec994afebe51c1aeec1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review-1

Tom,
You should also set the TIMERUS config register based on the new CLK_M, which should be 0x045f.
|Patch Set 1: -Code-Review

I have implemented these steps in my warmboot resume code (to be submitted), Joseph's patch is not complete.
|Patch Set 1:

Tom,
Your patch has nothing to do with suspend/resume.
Warmboot resume code will redo the same steps in its own code path.
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch set 2: Published edit on patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

(1 comment)
|Patch Set 3:

I did try foster coreboot emerge and hit this problem:

&gt;&gt;&gt; Preparing source in /build/foster/tmp/portage/sys-boot/coreboot-9999/work/coreboot-9999 ...
sed: can't read .config: No such file or directory
 * ERROR: sys-boot/coreboot-9999::chromiumos failed (prepare phase):
|Patch Set 3:

Tom,
Found that we don't have sdram_configs.c in foster board. The sdram_lp0_save_params() needs BCT to do its job.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4:

Split PS3 of this CL into 2 CLs: 1st one is for board/smaug, 2nd one is for tegra210.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Patch Set 6:

(4 comments)
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(6 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Patch Set 5:

Thanks, Tom.
I am able to build this CL for Foster. But, I cannot test it yet.
I still need to build/test sdram_lp0_save_params() for Foster in another CL (although I did that before I switched everything to Smaug). For that I need to port sdram_configs.c to Foster first.

After all these are verified, I still need a working kernel/os to see if system can enter suspend.
|Patch Set 5:

Yes, I saw that thread too.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

What I understand about MBIST is that it is the chip hardware function to perform MemoryBurnInTest.
|Patch Set 2:

That is hardware init function, even before BootROM.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Patch Set 3:

And, once this CL is approved, I need to do the similar steps in lp0-resume path.
|Patch Set 3:

I need to change the memory layout. Bootblock is &gt;24KB with the MBIST workaround code.
Will submit a CL to change memory layout before this CL.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1

(1 comment)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4:

Joseph,
We need to implement the same thing in warmboot path when CPU is resumed.
|Patch Set 5:

Varun,
Can you check if MSELECT_CONFIG register has changed when CPU is resumed?
|Patch Set 5:

Varun has pushed his changes in https://github.com/ARM-software/arm-trusted-firmware/pull/343.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Furquan,
That's fine. I can abandon mine.
|Abandoned

Furquan has the same CL.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1

(1 comment)

I have verified that after LP0 resume, all carveout regions are restored back to MC registers.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

Tom,

From scandump, we found where BR aborted, and from there we noted that EmcBctSpare2 is not zero, and traced it back.

I tried to be careful for those registers as much as possible.
It turns out that our handling of bct is different from nvtboot's. We load bct as part of our code, while nvtboot uses what's in IRAM loaded by BR. So I cannot use exactly what's in nvtboot.
|Patch Set 1:

Furquan,

update the LP0 firmware?
Do you mean tegra_lp0_resume.fw?
This change is entirely in coreboot, so there is no change in tegra_lp0_resume.fw.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

Tom,
Do these pad configs need to be implemented in lp0 resume code also?
|Patch Set 1:

Rhyland,
Can you make sure that pinctrl driver saves/restores those pad configs?

The reason I ask is because I have a similar pad control (QSPI_COMP_CONTROL) needs to be set in cold-boot path. And, if pinctrl driver saves/restores that, I don't need to set it again in lp0 resume code.
|Patch Set 1: Code-Review-1

(1 comment)

Tom,
The register addresses are all wrong.
|Patch Set 1:

Rhyland,
You are right, pinctrl driver restores those pad configs after resume.
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+1

I only have nv bug number.
|Patch Set 2:

nvbug #1629197
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

I will do LP0 stuff.
But, we need to be clear on whether we need to keep SDMMC1 and SDMMC3 blocks (and their clocks disabled) unrest to maintain those bit values.
|Patch Set 1:

(1 comment)
|Patch Set 1:

Chris,
I am not in the office currently.
Can you find out from syseng. or Laurent, what SDMMC1 and SDMMC3 state should be after program these 2 bits?
|Patch Set 2:

I am still waiting for our HW guys to respond.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Although I think this CL should be smaug specific (SDMMC1 and SDMMC3 are not used in smaug), I still do it anyway.
The better place should be in smaug driver.

I am also waiting for NV HW guys to respond to see if we can just leave SDMMC1 and SDMMC3 unreset.
|Patch Set 1: Commit-Queue+1

I got the response from NV syseng:
&quot;Do not reset the controller after programming to disable BandGap and comp pad's e_input. You can clock gate the controller via the clk_rst enb register for sdmmc host controller and it will retain the state.&quot;
|Patch Set 1:

Found a DP monitor.
With Tomâ€™s patches, plug in the monitor, nothing shows up on the monitor.

Hari told me that we need Seanâ€™s kernel which has the dp driver.
|Patch Set 1:

Invite Sean and Thierry to review, so they build/test the new coreboot.
|Patch Set 5: Code-Review+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Verified+1
|Patch Set 4: Code-Review+1 Verified+1
|Patch Set 1:

Rhyland,

After several weeks of testing, finally I got an ARB_LOST error on EC I2C bus, and your BUS_CLEAR code (using h/w) correctly recovers the ARB_LOST situation and the failed I2C bus continues operating.

There is one more thing to add to your code is to enable I2C_CNFG_MULTI_MASTER_MODE (bit 17) of I2C_CNFG register for T210.
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I've changed the method signature, but I have also moved these two private helper methods to USBController class, which I think is a better place to encapsulate those functions that convert the original USB driver parameters into data format form.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done: method DriverIsEnabled is implemented in this change: I8e5957fe4e8fd812513f64c0b55ad29cefebc3a9
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done, but this change is now merged with commit 0c87deb9
|Done
|I've made the relevant changes to the driver_configs_in_use logic in another change. This change is outdated and will be abandoned.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done: I have made the necessary changes to usb_configs.py and usb.py in two new changes: Ief1e01ba304f80a2b4c8e62fd672cbc481588ad2 and I18735082c50b45f0b7eb0d19b8963e5956e61e85
|Done
|Done
|Done
|Done: This is done after refactoring and moving the logic here to setter methods in usb_flow ( change-Id: If22842ca3a55890c8fdd63cd3841dae63c871a01 )
|Done
|Done
|Ahh I understand now. I will make changes to the error statements which are now shifted to usb_flow.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I have replaced this method with open_write_close() from base_utils, as Wai-Hong has suggested. Hence, this change will be abandoned.
|Done: Now supported formats are reset to None in DisableAudioDriver.
|Done: the fields _supported_playback_data_format and _supported_capture_data_format are removed
|Done
|Done: The refactoring is done in another change: I634cb744649633a36af22b520ea9036ad1b5bdd9
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This line is removed after I moved 'raise USBControllerError(.....)' to line 138.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This line was removed after moving error statement to the last else block as per Wai-Hong's advice.
|Done
|Done
|Done
|Done
|Done: Moved these two imports to the CL that added _CheckModprobeResultAndUpdateConfigs.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done: Set it to _captured_file_type, a newly added private attribute of InputUSBFlow to store the file type set by user for saving captured data. (see change: I92d79a8c60a496c51a43518342b7689414eaa64d)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done: plug() and unplug() for PlugHandler class are updated in the original patch. DummyPlugHandler class is implemented in another change (If2392858b85bea33455669283509f4cf2f0e633a).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 7.
|Patch Set 7: Verified+1

(6 comments)
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1

(2 comments)
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1

(1 comment)
|Uploaded patch set 11: Commit message was updated.
|Patch Set 11: Verified+1
|Uploaded patch set 12: Patch Set 11 was rebased.
|Patch Set 12: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Commit message was updated.
|Patch Set 8: Verified+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

(3 comments)
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 6: Reverted

This patchset was reverted in change: I94737280d4c20b1717fd24b0ceb3c22bd936eb1e
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified+1

(5 comments)
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 8: Reverted

This patchset was reverted in change: I3493403d1a7eba7a3764858dbef4ac62fd087a28
|Patch Set 8: Reverted

This patchset was reverted in change: I5447b0b564b85fb9c89ee79b61039724a7d2fb89
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1

(1 comment)
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Commit message was updated.
|Patch Set 7:

(1 comment)
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8:

(2 comments)
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9:

(4 comments)
|Patch Set 9: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9:

(6 comments)
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 8: Verified+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 6:

(1 comment)
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5:

(1 comment)
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12.
|Patch Set 12:

(1 comment)
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8:

(1 comment)
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15.
|Patch Set 11:

(1 comment)
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 4:

(3 comments)
|Abandoned

Removed during refactoring.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5:

(3 comments)
|Patch Set 5: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 1:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(3 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 9:

(2 comments)
|Uploaded patch set 11.
|Patch Set 10:

(2 comments)
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 8:

(2 comments)
|Patch Set 5:

(1 comment)
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 7:

(1 comment)
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 11:

(2 comments)
|Uploaded patch set 13.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Uploaded patch set 6.
|Patch Set 3:

(3 comments)
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10.
|Patch Set 9:

(1 comment)
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12.
|Patch Set 11:

(3 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Uploaded patch set 7.
|Patch Set 7:

(2 comments)
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Patch Set 10:

(1 comment)
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13.
|Patch Set 12:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(7 comments)
|Uploaded patch set 3.
|Patch Set 1:

(2 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6:

&gt; this should be before https://chromium-review.googlesource.com/#/c/295357/5

Done
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 7:

(2 comments)
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

Abandoning this change.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 1:

(4 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(4 comments)
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|error: expected ')' before '{' token
   if ((tmp &amp; SB_FET_OFF_STATUS) {
                                ^
|Thanks, will verify it.
|Fixed.
|Fixed
|Patch Set 6:

(1 comment)
|Patch Set 2: Code-Review+1 Commit-Queue+1
|Abandoned

wrong branch
|Uploaded patch set 1.
|Patch Set 2:

&gt; This looks ok, though we should note that the volume curve is tuned
 &gt; for Auron speakers here, this will need to be adjusted for Gandof
 &gt; speakers at some point in the future.

Yes, it need to be adjusted in ODM team and I will note that in EVT.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch firmware-auron-6301.B as commit caf88dcf23fd115f5038b9543b587275b74570d5
|Patch Set 1: Cherry Picked from branch master.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch firmware-auron-6301.B as commit e58ef5f7a218d0d936f1e3350eefdf5902886f0f
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch factory-auron-6459.B as commit 11ec23507e539eed72ee19584964e9a037993fee
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch release-R41-6680.B-chromeos-3.14 as commit 08c895a77d4ee89dcf48eb577d293db9610b777e
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch release-R41-6680.B-chromeos-3.14 as commit 643bf714f2aca9bf8acdd7afc1cc818ada969bc0
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 1: Cherry Picked from branch chromeos-3.14.
|Abandoned
|Patch Set 1: Cherry Picked from branch chromeos-3.14.
|Abandoned
|Patch Set 1: Cherry Picked from branch chromeos-3.14.
|Abandoned
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R41-6680.B-chromeos-3.14 as commit ac0bc0be3940673a4a3df3b97ff43621d63804a0
|Patch Set 2:

I have tested and updated on issue 34656.
|Patch Set 1: Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned

duplicate with https://chromium-review.googlesource.com/#/c/225032/
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-auron-6459.B as commit d2b6acc9a7c40db07c810e5ec308249dc0664826
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue -Verified
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Verified+1

Hi all,
I verified no flicker that set min_visible_backlight_level to 1 on paine and auron when resume with any events(ex. the touchpad or keyboards)
|Uploaded patch set 5.
|Patch Set 5:

I thought your image was not in R40 because I observed these series beginning at:
https://chromium-review.googlesource.com/#/c/217352
and ending at:
https://chromium-review.googlesource.com/#/c/221712 had resolved minimum brightness issue on all Baytrail projects. I attached two images that one is Winky as lowest brightness http://imgur.com/MSxtp7e and the other is Auron http://imgur.com/MSxtp7e.
|Patch Set 5:

Sorry, Daniel, I misread what you mean the same platform.

Bernie, do you have any concern about minimum brightness? Do we adjust brightness lowest level to 1 or 5% for Broadwell platform?
|Patch Set 5:

Bernie, I found it sometimes caused a flicker or flash when system enter s3 and resume if we only need instant_transitions_below_min_level file.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Hi all, 
It is fixed after adjusting panel timing T8 to 70ms on vga bios binary.
C
|Patch Set 7:

Bernie, could I push a patch for adjusting panel timing T8 to 70ms?
|Abandoned

Base on comments on issue #32878, this patch is abandoned.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue -Verified
|Abandoned

The ectool is not from factory branch
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R40-6457.B-chromeos-3.14 as commit c3deecd214ba7739547b062ccaf60f0559f29e88
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch factory-auron-6459.B-chromeos-3.14-original as commit f4d8b093f5fbf04cb3744986f0900afafc9a7f94
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch firmware-yuna-6301.59.B as commit 2d56733be2230952abc1a5c149182ff4817bf127
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch firmware-paine-6301.58.B as commit 1d971e67139cd534da6685c970aef3def1a550a5
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned

I have updated on issue and abandoned this CL.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned

I have replied on issue. We find to reduce in i915 suspend.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Abandoned

Abandon this CL because of comment 11 in issue 40105.
|Patch Set 5: Verified+1

Test 'emerge-gandof chromeos-ec' and verify the file ec.bin shows up in the build.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit d7e8750aa9ebf6b5f55ee3b58a1cf38882d27edc
|Patch Set 2: Verified+1

Test &quot;emerge-gandof chromeos-ec&quot; and verify the file ec.bin shows up in the build.
|Uploaded patch set 1.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 4aec4bfaa51b41962a7df0b9772a8dcd203cd523
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Topic null-release-R44-7077.B removed
|Patch Set 1:

Need to wait the CL https://chromium-review.googlesource.com/#/c/272847/ be merged.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue -Verified
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch master.
|Topic null-release-R44-7077.B removed
|Patch Set 1: Verified+1

The firmware 6301.136 has already fixed the command &quot;ectool batterycutoff at-shutdown&quot;.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit af16d8996d28229bedacc0aa13d718473bfd2e78
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit b588670d405496ca07d13bdec1c92df6059a0db0
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Published edit on patch set 3
|Patch Set 5: Published edit on patch set 4
|Patch Set 6: Published edit on patch set 5
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 7e6afe6709e02b0fef60feb2d730582dbe1dc1ad
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit f7466d0a3514affc6844a64a8914315b9f3a8bba
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Hi Bowgo,
Please refer the issue https://code.google.com/p/chrome-os-partner/issues/detail?id=40718.
Quanta team has already verified the DozingStress 1800 times with 1 test sample of B1, B2, B3 SKU, they all passed.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+1 Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

Thank you, Charlie.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit b2771d1daf85caa88373fd0a5e85c89c7b0cfbae
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R47-7520.B as commit fa44cf2191bd2ae124016d9b70b14ec5a0dd5454
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch set 2: Published edit on patch set 1.
|Patch Set 2:

(2 comments)
|Patch Set 2: Verified+1

Hi Bernie,
Please help review it, thanks.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Verified+1

Cherry-picked this CL and verified on Sentry.
|Patch Set 2: Verified+1

Verified issue 50471 on Sentry. Is it same as https://chromium-review.googlesource.com/#/c/332208/?
|Patch Set 1: Verified+1

Verified on Sentry.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned
|Patch Set 1:

Is it same as https://chromium-review.googlesource.com/#/c/330273/?
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated.
|Patch Set 2:

Hi Ben,
I think it's reduced but still has the pop sound. Does it same as Chell?
|Patch Set 2:

There are steps to reproduce easily:
1. Go to guest mode and open the console by CTRL+ALT+t in VT1.
2. Sometimes it has the obvious pop sound.
3. open console and then quickly plug/unplug the headphone.
|Patch Set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R50-7978.B-chromeos-3.18 as commit 46f2470c55ebe81740b271b6abb5671a2d891122
|Done
|I can not force the CONFIG_COEFFICIENT_RANGE_CHECKING on because it will has conflict with vpx_config.h
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Agree and done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This code is generated from another code.
I try to make it as human readable as possible.
But this kind of swap is a little bit too complicated to be generated.
|Done
|Done
I will also fix same problem of dct in other size.
|I was thinking about use 128 so that we could expand to adst32 and dct64 easily in case that we will use it in future.
|Done
|Done
|Done
|This printf is for explanation of max_abs_error
|I saw other test file which don't do indent after namespace &quot;{&quot; as well
|Done
|Done
|Done
|Done
|CONFIG_COEFFICIENT_RANGE_CHECKING is mainly for debug purpose. Therefore, it is important to have stage and input information. So I suggest to keep stage and input arguments.

get_max_bit() is used by unit test as well.
|Done
|Done
|Done
|Done
|Done
|Done
|My original intention is to add a general parameter. This parameter can be treated as a pointer, integer or any other 32-bit data structure. On one hand, different types of transform can treat this parameter in different ways.
On the other hand, the transform interface remain the same which will make the code flow cleaner.

However, our transform function doesn't need customized parameter for now, so I change it back in the next change list on top of this one.
|it's list
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Please assign the parameters to the macro in vpx_dsp/vpx_filter.h

#define FILTER_BITS 7

#define SUBPEL_BITS 4
#define SUBPEL_MASK ((1 &lt;&lt; SUBPEL_BITS) - 1)
#define SUBPEL_SHIFTS (1 &lt;&lt; SUBPEL_BITS)
#define SUBPEL_TAPS 8
|Write a check function for this condition
|Write a check function for this condition
|Why doesn't this condition need filter search?
|Write a check function for this condition
|Write a check function for this condition
|Instead of copying it, you could #include filter.h to get these filters from vp10_filter_kernels.
|This part checks that 
cos(angle) = N * sin(angle) or sin(angle) = N * cos(angle)
where N is an integer.
And if one of the conditions fit, then ignore the interpolation.

Is my understanding right?
|Merge this 4 parts logic if possible
|Done
|Done
|I think there will be a point that interp_filter will not be the index of vp10_interp_filter_set_list that's why I write a function here.
|Done
|Done
|Done
|Done
|Because range_check() is using abs() which belongs stdlib.h
|Use SUBPEL_TAPS&gt;&gt;1
|Got you!
|Since the src is only used by vpx_convolve8_horiz, this part should be inside the same &quot;else&quot; block containing vpx_convolve8_horiz
|Why this condition is used to decide using vpx_convolve8_horiz or not?
|Why the height is depends on the bs?
|Why isn't the width set to &quot;len&quot;?
|The naming seems not match the filter type.
|The naming seems not match the filter type.
|write down the method that generate this number
|Done
|Done
|Won't this mix up with BILINEAR filter?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Patch Set 1:

&gt; does the assembly look any different with this change? it's used
 &gt; elsewhere so you might consider marking it INLINE as a hint

I don't think the assembly will look exactly the same because some computation order has been changed. 

So is it required to have same assembly code for this change?
|Patch Set 1:

&gt; the function was already being inlined, but you've changed some
 &gt; load/store locations so though there's a difference it isn't
 &gt; meaningful. this may be a bit more readable, though it isn't clear
 &gt; that both arrays + temps are strictly necessary
So I plan to put range_check function for stages in idct4_c idct8_c idct16_c and idct32_c. The range_check of each idct is based on maximum possible stage values happen in corresponding 2d idct.
For example, idct4_c's range_check is based on maximum values of each stage when idct_4x4_16_add_c is calling it. However, if idct4_c is also used by idct_8x8_64_add_c, the range_check will fail. That's why I try to expand the idct4_c in idct8_c.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Hi Jinging, I still meet the &quot;same filename&quot; bug so I add prefix to every copied file.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch set 8: Commit message was updated.
|Uploaded patch set 9.
|Patch Set 9:

Hi Jingning,
As we discuss this morning, I remove the change in idct.c and idct.h.
I also remove the unit test for sse2.
|Uploaded patch set 10.
|Patch Set 10:

(1 comment)
|Patch Set 10: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

&gt; (1 comment)

Done!
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(11 comments)
|Patch Set 9: Code-Review+2
|Patch Set 9: -Code-Review

&gt; Hi, James,
 &gt; 
 &gt; can you take another look, I missed clicked +2 and removed.
 &gt; 
 &gt; thanks,
 &gt; yaowu

I accidetally clicked the +2 button too
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13:

(7 comments)
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15:

(6 comments)
|Uploaded patch set 16.
|Patch Set 16:

(7 comments)
|Uploaded patch set 17.
|Patch Set 17:

(3 comments)
|Uploaded patch set 18.
|Patch Set 18:

Resolve the conflict
|Uploaded patch set 19.
|Patch Set 19:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)

add vp10/common/x86/vp10_fwd_txfm_impl_sse2.h
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Add vp10_ prefix
|Uploaded patch set 3.
|Patch Set 3:

Alignment fixed
|Patch Set 1: Code-Review-1

Hi Johann,
I just add the fdct32 into the code.
The reason it is not called by now is because it is under construction.
Please don't remove it.
|Patch Set 1:

It depends on my working speed. Probably in 2 weeks.
Is there any other way to clean up the warnings?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

fix it
|Uploaded patch set 3.
|Patch Set 3:

I think the test's main purpose is not testing fdc so range_check should not block the test.
|Abandoned
|Patch Set 1:

Hi I disable range_check in dct.c and re-enable this test at
https://chromium-review.googlesource.com/#/c/301211/
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

Hi reviewers,
This change list is too big
I will break it down to small ones to make the reviewing easier
So please don't review this.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Patch Set 7:

(4 comments)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 7:

(4 comments)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 3:

(6 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3:

(1 comment)
|Patch Set 3:

&gt; Please run a few borg jobs to verify before submission.

Yup, I do run borg jobs on high bit depth and low bit depth. The behavior is exactly the same
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(2 comments)
|Patch Set 9:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 8:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

(4 comments)
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

&gt; Aren't these the ideal ones that match the decode behavior?
 &gt; Wouldn't it make more sense to remove the fp ones?

Both's quantizers' decoder behaviors are exactly the same.
Plus fp version's speed in encoder is faster and performance is similar. That's why I decide to remove b version. However during the removing process, I found out dependencies (zbin) between fp and b versions. and the zbin's parameter does not match fp version's parameter.
|Patch Set 4:

So all my previous experiment results may be not correct.
|Patch Set 4:

&gt; &gt; &gt; Aren't these the ideal ones that match the decode behavior?
 &gt; &gt; &gt; Wouldn't it make more sense to remove the fp ones?
 &gt; &gt;
 &gt; &gt; Both's quantizers' decoder behaviors are exactly the same.
 &gt; &gt; Plus fp version's speed in encoder is faster and performance is
 &gt; &gt; similar. That's why I decide to remove b version. However during
 &gt; &gt; the removing process, I found out dependencies (zbin) between fp
 &gt; &gt; and b versions. and the zbin's parameter does not match fp
 &gt; &gt; version's parameter.
 &gt; 
 &gt; Matches the decoder is probably the wrong term, sorry. What I mean
 &gt; is as we discussed at the codec meeting a few weeks ago, quantize_b
 &gt; is slower because it has a wider zero bin and this gives better
 &gt; results.
 &gt; 
 &gt; There's a speed/quality tradeoff here, and it seems like during
 &gt; early codec development we would want to choose the higher quality
 &gt; version.

 &gt; &gt; &gt; Aren't these the ideal ones that match the decode behavior?
 &gt; &gt; &gt; Wouldn't it make more sense to remove the fp ones?
 &gt; &gt;
 &gt; &gt; Both's quantizers' decoder behaviors are exactly the same.
 &gt; &gt; Plus fp version's speed in encoder is faster and performance is
 &gt; &gt; similar. That's why I decide to remove b version. However during
 &gt; &gt; the removing process, I found out dependencies (zbin) between fp
 &gt; &gt; and b versions. and the zbin's parameter does not match fp
 &gt; &gt; version's parameter.
 &gt; 
 &gt; Matches the decoder is probably the wrong term, sorry. What I mean
 &gt; is as we discussed at the codec meeting a few weeks ago, quantize_b
 &gt; is slower because it has a wider zero bin and this gives better
 &gt; results.
 &gt; 
 &gt; There's a speed/quality tradeoff here, and it seems like during
 &gt; early codec development we would want to choose the higher quality
 &gt; version.

 &gt; &gt; &gt; Aren't these the ideal ones that match the decode behavior?
 &gt; &gt; &gt; Wouldn't it make more sense to remove the fp ones?
 &gt; &gt;
 &gt; &gt; Both's quantizers' decoder behaviors are exactly the same.
 &gt; &gt; Plus fp version's speed in encoder is faster and performance is
 &gt; &gt; similar. That's why I decide to remove b version. However during
 &gt; &gt; the removing process, I found out dependencies (zbin) between fp
 &gt; &gt; and b versions. and the zbin's parameter does not match fp
 &gt; &gt; version's parameter.
 &gt; 
 &gt; Matches the decoder is probably the wrong term, sorry. What I mean
 &gt; is as we discussed at the codec meeting a few weeks ago, quantize_b
 &gt; is slower because it has a wider zero bin and this gives better
 &gt; results.
 &gt; 
 &gt; There's a speed/quality tradeoff here, and it seems like during
 &gt; early codec development we would want to choose the higher quality
 &gt; version.

Okay, I will remove fp version
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

This CL doesn't change behavior. It just facilitate the interpolation experiment.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 7:

(6 comments)
|Patch Set 13:

(1 comment)
|Patch Set 13: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

(7 comments)
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 4: Code-Review+2
|Patch Set 4: -Code-Review
|Patch Set 4:

Sorry I didn't see the comment
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1: Code-Review+2
|Patch Set 5:

(5 comments)
|Patch Set 7:

(1 comment)
|Patch Set 7: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned
|Patch Set 4:

(3 comments)
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Patch Set 11:

(2 comments)
|Patch Set 11: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2
|Change has been successfully merged by Angie Chiang
|Patch Set 2:

How do you do the test?
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Change has been successfully merged by Angie Chiang
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 4:

(1 comment)
|Change has been successfully merged by Angie Chiang
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Commit message was updated.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10.
|Patch Set 10:

(7 comments)

I should be more carefully.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Change has been successfully merged by Angie Chiang
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Change has been successfully merged by Angie Chiang
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Change has been successfully merged by Angie Chiang
|Uploaded patch set 1.
|Abandoned
|why do the comparison this way?  is it ok if data is a truncated version of expected_image_data?
|to... ?
|2015?
|2015?
|2015?
|no spaces around the named input assignments here
|This directory is in the test itself and contains four files.  The files are called for by name in the subsequent tests.  If there's a superfluous directory or file in this directory, the worst thing that will happen is it will be listed in the dictionary and not used.
|I don't think having a base class function to check whether the files exist actually saves much complexity, especially since not all of tests from this base need this check.  I'd like to keep the structure of the gestures directory possibly unique to each test.
|doesn't need to be a class level variable either
|change back to filename.  The thing named as files here is /a/ file, not a set of files.  The plural is confusing.
|call this gesture_paths or something more descriptive (and change above also)
|no need for these to be class level variables, since you don't use them again.  tap_click_filename and tap_drag_filename will work by themselves without the self._
|line too long
|while you're fixing stuff in this code, please change the variable filename to filepath
|I had this before and it was still flaky (in the lab but not at my desk).  I would prefer to figure out why the scroll position is jumping here instead of adding a page reload.  The same series of events does not flake for the touch_MouseScroll test, which points to some larger problem.  Leave it out for now and we can address it in a later cl.
|don't delete the logging statement here
|no new line here
|remove the space from the end of this line
|here's an idea: have directions like ['down', 'up'].  Then in the line below filename = '%s_scroll_%s'
|don't raise an error if it's not supported.  otherwise wmatrix turns orange and is frustrating to look at the results.  We should totally change that on touch_TapSettings too
|filetype isn't the right variable name (not that fh was any better...)  What about filepath?
|rename gesture as direction
|remove extra space
|can we have this be an actual error instead?  Check os.path.exists(original_file) to see if the file is there in the first place and then abort.  Also, don't put newlines in this message.  Do put .s.
|align the ' with the one on the line above
|I have no answers for you...
|yes, but I find it unlikely.  The small chance that os.path.exists() reports incorrectly for a good device is outweighed by the convenience when adding new files and supporting more devices (per the current plan)
|There are conflicting style guides about this one, whether you put 1 or 2 lines between methods of a class.  I'm matching the rest of the file here.
|Yep, the file format is &lt;stuff&gt; &lt;time&gt; &lt;movement description&gt; for many lines.  By comparing the first and last time, we can figure out the duration of the playback
|needs alphabetical order!
|this list is not in alphabetical order
|omit newline
|take that newline from above and put it below here
|.
|.
|what about using the tempfile library here instead, e.g. tempfile.NamedTemproraryFile(), which deletes itself when you close it
|what does crop() do if box is None?
|Format this better
|don't change the copyright on existing files
|We don't bump the copyright on existing files, just on creation
|I disagree.  poll_for_condition adds &quot;Timeout waiting for condition: &quot; before the provided desc value
|Maybe the right call is to not have a default None value in the other file.  There isn't one here.
|split onto two lines
|.
|string?
|add blank line before this one
|put at the top with a return between this and the autotest_lib ones
|nit: remove this line
|nit: remove this line
|blank line after this one
|move this line to above cros.ui (alphabetical)
|nit: remove this line
|nit: this comment does not need to be so long
|nit: move over by 8 total spaces if it doesn't fit on one line
|I'm not familiar with the take_screenshot_crop function, but should you be sleeping for a short time before taking the second screenshot?
|nit: use 'is' not '=='
|nit: feels a bit awkward for an error message.  &quot;Timeout waiting for condition:&quot; X.  Perhaps 'end of system tray animation' instead.
|what happens if mask_points is None?  Maybe you should check if it's none before calling draw_image_mask?
|nit: will fit on one line
|nit: not sure you need any of these comments, especially when it's no longer true about mask_points
|nit: not sure this is a needed comment
|oops
|Add &quot;crosdl wrapper:&quot;
Otherwise, this is confusing in a long list of changes
|couldn't this break on the first loop?  i.e. if the prev_time_s is 0 and the current time is 0?  There's been no sleep yet.  set prev_time_s to -1
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I feel ~5min is a reasonable amount of time given the finicky nature of Bluetooth devices and that it would be nice to run two at once.
|Done
|Done
|no mention of it in autotest style guide, so defaulting to google: http://google-styleguide.googlecode.com/svn/trunk/pyguide.html#Blank_Lines
|Done
|Done
|Sometimes, after clicking the Connect button, ChromeOS will mark the device as connected only to have it immediately change its mind and be disconnected.
|Done
|Swapped out for an mp3 file.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|only 1 for method defs according to style guide
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think so.  It depends a lot on the test.  E.g. if a person is expected to pair several bluetooth devices, 60sec might be too short.
|no...
|Done
|Done
|Done
|Not an autotest, so following http://www.chromium.org/chromium-os/python-style-guidelines
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No, it's not part of utils.  The one you pointed to was a method of class Host.  the other tests I found that use the kernel version all just call 'uname -r'.
|I don't think that opening the file once per run of this test is a problem.  I moved it to a separate file to keep this file from getting large and to make it easy to see/modify.

We can't say expected == actual since the actual kernel is of a higher precision (e.g. '3.8.11' vs. '3.8')
|Done
|Done
|Done
|Done
|Done
|Done
|that's a function in the Host class.  The similar lookups I could find in the codebase use 'uname -r' directly.
|Done
|Done
|will fix with next version
|&quot;&quot;
|Done
|Done
|Done
|This test is not intended to have a timeout - it's used by stress tests which could run for a few minutes or many hours.  poll_for_condition() requires a timeout.
|return needed if not using poll
|Script to collect browser test statuses and results from chromiumos builder.
|sometimes you use bld_ and bldr_ and sometimes build_ and builder_.  Use build_ and builder_ throughout
|If you only call _ListTestsOfResult() once, you don't need FAILED at all.  Also, PASSED and MISSED can be strings not lists.
|why do you need this?  use len(test_lines)
|delete this line
|1. if you have no matches, this will fail
2. use .strip() to remove a newline, not [:-1]
|change lineno to something else: i?
|stop looping on the inner loop when you find a match
|too many things called bld_url or bldr_url.  This function should live at the top with _GenerateBuildUrl().  Also, you use BLD_URL as a constant in that function and should do the same here
|If -2 is your default, given your check below, why do you need a default?  Just check whether it was defined when you decide which number to use.
|As above, do away with the default and say &quot;if build_num:&quot; here instead
|build_num and bnumber are confusing names.  Perhaps input_build_num and build_num instead?
|running..., missing... = _RunningAndMissingTests()
|instead of having this function and _GetStdioLogUrl, which share basically the same code, have one function for shared code and call it here
|you step through this entire list three times
|_PrintTestResults and _WriteTestResults do basically the same thing
|Done
|the move is in case you call it from outside the source tree (which I do often)
|Done
|Done
|Done
|Done
|It's not testing the feature though, it's just confirming that the value was set (or at least that get now returns the correct thing)
|No, it's repeatedly checking whether the feature is set.  There are two executions here, the first calls set and get and the second polls for the result of the get.  I'll reorder the command definition to make this more clear.
|Done
|Per discussion with Dominic, this is fine for now
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|yes
|Done
|Done
|Done
|indent over to ( of above line
|Change to &quot;Raises error if device does not have a lid.&quot;
|separate
|started_evt is a confusing variable name, both here and above
|Make the 3 and 5 into variables and multiply them together to get 15, in case you want to change them later.
|xrange()
|both are present in our codebase.  As the autotest guide is silent, I'm siding with the official google guide.
|Done
|Done
|Done
|Done
|Done
|Gone
|Done
|Done
|Done
|Done
|Done
|I want to read from it an arbitrary number of times, so cleanup sounds easier.  Done.
|I went with chrome://system for simplicity and the fact that I've encountered flake with setting up a server in the past.  However, I do not care that much.  Done.
|Achuith said to and I have no strong opinion?  If this fails then something's wrong with the code where this function was called, not the device.
|Done
|Done
|Done
|Done
|Done
|will fail for empty line or line of strippable characters
|Done
|Done
|Done
|Done
|Done
|the _1 is because it's the expected value of 1 turn of the mouse wheel.  It also matches the file names of down_1 and up_1, with which it belongs.  I've added a comment.
|Done
|Done
|Done
|It's already two tabs, not sure why it should be more
|Done
|Done
|Done
|Done
|Done
|trailing spaces on 18, 19, 90, and 101
|newline before &quot;&quot;&quot;
|ec_version here and everywhere
|@raises: here and everywhere
|you switch between saying
command = X; run_cmd(command) and just run_cmd(X).
Pick one.
|exp_ec_version, etc.
|there's no way I know of to get the values, just set them.  Because there can be no getter method, I don't think @property makes sense here.

I will fix this bad comment though.
|You mentioned making this optional before.  As intended?
|Done
|Done
|Done
|Done
|take out spaces
|newline goes before &quot;&quot;&quot;, not after
|why is this a self variable?  You don't appear to use it elsewhere?  If it's not, you can put all of the rest of this function into a with statement.
|you don't actually need the ( around this string
|do you need this variable (and the others like it here) if you immediately set self.mode below?
|you set a few of these twice.  I would suggest getting rid of this else and only modifying the values if 'dm-fake'
|this is a self variable, but you seem to pass it around as a parameter as well.  pick one or the other
|...
|...
|modify the original OR return a new one, not both
|does this need to be a separate function?
|this is also a pretty short function that you only call once.  inline?
|page is already loaded above
|trailing space
|this and other methods (other than setup, run_once, etc) should be private
|confusing name - too much like run_once
|= self.value or 'true'
|it makes more sense to copy only as needed, rather than copy all and remove the unneeded
|make this into a list instead.  Iterate over the list instead.
|don't put the name of the test in the function names
|Rather that list out the methods involved, loop over the items in the policy values list.  Inside the loop, call run_test(policy_value)
|Don't do this.  Instead, write a run_test(policy_value) function which does whatever needs to be done.
|leave it with the , instead (more common in the codebase)
|ditto
|add \n or ' ', or this will be a run-on
|nit: rather than saying if NOT X, switch it around to be if X.  It makes adding new exceptions easier in the future.
|Call this something more specific, like BLUETOOTH_3_BOARDS or something.  Also, separate this out from the INVALID_BOARDS variable and give it its own comment description.
|one line
|nit: newline here
|shouldn't be a self.  It makes more sense to pass two values to _match_bt_format().  Alternatively, set a local match_exp variable in the if/else statement, then compare them below without a separate function.
|Done
|_emulate_mouse() /is/ the super method.  The mouse_file can change depending on the test.
|we don't use the (c) anymore http://dev.chromium.org/developers/coding-style#TOC-File-headers
|=?
|no /n
|I get that commands are sent from a sever side test, but there's nothing here that mandates the ordering of commands.  E.g. you could call logout before login and then get a variable error because self.cr doesn't exist.

Maybe initialize self.cr and self.extension to None in init() and check whether they exist before using them, so you can fail gracefully.  Or add some text explanation of expected ordering.
|@raises
|spaces
|trailing spaces
|trailing space
|spaces
|spaces
|tabs?
|by your above description of what connected is, this is backwards.  E.g. connect_to_dut() is true, connected is true because &quot;should have been able to connect&quot;, then fail?  Change the description to match your testcases or flip this around
|no /n
|N isn't a number, it's literally the letter N (for name)
|horizontal
|horizontal
|horizontal
|indent is wrong here.  8 spaces
|extra newline
|extra newline
|extra newline
|extra newline
|extra newline
|extra newline
|insert newline to separate these two sections
|two /n
|put this below line 52.  first line /n /n second line /n /n params /n /n &quot;&quot;&quot;
|@param
|move these four lines down with the vertical scroll test to match the horizontal (and move the center cursor code too, I guess).  Check for failure to emulate mouse on the horizontal mouse too.
|change this to say Test vertical scrolling
|horizontal
|not a sentence
|remove these spaces
|put the second line back here
|I'm not in love with &quot;hori&quot;.  I think the full &quot;horizontal&quot; will be more readable.
|duplicate function
|for this and the above addition, make the function part of the vertical version.  Have a default parameter vertical=True and then and if statement where you choose which scroll position function and default scroll value you will use in the rest of the function.  Replace calls to self._get_scroll_position() with some scroll_position_function variable.
|Change the name to something else to avoid confusion.  Maybe &quot;Emulated Apple Mouse&quot; or something
|don't need this anymore.  Please also delete the other mouse name above.
|if you make the changes suggested in the test_base file, you can pass around vertical = True/False instead of having two separate functions (both here and below)
|'right' and 'left' seems more reasonable
|should just always set both
|wait for both
|wait for both to settle
|@param
|I would leave the expectation as its own line and add a separate @param for direction.  (This param doesn't explain what direction is)
|ditto
|alphabetical
|The movement playbacks are relative motion.  The test requires the cursor be on the page, so currently most gestures start my ensuring it.  This change will make that initial movement universal for all boards.  Best case, we'll eventually drop this centering entirely when some of the pre-freon functionality returns to it.  By simplifying this now before adding a bunch more boards, this test will be more future friendly.
|It's used to center the cursor - and save creating a unique gesture file for every device.
|&quot;Changed cursor centering behavior in touch_TapSettings test&quot;
|exclusively OR just, not both
|&quot;only do&quot;
|&quot;the newly added gesture file \&quot;center_cursor\&quot; will re-position&quot;
|cool.  It needs a better name (and a camelCase name at that).  maybe cursorOnPage?  the current name makes me think it should be the actual cursor position, not a boolean
|what exactly is this variable for?
|now that we have blocking playback to fix the drag case, let's switch this around to be a poll for condition with the given timeout.  I presume that blocking playback is too short for this case?
|yeah, that makes sense.  A poll is preferable to a sleep (no need to point out that I added the sleep in the first place :P)
https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/client/bin/site_utils.py&amp;l=197
|makes sense now that I see what that variable is for
|no reload should be needed here
|not done?
|more of a TestError in this case
|the drag file moves the cursor, though.  You mentioned before that multiple drags were moving the cursor too far, hence my confusion
|wouldn't you need to recenter the cursor somewhere after this playback?  Right now you only center the one time
|this check is probably not necessary
|My feelings on the matter are that this is a file for all devices, not just one.  It would be different if this were center_cursor_mighty and it might not be there
|&quot;the center&quot;
|Done
|Done
|Settings are user based and don't stick for test@test.test after logout.
|newline here
|call this DIRECTIONS
|&quot;down&quot; doesn't make sense in context anymore.  I'd change it to &quot;expected&quot; and have it be 1 or -1.  Then you can multiply the delta by the expected value and compare it to 0.  Or it might be easier to just rename it &quot;is_down_left&quot;.
|this function will always return true, because bool(&lt;string&gt;) is true for nonempty strings.
|merge this line with the line above it
|since there's actually no shared code in this function, and they're no calls that don't set scroll_vertical explicitly, make this two separate functions: _verify_vertical_scrolling and _verify_horizontal_scrolling.
|update docstring
|indentation is incorrect for this and the lines below.  You're probably best off moving filepath= to the next line over two tabs (8 spaces)
|I don't like this part.  There's no need to put files for all devices in a dictionary
|for direction in self._DIRECTIONS:
|do an os.path.exists here.  If it does, store it in a dictionary with key of direction.  Then above you can say path['down'] etc. and the code will be more readable.
|change @param info
|camelCase
|remove extra line
|on second thought, this also sounds weird.  what about &quot;is_down_or_left&quot;
|see note below.  Also, remove extra space: self._filepath[
|self._filepath is not a good name.  You need something plural to indicate that it's more than one.  E.g. self._filepaths
|&quot;filenames&quot; doesn't work here.  In the first place, the name needs to be singular (e.g. &quot;for thing in things&quot;), and in the second place, it's not a filename it's direction string.

for direction in self._DIRECTIONS
|This is a loop, why are you setting a self variable here?  Also, the outer parentheses are not needed
|don't make the key the filename.  make the key the direction.  Then above instead of calling &quot;self._filepath ['%s_scroll_down' % self._device]&quot; you can call self._filepaths['down']
|the center_cursor_file is not device specific, so don't check for it.  We don't check for long_page.html either.  If this file is missing, we have other problems.
|&quot;Emulate a USB test mouse and center cursor.&quot;
|Done
|nope, this one needs to be two tabs over (8 spaces)
|nope, this one needs to be two tabs over (8 spaces)
|Using external pages in an autotest is frowned upon unless there's a good reason.  Internal is better
|why don't you just make sure that get_policy_value_shown returns whatever matches the input policy_value variable?  Or the other way around - make sure that whatever calls this function matches what you get from get_policy_value_shown.
|make this a README instead?  Also, is every test going to have this same set of instructions?
|this doc is too long.  You're not going want to explain how to run the test in /every/ enterprise test.  You can assume anyone running a test can figure this information out elsewhere.  Save the test-specific stuff for this control file.
|I don't really have a problem with it, but I believe certain people would object to using these urls for future-proof reasons.  Is local http server pages an option here?  Or non-existent files, since you just need the url to match?
|If you run browser.SetHTTPServerDirectories(self.bindir) you can access a local file by tab.Navigate(browser.http_server.UrlOf(path_to_file))  This probably would not work here, given the timing of logging into the browser /then/ setting the directory.
You can also navigate to a file:///.
I'm not really sold on your having to change this; just a thought.
|here and everywhere:  formatting is TEXT\n\n&quot;&quot;&quot;, e.g. a blank line in between the last text and the &quot;&quot;&quot;
|autotest style guide: https://chromium.googlesource.com/chromiumos/third_party/autotest/+/master/CODING_STYLE
See line 124
|superfluous comment
|if you're not passing in any args, why define this at all?
|Sorry, I was unclear with my first comment.  You're not adding anything to the super() version of this function, so why are you redefining it?  If you leave this out, the parent version of initialize() will be called anyway.
|rephrase to indicate that the test is not the one opening these tabs, Chrome is.  e.g. &quot;When RestoreOnStartupURLs is set of one or more URLs, check that a tab is opened to each URL&quot;
|comment or logging.info, not both
|do the tabs have to be in the correct order?  Else you could just sort the list to be sure it matches.  If they do need to be in this order, consider using self.cr.browser.tabs[::-1]
|again with the switch of 'None' to None.  Try and figure out how to not do this.
|you turn two different lists into strings in order to compare them.  why not just compare them as lists?
|I'm still not on board with this whole lists -&gt; strings comparison.  Not sure why you can't just compare the two lists.
|ditch out early if not supported (e.g. if case not in self.TEST_CASES)
then you can just set the two values in the if/elifs and finish it up with a single call to test_StartupURLs()
|comment not needed
|comment not needed
|comment not needed
|mention the possible error conditions with @raises
|delete this comment.  In general, if you're describing line by line exactly what the code does, leave off the description.  You could put a more general comment instead
|ditto
|why are you printing this out if it's always True? (ditto for below)
|still a scary wall of text...  You really don't need to tell someone how to run an autotest
|you should still have the following info in this file:
- PURPOSE = &quot;Short string about what this test is for.&quot;
- CRITERIA = &quot;Description of pass/fail conditions (e.g. 'this test will fail if ...')&quot;
- DOC = &quot;A few sentences about what this test is checking for and an example showing what passing arguments looks like&quot;
|remove this trailing space
|there's no need to call the cleanup() of test.test, it's made to be overwritten, so it just calls pass anyway.
|multiple lines
|multiple lines
|remove the newline here (i.e. &quot;&quot;&quot;Runs)
|not a param?
|newline after this one
|why is this a subfunction?  You only call it once inline, it seems like this code could just be tacked onto the end of the function instead
|add @returns and describe the type of return (integer?)

Also say &quot;percentage memory used&quot; instead of &quot;used memory in %&quot;, which threw me when I first read it.
|think about putting the open() and the following code in a with statement
|it is unclear to me what creates this terminate file.  If the test just runs forever until manual intervention, please add a comment here to indicate that.
|remove the Terminate path
|not the name anymore
|name this file something else, like a description of what it does (e.g. &quot;3_tabs_enter&quot; or something)
|both of these variable names are a bit cryptic.  What about property_file and playback_file?
|hmm, that was dumb of me...  I reserve the right to fix that in the future
|player.emulate(evemu_describe_file, 'keyboard')
|player.blocking_playback(evemu_record_file, 'keyboard')
|set these as constants at the top of the class
|omit &quot;does&quot;
|lots of trailing whitespace! (here and elsewhere)  Also, this test has accelerated scrolls (the fast ones), so leave that out
|here and elsewhere, mention that you move the cursor well into a corner of the screen first, then move the cursor back.  Ensure that any starting cursor position will result in a centered cursor.
|remove these
|omit &quot;does&quot;
|delete
|delete (etc.)
|describe the drag part too
|emphasize that it's a tap click, not a physical click.
|it's what the WiFi tests do for this same type of log file.  Also, the file is only used in this class so only needs to be defined once.
|nope, it makes no difference to the outcome of the test.  I could check whether the two builds actually have different touch firmware, but that's much more complicated.  As this will have to be kicked off manually anyway, the test operator will just have to pick good builds.
|I have to do the variable checking before I can do the loop part, but I've moved some of it around
|Done
|yes it could.  My thinking here is that in practice we currently ignore all occurrences of this error.  If it happens on the real build when the FSI logs are present, it's also likely to happen when they are not.  Without this change, we ignore both cases.  With it, we would see only the second type of failure - but investigate.

I could attempt to determine at what point the log was written, but that seems overly complicated for what I hope is a temporary fix.
|irs.gov
|camel case
|()
|delete
|I don't like that this variable is almost the same as the method name.  Rename one of them.  Maybe make this one &quot;is_disabled&quot;?
|could be fit into two lines
|this is basically the same as from policy_RestoreOnStartupURLs.  You shouldn't put this same file in every policy_* test.  If there's this much overlap with every test, move that stuff to a common file.
|this function and test_SetFalse are the same, only one expects True and one expects False.  You could combine these into one function that derives True or False from the provided inputs, or you could pass that input in from _run_test_case, or you could move this functionality into the _run_test_case function
|why are you using camel case?  your method names should use _ separation
|returns:
|new tab is activated by default, and you don't need it to be active in this case regardless
|why the #1?  Omit that to future-proof
|is there some other way to check for this besides a sleep?
|I'd prefer is_add_bookmark_disabled, to indicate a boolean
|is used
|why not just print the list instead of one by one?
|Done
|this change will land in M47, so it only matters for M47+.  The _freon board names are gone.  Nyan boards are still not freonized, but since we've added new tests anyway, we'll handle those boards for /all/ our tests when the time comes.
|autotests
|don't put this.  Also, don't write this field as all one word.  say that you successfully ran the tests
|Done
|I'm inclined to leave it as is.  This function is basically the test's init() function.
|Done and fixed on the touchpad version too
|Done and fixed on the touchpad version too
|I believe so, yes.  It's 8 instead of 4 because it had to carry onto the next line.
|Done
|Done and fixed on the touchpad version too
|Done and fixed on the touchpad version too
|not needed
|remove
|why use URL_HOST above and URL_BASE here?
|looks like most people using this function don't put it in a try block.  Presumably the probability that it will fail is low enough that it's fine if the Exception isn't caught.
|put the cleanup at the bottom of the page
|space at the end.  I would actually leave this text the way it is - the test behavior hasn't actually changed.  It's still going to check both.
|ditto
|I considered that but decided as is was more readable
|Done
|Done
|Done
|Done
|Done
|Done
|They're used by the tests that use this class, as well as for general debugging.  For example, recorded gesture files are now associated with a hw_id, so that a daisy with an Atmel touchpad doesn't fail trying to run a file from a Cypress touchpad.
|Done
|Done
|Updated comment to be more clear.  To be super clear, I mean that when this problem occurs, there are log entries from earlier build(s) followed by log entries from the build under test.  The line we split the logs on can happen multiple times, and we want to catch the entire range.  E.g. AAAABBBBBBCCCC - in this example, we find the location of the first C by going backwards and finding where B != C.
|Done
|no, it's defined in the touch test base class
|\n after import re to separate the two types of imports
|why is this two functions?  This function has only two lines - calling a second function with the exact same inputs.  Furthermore, the second function catches an error to report False, then raises that same error again after getting False in this function.

Merge these into a single function and get rid of the try block below.  Just let the polling function raise the error.
|too long - only one line for the docstring start
|newline after first sentence in docstring
|not sure what this sentence means
|end with .  Also, technically the first line needs to be &quot;&quot;&quot;\nLoads (i.e. a newline between the &quot;&quot;&quot; and the first word - but I care less about that.  However, you've got both conventions in this file so change them all to match
|put entire string on second line and indent 8 spaces, or define the string as a variable on another line if that won't fit either
|see message above why you should consider omitting this try block
|8 space indent.  If you can't fit it onto one line, fit onto two
|see other file
|formatting
|formatting
|formatting
|formatting
|remove \n
|might as well format this here, like you do with bucket_pattern.  Also, having all caps doesn't match
|remove \n
|remove \n
|no space after histogram name?
Also, it's weird that you define this variable here and have bucket_pattern defined in the function itself.  I'd move one or the other.  Personally, I'd put this below.
|extra \n before the &quot;&quot;&quot;, not after
|too many \n
|extra \n needed here
|I'd prefer you get rid of these variables entirely if you're going to also use the more descriptive names.
|what about something like:
policy_value = ','.join(self.TESTCASES[case]
policy_json = {'JavaScriptAllowedForURLS': self.TESTCASES[case]}
instead of listing out each case individually?  You already checked whether this is a valid testcase, so you don't even need to do that
|@raises: error.TestError
|no newline between these two
|no newline here either
|only one newline between last text line and the &quot;&quot;&quot; line
|no newline here
|spaces, not tabs (on any of the lines with the red &gt;&gt;)
|no newlines between function and &quot;&quot;&quot;
|no trailing space (and fix spacing in above paragraph)
|change this sentence to say that you separated the set_scroll() functionality into its own function (since its relative location isn't so important)
|blank line; no spaces (and same below)
|&quot;set scroll position to given value&quot; (this function doesn't wait)
|add @param value
|only try twice
|remove the debug print statements (here and below)
|perhaps print the current scroll position after this if statement?
|no trailing space
|probably not something that needs logging.  Without the logging, you don't actually need to change this function at all.
|not my code, so I hadn't noticed.  I.e. no
|that would require the TestPage class to have a secondary location to search for the filename, and right now it has no idea of any file structure on the DUT.  I also want to ensure that the EventsPage is using the right file, so being able to pass in a filename might be confusing and not really what users should be doing.
|inline puts me over the line limit, but I can at least make the first line shorter?
|no longer a one liner :)
|I also like option 2.  I've added that class and will make the other tests use it more thoroughly in a future CL.
|none at all.  Probably an accidental hit of the x key in vim...
|Done
|Done
|Done
|I was hoping to keep this function agnostic of any sort of extension - which you need to verify whether ChromeVox is on.
|Done
|I don't see that exactness will be a problem here.  Will leave as is
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

(4 comments)

a few nits, and I can't say I know much about the document scan side of things, but otherwise looks good
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3:

(3 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 5:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

For future reference:
- The print function tweaking is to make repo upload happy
- The copyright date is to undo an accidental change
- cid and lulu are not named auron-cid and auron-lulu as this script optimistically anticipated.
|Patch Set 1:

(9 comments)
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 5:

(2 comments)
|Patch Set 6: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

(8 comments)
|Patch Set 1: Code-Review+2

Once this lands on ToT, you'll need to request permission to merge from the TPMs via bug labels.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1

(1 comment)
|Patch Set 1: Commit-Queue+1
|Patch Set 3:

(19 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Carrying Kalin's +2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready

Cl only has string changes
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1: (13 inline comments)


|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 2: (16 inline comments)


|Uploaded patch set 4.
|Patch Set 3: (5 inline comments)


|Uploaded patch set 5.
|Patch Set 4: (11 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved; Ready; Verified

Fix krisr's nits; carry the +2

This test is fired manually.
|Patch Set 6: Ready


|Change has been successfully cherry-picked as 9dff94f2e1a1ffb681605e4d2fa473c34f893a5a
|Patch Set 1: Looks good to me, approved; Ready; Verified

First Attempt https://gerrit.chromium.org/gerrit/#/c/59128/

This test is run manually.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (3 inline comments)


|Patch Set 3: Ready; Verified


|Patch Set 3: Ready


|Patch Set 3: Ready


|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(8 comments)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(7 comments)
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)

Upon further investigation, there is no information here that is not already checked-in publicly.  I do not think we need to move it to autotest-private.  See /server/cros/faft/config/
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Message shortened.  Carrying the +2
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Made Alex's suggested cosmetic changes
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Carrying +2
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Change has been successfully cherry-picked as f3e0a2485a23a68d07324cc094e0d2bb0a6a1355
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Change has been successfully cherry-picked as f4c4236d85b1aab3b00fc2603de6a512bae96546
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 4:

(16 comments)

I'll review it again after Scott addresses the following issues:
- variable names should be consistent and understandable
- unnecessarily repeated work
- code duplication
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)

Re: Yu-Ju
The premise is to download image(s) or specific file(s) from chromeos-releases and, if requested, use cros flash to create usb sticks
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)

This test is meant to catch errors like we've had in the past: enable ChromeVox and the OS crashes.

I think we can have additional, more complex tests but this should be as is.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(7 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

Added the ChromeVox specific tests as per conversation with Dominic.
|Patch Set 5:

(12 comments)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3:

(5 comments)
|Patch Set 4:

(1 comment)
|Patch Set 1:

There are two cls here with the same change: this and 202081
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(11 comments)
|Patch Set 4: Commit-Queue+1 Verified+1

2 newlines between each class method is not explicitly described in the autotest style guide and 1 newline /is/ listed in the google python style guide. Going with that, as there are examples of both in the cros autotest codebase.

Given that the rest of this isn't that major, I'll catch it the next time.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)

Kalin: I did run a sanity test on the paths changed by this code, I just didn't put that in the TEST field.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

(5 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

After some discussion, skipping Synaptics touchpads since this setting is hardcoded and the touchpads are not on the avl.

The other three touchpad types run with no problem.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(5 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

DEPLOY=suite_scheduler
|Patch Set 1:

(5 comments)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1

You should get someone who actually knows what this test is supposed to do (e.g. Yusuf) to +2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2

Carrying adlr's +2 after a comment fix.  Will mark this as ready after the corresponding ebuild change is ready
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Carrying +2 after rebase
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Carrying +2 after rebase
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 5.
|Abandoned

&quot;cannot merge&quot; error
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Carrying +2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2:

(4 comments)
|Patch Set 8:

(13 comments)

There are perhaps more comments here than necessary, and the docstrings are, in general, too long.  I suggest going through your comments and deciding whether they're actually needed to understand the code.
|Patch Set 9:

(1 comment)
|Patch Set 10: Code-Review+2

(4 comments)
|Patch Set 10:

is there an ebuild cl as well?
|Patch Set 1:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 2:

(13 comments)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review-2
|Patch Set 1:

(9 comments)
|Patch Set 1:

(2 comments)
|Patch Set 2:

(5 comments)
|Patch Set 3: Code-Review+1

(11 comments)
|Patch Set 4:

(1 comment)
|Patch Set 6:

(3 comments)
|Patch Set 8:

(3 comments)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(11 comments)
|Patch Set 2:

(6 comments)
|Patch Set 3: Code-Review+1
|Patch Set 3:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

carry the +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Carry +2 after comment fix
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(11 comments)
|Patch Set 2:

(10 comments)
|Patch Set 4: Code-Review+1

(1 comment)

minor nit
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

carrying the +2
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 4:

(16 comments)
|Patch Set 7:

(7 comments)
|Patch Set 9: Code-Review+1

(3 comments)
|Patch Set 12:

(1 comment)
|Patch Set 1:

(10 comments)

I assume there's an ebuild cl for this somewhere?
|Patch Set 2: Code-Review+2

(2 comments)

fix these two remaining nits and then submit away
|Patch Set 3:

(5 comments)
|Patch Set 4:

(2 comments)
|Patch Set 6: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2:

(9 comments)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(3 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Carrying mussa's +2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

(8 comments)
|Patch Set 2:

(5 comments)
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Carrying +2 after merge-conflict resolve (no changes)
|Patch Set 4: -Code-Review -Commit-Queue -Verified
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(6 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 7: Patch Set 6 was rebased
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

(2 comments)

Discussed in person with Scott the possibility of a not-screenshot-based approach.  He is investigating.
|Patch Set 6:

(3 comments)
|Patch Set 8: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(9 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

Nit on Commit Message: put [Autotest] at the front and say changing /expected/ audio length.  The current subject suggests that we're changing ChromeVox in some way
|Patch Set 1: Code-Review+1
|Patch Set 7:

(14 comments)
|Patch Set 9: Code-Review+2

(4 comments)

+2 with some remaining nits
|Patch Set 10: Code-Review+2

(4 comments)
|Patch Set 2:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2:

(10 comments)
|Patch Set 6:

(6 comments)
|Patch Set 8:

(1 comment)
|Patch Set 9: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Carrying David's +2 after adding back a missing space in a logging string
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

(1 comment)
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|You'll want to use 0x33A0 and 0x33A1.
|Most extensions to EGL and ES don't use quotes at all around the additions to spec text, actually.
|Allman-style braces, plz.
|Could you add comments in the places where division is being avoided, to make the intention clear and make sure we don't later forget and end up adding more division ops back in?
|Sorry, I meant leave this one at 0x320E to retain the contiguous range, but update the enum in the robust initialization extension to be 0x320F.

(But if you're just sick of messing with it, it's not that big a deal.)
|I think I didn't leave enough room before the enum for EGL_CONTEXT_OPENGL_ROBUST_RESOURCE_INITIALIZATION_ANGLE. Can you update that one to 0x320F in this CL?
|Sorry for not catching this before, but this enum is already used in the window fixed size extension...
|Eh, that could imply that the renderer requested with SOFTWARE_ANGLE isn't conformant.

Geoff, are the SOFTWARE_ANGLE and REFERENCE_ANGLE options meant to differentiate between WARP and refrast? Would it be better just to explicitly call those out? Are you using more generic language just to make this attribute DX9/11 agnostic? Or are you leaving room for other software renderers (e.g. SwiftShader) here?
|Re: implying incorrectness of speed-oriented renderer-- yes, but I think the implication is less so than if it were stated as &quot;conformant&quot; vs. &quot;performant&quot;. Conformance is a binary state, where as &quot;correctness-oriented&quot; sounds a little more wishy-washy.

I'd suggest &quot;the reference rasterizer&quot; and &quot;a performant software rasterizer&quot; or &quot;an optimized software rasterizer&quot;, which would remove the implication entirely.
|We're already taking a parameter to request a d3d9 or d3d11 renderer as part of the same API call-- we could just specify in the extension that WARP is only a valid attrib when the d3d11 renderer is requested?
|Remaining question: what is the appropriate default value for texel data? Should RGBA textures be initialized to (0, 0, 0, 1), or (0, 0, 0, 0), or something else? What about depth, or stencil? All zeroes is easiest to write the spec text for (because &quot;zero in all channels&quot; works for RGB, RGBA, L, LA, depth, and stencil formats), but easy spec text is not necessarily correct behavior. What does Chrome do?
|This is not necessarily true, depending on how the default value is specified.
|The EGL_EXT_robust_initialization line was actually meant to mention EGL_ANGLE_create_context_robust_initialization. Victim of reading another extension and typing at the same time + the three times I changed the names of both of these extensions before putting them up.
|Should say EGL_ANGLE_create_context_robust_initialization (or whatever that extension is ultimately called).
|I suspect these extensions have some chance of uptake by desktop GL &amp; its window system binding APIs-- I think it would be advantageous for WebGL to be able to rely on native GL implementations for initialization behavior, like they were able to get put in place for robust buffer access.
|Picked up this wording from the other robustness extensions. It's basically a hedge against such functionality just being put into core implementations, and allowing this extension to be used to bootstrap the same behavior implemented in other extensions.
|ditto above
|We shouldn't use Windows type definitions outside of the D3D-specific backends. I'd suggest uintptr_t or khronos_uintptr_t.
|A nested 1-pixel memcpy seems like a place where we could possibly find a more performant path. Is there a way to copy more at once, given that every pixel we're copying in is the same? If it's a choice between having a single type-agnostic function and doing fast copies, is single type-agnostic function the right choice?
|Oops, typo. (One of the downsides of gerrit is the lack of ability to say &quot;fix this before commit, approved&quot;)
|This could probably use a comment explaining why RequiresInit needs to be checked every dirty check, not just at init time.
|Do we need to be checking the results of these? If not, why are we storing it?
|Here too, please.
|Does this also need to happen in unapplyRenderTargets()? Alternatively, do we need to store the current framebuffer at all? It's already retrieved in Context::applyState() via getDrawFramebuffer(), and that's the only function that calls through to setBlendState(), which is in turn the only place that needs to access the cache, right?
|I'm sorry to pingpong this one again, but can the framebuffer go at the front of the arguments list? We usually provide contextual objects before current state. (Sorry to nitpick.)
|Is it worth ASSERTing here that depth is nonzero? (In any case, this is way better than what was there before...)
|Do these shaders run into problems binding a cube SRV to a Texture2DArray object in the shader? I thought we had issues with that elsewhere...
|Can this function either be named or commented to make clear that it's the stored pre-swizzled texture that's being invalidated, rather than the value of TEXTURE_SWIZZLE_&lt;channel&gt;? Similarly, can the full-chain invalidation function reflect that it's doing invalidation for the full chain more clearly either in its name or in a comment?
|Can this function be named something which conveys that it's a one of the draw-time oriented functions, which relies on current program bindings, rather than a more purely informational one, as most of the functions beginning with &quot;get&quot; are? It's a bit nitpicky, but I think it's an important distinction.
|Any reason not to pass the program binary down through this get function, since we have to retrieve it above anyway? That might mitigate the get/apply informational/draw-time setup confusion as well.
|Why does this need to be done in drawElements but not drawArrays?
|This should conform to our style guideline: https://code.google.com/p/angleproject/wiki/CodingStandard

(All caps, files in the compiler directory prefixed with COMPILER_, and a trailing underscore.)
|Can we just carry over the version from the es3proto branch (it uses &quot;resource&quot; instead of &quot;variable&quot;), and SafeDeleteArray while we're at it?
|The reason this wasn't handled before was that things didn't seem to work right at the next Present call on some systems (or at least the iMac you were on at the time). Is there any way to test this on a bunch of different hardware without any ANGLE bots? Or should the removed-device-specific handling take care of the issues that were seen way back when?
|Should we clear the divisor for all attribs like we do before clears and blits?
|Worth commenting here that D3DERR_DEVICEREMOVED is only a possible return code for non-D3D9Ex, so we're not going to trigger this assert every time device removed happens. It'd also make the restructuring of the ifs below a little less confusing.
|Did this change from while() to for() for a programmatic reason?
|The three different sleeps for three different intervals is starting to feel a little magic-numbery. Can we have comments for why the sleeps are the intervals they are? Might save some &quot;maybe fiddling with this number will fix something&quot; by someone else down the line.
|Is the the sampler state &amp;c actually needed here? Or would just the texture suffice?
|Nitpick: can this be &quot;ES2 or D3D9&quot;?
|Is this a double AddRef for mTexture?
|If resource was non-NULL at constructor call time, should we be decrementing its refcount here before setting mTexture NULL?
|This makes me pretty leery-- the refcounting behavior now differs between SwapChain11's DX object getters and SwapChain9's, which seems like a recipe for refcount problems down the line.
|This comment should probably appear above the RenderTarget11 constructor call, and specify which resources it means-- right now it looks like it's applicable only to the RTV. The comment should also call out that taking ownership of the resources includes incrementing the refcounts for all the objects itself. (Likewise for below snippets.)
|Is warnings the updated def, or is deprecate? I can't remember.
|Done
|Done
|Ah, much better. Didn't realize the major version had gone up with the last commit hash patch-- this is better.
|I second this request, and ditto my comment about the typo on master.
|Stray whitespace nitpick.
|Ah, sorry, I'd just referenced the section defining all the errors, which refers specifically to function arguments. It does sound like BAD_NATIVE_WINDOW is acceptable, although I don't know if it's more or less appropriate than CONTEXT_LOST.
|I don't think any of the entry points that call down to this function take a window parameter; I don't think this is the right error. CONTEXT_LOST or maybe BAD_ACCESS would probably be preferable.
|D3DERR_DEVICEREMOVED is something like 0x88760870, isn't it? 0x8XXXXXXX is a failure-- the high bit is set, which makes it negative, no?
|Would the second half of this condition ever be checked? I think all of the device loss codes are FAILEDs.
|I think this is covered by &quot;If a value is so large in magnitude that it cannot be represented with the requested type, then the nearest value representable using the requested type is returned&quot; (3.0.2 spec, p222, sec 6.1.2 &quot;Data Conversions&quot;). If we want to return a value higher than max int when queried, we can via GetInteger64v as long as we cap it when returning via GetIntegerv. Do we actually have any idea how many vertices might make DX11 cranky? If we don't, this is fine-- you could update the comment so it's clear we're choosing max int for the convenience of not having to have separate handling for GetIntegerv and GetInteger64v, but it's probably not strictly necessary.
|It looks like there might be a hole in our context version checking for the query functions-- if you call the appropriate function for the native type of the item being queried (i.e., call glGetIntegerv for something that's stored as an integer), Context::getQueryParameterInfo is never called, and I think that's the only place we're enforcing context versions for queries. So it might actually be possible to get to this UNREACHABLE. (But it should still be UNREACHABLE-- we just need to fix the validation.)
|You'll need to create a section for your company, if you're contributing on its behalf, and list your names there. Also, whoever the copyright holder is (the company if a corporate submission, yourselves if individual) should be added to AUTHORS.
|It would be a good idea to keep ANGLE-specific defines out of the Khronos headers, since we'll want to submit them back to Khronos. Is there a Windows system define that can be checked instead?
|I'm not sure this is the right place for this define-- a cast convenience macro probably belongs at the project level, rather than redistributed by Khronos.
|This is fairly pedantic, but would you mind restating the full type rather than reusing EGLNativeWindowType? While they'll both be using the IUnknown type, it'll be QueryInterfaced into something different in each case, so it would be good not to imply that the window and display types are equivalent.
|Could the ifdefs be structured such that the vanilla defines don't need to be repeated?
|I think it's a little confusing, especially because one of the increments for the value is inside an unreachable clause (why express it if it can't happen?), and because it could be parsed as &quot;argument count to which a bias has not been applied&quot; instead of &quot;count of arguments which are not the bias argument.&quot; I also wouldn't have known you were comparing the number of actual arguments to the number of mandatory ones (Is that what gets accumulated to nonBiasArgumentCount? Why not call it mandatoryArgumentCount?) without this explanation.
|If we're going to have something like this in the repository, an #ifdef guard would be nicer than commented-out code, imho. This just looks like someone forgot to remove their debug crumbs.
|Please let's not introduce a new style at this point in the project.
|Why does this take a Context pointer?
|GetPixelBytes is dividing the stored number of bits by eight before returning it-- it seems silly that we do that before multiplying it right back in here. Was there a reason we didn't provide a GetPixelBits?
|We definitely don't want to remove GetPixelBytes. If this is the only place that we need bits, I don't think adding a Bits version would be worth it.
|Can this have a comment or something to clarify that it's not specifically desktop GL formats? It's an unfortunate side effect of the naming of the APIs that GL without qualification is often assumed to mean desktop.
|Any reason you've switched from the insert semantic to the assignment one?
|The choice between the two doesn't matter much for a map where we a) will not have key collision, so the different collision behavior between the two doesn't affect us, and b) are using scalars for both key and value, so the wasted default initialization in operator[] probably doesn't matter. (I'm assuming that's why you left the insert()s in place for maps which hold complex values.)

I'd prefer not to change some but not all of the map insertion behavior in our format table handling (this doesn't change the swizzle format tables, for example) with no reason other than personal preference. I wouldn't feel differently if it were all the instances-- since the originator of the code preferred to do it the other way, there are multiple personal preferences, and I'd prefer not to open the door to style thrash and spending lots of time revising other people's code to suit one person or another. Unless there's a compelling reason to change from the already in-place code, let's stick with what's already there.
|Nit: These sections don't traditionally get indented-- the modifed or added section just needs to be set off in quotes (and also set off with a carriage return, which you've done).
|To make clearer that this concerns the surface responding to changes in window size over its lifetime, not just at creation, I'd suggest changing the first sentence to:

&quot;EGL_FIXED_SIZE_ANGLE specifies whether the surface must be resized by the implementation when the native window is resized.&quot;
|These sentences should make clear that this describes the lifetime behavior of the surface. I suggest:

&quot;If its value is EGL_TRUE, the window surface's size in pixels is specified by the EGL_WIDTH and EGL_HEIGHT attributes, and will not change throughout the lifetime of the surface. If its value is EGL_FALSE, then the window surface must be resized by the implementation subsequent to the native window being resized, and prior to copying its contents to the native window (e.g. in eglSwapBuffers, as described in section 3.9.1.1). The default value is EGL_FALSE.&quot;
|I'm a little hesitant about the interaction between EGL_FIXED_SIZE_ANGLE and EGL_WIDTH and EGL_HEIGHT (specifically the part where the latter two must be specified if and only if the first is), because there aren't other attributes that behave that way. Would it maybe be better to specify defaults for all the values, and then say that EGL_WIDTH and EGL_HEIGHT are ignored if EGL_FIXED_SIZE_ANGLE is EGL_FALSE?
|I'd reference the EGL_FIXED_SIZE_ANGLE enum directly here.
|I don't think these need to be broken out into subsections-- extensions generally identify the section in the first modification to it, and then say &quot;in paragraph XYZ of the same section&quot; for subsequent modifications.
|That's the third paragraph, I think.
|I'm still uncomfortable with how this behaves as compared to other attributes in the list. The others have explicit defaults, while EGL_WIDTH and EGL_HEIGHT are not actually values with their own defaults, but implicit overrides of other behavior of the surface. If we're going to introduce unresizeable surfaces (which I don't think are great in the first place), that should be an attribute in and of itself, and it should be queriable-- maybe EGL_FIXED_SIZE_ANGLE or something similar?-- and default to EGL_FALSE. The defaults for EGL_WIDTH and EGL_HEIGHT can be then be specified to be the size of the native window.
|However I count it, I can't get the EGL_WIDTH/EGL_HEIGHT paragraph to come out to 16. It's probably better to say &quot;in section 3.5.6, replace the last paragraph on page 37 with&quot;.
|Probably better to identify this as the first paragraph in section 3.9.1.1.
|The question of explicit resizing should be added to the issues list.
|Missed this before-- we need company affiliation.
|Also missed this-- I think we've usually used Google addresses. (Actually, I was TG last time I wrote an extension; had to check the registry to see what people have done before.)
|Extra leading quote.
|This error is no longer called out in the extension text. We should either specify an error for zero values when fixed size is set, or silently allow creation of zero-sized surfaces if the application asks for them. The extension text would be cleaner with the latter, but it'd be less friendly to careless users. I... could go either way on this one.
|Ah-- strictly speaking, our behavior for pbuffer surfaces is also out of spec (although, for EGL, a lot of our behavior is across the board). As far as silent creation of a 0x0, I was thinking just return without error, but not actually create anything D3D-side? Not sure-- I'm just particularly concerned about obeying the spec on a vendor-specific extension that we write ourselves and are likely to be the only implementors of.

Jamie-- I think you had some run-ins with 0x0 windows around this time last year. Do you have any opinion/insight on this one?
|I doubt it's a functional issue, but should we continue to initialize these to -1 if fixedSize is false, so that it's easier to tell if something goes wrong in that case?
|Is this defaulting to EGL_TRUE because this is the constructor called for offscreen surfaces? If so, please comment to that effect.
|Is there any point in doing the comparison if autodetection is not enabled? It might be better to define sizeDirty above the if (mAutodetectSize &amp;&amp; ...) clause, and flag it as true inside that clause if the client width/height do not correspond to the surface's.

What is the intended behavior for non-autodetecting surfaces on native window resize? The specification (in sec 2.2.2.2) discusses the possibility for definition of extensions to give surface resize control explicitly to the client, but I think the language of the spec is pretty clear that expects surfaces to be resizable *somehow*.
|Eh, I'm not sure how comfortable I feel with leaving functionality holes in an extension because it's not useful to Chrome-- it seems like something ANGLE should avoid doing if possible, as a good citizen of the standard and an implementation used by multiple projects, rather than just an appendage of Chrome.

Of course, my feelings would have a bit more weight if we fully implemented the EGL spec. We're already not the best citizen of the standard.

If we go forward with creating an extension which removes the spec language indicating that native window resizing should be handled or else control of resizing should be given to the client, it would probably be best to make creation of a non-resizing surface very explicit-- not just implied by the inclusion of EGL_WIDTH &amp; EGL_HEIGHT.
|Probably ought to put the early return above the comment, since it goes more with the body of the function.
|I'm not a fan of macroing this in general. It makes the resulting code less clear.
|Should we be proliferating C++11isms outside of D3D-specific areas of code? Are we going to need to compile this with elderly versions of GCC at some point, with the coming refactor?
|Any reason to move this inside the context check clause? The context isn't needed for this bit of validation.
|The ES3 entry points are different cases, because we have to evaluate &quot;is this a valid entry point in this context&quot; before any other error. I'd honestly not worry about making these parallel, since the ES3 entry points all parallel each other in that respect.
|I'd prefer if static methods got declared at the head of the file instead of in the midst of the member function definitions. Also, the name of the function is typoed.
|You'll probably want to make this more descriptive before landing it.
|Almost-- the usual format has the 'at' obfuscation even, like this: http://www.khronos.org/registry/gles/extensions/ANGLE/ANGLE_framebuffer_blit.txt
|Call this one EGL Extension XXX for now (sorry for not noting that before)
|The TYPE enum should be kept, but a second section for &quot;accepted as values for the EGL_PLATFORM_ANGLE_D3D_TYPE_EXT attribute are:&quot;, and token names for D3D9, D3D11, and WARP added there. Or, if it makes more sense, WARP could be an attribute (rather than a value) that takes EGL_TRUE/FALSE specified alongside TYPE.

I think our token names and the extension name itself should probably carry the ANGLE suffix in place of EXT, since we're the only ones likely to implement it (although admittedly, vendor-specific suffixing seems a little less meaningful in the context of platform-specific extensions).
|This'll need to be ANGLE_platform_angle_d3d if we're doing vendor-specific suffixing.
|Rather than specifying &lt;native_display&gt; to be unused, we should specify that the native display type for ANGLE is EGLNativeDisplayType (we could be specific to Win32 and say that it's an HDC-- but it might be wiser to use just the EGL type, given that the type would be different in WinRT, and we're anticipating WinRT support patch contributions soon), and continue to support the language from EGL_EXT_platform_base and the EGL 1.4 specification that the same display is returned if the function is called repeatedly with the same display id.

Also, EGL_PLATFORM_ANGLE_D3D_EXT should be _ANGLE rather than _EXT here.
|I would say &quot;created&quot;, rather than &quot;assumed&quot;. Also, given the language in the base extension and the specification about returning the same display any time the same display ID is passed, we should clarify what happens if a different EGL_PLATFORM_ANGLE_D3D_TYPE_ANGLE is passed than the one used when the device was created. (Also _EXT should be _ANGLE here too.)
|I think this is mistakenly included in the wayland extension...
|2014 now, time for new boilerplate!
|Don't need to indent for the namespace
|Boilerplate date update
|Transform feedback objects aren't shared between contexts, according to Appendix D. XFBs should be owned by Context, like Framebuffer, Fence, Query, and VAOs.
|Section ID would be helpful in these comments, too.
|This may be a derpy question but-- any idea about whether there's a performance impact in marking all vertex buffers as stream output as well? Will our never-XFB-bound buffers suffer for being flagged for stream output binding?
|So InfoLog violates our style guide in that it's a non-const reference, but it's handled that way *everywhere*, so... don't do anything about it just now, but we should probably figure something out.
|Is there any potential downside to resizing the output vector before we know whether the component count has been exceeded, as ProgramBinary's linked varying vector is used directly? Does that vector have any meaning for a program that was not successfully linked? I don't think it ever gets accessed for a query, etc, but I'm a little hesitant about modifying internal state when we don't know whether we're going to successfully link.
|Count needs to be checked to make sure it's non-negative no matter the bufferMode.
|If program doesn't refer to a valid program object, it needs to return INVALID_VALUE. (This doesn't get called out specifically in the XFB entry point specs, but is a blanket error described in 2.11.1 -- &quot;Commands that accept shader or program object names will generate the error INVALID_VALUE if the provided name is not the name of either a shader or program object and INVALID_OPERATION if the provided name identiï¬es an object that is not the expected type.&quot; This is probably a good candidate for a validation helper function.)
|Need to check validity of program (as above) and check bufSize &gt;= 0 (all sizei vars invoke INVALID_VALUE if negative).
|Nit: soshader should get camelcased.
|Nit: all the XFB constants should probably get grouped together, no space.
|Is GL_TRANSFORM_FEEDBACK_VARYING_MAX_LENGTH missing from this switch?
|What about GL_TRANSFORM_FEEDBACK_BUFFER_MODE?
|Should we consider the double draw a performance caveat?
|Needs replaced with the real include guard name
|Needs newline
|You initialize this ahead of all the member function definitions-- did you mean it to be const?
|This should be covered by:

&quot;When values for a vertex shader attribute variable are sourced from an enabled generic vertex attribute array, the array must be specified by a command compatible with the data type of the variable. The values loaded into a shader attribute variable bound to generic attribute [index] are undefined if the array for [index] was not specified by: 
  * VertexAttribPointer, for floating-point base type attributes
  * VertexAttribIPointer with [type] BYTE, SHORT, or INT for signed integer base type attributes; or
  * VertexAttribIPointer with [type] UNSIGNED_BYTE, UNSIGNED_SHORT, or UNSIGNED_INT for unsigned integer base type attributes.&quot; (ES 3.0.2 spec, sec 2.8 Vertex Arrays, pg 25)

So it's undefined and we're at liberty to do whatever makes D3D11 happy. (Unless I've misunderstood what situation we're talking about. The default vertex attrib values are also specified to be undefined if the base type specified in the shader and the type used to define them in the API do not match.)
|Is this handled by another patch somewhere?
|Can this be != 0 instead?
|Looks like the != 0 didn't make it into this commit.
|In libGLESv2.def, we list the extension entry points in a separate section. I also note that we haven't listed the other entry points added via extension (eglQuerySurfacePointerANGLE and eglPostSubBufferNV) in EGL in this defs file. I'm not sure why that is. (They do appear in eglGetProcAddress, which eglGetPlatformDisplayEXT should as well.)
|Please stick some parens around the right hand side of the assignment-- helps with the reading when there's a comparison and an assignment in the same statement.
|Are the other extension entry points missing from the .def file here?
|I think there's a potentially bad interaction here between EGL_ANGLE_platform_angle and EGL_ANGLE_direct3d_display. If eglGetPlatformDisplayEXT is called with (*native_display == EGL_D3D11_ONLY_DISPLAY_ANGLE), but  EGL_PLATFORM_ANGLE_TYPE_ANGLE set to EGL_PLATOFRM_ANGLE_TYPE_D3D9_ANGLE, for example, the attrib is overridden by the sentinel value in native_display. I don't think we should allow that-- we don't intend to ever move EGL_ANGLE_direct3d_display to published status, and we don't mention the language interaction in EGL_ANGLE_platform_angle. I think we should recognize the sentinels from EGL_ANGLE_direct3d_display only if no requested display type was passed in the attrib list. (And perhaps we should not recognize them when passed via the extension entry point at all. We should remove support for EGL_ANGLE_direct3d_display once we get Chrome to move onto the more proper extension.)

Tangentially, I realized in the course of checking the extension text that we incorrectly state that &lt;native_display&gt; is of type EGLNativeDisplayType, when actually it points to a value of that type.
|Can these be !=s instead of &gt;s?
|Since ConvertMapBits doesn't handle all the flags present in the GL access pattern, is there any name we could give it so that it makes clearer the distinction between the map access type and flags in D3D?
|Do we have a way to handle flush behavior?
|What does this requirement mean for any projects out there that may be using EGL_ANGLE_direct3d_display, but not trying to use an HWND cross-process? This won't be an issue once the newer, cleaner extension is out, but if someone's passed a display ID of EGL_D3D11_ONLY_DISPLAY_ANGLE, that'll still get propagated into mDc, and they may be single-process. Can we put this behind an on-by-default compiler flag, so that projects that want to do run-time selection of renderer via the old extension, but not use a window handle cross-process, can still do so if they turn off the flag? I don't know that such a project exists, but if it does, we should try not to break it.
|Can it be #define 0ed somewhere please?
|Hm. I mostly made the request for consistency and because I got asked to do the same by Daniel. But after doing some spec checking, I think it may be more appropriate not to do error checking when there is no current context. (The ES spec itself doesn't say so, because contexts are outside of its view, but MSDN and the GLX spec say &quot;commands have no effect&quot; and commands are undefined&quot;, respectively. EGL doesn't actually say anything about ES or GL API commands called while there is no current context.)

Doing some code archaeology, it looks like the order of operations goes all the way back to Nicolas's original prototype; I'd check with him to see if there was a reason for error checking before context retrieval that is still relevant, but in the absence of that, I think we should move to validating after context checks. That said-- consistency would be nice, so we should probably do all of them in bulk as their own ticket/issue.
|Is pixels/data actually needed?
|Would you mind adding a comment that even though getCurrentReadFormatType also checks framebuffer completeness, ValidateReadPixelsParameters needs to do the same check first, because glReadPixels returns GL_INVALID_FRAMEBUFFER_OPERATION if the framebuffer is incomplete, while the check in getCurrentReadFormatType is for calls to that function from glGet functions, where if the framebuffer is incomplete and read format/read type are being queried, it returns GL_INVALID_OPERATION instead.

(Oy. Refactoring all the validation out into one place is a really good idea. That took... a frightening amount of code history and spec spelunkage to figure out.)
|Could these use reinterpret_cast as all the other instances of pointers returned from error() do?
|Why did IsUnsignedAdditionSafe end up in the renderer namespace again? (not really something that needs fixing in this ticket, I just don't remember and it seems weird.)
|Missing the check for negative offset or length here.
|Can this get a &quot;currently&quot;?
|Can you put in a comment here to document the meaning of the 0 sentinel value?
|Was the move away from the MSVC &quot;secure&quot; printf functions intentional?
|Should be MultipleRenderTargets
|Should be postsubbuffer, no?
|This is nitty, but I'd prefer if inputIndex was declared with semanticIndex rather than in the for line, unless there's a scoping reason it's needed otherwise.
|Similar nit-- would prefer variables that don't govern the incrementing or end of the loop not to be declared in the loop declaration line.
|About luminance bits -- I don't think that LUMINANCE8 or LUMINANCE8_ALPHA8 are valid internalformat parameters for CopyTexImage. They're added by EXT_texture_storage, and that extension doesn't add them as valid formats to give CopyTexImage. From the perspective of ES3, luminance formats are legacy, so it doesn't add sized versions of them itself. So while we should expect to handle LUMINANCE, I think the sized luminance formats aren't actually relevant here.
|Done
|Done
|Can this have a comment about it being safe to cast w/o assertion because we checked when we set it? (Or an assertion would be fine too, and would catch any mistakes in future changes.)
|This is really nitty, but would you mind putting the dynamic type assert and the cast adjacent to one another?
|I suspect you're right-- we should be using the constrained read dimensions in the pixel copies below.
|Could this first argument just be &quot;area.width + std::min(area.x, 0)&quot;? negativeX is a bit confusing-- it's area.x negated, but it's also always zero or positive. I think it would be clearer just to put the min(x, 0) inline. This is definitely much clearer than previously, though!
|This math is a bit hard to follow. Should it expect to be able to handle incoming negative-origin areas? If I follow through this section with an input area: { x = -500, y = -500, w = 30, y = 30 } and texture size 256x256, safeArea becomes { x = 0, y = 0, w = -470, h = -470 } (check my math on it, though), which seems like it could cause problems.

Could gl::clamp() be used here to simplify things a bit? Similar to how the scissor dimensions are clamped to the render target dimensions in Renderer9::setScissorRectangle()? You could fairly easily describe the clamped area as x1, y1, x2, y2, that way, and then determine the clamped width &amp; height with max(x2 - x1, 0), max(y2 - y1, 0).
|Would it be possible to do this with larger memcpys instead of pixel-by-pixel if the float &amp; byte versions were split up? Will this underperform what's currently on the es3proto branch?
|Nope-- the ordering got swapped because I'd pulled pixel pack/unpack up to es2 + PBOs initially, and then recollapsed them. (It makes more sense if you look at patch set 1.) I can put the order back if it's desired, but I'm going to pull them back out again for NV_pixel_buffer_object, so there's not a lot of point.
|I'm not a big fan of calling the parameter that controls mip chain creation just &quot;mipmaps&quot;, because it's easy to conflate with whether mip filtering is enabled. Maybe createMipChain (or a less lengthy version if you can think of one)?
|Will we now always be creating either a full mip chain, or a single level? Were there situations in which we were purposefully creating different numbers of mip levels than would exist for the texture dimensions? I don't think the non-4x4 DXT case would have been one of those situations, since we're sizing it up above in MakeValidSize, but am not sure if there are others.
|I think the confusion arose here because mipLevels(), below, returns the number of the smallest mip level, with the largest starting at 0, rather than the actual number of mip levels (as would be returned by GetLevelCount()). The names of one or both of these functions is misleading.

That said, Nicolas's patches appear to reduce the usefulness of this function to determining if there is more than one level. Can the two of you coordinate on what's the proper way to solve the issue?
|I wouldn't mind a comment about the D3D automatic mip chain creation sentinel either. (And it's probably my bad that it wasn't already here.)
|I'd still prefer it to get fixed in this patch. *pedant hat*
|We do this check a couple of times-- would this be a good case for a helper func? It's a small scrap of code, but ternaries are easy to fiddle wrong.
|Are you avoiding a map on purpose here?
|Eh, I actually kind of prefer the &quot;why this change is being made&quot; rather than &quot;what specific thing got changed&quot; as the first line of the commit message. But an elaboration would certainly work for me.
|The top level/base level/max level distinction is especially fuzzy here. Could you please comment here (and possibly other places the various variables are used) to remind readers which item is which?
|Could this use SafeDeleteArray?
|I concur with this.
|When I asked the infra folks, they said the syntax for this was BUG=angle:###, but I'm not sure whether that integration is actually currently working.
|Worth calling out in a comment that the usesDiscard optimization workaround will supersede the nested break optimization. (What should we expect for shaders that use both? Will compilation hang?)
|Can we stick a comment here, and possibly on the optimization level setting in the build file, to call out that we really don't want to inadvertently change this ever again?
|Ye old whitespace nit.
|Here's the K&amp;R-to-Allman change I mention in another comment.
|Still seeing &quot;No newline and end of file&quot;, but it's less of an issue for .cpps than .hs.
|Trailing whitespace/missing newline nit.
|In one of the other files in this patch, you change a clause from K&amp;R bracing to Allman. Is there a convention for the translator?
|You may have already explained this to me long ago when you were planning out this feature but-- why do we need to copy out from the staging texture to CPU memory? Could we just map the staging texture and expose its memory directly?
|Do we anticipate any fast-pathable situations, where pack parameters &amp; DX pitch gel and make the copy unnecessary? If there are any situations at all where we can get out of the application code's way on this one, it'd be good to make those paths available.
|SafeDelete?
|Should also add a comment here specifying where the BGRA internal formats come from
|Do we want to be able to bypass this if we detect somehow that the first use of the buffer is to fill it completely? (Is there a way to detect that at all?)
|Nit- inconsistent spacing.
|I'm not great at gyp syntax-- is there an implied else here?
|We've got an OS != win, an OS == win, and an OS != win &amp;&amp; OS != mac. Could we collapse these a bit? (And I'm not clear on syntax-- will the later non-win + non-mac section add to target_defaults, or replace it?
|Possibly worth a comment to note that the read &amp; write offset bounds are checked up at the API level? (Can we arrive here from anywhere other than glCopyBufferSubData?)
|Nit: could this be isMappable instead?
|Nit: indent
|We should double-check that we can expect dEQP test names not to contain nonpublic information.
|Could you move the silent ignore check to after the transpose check? It'd be good to catch all of the static/non-state-dependent parameter errors before the silent return.
|These are not included in Chrome's current computation of this string (see http://src.chromium.org/viewvc/chrome/trunk/src/gpu/command_buffer/service/shader_translator.cc) -- despite them being longstanding parts of ShBuiltInResources, possibly because they don't affect the end result of compilation? (I'm not sure.) Either they're missing from Chrome's current code, and need to be added, or they're not pertinent, in which case I can add a comment about them.
|Done
|Done
|Done
|Done
|Done
|Done. (This is the documentation of the parameters for this function.)
|I'm definitely not averse to that. Done.
|Mind taking care of the EOL whitespace in this file while you're in here?
|Comment conflicts with value returned in following line.
|Nittiest nit ever: can the break go on the following line? We usually don't mix single-line and multi-line switch cases.
|Can we consolidate these? IsInternalTextureTarget is just this function with an UNREACHABLE because it assumes its input has already passed validation.
|Ah. I... was previously unaware you could even do that. O.o
|initRenderer (kind of redundant)? initSpecific?
|Aren't at least the tr1 versions available all the way back to GCC 4.0? Chromium uses them itself, I believe.
|These lines are long enough that we should probably break the single-line format for them.
|Should probably sweep through all the affected files and update the copyrights in them.
|Did we catch this case elsewhere before, or is this a novel error for us?
|Same question as above for depth.
|There may be extensions we explicitly don't wish to advertise above a given client version. We should have a mechanism for excluding them here.
|If it weren't only being used internally, an ASSERT wouldn't cut it. :P But given that it's just a tack-on helper for the function below, eh, it's fine.
|worth asserting that the vector pointer isn't NULL?
|Can this get a table header?
|Hmmm...

I definitely understand the first point, although it feels a little artificial to worry about, given that the information already exists in the caps's texture format caps table.

It makes me a little itchy to have a big collection of global methods whose only purpose is to inspect the contents of a data structure, so that the structure didn't have to have the methods itself. I guess it sort of parallels what we have going on with the format tables, but it feels like the sort of thing we shouldn't proliferate.

Jamie, do you have an opinion one way or the other on this particular point?
|I definitely grok that they're not really getters-- they're acting more as inspectors. It just seems awkward to have a big collection of functions that are basically for &quot;Hey, have a look at this data blob and tell me if it says XYZ&quot; that are external to the data blob itself. To me it would feel more natural to have them either be members of caps that would possibly get kicked off by a central &quot;determineAndCacheSupport&quot; (or something) function, or members of the class that owns generateCaps, or... maybe members of an object whose job it is to process Capses, although that feels way too I-just-read-Design-Patterns-y.
|Why did you go with the approach of making texture and extension support queries global helper functions instead of methods of Caps?
|Can this have some comments? Function pointer syntax + templates is kind of bizarre-looking.
|I don't think having a pure virtual generateCaps is a bad idea-- it'd force generation by any later implementer of a Renderer child class, but retain a common base class ownership.
|Any reason to have this stored in the 9 and 11 renderers, instead of the base class?
|Has OES_texture_half_float been unusable this entire time?
|We're not actually ever validating depth against the max layers (or against the max 3d dimension, in the case of 3d textures), though, it looks like...
|Ah-- I can understand why they'd expect that, but I think they're wrong. I'll raise an issue with them; INVALID_ENUM is a blanket case that should cover basically anything that takes a GLenum, unless somehow it's expected that we determine whether the value corresponds to ANY defined enum (in which case, both 0x0000 and 0xFFFFFFFFFFFFFFFFull still count as enums).
|I'm not sure I understand why this error message is changing. The two error cases I'm aware of for internalformat are a) the format is an enum which represents an format which is supported, but is not a valid combination with the enums passed for format &amp; type, it generates INVALID_OPERATION (handled below with IsValidFormatCombination), and b) the format is not an enum which represents a supported format, in which case INVALID_ENUM should apply under the blanket rule for that error (spec v.3.0.2 p18 for ref). I don't see a different error being specified anywhere for this case-- did I miss it? Or is dEQP either expecting the wrong error, or expecting multiple errors to resolve in a specific order maybe?
|Very nitty nit-- can this get indented past the assignment operator on the previous line?
|The relevant tests are:
https://www.khronos.org/registry/webgl/sdk/tests/conformance/rendering/gl-viewport-test.html
https://www.khronos.org/registry/webgl/conformance-suites/1.0.2/conformance/canvas/drawingbuffer-test.html

These tests both pass with and without this CL. Looking back through the history of changes in this area, I suspect the viewport dimension scaling introduced to finally fix issue 224, landed in 42832a654cfe1fb76a54a8318c8a728ce0692f3b, may be what's handling everything correctly.
|I do want to make sure, if the maximum viewport dimension is being increased for D3D11, that it's absolutely safe to do so, and that our reasons for needing this assurance are no longer applicable.

From the Trac log, Nicolas recommended:

&quot;The spec for glViewport says that &quot;width and height are clamped to implementation-dependent maximums when specified. The maximum width and height may be found by issuing an appropriate Get command&quot;. We currently return mMaxRenderbufferDimension (= mMaxTextureDimension) for this, which is probably the only safe value for D3D9. I suggest to create another virtual method for Renderer to make this independent of texture dimension, and for D3D11 return something like D3D11_VIEWPORT_BOUNDS_MAX - D3D11_REQ_TEXTURE2D_U_OR_V_DIMENSION (since both TopLeftX  and TopLeftX + Width have to be &lt; D3D11_VIEWPORT_BOUNDS_MAX but it's useless to have a viewport totally outside the render target).&quot;

Does the viewport scaling introduced later make this moot?
|Much +1.
|typo
|Need to update the filename for Renderbuffer.h/.cpp
|Are all the forward declarations still needed?
|Ah, ok. 

For the extra allocation-- I'm mostly thinking about alloc thrash and rendundant state performance stuff. Will it still be there when the attachment impl goes away? We could at least have a TODO comment to remind us to optimize that once we're done moving stuff around.
|Ah-- I like the approach you've taken here. Making the concept of the &quot;attachment&quot; ephemeral and only valid while attached to the framebuffer clears up some potential confusion. Can you add comments to explain the difference in lifetime between FramebufferAttachmentImpl/RenderbufferAttachment/Texture*Attachment and the Renderbuffers and Textures they refer to? And maybe remind the reader that the cleanup for the previous FramebufferAttachmentImpl and child attachment will be handled by .set() and the destructor for FramebufferAttachmentImpl-- it looks a little scary until you remember/learn the guts of BindingPointer. I think that will also help.

What happens in the case that we call glFramebufferRenderbuffer or glFramebufferTexture2D with the same renderbuffer or texture that's already attached? Do we go through the process of destroying and recreating the attachment objects?
|Can update the date for a few files in this CL, I think. (I know I'm super-inconsistent about actually catching it or updating them myself; sorry for that.)
|Hm. Ok; I didn't realize there was a countervailing recommendation in Chromium. I'm cool with picking up whatever their rec is; was just carrying the update requests over from TG.
|I don't really think there's a great reason to make it a locally defined global instead of a private member function, personally.
|Ok, works for me.
|We do the same thing in quite a few places in Renderer9 for ES3-only functionality.

That said-- I don't disagree that it's a longstanding ickiness in the Renderbuffer implementation that we expect non-texture renderbuffers to implement this function. Maybe instead we could do something similar to what we do with the MakeObject11()/MakeObject9() functions, where in the places we need to retrieve texture serials, we cast the storage-agnostic FramebufferAttachment to a FramebufferTexture2DAttachment (or whatever the proper name is) before calling texture-specific functions on it?

(We should at least return -1 from here as the prior function did, but it would be best to remove the need for the function entirely.)
|Could this have a name that makes clearer what it checks? hasUnifiedDepthStencil, or something?
|I didn't catch this typo previously-- mind fixing it while you're in here?
|Any reason to make this protected when the class is already necessarily abstract via pure virtual methods?
|If this is only used to quiet warnings occurring because ASSERTs don't actually use the variables on which they depend when in non-debug builds, can we define it only for non-debug cases?
|In debug builds, for the variables where this is necessary, it's already not doing what the name states-- the variable is not unused, it's being checked in an ASSERT. Otherwise, we'd just remove the variable.
|I'm interested in keeping it as narrow-case as possible, because it's an explicit ugliness just to quiet an otherwise useful compiler warning.
|Also a description here plz.
|Should ENABLE_PERF get some kind of suffix to make clear it's windows-only, so that people don't toggle it and then become surprised their compile depends on d3d9.h?
|Can you add a description of what's contained in the file to the boilerplate?
|Description for this boilerplate too, please.
|Should probably get Nicolas's input on this one. We should probably include a software rendering token of some sort-- currently the initialization for that has been moved outside of ANGLE since it doesn't have to speak D3D anymore, but it may move back once ANGLE's the interface to the GL backends as well.
|Ok. Let's remove the token for now; if we need it later we can update or add another extension.
|Honestly, if the default display type is wanted, applications should probably be using eglGetDisplay rather than eglGetPlatformDisplayEXT.

Part of the possible complication with reusing the EGL default is that the type is specified as EGLNativeDisplayType, which is what we're using as the native_display parameter's type (although we need to amend this language: we can't reassign the type of the native_display parameter, just require that it *point* to a value of that type). It should be perfectly valid to specify a native_display of EGL_DEFAULT_DISPLAY but still express preference as to the rendering backend using the attrib list.
|Ah-- do you mean for users to use EGL_DEFAULT_DISPLAY both as the native_display parameter and the value of the  EGL_PLATFORM_TYPE_ANGLE attrib? I think it would be better not to double the meaning of that enum-- it refers explicitly to the display.

(Incidentally, even if we don't specify a default EGL_PLATFORM_TYPE_ANGLE value enum, the above specification allows users to get a default display backed by a default renderer by passing an empty attrib_list. But it's still wise to create a default enum, I think.)
|Eh, it's more the name of the extension that I wonder about.
|There's a chance Khronos/the EGL group would prefer we not use an extension suffixed with OpenGL to add the ability to request an OpenGL ES backend (or, possibly, at all)-- we should check into it before landing.
|Go with this for now, we can rename it upon submission to the registry if necessary.

One other problem-- these tokens are defined by both this extension and EGL_ANGLE_platform_angle. They can't be introduced by both.
|I agree-- I'm usually reluctant to use many ternaries where they don't already exist. I went with tracking binding intention in three bools, because I wanted to keep the notion of &quot;does an SRV binding format exist for this texture type&quot; separate from &quot;do we actually want to bind as an SRV&quot;, and because I could then reuse the bools for simpler checks below. LMK if that'll suit.
|Style nit: if this line is going to hang out outside of a conditional, can the entire case statement get tucked inside braces, please?
|The max anisotropy lines are getting way longer than their surrounding brethren. Can they get multilined?
|Nit: Can the framebuffer param go ahead of the transformFeedbackActive bool?
|Would also be good to move this argument farther forward in the list.
|Missing &quot;which&quot; or &quot;that&quot;.
|Could also add a note that we don't anticipate more unsized formats to be added in future spec versions -- those already present are for backwards compatibility reasons.

Also-- where do ES2 formats introduced via OES_texture_float stand on this point? The extension doesn't mention the color renderability of the added formats, but all can be created with unsized internalformat. We mark the floating point formats as renderable conditionally depending on underlying D3D support, but I'm not sure whether it's possible for the format to be supported, but not rendering to it.

...it also looks like we currently have the floating point texture formats as renderable in the ES3 table, citing the extension as the origin for color-renderability, but presumably allowing textures to be created using the sized internal formats and then rendered to. I'm not sure that's kosher.
|Re: renderable floating point textures in ES3, here's the language that concerns me:

&quot;If the level(base) array was not specified with an unsized internal format from table 3.3 or a sized internal format that is both color-renderable and texture-filterable according to table 3.12, an INVALID_OPERATION error is generated&quot; (glGenerateMipmaps, GL ES 3.0.2 sec 3.8.10, pg 155)

and

&quot;An internal format is color-renderable if it is one of the formats from table 3.12 noted as color-renderable or if it is unsized format RGBA or RGB. No other formats, including compressed internal formats, are color-renderable&quot; (Framebuffer Completeness, GL ES 3.0.2 sec 4.4.4, p207. This is also the section to specify legal internalformat arguments for glRenderbufferStorageMultisample on pp199-200.)

If the texture was created with internalformat RGBA32F, we're still treating as color-renderable, no? It's explicitly not, in table 3.12.
|ANGLE's switch case style is a weird one: &quot;switch statements: indent the case statements by 2 spaces. The body of the case statements should be intended another 2 spaces so that they are a full 4-space indent from the switch.&quot;

(Single-line statements should just get indented the initial two spaces.)
|Indentation. Also, we apparently vary WILDLY on whether we stick struct constructors at the head or foot of the struct definition. I need to stick something in the coding standard about that (and should probably very briefly get a consensus opinion on which it should be during the next ANGLE meeting).
|Is this being made an external-to-class global inspector function to force VertexAttribute more towards a straight POD struct instead of the weird hybrid it had become? Or are the global inspector functions more of an overarching design decision (this is mostly a question for Geoff).
|we probably don't need to populate the .cpp file with the bodies of these-- since they're stubs, we can leave the definitions in the header. This would also give us a good place to add a comment to note that they're noop stubs, that the guts are handled in InputLayoutCache &amp; VertexDeclarationCache, and that this class (and the D3D11 equivalent) are expected to take over that functionality at a later time.
|Sorry, I'm not familiar enough with this code, I think, but-- why is this return only done in the struct case?
|Capitalization typo.
|I think probably it'd be more accurate to say that core ES 3.0 supports GenerateMipmaps for sRGB textures, no matter how they were created.

I don't think we should advertise EXT_sRGB on in ES 3.0. ES 3.0's support for sRGB is more complete-- I think I was mistaken in my prior assertion that ES 3.0 doesn't support specification of sRGB textures via TexImage2D due to sRGB not being specified as an external format. (The documentation http://www.khronos.org/opengles/sdk/docs/man3/html/glTexImage2D.xhtml suggests that an sRGB internal format by itself will cause the data to be interpreted as sRGB-encoded. I think. The spec, as far as my reading goes, describes what happens when sRGB textures are applied, and when the blend stage is completed for an sRGB framebuffer, but doesn't discuss conversion-or-not of incoming data for upload to an sRGB texture. This may be cause the authors assumed it was obvious that it isn't converted. Does anyone else see it covered somewhere in the spec/have a different reading?) I suspect supporting both sets of enums in glTexImage will make things muddy.
|I don't think we need to add EXT_sRGB to our extensions folder-- in general that's just for extensions we've authored, helped author, or began implementation of while still in draft. (We have a couple other erroneously added extension specs already in the directory.)
|Can this get a FIXME comment about not advertising it on ES3, please?
|We could use SafeDelete() here to handle delete-and-null.
|+1
|Ah, I see why this was a virtual function before. I don't think we should keep pointers to the renderer both in the abstract base and in the concrete child class-- either we should use MakeRenderer11 on the parent's protected mRenderer on the occasions we need to access Renderer11 functions from the child (in which case I think the getRenderer() function in the parent can be entirely removed), or go back to using a virtual function.
|Could use ValidFramebufferTarget here?
|Was this just a placemarker comment for when you were comparing the functions?
|redundant break
|Should have reverted to delete from release when I removed the refcounting from VertexArray. Fixed.
|getTargetFramebufferHandle goes away in the State refactor CL.
|Done
|Done
|This is basically how I decided which way to return State. Heh.
|I very much agree with this, and explicitly want the variable to get  a different name than the renderer version.
|space went missing between type and variable name
|Yes-- the BindingPointer to a ProgramBinary in this file requires that ProgramBinary be fully specified prior to declaration. It had been getting declared by this point previous to the State refactor through other includes, I believe.
|The function name sounds like it's checking for any existing attachment-- could it be renamed so that it's more clear that it's checking whether it has an attachment that matches the parameters?
|Now that I see getTarget() here I kind of wish it'd been called getTexTarget() to make it clearer it's not, say, a rendertarget. I might just think that because this CL is about FBOs.
|Yup, I think so too.
|+1
|Looks funky with just the one unexplained break. Mind adding comments to indicate what the categories are?
|Should probably comment here about maxElementsIndices/Vertices being unused in ES2, as calling it a primitive count limit is a bit confusing.
|Ditto my request for comments from the other patch. (They can be super-brief ones though.)
|Missed replacing a couple of these with the local.
|Can we tag the ES3-only ones in a comment so it's easy to see at a glance why they're being zeroed?
|Can we add a comment about truncation expectations? Would like to document intent here.
|incredibly nitty nit: extra space not really needed
|nit: Typo, but it's in a todo, so I don't know that it matters...
|Could this function eventually move to the root D3D Texture implementation class? For the most part, we retrieve Storage from within the Renderers themselves-- inside those, we'll know that we're backed by D3D, so we could downcast to the D3D implementation and retrieve storage at that point. The only places outside the D3D Renderer classes that I think we're grabbing the storage are places where we need to do things like calculate the level offset, which should get pushed down into the D3D layer anyway.
|We appear to be delightfully inconsistent in the codebase about whether we bother specifying DISALLOW_COPY_AND_ASSIGN on abstract base classes. I don't think it necessarily needs to be done here, but we should probably get a quick consensus on what the rule is, and open a ticket to make it consistent throughout the codebase.
|I'd prefer this get a less generic name, especially given that it's unnamespaced. (And Str up there gets a side-eye from me on the same point, though it's not new to this CL.)
|The default projects will also need to be regenerated with this change.
|Ah, right. erase() continues to be one of the worst-named functions in the STL.
|This fundamentally changes our error-handling behavior. We currently track INVALID_ENUM, INVALID_VALUE, INVALID_OPERATION, INVALID_FRAMEBUFFER_OPERATION, and OUT_OF_MEMORY separately, so that if multiple errors have been generated since the last GetError() call, it will take multiple calls to clear them. This is described in the spec in the paragraph beginning &quot;To allow for distributed implementations...&quot;
|Also needs a description comment.
|Needs a description comment here.
|The return-errors-from-all-functions paradigm worries me slightly because of things like this-- does this mean we'll need to avoid ever actually using the return variable for actual data? Errors really feel like something that should be handled out-of-band, but I admit that's more of a feeling than something I can back up with reasoning &amp; data...
|mStarted basically only ends up being used by ValidateEndQuery, to catch the case where BeginQuery was called, but the query wasn't successfully created, and return INVALID_OP. It's a proxy for the D3D query object having been created, which is always true once begin() returns successfully.

An alternate solution to the problem might be to propagate the success/failure value from begin() up to the calling Context, and reset the active query ID to zero if the query was not successfully created, but I'd need to check the spec to see if that behavior is kosher. Thoughts?
|Done
|So &quot;started&quot; is fairly simple to track in the GL object, but the type ends up needing to be passed through begin(), getResult(), and isResultAvailable(), because it affects how the D3D-side query is created, and how the results are interpreted. This is (as noted in Jamie's comments), a byproduct of the implementation's lack of access to the GL object. I think it's somewhat messy. Alternatively, the QueryImpl can get a pointer to the Query which it implements (I've done it the first way in the next patch).
|mRenderer being null is an indication that eglInitialize() hasn't been called for this display. There are a couple of different errors that should be getting generated, depending on what the context and surface arguments are set to, and I don't think we're correctly handling all of them (see sec 3.7.3 of the EGL 1.4 spec, pg 47):

- if context is not EGL_NO_CONTEXT and draw &amp; read are not EGL_NO_SURFACE, but the display is not initialized, we should generate EGL_NOT_INITIALIZED. This case is caught and handled correctly in the call to validateContext() just above the context loss checks.
- if context is EGL_NO_CONTEXT, and draw &amp; read are not EGL_NO_SURFACE, or vice versa, we should generate EGL_BAD_MATCH regardless of whether display has been initialized. We currently fail to handle this case, and should fix this.
- if context is EGL_NO_CONTEXT and draw &amp; read are EGL_NO_SURFACE, we should correctly handle uninitialized displays and skip the context loss checks. I suspect this is what's happening in the utility in question, because otherwise the null renderer dereference would just be postponed to context::makeCurrent(). I think this would best be handled by skipping the device loss check block entirely if the display is uninitialized (that is, add &quot;&amp;&amp; display-&gt;isInitialized()&quot; to the conditional on line 802).
|We're eventually going to pass around extensions &amp; caps structs rather than the whole context for functions like this, right? Could this get a //TODO or //FIXME to that effect if that's the case?
|I'm a little bit torn on these. Part of me wants to say they should be pure virtual at the TextureD3D level, and that any child for which they don't make sense should provide UNIMPLEMENTED() methods themselves explicitly, so no one's exposing them inadvertently. But another part of me would be annoyed at the code duplication. Other reviewers-- opinions?
|Done
|Done
|Cut &amp; paste needs updating
|needs update
|Needs update
|It looks like a similar GL_DEPTH_STENCIL/GL_DEPTH_STENCIL_ATTACHMENT swap was made in glGetFramebufferAttachmentParameteriv, when checking for the depth-stencil attachment case when param is GL_FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE-- we should either address that here, or open a new issue. Also-- DefaultFramebuffer::getAttachment() currently handles DEPTH_STENCIL, but I'm not sure that's actually a valid attachment. That value is correctly filtered out by ValidateInvalidateFramebufferParameters, but I don't think it's valid to attempt to retrieve it from the default framebuffer at all...
|I don't think getDepthOrStencilbuffer() can be switched out for getAttachment() here. getAttachment() in the case of GL_DEPTH_STENCIL calls through to getDepthStencilBuffer(), which returns NULL if hasValidDepthStencil() returns false. hasValidDepthStencil() is only true if both attachment points are non-null, and the same attachment is used for both, so using GL_DEPTH_STENCIL on a framebuffer with only a depth or a stencil attachment would result in a null attachment pointer, and that in turn would mean that whichever of depth &amp; stencil that the FBO *did* have wouldn't get cleared. But the spec says:

&quot;Including DEPTH_STENCIL_ATTACHMENT in the attachments list is a special case causing both the depth and stencil attachments of the framebuffer object to be invalidated.&quot;

and:

&quot;If an attachment is specified that does not exist in the framebuffer bound to target, is is ignored.&quot;

I don't the spec requires that GL_DEPTH_STENCIL_ATTACHMENT only have an effect if a unified depth stencil is used.
|I'd definitely be in favor of limiting blanket namespace inclusion as much as possible. (And am also not a fan of using.)
|Done
|I'm on board with this, too.
|Is there a better indentation scheme that you could use? I'm not aware of anywhere else in the codebase that we don't maintain alignment with an open paren, open brace, or operator. (This comment applies several places throughout the CL.)

Is calling through a Renderer pointer contained in the program binary the expected pattern at the end of the refactor? If so, I might consider adding a compilation helper function to the program binary impl itself.
|This in particular should definitely be aligned with the opening paren of generateShaderLinkHLSL. Also please note that ANGLE permits up to 120 character width.
|I'll open an issue for it; I can be OK with this in the meantime as it doesn't represent a regression.
|Is it possible for the caps to change between save and load without rendering the binary format incompatible? Would someone possibly try to load a binary under different caps than it was saved? (Note that we shouldn't rely entirely on Chrome's shader cache to validate this.) Given that the caps do influence the binary format directly, I'm not sure it's unreasonable to need to pass it in to the function...
|What I meant by saying that we shouldn't rely entirely on Chrome's shader cache is that Chrome isn't the only thing using ANGLE, so we can't assume that this is entirely handled outside of our implementation. The spec states that loading &quot;may fail&quot; if the hardware or software config has changed since the binary was compiled-- if we're not already handling that gracefully, shouldn't we? What currently happens if a non-Chrome app, compiles a binary with, say, the DX11 Renderer, but then tries to load it with the DX9 one? Or compiles with a discrete GPU, and then loads it later with an integrated one? Do we already have a way to fail out?
|Should we ASSERT here that the sampler count is within the allowable range? I assume we've checked it before streaming it out, but theoretically it's possible that someone screwed with the binary before we're reloading it...
|Also-- added Jamie &amp; Nicolas to bring their attention to this open question to everyone.
|Are there analogous places where we're doing it via pointer? I also don't want to fragment style, and I don't want to open the floodgates without consensus, so it would be good for others to weigh in here on preference.
|It feels really strange to be passing container classes around by pointers. Did we run into this issue before? It feels like a conversation we've already had recently, but this miiiiight be an acceptable case for non-const references. (Although for all I know I thought the opposite last time...)
|Ok. Let's discuss an explicit amendment to the ANGLE style guide at our next meeting, and then generate a CL to unify style for those. As far as making this the last arg-- usedRange is also an output var, yes? Our style guide requires output params at the end, and I'd agree with pointers-after-refs, but we should probably tag that one with &quot;out&quot; as well. (Sorry for the endless style nattering.)
|I agree-- these are only called from the ensureRenderTarget() functions, and we're already asserting there if source is null, so there's no reason for that to generate an error here. We also create the destination object just before calling this function, and if we want to check that that allocation happened, the right place to do it is where it's created; if it reaches here undetected, that's ASSERT-worthy.

It might be best to split that change into a separate CL, though, as that changes functional behavior (albeit behavior that should not be reached).
|We need to add something to the style guide about C++11 only being usable in src/renderer/d3d and its subdirectories.
|Ah! Sweeeeet.
|Nit: could nuke the extra whitespace while you're in here.
|Nit: Could get the no-op comment here to match setImage.
|This should probably be the responsibility of the call level where the surface is created or requested.
|Ditto above.
|Ditto above.
|Nit: Nuke whitespace while you're in here?
|nit: missing space
|missing &quot;there&quot;
|This check has to be done in either case-- why not nest the dynamic/static if/else clause inside the nonzero data check? That'd also fix Geoff's concern about skipping the data invalidation call below, I think.
|+1
|An EOL whitespace if you wanna get reeeeeeeeally nitty
|Can these blocks get a comment about being first-time use initialization only?
|The following call path exists:
  Renderer9::initializeDevice()
  IndexDataManager::IndexDataManager(Renderer *this)
  StreamingIndexBufferInterface::reserveBufferSpace(INITIAL_INDEX_BUFFER_SIZE, GL_UNSIGNED_INT)
  IndexBufferInterface::setBufferSize(INITIAL_INDEX_BUFFER_SIZE, GL_UNSIGNED_INT)
  IndexBuffer9::initialize(INITIAL_INDEX_BUFFER_SIZE, GL_UNSIGNED_INT, true)

I don't think the presence of the extension is checked anywhere in there, so this assertion seems like it would be triggered any time that UINT indices aren't supported.
|Ah, it looks like this is addressed in the previous patch in the series. Nevermind.
|Are we validating this elsewhere?
|Question ping
|Ping on this question
|Is this a good metric for whether it's dynamic? We don't create the static buffers until we pass a larger threshold-- maybe we should be either using the existence of the static buffers, or tracking with a separate flag. The above code seems like it could get us using direct binding for buffers that change every other frame, if I'm reading it right?
|The left 6 or so columns of each of these lines are being highlighted in my viewer. These didn't get changed from spaces to tabs, did they?
|more indentation nit
|Standard indentation style nit
|I like this comment a lot.
|Can this get a const representation?
|This probably wasn't meant to get committed.
|Can this get a const value representation?
|There are certainly functors that don't define operator(), but they're generally used to represent a single function and/or be invoked indirectly. What I am saying is that it's a stretch to think of this particular design as a functor, and using &quot;this is a functor&quot; to dismiss criticisms of the design is unwise.
|This gets back into my prior objection-- one, it's not a recognizable function object because a) there's no operator(); it can't be invoked *as a function*, which is pretty much the raison d'etre of a function object, and b) if persistent state is a key part of a pattern, and issues are raised about the persistent state, saying &quot;this is an implementation of pattern X&quot; doesn't render the issues immaterial, it's an indication that the pattern is possibly not a good design choice.

Please note that this does not mean that this design is not correct, it just means that stating &quot;this is a functor&quot; doesn't get rid of concerns about its use. Or make it a functor.
|Hrm. On the one hand, this kind of makes it look like the function is expected to have side effects/do what's described in the GL spec for this func. On the other hand, I think it would be really pointless to prefix every method of the validator with &quot;validate&quot; or &quot;check&quot;. I don't have any really great other ideas, though.
|These lines kind of imply that fail() returns a value-- I think the explicit separate valueless returns are preferable.
|I'm not sure about expressing &quot;detected no error, and the context is free to render&quot; as &quot;ready&quot;. It kind of makes more sense to me for whether-or-not-something-gets-drawn not to be any of the validator's business at all. Although that would be complicated by the need to go without a context or renderer for a mock setup. Could we create a mock base class for one of those objects, or would that just be making a mess?
|This is a good idea, but it strikes me as maybe better as a member of the Context, which could be cached here if it's really needed? It's the context that's really noopping functions, rather than the validator, which still validates.
|Oh! I think I completely misunderstood the point of this-- I thought it was intended to be an indication of a null-renderer, so that if this value was set, *all* rendering calls would be noopped. I understand now why it's part of validation-- maybe there's something else it could be named that would make it clearer? Not sure what, though.
|Why does this go here, rather than at the head of the file, with the base class? (Or in the ES2 validation header?)

I like the definition of the helper/base validation functions as private.
|It doesn't matter that these persist and don't reset after a call is validated as long as the validator is created and destroyed once per API call, but that might be an easy pitfall for future coders. We should probably at least stick a comment on the validator that it needs to be destroyed each time we're done checking the results of the validation, or possibly have the validation functions return a Error-plus-side-effect-bool blob?

It also feels a little weird to be creating a new validator every API call-- I doubt there's much overhead in creating a bunch of references, but my first instinct is to wonder why it's not just part of the context. (Although if the aim is to run validation without a context for testing purposes, I suppose it makes sense. It just... feels strange.)
|Given that the class doesn't follow the key feature of the pattern by having multiple methods invoked by name rather than using operator(), and its name doesn't include the pattern name, it's not a good idea to count on it being recognized as the pattern. I'm not really sure what qualifies it as a functor here, or why the pattern is particularly useful for this case-- we don't need to pass the validator around or invoke it on the contents of a container, and where the internally maintained state is concerned, mError and mCallHasNoSideEffects aren't useful or necessary pieces of information to maintain between subsequent validation calls. If this *did* have a single operator() function, it still wouldn't want to aggregate information with mError-- consecutive calls to validate() would need to be interspersed with validate.error(GL_NO_ERROR) to keep it from stepping on its own toes.
|Nit: We should probably follow the same indentation pattern for this as for our class methods in .cpp files.
|We mostly use &quot;: param(arg),&quot; on the same line as the last line of the constructor definition, though I don't think it's specifically codified in the style guide.
|Should this be DISALLOW_COPY_AND_ASSIGNed?
|These should get lowercase first characters, since they're methods.
|Is this avoiding recording the error on purpose, or is it because this is expected to get refactored imminently?
|I'm somewhat suspicious of removing the readback, because we specifically eliminated GetDesc calls that we could, and the one from the tail end of this function was added then specifically to cache the miplevels value. If we didn't need to read back the value, it seems odd that Daniel, Nicolas, and I all missed the chance to remove GetDesc specifically in a ticket to remove GetDesc calls...

But we didn't happen to mention in the reviews why we needed to read it back directly after filling it out when creating the texture. 

I'd say poke Nicolas to ask if he remembers why we needed to do that readback, and if not, and if it passes all the tests &amp; samples, and edge cases that you can think of, then I guess it's removable...
|Done
|Done
|Done
|Done
|You already mentioned this in a previous review, and it is fixed in the patch series I will next be uploading, which is why I haven't yet posted a &quot;done&quot; response. You'll need to wait until I finish straightening out issues in Transform Feedback.
|Done
|No warnings in either build, but added explicit casts anyway.
|Is ProgramBinary fully de-D3Ded at this point, or is there more work to be done to reach that point? Before we consider it complete, we should probably change references to pixel shaders/executables/programs to fragment, to keep the D3D/GL distinction clear. (Unless there arguments that that would create confusion following code down the stack, which I could see.)
|Is this going to remain exposed outside the renderer/across APIs? We don't support geometry shaders in ES-- will we be able to distinguish between geometry shaders used in DX to emulate ES features, and the concept of geometry shaders in ES?
|Similar question-- ILs are DX-specific. Is this just a during-migration function?
|+1
|ANGLE convention is to name files that implement/define a class with the same capitalization scheme as the class itself.
|I think this class could be named to more clearly convey its purpose-- SurfaceHost sounds more client/server-y than this looks. Maybe WindowHandler or SurfaceInterface or... maybe Geoff has a better idea here.
|public/protected/private keywords need to be indented two spaces.
|This constructor needs the &quot;explicit&quot; keyword.
|Stray whitespace.
|Would prefer to use &quot;IsIconic(mWindow) == TRUE&quot; here, rather than implicit cast.
|This function sounds like it's a query of what the native window type is (as a result of EGLNativeWindowType being unfortunately named)-- would getNativeWindow() work here?
|The intent here is to choose the file containing the correct implementation for the system type at compile time, right? This file should either get named SurfaceHost.cpp to reflect the class, and stuck in a directory reflecting the implementation it belongs to (which win32 may be sufficient to denote-- I'm not familiar with all of the nomenclature), or get named SurfaceHostHWND.cpp, to follow the pattern of, e.g., the renderers.

This is somewhat intertwined with a greater file organization issue I've got, which I'll cover in the overall comment.
|Same complaint here as for IsIconic in the header.
|ANGLE convention is to list the first parameter on the same line as the function definition, and align following parameters with that one. See src/libGLESv2/renderer/d3d/d3d11/RenderStateCache.cpp for an example.
|We try to keep line length &lt; 120char.
|Stray whitespace.
|Function parameter alignment in ANGLE is generally: the first or more parameters on the line with the function name, following lines indented to align with the first character of the first parameter.
|Initializer alignment (mentioned previously in more detail).
|This is going to end up being rewritten in any case, because the current XFB implementation stores the bindings globally, instead of per-XFB object. That being the case, my aim here was just to produce no functional changes.
|To the question about this function in patch set 7: because I don't think this is better. It's less clear, still adds an extra array (which I am guessing is what you mean by code style issues?), and requires redundant retrieval of storage objects. But if consensus would prefer this, that's fine.
|Note that there is a functional change in here, to fix a bug where we would append to buffers instead of start at the new offset if a buffer was rebound with a different offset. This is not really material, given that we can't really perform this rebinding while XFB is active, because the only allowed way to do so is by changing the current XFB object, and we do not currently track XFB buffer bindings per-object, but there was no point in not addressing it if the function was being overhauled.
|Done
|Ugh, I must have been thinking about std::map semantic while typing this.

I addressed the greater dynamic allocation issue by passing the state directly to the renderer. Some further work there removes the need for dynamic allocation.
|Done
|The changes here include keeping track of d3d buffer/offset data in class member arrays, which can be changed to vectors when the arrays outside of State are taken care of. This will avoid the need for allocations in this function, and all vectors can be sized with the same caps value.
|Done. Also shortened the comment, as there's now an assertion at the head of the function that illustrates this.
|Chromium doesn't require updates every time we alter ShBuiltInResources anymore, actually-- we need only to add new fields to TCompiler::setResourceString, which I believe this patch does.
|If we intend to handle the error gracefully, do we really want to assert on it?
|The one thing I'm hesitant about here is that I don't know whether there was a reason we only performed the proactive device lost check on blocking calls before (which changes with this patch), and some of this code was added because of particularly sneaky infinite looping and crash behavior we were seeing on only some drivers. Nicolas was involved in the diagnosis, so I'll add him in case he can fill in this question.
|If you must use macros, please define them directly before their use, and undef them directly afterwards.

Usually I would respond to the use of macros thusly: http://goo.gl/VRVvtQ -- you'll note that the only other place in the entire library that they're used is in constructing the vertex format tables in D3D9. I'm potentially willing to stifle my inner Nonono Cat here because a) the macros are well enough named to not completely obfuscate what the underlying code does, b) the underlying code doesn't actually perform meaningful operations, so it's unlikely to be the source of irritation for people trying to step through code that doesn't exist in the debugger, and c) that certainly would be a lot of typing just to pass the functions through to the impl.

That said, the pre-refactor code also was a lot of typing, but someone had to type it once, and people had to spend time understanding it thousands of times-- so it's the latter I'm generally in favor of optimizing.

So basically, this is OK, but with reservations, and no one is getting a functional macro into the codebase without having to suffer paragraphs of text from me. And reaction gifs. http://i.imgur.com/R4hux.gif

Alternatively, could the calling functions just retrieve the Impl themselves, or is that something we're trying to avoid? I think there's some inconsistency in how the refactored objects go about passing calls off to their implementations currently. Maybe Geoff should weigh in...
|For this-- we've been wavering in style between allowing non-const ref arguments just for STL container types, and using pointers for these to adhere to our stated standard. Do you have a pref. one way or the other? I think Geoff may favor references for these, and I lean somewhat reference-ward. Would be good to gauge consensus and then either confirm or change the style standard.
|I've been waiting for a usable foreach in C++ for ages. No objections from me!
|Now that the coding standard's updated-- can this be a ref?
|It's not function parameter, so the recently amended rule doesn't apply here. We're inheriting C++11 usage from Chromium, which is ok with auto&amp;. Unless you're talking about the last footnote on the range based for loop item in the Chromium C++11 guide, about pointers?
|The language on p63 is referring to the units in which the value in size is measured, not the type used to represent size itself. UNIFORM_SIZE is specified in the state tables (table 6.20) to be a non-negative integer. Note that the state tables do not differentiate between numbers represented internally as ints or uints, and doesn't provide a mechanism to query most values specifically as a uint.

That said, the only clue we have about the &quot;intended&quot; type of the array size is the one place it's got its own query argument (rather than using a generic param), and there it uses GLint. I haven't tallied up all the Get* entry points, but from a quick glance, it looks like integer types (either GLint or GLsizei, which is signed) are pretty much always used to contain size/count/length types across all of the query calls in the API.

The value is required to be non-zero, so that doesn't pose a problem for storing it internally as unsigned int, but I want to make sure I understand why we need to do so?
|Is the layerIndex not being checked as a valid face anymore?
|I think this comment is still accurate, but am unfamiliar enough with the Win32/WinRT/Windows Store distinctions and vocabulary that I wanted to make sure you'd considered it. Windows Store apps still fall under the categorization of Win32, yes?
|Could this get a comment noting what it's selecting for? Also, does this select for Win 8.1 store apps only, excluding Win 8.0 store apps?
|Very nitty-- the quotes mostly make it obvious, but I'd still probably prepend the comment with &quot;error X3531&quot; just to make it abundantly clear that the string is being searched for because it's the error ID.
|This is not one we've been traditionally stringent about enforcing, FWIW.

https://chromium-review.googlesource.com/#/c/199200/2/src/libGLESv2/renderer/d3d11/RenderStateCache.cpp

https://chromium-review.googlesource.com/#/c/206836/14/src/libGLESv2/renderer/d3d/d3d11/TextureStorage11.cpp
|Done
|Done
|Done
|What would the call path from glRenderbufferStorage be, then? Currently Context gets the Renderer to construct a new impl object for the renderbuffer, and sets the Renderbuffer's impl accordingly. If setStorage() moves to the Impl, then would Renderer need to set the storage directly? I don't think Context::setRenderbufferStorage should be directly handling RenderTargets directly, since they're D3D-specific, and Renderer manipulating the objects rather than simply creating them seems counter to the &quot;Renderer just creates objects and draws things&quot; goal. I also think that it would be good to mirror the GL object as closely as possible, but I'm not sure that's a good use of mutable (although I'm not seeing at the moment the places we'd need to manipulate it from const functions).

getImpl() in particular mirrors the other refactored objects (although I suspect I should have named it getImplementation() to match them, and *usually* it's only called from within the API-specific Renderer object code, although there are a few exceptions.
|Ok, that's reasonable enough. Done.
|Done
|Done
|This ended up moving in both directions-- it's stored at the GL level, but there are functions to query it from the implementation, which plumb through to the D3D version, which retrieves the information directly from the RenderTarget. When the storage is set, the GL-level Renderbuffer object caches those values.
|I agree these should move, but I'm actually not sure about the direction. These values are inherent to the GL object, not specific to the D3D implementation-- I thought we'd been keeping GL data at the GL/ANGLE engine level? It looks like we're fairly inconsistent about this in the refactoring that's been done so far-- Buffer keeps the GL-descriptive members in Buffer rather than the Impl, but Texture has moved it down. We should be consistent about this, and know why we've chosen whichever choice we go with.
|Done
|Done
|Done
|Forgive my gtest ignorance, but... is this seriously a namespace used in that library? O.o
|This makes me itch, but I'm going to assume this is completely normal syntax inside this lovely library.
|Comment needs updating
|This should follow the QPC calls to Fence11.cpp
|This should follow the QPC call over to
|nit: namespace designation not needed
|nit: namespace designation not needed
|Style: Include guards should be all-caps
|nit: namespace designation not required
|nit: namespace designation not required
|nit: namespace designation not required
|nit: namespace designation not required
|nit: namespace designation not required
|Grab this space while you're in here?
|Another changed error case.
|It shouldn't be-- eglCreateContext shouldn't return EGL_BAD_SURFACE for any reason, I believe.
|The only BAD_MATCH case for eglMakeCurrent is handled above, so I think this one was also accidental.
|Ditto my above comments.
|I'm in favor of consistency.
|This one too.
|And this one.
|Don't think this semicolon is necessary.
|I missed this function for CamelCase. (ANGLE's rule of thumb is global functions are CamelCase, and member functions are camelCase.)
|Would you mind fixing the indentation on these labels while you're in this file?
|Can this global func go into the namespace as well?
|Global functions should get a capital initial letter.
|Also missed in a prior patch-- the constructor/destructor should always be first to be defined in a class.
|Missed in a prior patch-- needs indentation.
|These guys all should have been CamelCase instead of camelCase.
|Just 2014
|Needs updating
|&quot;be&quot; missing, I think?
|Just 2014 is OK for newly introduced files.
|Needs to be updated with current filename (and preferably-but-nittily, the same capitalization).
|Also needs updating to reflect the name of the file. We also try to include the directories in the path as part of the include guard name, although that's fallen apart a bit with some of the recent code reorganization, but I think it would be a good idea in the case of WinRT-specific files, since platform-dependent compilation allows for identically named files in WinRT/Win32 (and that may be desirable at some point).
|Format nit: Some vertical whitespace would be helpful for reading this. I'd recommend a blank line after the destructor and before the &quot;private&quot; label at least.
|Format nit: needs indenting
|Does this come from RuntimeClass itself? Generally our member functions are lowercase-initial-character, but I fear there's likely to be some amount of clashing style where interaction with Windows-specific classes happens...
|Would prefer a more descriptive var name here than &quot;e&quot;
|Global functions for us usually start with a capital (it looks like I missed one of these previously with isValidEGLNativeWindowType-- my apologies!)
|Needs updating
|This wording probably needs to be changed (and is missing a description of the &quot;from&quot; resources in any case).
|&quot;Native&quot; works.
|This probably needs rewording-- I'm not sure displays translating to D3D is the right description. Maybe &quot;To request a display backed by D3D resources...&quot;?
|In conjunction with the above-- EGL can be used as the system interaction layer not just for ES, so I'm not sure we should explicitly state that it translates to ES here. It's just that we don't support any other client APIs but ES currently.
|&quot;non-conformant feature level&quot; is not necessarily clear. Either we should specifically state that we won't fall back below feature level X_Y, or say something like &quot;Unless a feature level is specifically requested which is not capable of supporting all available client APIs...&quot;
|Is WARP compatible with D3D9 at all? If not, we should specify what happens when D3D9 is specified as the platform type, and the WARP attrib is true.
|Hah-- yes, I think I spaced on that paragraph.
|Be aware that landing this will require changes to Chromium at the next ANGLE roll, because it currently uses the old method of requesting a WARP device, I believe.
|I would probably change the end of the sentence to &quot;those provided in the attrib list, if any.&quot;
|Commenting on this version because that's where the rest of my comments are-- this should probably return an error condition, no? EGL_BAD_ATTRIBUTE, maybe?
|Wouldn't this make more sense to specify in the DX/GL/etc specific extensions?
|I see this has been corrected in the most recent patch, but as a side note-- our current reserved enumerant range only goes to 0x320A, so please be aware of that if more enums are added. We should be conservative about adding additional ones, but if we hit the limit, I'll need to request a new allocation. (And 0x3210 is already allocated for KHR.)
|So, after checking around in other specs, the most analogous specs to the proposed major/minor version language would be the behavior of the EGL_CONTEXT_CLIENT_VERSION attrib in eglCreateContext, and the EGL_PLATFORM_X11_SCREEN_KHR attrib from EGL_KHR_platform_x11 (also passed to eglGetPlatformDisplay). Those are both intended as exact matches, and generate errors (EGL_BAD_CONFIG and EGL_BAD_ATTRIBUTE, respectively) if they aren't supported-- but they have the added benefit of knowing at display creation time whether the attributes are supported, instead of having to chance it and wait until initialization...

I'd say either this is an indication that we need to somehow separate the major/minor version specification from display retrieval (the only other place I can think of, though, is config choosing time, by which time we need to already have initialized the backing renderer), or we should explicitly treat it as a &quot;MAX&quot; version, and name it that way in the spec, to differentiate it, so that expectations on its behavior aren't similar to, e.g., the X11 screen attrib. I don't think it would be problematic to store that information in the uninitialized display, then...
|Fix this tab while you're in here?
|Geoff: should we consider generating errors in this case? We want to leave ourselves open to supporting increasing major/minor levels without having to repeatedly revise the extension, should they occur, but we probably want to have some mechanism for alerting users that they've requested a feature level that we know before even compile-time isn't supported. (And to document it in the extension text.)
|I think there's no need to explicitly specify a ceiling on it.
|Why is this the only place that we're encountering a rounding error, across all the places we're applying exact expectations? And do we expect the error range to be as big as 5? The only other place we allow a range is in the depth stencil draw test, and there we specify a narrower range. Should we maybe have an angle_tests-wide range defined, so that we aren't being inconsistent about how permissive we are?
|No, we can't use this value. It's in use in EGL_ANGLE_platform_angle_d3d-- we've used a number of enums since the last update to this value. We've fully exhausted the 0x3200-0x320F range; our new range is 0x33A0-0x33AF, and it looks like the first unused enum value, from a quick grep of our extensions directory, is 0x33A2.
|There's no EGL_ANGLE_keyed_mutex extension specified, and 0x3202 is already in use by EGL_platform_angle (in draft).
|There's also no EGL_ANGLE_d3d_keyed_mutex_client_buffer extension specified, 0x3209 is in use in pending changes to ANGLE_platform_angle_opengl (https://chromium-review.googlesource.com/#/c/225081/7/extensions/ANGLE_platform_angle_opengl.txt), and there's a typo on line 473.
|Could this be prefixed with something like ANGLE_surface_d3d_texture_2d_share_handle's sentence about &quot;Some EGL implementations generate...(etc)&quot;? Right now this reads like an IDXGIKeyedMutex is an EGL native concept that all EGL surfaces could reasonably be expected to have.
|As mentioned previously, this is in use in an extension revision pending review: https://chromium-review.googlesource.com/#/c/225081/9/extensions/ANGLE_platform_angle_opengl.txt

0x320B is the first value in our range with no current claim on it, I believe.
|It's probably relevant to mention that this is supported only by surfaces backed by D3D11 resources.
|Nit: spaces have been replaced by tabs here.
|I think this would be better phrased as &quot;Keyed mutexes are only available from EGL surfaces backed by Direct3D 11 surfaces.&quot;
|Done. (Did we used to use getImpl elsewhere, or did I just wander off on my own? Ah, well.)
|This changes the error returned when glRenderbufferStorageMultisampleANGLE is called with samples &gt; formatCaps.getMaxSamples. We were previously returning GL_OUT_OF_MEMORY in the case that samples exceeded the max samples supported for the format, but not the value of GL_MAX_SAMPLES_ANGLE, because INVALID_VALUE isn't specified by ANGLE_framebuffer_multisample for those cases. This does the checks in the other order, and returns the wrong error.
|Upon checking, this function actually no longer exists. The value is now accessible via Context::getExtensions().maxSamples.
|This will never be hit, because the clause above returns if the ES context is &lt; 3. The extension entry point invokes ValidateRenderbufferStorageParameters independently of this function, so this can be omitted.
|This is guaranteed by this point in the function, for the same reason as above.
|Nit: this needs to get indented to the open paren on the previous line
|nit: typos (&quot;buffers are&quot;)
|It's good to confirm that we're not performing contrary to extant drivers, but I'd rather not document &quot;conforms to &lt;single vendor&gt;'s driver behavior&quot; as a justification for implementation details in the code, lest it encourage other contributors to do the same. The specification is what we should be ensuring conformance to-- every vendor has an occasional bug.
|Typo (&quot;Multisample&quot;).
|Typo (&quot;why&quot;). I might simplify this entire line to &quot;It affects only validation of internalformat in RenderbufferStorageMultisample&quot;.
|Given that the spec states that the values of stencil components are represented by unsigned integers, but also implies that they're not intended to be included when it refers to &quot;signed and unsigned integer formats&quot; (because it does discuss their treatment in multisampling, where those formats are disallowed), I'd argue that stencil formats are indeed a special case type (&quot;index&quot;, probably). That said, I'm okay with the handling of the format in the latest patch, given the comments.
|Nit: typo
|This will still return INVALID_VALUE when:
formatCaps.getMaxSamples() &lt; samples &lt;= GL_MAX_SAMPLES_ANGLE

It should return OUT_OF_MEMORY from the extension. ANGLE_framebuffer_multisample specifies INVALID_VALUE only when: 

  * width or height &gt; MAX_RENDERBUFFER_SIZE
  * samples &lt; 0 &#124;&#124; samples &gt; MAX_SAMPLES_ANGLE

OUT_OF_MEMORY is explicitly specified by ANGLE_framebuffer_multisample when the requested storage cannot be created, which includes cases where the number of samples requested is greater than the number supported for this format, but less than the maximum number of samples supported amongst all the supported formats.
|Any reason not to omit the constructor, and define the destructor as {} in the header?
|I don't remember why we don't do multisample swapchains... can this get commented to refresh my memory?
|Part of me kind of wants these to get defined the the .cpp file, since the SurfaceRenderTarget11 equivalents are, and they look missing in TextureRenderTarget11 if you're just looking there. But... ehhhh, not a huge part of me.
|Ditto question from RenderTarget11
|Done
|Done
|Can we just initialize it with other syntax for clarity's sake, regardless of whether it's allowed? I'm kind of annoyed at uniform initialization for being delightfully easy to mistake for at least two other things if you're reading quickly.
|And so you did. Disregard this, then!
|Not sure if this is intended to go in commented out?
|Allman-style braces (brace on new line), please.
|Just for future reference, default values are explicitly forbidden in the ANGLE &amp; Google style guides, so it's not just preference.
|Done
|Done. This also made more obvious a bug-- I was defining only level 0 of the subsequent textures, which did have an effect on the benchmark, which I'd found confusing. Draw times are now very similar for both resized &amp; newly created textures, and only the definition shows a difference. (NB-- benchmark data quoted in the article was on an HD4000, while today I'm working on my Q600 system.)
|Removed.
|Done
|Done
|s/input/output/ ?
|Haven't we already done this check at Renderer initialization time in most cases? Should we cache that result instead of doing it a second time? (Also, we use QueryInterface instead of DynamicCast in init. Is there any reason to be doing the cast here, if we don't use the resulting pointer?)
|FWIW I generally consider consistency/readability &gt; compactness. I'd keep it off, and maybe feature request all-or-none mode?
|Should be &quot;dependent&quot; (I think that the word can very occasionally be spelled that way in British English, but only when used as a noun. Not sure if this is one of the places Canadian English follows American English in spelling or not, but it's an adjective either way, so should get an 'e' instead of an 'a').
|Very nitty: second use of a variant of &quot;allow&quot; in the sentence, consider changing one of them.
|Very nitty: I'd probably use present tense (translates) here, although a case can be made for past tense.
|Very nitty: I think technically &quot;entry point&quot; is two words, but I have a personal tendency to mash technical terms together into novel compound words, so I don't mind it at all.
|from
|Could this get rephrased a little less informally? Possibly something like &quot;There are tools and strategies available for debugging ANGLE across the various platforms it supports. Our tips for using them can be found below.&quot; (On that note it would be cool to include, e.g. Geoff's walkthrough for debugging with MSVC's graphics debugging tools, and possibly the tips we got from the MS folks on how to attach to a running process for graphics debugging.)
|ANGLE exposes the same symbols as ANGLE-- one of these ANGLEs should probably be an apitrace? Also the &quot;flow&quot; description is a little confusing-- could you just state that apitrace intercepts the entry point calls intended for ANGLE? And this is me being pretty nitty, but the use of &quot;we&quot; seems a little pedagogic-- would prefer just something along the lines of &quot;To avoid this call interception:&quot; or &quot;To avoid this, use the following steps.&quot;
|I'm not sure if this is the same markdown format I'm used to dealing with, but if this isn't an ordered list, could you please make it one? Also, you should give the exact command to be entered on the command line for clarity.
|Semicolon or period/full stop required here.
|You can just show the command on its own line with a prompt. I believe this style is used elsewhere, like the DevSetup article-- copy the style there for consistency.
|explicitly
|This should technically be future conditional tense (won't).
|by
|Comma splice. Should be semicolon or period.
|This phrasing makes it sound like the argument should get followed by a noun, e.g. &quot;the '-D angle_link_glx=1' argument.&quot; It should probably just get shown explicitly as menioned for the other define argument above.
|aside from
|missing &quot;is&quot;
|Comma required. Ideally, I'd change &quot;Using all this&quot; to &quot;If you have followed this steps.&quot; If you make that change, you'll also need to change &quot;apitrace works&quot; to &quot;apitrace will work&quot; or &quot;apitrace should work.&quot;
|I'd use $PATH for clarity.
|Would be better phrased as &quot;For example, to trace a run of...&quot;
|comma needed
|&quot;that&quot; unnecessary
|There are two ways we can interpret this.

A) INVALID_OPERATION is returned for the explicitly specified cases. For other cases which are not valid, no behavior is specified, therefore it is undefined, and INVALID_OPERATION or INVALID_ENUM are both valid.

B) INVALID_OPERATION is returned for the explicitly specified cases. In other cases, the blanket specification for INVALID_ENUM in 2.5 &quot;GL Errors&quot; applies:

&quot;If a command that requires an enumerated value is passed a symbolic constant that is not one of those specified as allowable for that command, the error INVALID_ENUM is generated.&quot;

In that case, I would say that there's room to interpret it as applying even to the default framebuffer, despite the loose language about &quot;...a constant other than...&quot;
|Jamie's interpretation is correct for the ES 3.1 specification-- INVALID_OPERATION is specified for the narrow cases where a token representing an actual attachment is passed, but is not appropriate for the type of framebuffer currently bound (i.e. passing a numbered color attachment while the default framebuffer is bound, or passing BACK while a user-created framebuffer is bound). INVALID_ENUM is specified for cases where the token does not represent an attachment at all, like GL_FLOAT or GL_SOMETHING_I_MADE_UP.

However, the INVALID_ENUM text doesn't appear in ES 3.0 at all. IIRC this was simple oversight, and it was fixed in ES 3.1, but the spec authors either didn't carry the fix back to ES 3.0, or they declined to apply the fix to ES 3.0. The most spec-adherent way for us to implement this would be to return INVALID_OPERATION for any cases other than the valid ones, as we're implementing ES 3.0 currently. When we add ES 3.1 support, we'd need to do a version check and apply the INVALID_ENUM return appropriately. 

However, if there's a dEQP test which expects the INVALID_ENUM rather than INVALID_OP in ES 3.0, we'll need to sort out with that team what the appropriate thing to do is, since the INVALID_ENUM return is the intended behavior, but not the specified behavior, for ES 3.0.

(Just a note-- please make sure to use the ES 3.0 specification when implementing ES 3.0 entry points. It's a good idea to check for differences with ES 3.1 as well, so that we can implement things in a way that will accommodate future API revs, but ES 3.0 is the one that should be governing what we're currently adding.)
|Extensions which make changes to the spec should do so in a way that's controllable by the app-- it's not really fair game to make a blanket change to the specified behavior via an extension that the application may not even know to check for. Is there a way to make this enable/disable, or otherwise enabled by request only?
|Yes, I think that sounds sensible.
|Khronos has allocated us a new block: 0x9690-0x969F. We also have the remaining ones from the old block: 0x93A8-0x93AF. I think it would be best to use a contiguous range for the enums in this extension, so I'd suggest using 0x9690-0x969A for these (note that these values are in hexadecimal, not decimal notation, so 0x969A follows 0x9699).

Other extensions should continue to draw from 0x93A8-0x93A until it is exhausted.
|Yes, we'll need to reserve more enums; we only have 8 remaining in the GL namespace (0x93A8 to 0x93AF). I've requested a block; Khronos bug ID 15423.
|OPTIMAL?
|I don't think anything has 0x33A7 yet.
|Missed one
|Patch Set 1:

Is it possible to +3 things?
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 5:

I've a pending question out about Khronos process for EXT prefixing; would like to answer that before landing
|Patch Set 5:

Pending question answered; no objections remain from me. (Might be a good idea to give James a chance to weigh in on the spec language, though.)
|Patch Set 3:

This one got missed because no reviewer was designated. Please be sure to add reviewers to patches, as described on the wiki-- otherwise patches stand a good chance of falling off of our radar.
|Patch Set 5: Code-Review+1

Looks OK to me. Nicolas, any objections?

Is there a Chromium issue associated with this feature? What testing has been done on this patch?
|Patch Set 5:

GL_CHROMIUM_NV_path_rendering is a Chromium pseudo-extension. I'm not certain that there *is* a spec for it.
|Patch Set 5:

I don't really want to leave this stalled-- is there a Chromium or related issue for supporting this feature? Do we need to draft an extension against ES? Does anyone know?
|Patch Set 5:

Can the issue ID be included in the commit msg, please?

Nicolas, just want to check with you-- what is your disposition on including non-standard extensions/pseudo extensions in compiler support? I assume there's no issue with it; WebGL-specific items sort of fall into the same bucket. I give you final +2/not +2 on this one.

Also relevant-- how difficult will this be to merge to es3proto? For Chrome support purposes, master branch is going to become moot soonish.
|Patch Set 6: Code-Review+2
|Patch Set 6:

I've no objections to landing, but we'll need to ensure everything goes in in the right order to not break the FYI bots.
|Patch Set 6:

Yes, certainly-- if this were landed without the Chromium-side change, the GPU FYI bots would break, so it's definitely necessary to wait.
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

One word of caution-- we've had this enabled since late 2013, so while we're safe from disabling a WebGL feature because it's not exposed there, this may impact external projects which use ANGLE directly. (That said, I don't see any huge benefit to or use case for the format on D3D9, so I'd be inclined to disable it for now, and if it turns out to be problematic, we can add a method to conditionally enable it.)
|Uploaded patch set 1.
|Abandoned
|Patch Set 1:

Could you stick a //TODO in there to remind us we need to clean this up? Only implementation detail that differs at a quick glance is the existence in core of PROGRAM_BINARY_RETRIEVABLE_HINT, which we'll need to add later. Also may be worth making sure the non-OES-suffixed versions of the queries (GetProgramiv + PROGRAM_BINARY_LENGTH and Get&lt;Type&gt;v + (NUM_)PROGRAM_BINARY_FORMATS) work in this CL, but if you'd prefer to do that later just to get the WebGL 2 loader working, just add it to the //todo
|Patch Set 3:

I echo that +2.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 9: Code-Review+2

Sorry for the delay-- looks great, ty.
|Patch Set 2:

Tangential, but also worth mentioning: if Skia is creating BGRA render targets to avoid behind-the-scenes swizzling in ANGLE, it's no longer necessary in D3D11, as RGBA formats are directly supported there.
|Patch Set 4:

Also works in the standalone ANGLE build, but I suspect that enabling some of these may cause issues for the MS folks and the WinRT build. Cooper, does the build throw errors for you with this CL?

As an aside, if we do need to keep some of the compiler warnings disabled, can we document the reasons why in a comment? We accumulated a lot of disabled ones over time, and I'm wary of what may bite us again without the knowledge of why they had to be disabled before.
|Patch Set 9:

Added Nico to committers-- I'm sure you'll need to land changes again in the future.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

This is a preliminary first pass. The biggest issues I see so far are:

Name length &amp; inconsistency - I tried to use the pattern set in EGL_EXT_create_context_robustness, GL_EXT/ARB/KHR_robustness, and GL_KHR_robust_buffer_access_behavior, but I'm not sure I arrived at the optimum name set. Suggestions welcome.

Implementation-dependent initialization values - We could also be more stringent and specify that the initializer is 0 for buffer objects, and (0, 0, 0, 1) for texel values. Is that what WebGL would prefer?

Disparate specification text location - Because the immutable texture functions explicitly discuss the value of texel data (or at least TexStorageMultisample2D does), initialization behavior at texture image creation time is discussed in the actual section on textures, while buffer data store initialization is only mentioned in the overview of object types. I'm not sure this is entirely problematic, given that people using the extension will see it called out in the extension text, but it is a difference. Additionally, texture image initialization is discussed only for immutable texture creation, while legacy-style texture creation only mentions data specification via pixel rectangle transfer. I believe we'd still be initializing in the case that the &lt;data&gt; attribute passed to TexImage* is NULL.
|Patch Set 2:

(Also note that the extension to toggle validation is yet to come.)
|Patch Set 2:

(5 comments)

Re: robustness == unexpected input. I'd argue that robust buffer access is primarily a security feature, and do want this extension to be grouped semantically with that one.
|Patch Set 2:

Additionally-- EGL_ANGLE_robust_resource_initialization is referred to a couple of different ways between the two extensions &amp; my comments therein. I'm gravitating towards EGL_ANGLE_create_context_robust_initialization, but whatever it is, I need to fix it so it's consistent.
|Patch Set 2:

To the Q about EGL_ANGLE_validation-- yep, I intend to define that one as well (see comment #4, the second at Jan 7 7:14pm EST), but if you'd like to take custodianship of that one, that's fine too. I'd paused on the extensions entirely until I could get your (kbr) input on this extension.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)

Addressed most of the concerns. Thank you for pointing out the area where TexImage data store initialization is covered; I'd missed that in-spec, as well as RenderbufferStorage. 

I added specification of buffer data initialization, but have a question about the appropriate default value for texel data, which I've highlighted in the relevant extension.
|Uploaded patch set 6.
|Patch Set 6:

Added specific language for texel/pixel initialization for 0 in all present channels. Worth noting:

1) My language for image specification in TexStorage2DMultisample and RenderbufferStorage is vague, because the only way to write to a multisample texture or a renderbuffer is by rendering or blitting to it, and that language is not nicely contained for referencing as the pixel rectangle transfer language is. This may get a side-eye from other implementors or Khronos folks.

2) Pixel unpack parameters will affect the initialization. ES3 adds parameters which can skip pixels you might otherwise assume to be present-- UNPACK_SKIP_ROWS, UNPACK_SKIP_PIXELS, UNPACK_SKIP_IMAGES, and maybe UNPACK_IMAGE_HEIGHT and UNPACK_ROW_LENGTH. Is that what is intended, or should initialization ignore these? I suspect it's more secure to ignore them, but the current implementation obeys currently set alignment, so I went with what's most like status quo.

3) I let the channels that are initialized be governed by internalformat, rather than format, but the current implementation uses format as the incoming initializing format. This doesn't matter in ES2 because they must match, but that restriction is lifted in ES3. Should I use format as implemented, or internalformat? It seems like we could just avoid potential conversion overhead by using internalformat.
|Patch Set 6:

(And sorry for the continued back and forth, but texture image specification is a particularly persnickety part of the spec.)
|Patch Set 6: Code-Review+2 Verified+1

My mistake-- I'm not sure why I thought pixel unpack parameters impact loading into GL memory. They only describe how data is accessed in client memory or the pixel unpack buffer from which the source data is being transferred. This should suffice.

Going to go ahead and land this, lacking other commentary.
|Patch Set 1:

Is there an open bug on chromium or angle for this? If so, please add the bug ID to the commit msg. If not, can one be opened? Would be good to be able to track this in the history.
|Patch Set 2:

Ty! Will leave plustwo to Geoff &amp; Jamie.
|Patch Set 1:

Is this an upload of an amended commit? If you're getting duplicated gerrit CLs on upload, you may not have the gerrit commit hook installed properly.
|Uploaded patch set 1.
|Patch Set 1:

Updated a patch from Mozilla on a longstanding issue in our tracker to apply to current master. It does look like this'd still be relevant, unless something's changed about our expectations for client applications filling out ShBuiltInResources.
|Abandoned

Issue closed wontfix; ShInitializeBuiltInResources is appropriate way to generate these.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

One question-- Cooper &amp; Austin were originally added under MS OpenTech, but is MS itself actually the entity for whom they've contributed? If so we should probably remove the Open Tech section entirely (and Open Tech from the AUTHORS list). 

Whichever way that gets settled, LGTM as long as the doubled appearance of Cooper &amp; Austin is resolved in one direction or the other.
|Patch Set 1:

Ah, ok. LGTM, in that case.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

I laughed! I cried! I LGTMed! Two thumbs up!
|Change has been successfully merged into the git repository.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Shannon uses LGTM! It's very effective.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Abandoned
|Patch Set 1:

(1 comment)

Does the master branch also need this fix? This won't cherry-pick cleanly, I think, because the master branch doesn't have the format handling refactor, so a separate version is probably needed there.
|Patch Set 1:

Mind adding a comment to call out the potential optimization &amp; memory tradeoff before landing?
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2:

Ehhhh, I think I'd err on the side of not adding another piece of state to track (and potentially get out of sync if we're not careful).
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

LGTM, although it seems like if we have to name members of Blit such that it's clear they're for blitting, we might want to rename the class. Not sure there's anything that makes sense to rename it, though.
|Change has been successfully merged into the git repository.
|Patch Set 1:

Argh. That was the wrong button. If it's problematic that this got merged already, please feel free to revert it.
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

The texturecube binding problem we ran into before may actually have been binding a cube texture to a Texture2D object in the shader, now that I think of it. LGTM.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)

It seems like there's quite an explosion of textures, RTVs, and SRVs that we have to hold for a single GL-side texture at this point. Should we be afraid? Or doing anything to mitigate it?
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

(3 comments)
|Patch Set 1:

This one I'd like to get you to walk me through, because the object hierarchy for TextureStorage/Renderbuffer is pretty complicated, and I want to make sure we're not introducing any code ouroboroses.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Ok, LGTM. I'd mostly been worried about the ref loop between Textures and RenderbufferTextures, which this sits well below. Still mildly apprehensive about returning pointers into this horrible knot of hierarchy, but less so now.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Promoting CQ+1 and V+1 because it's been CR+2ed.
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Patch Set 1:

(1 comment)

Thank you for the patch! Just a small style issue which needs to be corrected before it can land.
|Patch Set 1:

If the commit hook Gerrit needs to track changes to commits is installed, then you should be able to just amend the commit, and then do another &quot;git push &lt;remote name&gt; &lt;local branch name&gt;:refs/for/master&quot;. (It looks like this commit has a Change-Id, so you do have the hook installed.) Gerrit will automatically see from the Change-Id that this is an update to a previously uploaded patch, and put the updated patch on this page.

I should have put a section on the Contributing Code page to cover that-- I'll add one now.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Looks good, thank you!
|Change has been successfully merged into the git repository.
|Patch Set 2:

Nope-- the change is already merged to the repository.
|Patch Set 1: Code-Review+1

LGTM, would like nicolascapens@ to have a glance as well.
|Patch Set 1:

I think I'd prefer the ERROR define be prefixed here if that's what was done for SwiftShader.
|Patch Set 2:

Are you trying to build just the shader translator, or all of ANGLE? The translator can be built as a stand-alone module, although it looks like it's possible that some recent changes to the project structure may have made the &quot;GLSL ES to GLSL Translator&quot; section of the DevSetup wiki no longer completely accurate.
|Patch Set 3: Code-Review+2 Commit-Queue+1
|Patch Set 3: Verified+1
|Change has been successfully merged into the git repository.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Patch Set 1:

I don't think this is needed for es3proto, but if I'm wrong, holler.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1:

es3proto looks like it's in line with some of this, but gclient may be stale. (Not sure if it's just me.)
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

This works for me if it fits the needs of chrome-gpu/kbr@/zmo@/etc.

Will this be portable to the main branch?
|Patch Set 7:

As a reminder: We need to do something about the weird solution explorer directory layout in the default project before we can port to master.
|Patch Set 9:

Is the discard workaround change supposed to be in this patchset?
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 11: Patch Set 10 was rebased
|Patch Set 11: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1

I really don't care who wields the almighty power of the +2 as long as it gets two sets of eyes on it before it goes in. That was just an easy way to gate it. If it makes you happy, +2 away.

LGTM.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

LGTM. Geoff, was your review a &quot;looks good but fix this before checkin&quot;, or do you need a second pass? Please + it if it's fine by you.
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Change has been successfully merged into the git repository.
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Could add a //TODO or comment indicating that streamfreq is an area we could look at cacheing for a possible slight performance enhancement. LGTM either way.
|Patch Set 3: Code-Review+1

Ah, I'm first to review-- I'll keep it at +1 until a second set of eyes has seen it.

(NB for non-ANGLErs: ANGLE has a 2-person review policy, so it needs to be OKed by 2 people before commit.)
|Patch Set 3:

When instancing is enabled, SetStreamSourceFreq is called every draw during applyDeclaration, so it will get set back at the next draw without us needing to store it before the swap. We similarly reset all streams to 1 each time we perform a blit or a masked-clear (I believe these instances are what Jamie was referring to when he mentioned legacy code).
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Ah, LGTM, and I think I answered my Q from the prior ticket about issue #s.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Rebase OK by me.
|Patch Set 1: Code-Review+2 Commit-Queue+2 Verified+1

LGTM
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1

Leaving +2 for jbauman@
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

LGTM
|Patch Set 3:

This one's also needed by es3proto.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1

LGTM. Does this have an associated issue in the bugtracker?
|Patch Set 1: Code-Review+2

+2ing 'cause Geoff LGTMed in prior ticket. Can the commit msg get the bug ID for this one too?
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Rebase ok by me.
|Patch Set 1: Code-Review+2 Commit-Queue+1

[LGTM] *stampstamp*
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Ah, sorry, I'd spaced on the fact that it was retrieving each texture used by the shader, rather than just getting the currently active texture.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

(4 comments)
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4:

Works for me-- but can there be a //TODO or something for the D3D9 side?
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1

LGTM.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1

Rebase LGTM
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1

Was the last patchset just the result of patch stack shuffling?
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1

Fixes the build for me!
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1

I have deja vu. Did this one go through already?
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

When I open the pregenerated project, the libGLESv2 project has a folder inside of it called libGLESv2, and ditto for libEGL, and the compiler projects have compiler &gt; preprocessor and compiler &gt; translator -- I don't suppose it's possible to remove that bit of nesting? 

Much better though!
|Patch Set 2: Code-Review+2

Ok, works for me then.
|Patch Set 1:

(1 comment)

Does this incorporate Jamie's changes for the prettier-looking public projects and the auto-updating commit?

Note to zmo@ -- we definitely want ack from you or others in chrome-gpu before landing, so we know you won't be surprised by the project changes.
|Patch Set 2: Code-Review+1

LGTM. Will +2 once we get an ack from Chrome team.
|Patch Set 2: Code-Review+2

Not going to hold this one up on Chrome feedback any longer; as you've tested with Chrome builds, I'm fine with landing this.
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2

Erps.
|Patch Set 3: Code-Review+1

Buildsforme!
|Patch Set 1: Code-Review+1 Commit-Queue+1

Typo in the commit message, but other than that LGTM
|Patch Set 1:

Also, is this tied to a bug in the tracker? If so, please include the bug ID in the commit msg.
|Patch Set 3: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (1/9)
|Patch Set 2: Commit message was updated
|Patch Set 2:

Ah, I meant to change that. Commit msg updated! I can haz stamp-proval?
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

Rebased. NEED MOAR STAMPS!
|Patch Set 3: Verified+1
|Change has been successfully cherry-picked as 86f601cb0a4311accd39460e22794987873d126a
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (4/9)
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5: Code-Review+2 Verified+1

Thoroughly LGTMed, rebasing and submitting
|Change has been successfully cherry-picked as e88dcaf333a8a583e023b1db372668af2ce8b273
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (5/9)
|Patch Set 1:

zmo@ is probably best equipped to answer this one
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Verified+1

Has been LGTMed, rebasing and submitting.
|Change has been successfully cherry-picked as 6cb95f3a235c20dbe4bb9f5de75401a16014c012
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (9/9)
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Verified+1

Patch already LGTMed, rebasing and submitting.
|Change has been successfully cherry-picked as a738f085a9d1ce14d7154b679f4600f2f80e846b
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (2/9)
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Change has been successfully cherry-picked as 1bfaf78263063660a68aceaa6b4eb2d19960ef25
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (3/9)
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4: Code-Review+2 Verified+1

Re +2ing myself because the rebase dance is getting tedious.
|Change has been successfully cherry-picked as 5cd4761f38e7cbc6fca53720b365c8c6b889a148
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (6/9)
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 1:

(2 comments)
|Patch Set 4: Verified+1

Will fix the tab in another commit.
|Change has been successfully cherry-picked as 7cab38b594213c7c80f70871b72d40d30e878035
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (7/9)
|Patch Set 1:

Ok, somebody has to +2 things. The original authors of the patches were auto-added by Gerrit as reviewers because they appear in the commit message; we don't necessarily have to wait for their approval for commit.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Verified+1

Patch has been LGTMed, rebasing and submitting.
|Change has been successfully cherry-picked as 827a471b7436ae43a31b01753cca13a6ff41e12d
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick of patches from master (8/9)
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Verified+1

Patch already LGTMed, rebasing and submitting.
|Change has been successfully cherry-picked as d7f2135fcc5b3cbe0a50205fb07159cd97c66886
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+1

(1 comment)

LGTM w/ one very nitty nit.
|Patch Set 2: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)

Ok. This works for me if it works for Chrome. As a side note, if we're adding functions for clearing device removed, we might want to update device lost to parallel it (in another ticket, not a pressing need).
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 6: Code-Review+1
|Patch Set 1:

It looks like you need to add yourself to AUTHORS, and sign the contributor license agreement (the applicable links are in step 3 of the &quot;Get Your Code Ready&quot; section on https://code.google.com/p/angleproject/wiki/ContributingCode)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

LGTM, thank you!
|Change has been successfully cherry-picked as e4c89424e3f9544444cd3a7a8e783d45c2f34598
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+2

LGTM; please create an issue or changelist for the value query issue so it doesn't get forgotten.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Abandoned

CL set is now six months out of date. Please feel free to resubmit if the outstanding issues are resolved.
|Patch Set 1: Code-Review+1

Sorry for the delay in reviewing; I wanted to check into the history of why the gets had originally been written to only get the parameter info if a query of the requested type failed, which took a little digging. It looks like the preference for it wasn't strong, so no issues changing it to be clearer now.
|Patch Set 4: Code-Review+2
|Patch Set 1:

Is changing the Bison version going to cause headaches for Chrome or WebKit? We've been bitten by that in the past, IIRC.
|Patch Set 2:

I wasn't asking just about whether it would compile &amp; run-- WebKit has had issues in the past with the Bison license. It would be good if we could refrain from approving through changesets with a standing question open.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1:

(4 comments)
|Abandoned

CL set is now six months out of date. Please feel free to resubmit if the outstanding issues are resolved.
|Abandoned

CL set is now six months out of date. Please feel free to resubmit if the outstanding issues are resolved.
|Patch Set 1:

Versioning is going to change relatively imminently, so that it doesn't have to be manually increased with every checkin. I believe the es3proto branch is using the versioning scheme we intend to bring to mainline shortly. This patch will likely be moot at that point.
|Abandoned

CL set is now six months out of date. Please feel free to resubmit if the outstanding issues are resolved.
|Patch Set 1: Code-Review+2 Commit-Queue+1

Are we using 0 as a sentinel value for shoulde-be-unreachable uninitialized attrib array data anywhere? (I didn't see anywhere, but a second set of eyes couldn't hurt.)

LGTM, assuming you see the same as me for the above Q.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2

Much clearer, thank you!
|Patch Set 1: Code-Review+2
|Patch Set 2:

Maybe getDepth should actually be getLayers for Texture2DArray, for clarity, since Image means something different by &quot;depth&quot; than Texture2DArray does.

It's possibly also worth it to add a comment to getBaseLevelImage to make clear that the retrieved image should really only be used for finding its dimension and format, since if the underlying texture is a 2D array, there are multiple base images, and you only get the 0th one.
|Patch Set 2:

Also very nitty nitpick-- commit msg has a typo in &quot;correctly&quot;.
|Patch Set 4: Code-Review+2

Looks great, ty!
|Patch Set 2: Code-Review+1
|Patch Set 5:

(2 comments)
|Patch Set 13: Code-Review+2

Ty!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 934ab062ccaf09bebefa596aeb98c0b10fc0caa8
|Uploaded patch set 1.
|Patch Set 1:

es3proto version. At this point, I suspect that the cherry-pick submit type for the repository prevents us from cleanly cherry-picking from the Gerrit web UI.
|Change has been successfully cherry-picked as f831e3dd196e496edfb9b5380b2f0ab14eb18e31
|Patch Set 1:

The Stanford models aren't free for commercial use-- I don't think we should include them in our (BSD-licensed) repository.
|Patch Set 1:

(http://graphics.stanford.edu/data/3Dscanrep/)
|Patch Set 1:

If the models and dependence on them are removed, sure. (Incidentally, I don't think the bunny is referenced in the test?)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)

Comment is a nitpick and doesn't necessarily need addressing.
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 3: Code-Review+2

I could go either way on the map insertion unless it can be expected to affect performance.
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+1

LGTM. Would like zmo@ to look at this one too, since he had expressed interest in this feature, and because I'd like to know if invoking the script during build works OK for people outside the immediate ANGLE team or causes any unexpected headaches.

zmo@, please feel free to +2 if it LGTyou
|Patch Set 6:

Poke poke-- is this waiting on anything?
|Patch Set 7: Code-Review+2

Yesplz
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2

The pregenerated VS projfiles will keep trace enabled by default in debug builds, correct?
|Patch Set 5: Code-Review+2

Alright, that's fair. LGTM.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

Thank you for taking care of this.
|Patch Set 2:

Maybe it would be better to include this in a utilities subdirectory in samples?
|Patch Set 4: Code-Review+2

Works for me.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Could also add a mention of stdarg in the commit msg if you're inclined.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

I'm good with the entry define either way.
|Patch Set 1:

It would be helpful if the commit message had more information about why/for what application this change would be needed. If these functions are causing issues on non-MSVC builds, it might be better to use a #define so that we don't lose access to the secure versions of the functions on Win32.
|Abandoned

CL set is now six months out of date. Please feel free to resubmit if the outstanding issues are resolved.
|Patch Set 1: Code-Review+1
|Patch Set 2:

master/es3proto audit: is this needed on es3proto?
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)

I think splitting this into two maps is a very good move. Semantically, the details of a given format and its association to another are definitely separate concerns.
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1

I like your solution for the insert() vs operator[] thing. Looks good, thank you!
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3:

(One nit-- typo in commit message.)
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3:

master/es3proto audit: is this needed on es3proto? (Or is it moot because of the redesigned format handling?)
|Patch Set 2:

master/es3proto audit: is this needed on es3proto?
|Patch Set 1:

It does require an extension. 

&quot;Attributes that can be speciï¬ed in
attrib list include EGL_RENDER_BUFFER, EGL_VG_COLORSPACE, and EGL_VG_ALPHA_FORMAT.
It is possible that some platforms will deï¬ne additional attributes speciï¬c to those environments, as an EGL extension.&quot; (p28, EGL 1.4 specification, on eglCreateWindowSurface)
|Patch Set 1:

(1 comment)

The CL would need to include such an extension before it can be landed. Not that our implementation is complete, but the parts we've implemented have been implemented in spec or extension.

The option of implementing these sorts of extensions is already alluded to in the spec (sec 2.2.2.2, p6), but to my knowledge none have been published. Please note that in drafting the extension, attention will be needed to the definition of eglQuerySurface, as well as section 3.9.1.1
|Patch Set 1:

(1 comment)

EGL_ANGLE_window_surface_size could work. Possibly complicating the matter is EGL_EXT_platform_base-- this extension defines versions of eglGetDisplay, eglCreateWindowSurface, and eglCreatePixmapSurface which are intended to be overridden with functions which accept platform-native window/display/pixmap types. ANGLE intends to specify an extension on top of this one to more cleanly allow selection of D3D API at runtime. Our implementation for that will need to interact with any surface sizing extension.
|Patch Set 2:

(6 comments)
|Patch Set 2:

As it stands, we're unlikely to add any support for eglCreatePlatformWindowSurfaceEXT, since we only need platform-specific handling at display creation time, so it won't need to interact with this one.

For adding resize support-- it might be a good case for adding a new entry point, but if we're approaching this as &quot;adding the ability to specify a fixed-size window surface&quot; rather than &quot;adding the ability to explicitly specify window size at creation,&quot; it's less of a problem that it's not there, I think. Regardless, this should be documented in the issues section.
|Patch Set 3:

(5 comments)

A few fairly minor language issues.
|Patch Set 4:

(6 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1

That also satisfies my qualms about returning out-of-spec errors. Will leave +2 to jmadill since there's been significant change since it was initially +1ed.
|Patch Set 6: Code-Review+2
|Patch Set 8:

master/es3proto audit: This needs to be merged to es3proto branch before that branch is merged back to mainline. I'll create an issue to track.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2

Nit: Can you add a comment about the expected smallness of the map?
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2

(1 comment)

Just one tiny nit. Huh. I hadn't expected D3D to be so easygoing with null pixel shaders. That's a pleasant surprise.

Is this testable yet?
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1

Nothing additional beyond what Geoff said.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

Sounds reasonable, and well-commented.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2:

master/es3proto audit: is this needed on es3proto?
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2

Approved, whichever way the context check gets sorted out.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 2:

(4 comments)
|Patch Set 5: Code-Review+1

LGTM! ANGLE's got a two-reviewer policy, so I'm going to add Nicolas as a reviewer.
|Patch Set 7: Cherry Picked

This patchset was cherry picked to branch es3proto as commit d163ae721a0dc688d85d7b71a834c07a02a184ad
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+2

Marking this as +2 'cause I think Jamie meant to after the issue number got attached.
|Patch Set 1: Code-Review+1

(1 comment)

Also, while I'm thinking about it -- the boilerplate copyright dates can be updated for all the files you touch. Hooray Janu... er, February.
|Patch Set 3: Code-Review+1
|Patch Set 7:

(6 comments)
|Patch Set 9: Code-Review+2
|Patch Set 1:

(3 comments)

Is support for querying GL_MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS, GL_MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS, or GL_MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS added somewhere else?
|Patch Set 7: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 5: Code-Review+2

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 3:

General comments:
- The tests could use comments indicating what the purpose of each test is, and what the steps within the test are doing.
- We should have tests that provoke the possible errors/do negative testing
- We should test pause/resume
- We should test edge cases such as attempting to read back more varyings than the limits allow, attempting to read back varyings that don't exist, etc
- We should test the interaction of point sprites and transform feedback. (I see gl_PointSize being used, but no draws with GL_POINTS...)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(2 comments)

I really like that this is being encapsulated like this.
|Patch Set 1: Code-Review+1

With the automatically updating commit version, we no longer need to do anything to prevent binaries from before and after a format change from being loaded by the wrong version of the code, right?
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

Looks ok to me. Was there an issue in the tracker associated with this one? It'd be good to track stuff like this.
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2

*stampstamp*
|Patch Set 1:

(2 comments)

A couple of non-line-specific things:

* We need to advertise support for the extension. But, because  eglQueryString as specified in core EGL requires a valid display handle, and this extension is needed before the display is created, we're going to need to also support EGL_EXT_client_extensions.
* Looking over the Renderer creation code, I realize I forgot about EGL_SOFTWARE_DISPLAY_ANGLE, which is another hacky sentinel value we use. Could that get added to the EGL_ANGLE_platform_angle_d3d specification?
|Patch Set 1:

Geoff: this was the platform extension we were discussing earlier. I think EGL_SOFTWARE_DISPLAY_ANGLE is moot at this point, because we've removed that support, but I'm not sure whether there's still a need for the Warp path? We do need to implement EGL_EXT_client_extensions, in any case.
|Patch Set 3:

(2 comments)
|Patch Set 4:

Ah, I'd forgotten that EGLNativeDisplayType is a handle rather than a direct value.

I do think it would be best to keep from recognizing the EGL_ANGLE_direct3d_display value in this extension's entry point, though.
|Patch Set 5:

Do we actually have to track which entry point was used? EGLNativeDisplayType is a pointer type everywhere but Symbian (at least currently), so those should basically not be valid values to pass in to eglGetPlatformDisplayEXT at all, shouldn't they? So we could just validate this at the entry point level instead of propagating the information down to the renderer?
|Patch Set 1: Code-Review+2

May be worth adding a comment that we plan to re-enable this once we're able to remove unused pixel shader output code for unbound RTs.
|Patch Set 2: Code-Review+2
|Patch Set 3:

master/es3proto audit: is this needed on es3proto?
|Patch Set 1:

Definitely take a look at https://chromium-review.googlesource.com/#/c/184985/ -- the implementation of EGL_ANGLE_platform_angle_d3d is currently underway. The default in the extension is D3D9-- if you have an opinion on that changing, it'd be good to mention over there or on the implementation ticket at https://chromium-review.googlesource.com/#/c/185396/
|Patch Set 2: Code-Review+2

This will also necessitate an update to the wiki-- DevSetup, the section about choosing a rendering backend.
|Patch Set 1:

Is there an associated ANGLE issue? Was there a bug that this was meant to address, or is it just part of a housekeeping effort?
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 3:

FYI: Our timing is excellent, but-- we're going to be merging es3proto back to mainline imminently.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4: Code-Review+2

+2ing rebase
|Patch Set 4: Verified+1
|Change has been successfully cherry-picked as f561ca40713380d620ea90b7746726871b7fe624
|Patch Set 5: Reverted

This patchset was reverted in change: Iecd3b9803930d89341ce6785daedf1a8925c3916
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

Does this imply the specification for ANGLE_depth_texture is incomplete? Do we just ignore the filter modes for depth textures in our ES2 implementation?
|Patch Set 3: Code-Review+2

Nit: We may want to either use the _EXT tokens, or clarify in a comment that GL_MIN and GL_MAX are supported via extension when the client version is &lt; 3, as currently it may appear from the code that MIN and MAX are supposed to be part of core.
|Patch Set 5: Code-Review+2
|Patch Set 5:

(May also want a comment re: EXTs in the API entry point. Up to you on that one.)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2
|Patch Set 2:

Added jbauman and vangelis for FYI purposes. 

Are we planning to do this just temporarily? If so, the comment should probably reflect that. Ideally, overall, I think it would be a better idea for Chrome to do the detection for DXGI 1.2 and not request a DX11 context if it's not present.
|Patch Set 4:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2

LGTM. Do we have other off-by-default flags that we're not defining? Mostly I wanted there to be a particular define we can point people to if they arrive with questions about their build no longer working. If we receive contributions back, it'll reduce the chances of the flag turning up defined in places we're not looking for it.
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3:

INFO_LOG_LENGTH is queriable only by GetShaderiv, which uses int* for params, so perhaps maxint would be a good upper limit?
|Patch Set 3: Code-Review+2

Works for me!
|Patch Set 1: Code-Review+2

+2ing as cherry-picked.
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+1

LGTM. Would like Nicolas to have a brief look at least.
|Patch Set 1: Code-Review+2 Verified+1

+2ing my own trivial cherry pick, +2ed in master
|Change has been successfully cherry-picked as ac97d59fb2ca87c993eddac0dd9dd11eb969447a
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as aacedfcffbca780c56dda2ab03ee07faccf0fbec
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: I437bdec916dbfe12cb310a20d4f38c18072eacd0
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

Skipping +1 for clean cherry-pick.
|Patch Set 2: Code-Review+1

Ditto my comment on related patch
|Patch Set 4:

master/es3proto audit: is this needed on es3proto?
|Patch Set 1: Code-Review+1

Doh.
|Patch Set 1:

(Also, don't forget to cherry both changes to es3proto.)
|Patch Set 2: Code-Review+1

Ditto comment on related
|Patch Set 4:

master/es3proto audit: is this needed on es3proto?
|Patch Set 2: Code-Review+1

Looks OK to me, definitely want Nicolas to look at it tho.
|Patch Set 1: Code-Review+2
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 1:

(3 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as d5affaa778770fadcd79aa2c98278ada0b43368c
|Patch Set 2: Cherry Picked

This patchset was cherry picked to change: I2c653ea6d0b450c2afee2ead671fe9e334a2edc3
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2:

(4 comments)
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2

ty!
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2

Skipping +1 for clean cherry-pick.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

For this and the samples that use it-- since this is adapted directly from the ES book samples, I'm not comfortable replacing the copyright info wholesale-- we should document their original origin, even though we've made substantial changes.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

Wait, I lied. Ignore that last comment.
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

(I think MipMap2D.cpp made it in here by mistake.)
|Patch Set 2:

Right-o, carry on then...
|Patch Set 2: Code-Review+1

(1 comment)

(One comment on a comment, fine otherwise)
|Patch Set 2:

Also this comment. Ignore that one too. And have some more email.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 9d30ce3f573416a993e1ed1cddd31ebed6793618
|Patch Set 3:

(Merged so this can be used ahead of https://chromium-review.googlesource.com/#/c/189061/ )
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 276abc85533a3e41fe2b159786c6b92df10a3a15
|Patch Set 1: Code-Review+2

Skipping +1 for cherry-picked CL. Will need to regenerate project files from Windows after landing.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Proj files have been regenerated in other CLs, and there's an open ticket on getting the script in shape on other platforms. Can this CL be abandoned?
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

Cherry pick from master, clean aside from whitespace changes.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 72b16b25351027dfab3121af76262cc9e44682bd
|Patch Set 2: Code-Review+1

(2 comments)

Just nits from me.
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2:

I don't understand what's changing for structs-- were gl_ or dx_ prepended structs getting turned into _gl_thingy before?
|Patch Set 3: Code-Review+1

Commit message clarifies things, thank you muchly!
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 3: Code-Review+2

LGTM. Going to CC jmadill for FYI purposes
|Uploaded patch set 1.
|Patch Set 1:

Not yet tested; uploaded WIP CL
|Uploaded patch set 2.
|Topic set to Validation
|Patch Set 2:

Sorry, yes.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

Patch set 4 fixes some missing text in the spec citation.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Change has been successfully cherry-picked as 4d161bad7c290636192645e376395519dadd9159
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 9a2e5b94902061cda27320f7daf8ed78407be1e6
|Patch Set 2:

I've been using this locally for a day or two, so Verified really does mean verified here. Landed because holy wow is this bothersome if building the &quot;all&quot; solution.
|Patch Set 2: Code-Review+1

I'm cool with it, but someone more invested in our build system than I am should definitely weigh in.
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(+2 for clean cherry pick)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1

Our use of serials for tracking applied objects may be at odds with the DX11 multiple-views-per-object paradigm. We should probably take some time during the refactor to consider whether they make sense outside of our DX9 implementation, and if not, if there's a better solution for DX11.
|Uploaded patch set 1.
|Patch Set 1:

This gets GLES3.functional.negative_api.texture.copyteximage2d_invalid_target passing.
|Topic set to Validation
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

Clean rebase
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 4dfed837cbbdf55d82b2a602d9f5806201f80fa7
|Patch Set 1:

Direct cherry-pick from master.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 3e29695d0dbe539eac0f1ccb05fe2a8d751af87d
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+2

Re +2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(This is a clean cherry pick, right?)
|Patch Set 1: Code-Review+2

+2ing clean cherry pick
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Manual cherry pick from master. (Only hand-merged item is new enums in eglext.h.)
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 3dc300a592756d292225141eded4a3a61bd511da
|Patch Set 1: Code-Review+2

LGTM, but can you add to the commit message a comment about the internalformat-&gt;actualformat change and the rounding fix?
|Patch Set 1: Code-Review+1
|Patch Set 1:

(Apparently, if you use the magic letters, it automatically plus two's it.)
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 2: Code-Review+1

(2 comments)

We should definitely update the documentation on the wiki about the Buffer implementation, since it's gotten much more complex. (I think the version currently up covers only the original, DX9-only version.)
|Patch Set 5: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2

+2ing manual merge of previously-approved CL.
|Patch Set 1:

(Although can you put a link to the prior review page in the comments so we can find it later if we need to?)
|Patch Set 1: Code-Review+2

+2ing cherry-pick.
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

So it is. Helps if I read the comments!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Topic set to NV_pixel_buffer_object support
|Uploaded patch set 2.
|Patch Set 1:

Removed pixel pack/unpack targets-- they get added later-- but left the support detection function, since we'll need it shortly and it's not out of spec in and of itself.
|Uploaded patch set 3.
|Patch Set 3:

And caught a missing return.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Change has been successfully cherry-picked as b3801744ed9df17a7d8d290e203938818ad90add
|Uploaded patch set 1.
|Topic set to NV_pixel_buffer_object support
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 916e769a5ad557f3b8a7f19ef1d3a2577e0f3165
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+2

Those SRV matrices are pretty gross. I'm ok with it if it's being replaced very quickly. (Otherwise-- bools as array indices are yucky and constant literals as member array sizes are yucky.)
|Patch Set 5:

(I might even add something to the commit message along the lines of &quot;don't roll Chrome to this commit&quot;, although the other d3d9 failures mean we likely won't.)
|Patch Set 6: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 4:

Does this break things that need an accurate level count/level number until the following patch arrives?
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 4: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

It's less about actual conflict/independence of changes, and more about creationLevels() not really being used other than to detect whether there are any levels at all-- but I'm having trouble finding the bits that made that change at this point. Approved, but please be cautious that we're not leaving any orphaned bits of functionality that would be better removed to avoid confusing later readers.
|Patch Set 1: Code-Review+2

Skipping +1 for strict revert
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

Looks good from my perspective. Would it be worth getting zmo@ or kbr@ to take a look at it as well?

Also-- it might be a good idea to have a brief doc up on the wiki about the interface between ANGLE or Chrome and the shader translator, both code and build process-wise, since it's been one of the project's brittler points. Would you mind throwing something together?
|Patch Set 3: Code-Review+1

So the ToT bots should be fine, as they're essentially auto-rolled whenever we commit, but our testing burden will increase until Chrome uptakes all changes up to and including this one? Should we possibly hold off of landing this until all other es3proto merge blockers are taken care of, at least?
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(3 comments)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 5: Code-Review+2

We do definitely need to have a rule for consistency. Are there places already in the codebase using map where we would choose to do otherwise by this rule?

That said, this is fine with me.
|Patch Set 1: Code-Review+2

(1 comment)

Approved, but with an additional comment on the commit message.
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 1:

The optimization setting has gone back and forth a bunch of times due to bugs at various levels:
https://codereview.appspot.com/7197054
https://codereview.appspot.com/6943062
https://codereview.appspot.com/6821060

Will this change affect any of the prior applications in which we've see issues with optimization? If it's an optimization bug, why do we not see the issue on master? Is master using a different optimization level? I'd also advise pinging kbr@ on this one, since he's been involved in several of the optimization flag toggles in the past.
|Patch Set 1: Code-Review+1

Ah, ok, if O3 is the current state of master, we should definitely bring es3proto into alignment.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Do you have a patch for the implementation of the added functions yet? I'm interested in seeing how the memory buffer and the texture interact-- do we introduce additional copies in the chain?
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1

Reverting change to avoid leaving FYI bots red over the weekend.
|Change has been successfully cherry-picked as b16827b0371b46029e87bc6d90456537aaa93eda
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+2

This caught a number of places where we record but do not report/take action on the result. Is there a way for us to sweep for places where we record a result, act upon it, then reuse the variable to record another result, but fail to return or act on that error? I wouldn't be surprised if cases like that have also snuck in.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+1

Finally got a chance to finish looking over this. Ok, I think this makes sense.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

What's our confidence that the window will always recover on all systems/hardware/SP levels/etc after throwing this error? The lack of MS docs on this makes me a little paranoid. Does this error ever show up on 8.1? (Do we have a way of finding out?)

And I concur with Jamie's suggestion about getting additional input from MTV. kbr@, bajones@, or jbauman@ would be good candidates IMO.
|Patch Set 1:

(Basically I'd like to hear from MTV folks whether they'd prefer for us to call this a bad native window error, or whether Chrome should be reacting differently to the lost context we were sending previously.)
|Patch Set 4: Code-Review+2

If there isn't a bug already open for the es3proto issue that's affecting the floating mountains demo, please open one.
|Patch Set 2: Code-Review+2
|Patch Set 2:

LGTM. This will also need merging to es3proto, correct?
|Patch Set 1:

(3 comments)
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 8: Code-Review+2
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+1

(3 comments)

Comments from me are all about formatting, so +1ing.

(As a non-useful aside, the existence of RestrictFragmentShaderTiming.cpp bewilders and intrigues me.)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

I like using the same ShBuiltInResources on both branches. We still need to work on getting rid of Chrome's compile-time dependency on it, but that's a good step in the meantime.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1

If Chrome still has what Chrome needs, that works for me.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

Fair enough. Can haz //comment about possible future fastpath? I know it's one narrow case, but if people are using pixel buffers, they're probably going to be interested in hands-on resource management, so even if we can only give them one specific way to avoid the pitfalls, it'd be good to do it.
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1

+1ing as Geoff's issue is standing.
|Patch Set 1: Code-Review+1

Did we want to change COMPILE_TIME_ASSERT's name? I'm good with it either way. (arglebargle preprocessor.)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 32e66b7a722532b9f423302d349f4f190af05758
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

The bug mentions not properly validating in, eg. TexImage2D for BGRA formats. If we were allowing them through when the extension isn't advertised, that's a bug in and of itself. (Or was the improper validation just that we weren't accepting BGRA?)
|Patch Set 2: Code-Review+2

(1 comment)

Mostly I was concerned about why we allowed the formats through before the extension was advertised. Assuming there are no other formats provided via extension which we're including in the internal format table but not advertising the extension for, this is good with one comment nit.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

Leaving plus-two for Mo.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

lg from here as well.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)

Only comment is on a comment.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2

Carrying over +2 from review on es3proto
|Patch Set 1: Code-Review+2

Carrying over +2 from review on es3proto
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

Carrying over +2 from review on es3proto
|Patch Set 1:

(1 comment)

I want to make sure I understand what the problem &amp; fix here is. What was triggering the update of the commit ID previously? And now it gets regenerated any time the index moves-- it'll generate the same ID every time the index is pointed at a specific/particular revision, right?

(Sorry if the questions are silly, gyp is not my forte.)
|Patch Set 3: Code-Review+1

Thanks for the explanation, and the comment is very helpful.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 4:

Nice simplification!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 334f19b705ada0ec67f70c838d298ce044381939
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 158c43846f00a3c283c20898ddaf2e6705b51103
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 6667f76bdbf2ae3cf7d49307b62c606c1bf33c37
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Sorry, had failed to notice the FBO &amp; texture are unused by the tests I copied from ReadPixelsTest. With those removed, NV_pixel_buffer_object and the extensions it layers with are the only required ones.
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 6b6fd54a2dddbe91e18af1b98a81b3fd6983128f
|Patch Set 2: Code-Review+2

I'm ok with the verb-prefixed function name; I leave it up to you whether to change it.
|Patch Set 1:

We should stop advertising EGL_ANGLE_software_display as well.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

Just a comment comment.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

One nit.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

Looks ok to me, but definitely want to get jmadill's take on it. One question-- on master (formerly es3proto), it looks like we pad with individual floats, rather than float/float2/float3 depending on size of pad needed. Any reason for the difference?
|Patch Set 1: Code-Review+1

I'm good with it, then. (Format nit notwithstanding-- this is destined for a dead-end branch in any case.) We need to make certain we test across all platforms, though.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Cherry-pick of m36 changes to legacy branch
|Uploaded patch set 1.
|Patch Set 1:

Cherry-pick of m36 changes to legacy branch
|Patch Set 1:

Trying this on my system, I fail missing VersionHelper.h. I'm using Visual Studio 2010-- I don't remember if we moved the formal requirement to VS 2012 &amp; Win 8 SDK, but I can build ToT master in 2010, so this would represent the first breakage for the old toolset to my knowledge.
|Patch Set 1:

Firefox currently only lists 2010 &amp; Vista under Win build prerequisites, though.
|Patch Set 1:

Actually, it looks like it's the Windows 8.1 SDK that's needed, rather than a specific version of Visual Studio. VersionHelpers.h doesn't appear until the 8.1 SDK, and Chrome currently has its dependency set at 8.0. MS recommends using the header with prior releases of Visual Studio if needed, so that itself shouldn't be the issue. I'll check in with various folks about the SDK dependency.

(The Firefox build instructions I'd seen are here: https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Build_Instructions/Windows_Prerequisites
This may be out of date.)
|Patch Set 1:

After checking, it sounds like we should probably take our cues from what Chrome itself has done: https://codereview.chromium.org/39693002/#msg15
|Patch Set 2:

You know, I'm not entirely sure either. The trace event header we picked up from Chromium is in third_party, so it might be best to put it there, so that it can retain the &quot;Chromium authors&quot; header?
|Patch Set 3:

So trace_event inherits its file name style convention from Chromium, where it originated. SystemInfo.h/cpp should probably retain their capitalization scheme (which I guess they inherit from the greater Blink style). Since we're adding the namespace ourselves, I think the namespace should follow our own style guideline (which uses all-lowercase for namespace names).
|Patch Set 4: Code-Review+2

rx works for me to. Although we should probably consider renaming our namespaces, as GL/Renderer will be a less than ideal semantic separation once the redesign is done. (That's definitely not a this-ticket thing, though.)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Geoff, if there isn't an issue in the tracker for this yet, would you mind creating one &amp; assigning to yourself, and then marking this CL abandoned?
|Patch Set 1:

Does this have an open issue in the ANGLE issue tracker? Also is there one in the Mozilla tracker? If so, can this get a reference to either/both in the commit message?

Adding jmadill@ to reviewers.
|Patch Set 2: Code-Review+2

LGTM. Thank you for the fix!
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as b66feb31c258d328a03c6555c41fabfa27af1636
|Patch Set 1: Code-Review+2 Verified+1

I think Qt may use mingw for ANGLE as well.

LGTM. (Checking verified as I've tested both ninja and pre-baked projfile builds on Windows.)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)

I don't have a sense of how much work it would be to change the dEQP build scripts either. Non-ASCII-range UTF-8 is allowable in comments in ESSL 3.00, incidentally-- we just have no need to parse them. If it's low effort to keep UNICODE support, I'd prefer to do it. Any idea what it'd take?
|Patch Set 2:

Ah, ok, Unicode worries abated.

I'll check into the test-names-as-public-info thing.
|Patch Set 2: Code-Review+2

Verified -- test names are A-OK.
|Patch Set 3:

(1 comment)
|Patch Set 4:

Yah, is cool by me. Historically we've done the &quot;is there a currently assigned object for this type&quot; checks last, but it was largely out of a desire to early out before messing with getting the context/info from the context. Given that we have to check context fairly early with the combined ES2/ES3 API, I'm not sure we need to continue doing that.
|Patch Set 6: Code-Review+2
|Patch Set 7: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

This CL, along with https://codereview.chromium.org/295803002/ , will move generation of the string representing ShBuiltInResources values into ANGLE, removing the need for Chrome to receive a source update every time that struct is updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(5 comments)

Ty for catching those.

Re: Additional review-- ANGLE's policy is for all CLs to have two reviewers (excepting clean cherry-picks of an already-reviewed patch from another branch), so it will most definitely get a second review.
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 6: Commit message was updated
|Patch Set 6:

No ANGLE-side issue for this, which I think is fine unless anyone disagrees. Will wait for Nicolas's input on the issue he raised before landing.
|Patch Set 6: Verified+1
|Change has been successfully cherry-picked as 2d76e5f66595e1cef04f4ad678deda0d0e4643d7
|Patch Set 7: Cherry Picked

This patchset was cherry picked to branch test-cherrypick as commit baf80fe709f54f2eb14fa8f6b58fc8fc23c16596
|Patch Set 7: Cherry Picked

This patchset was cherry picked to branch test-moose as commit 4670b66fc7d787719f87d4fd736ffcc6c23f6cea
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1

MOOSE SELF-APPROVAL RAMPAGE!
|Change has been successfully cherry-picked as fc0566c6af0021c9bd119cd6039838e9152229a2
|Patch Set 1: Code-Review+2 Verified+1

mooooooooose
|Change has been successfully cherry-picked as 83490dc226d846744bebbb9b5c29d861f8a162cd
|Patch Set 3: Code-Review+1

(3 comments)

Just a few nits from me.
|Patch Set 4:

(1 comment)
|Patch Set 4: Code-Review+2

Ok, SGTM
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1

PLUS TWO FOR THE MOOSE.
|Change has been successfully cherry-picked as 07adc311565a2c38c261258c5e2ac264d9f40067
|Patch Set 3:

Vlad, if you've run this through the conformance suite and seen no issues, can you check the &quot;Verified+1&quot; box? (Or if anyone else has run it through the suite, feel free to verify.) Once that's done, one of the committers can land it.
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 7:

(8 comments)
|Patch Set 7:

(3 comments)
|Patch Set 10:

(1 comment)
|Patch Set 11:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 12: Code-Review+1

(2 comments)

I think this approach limits the reach of the &quot;inspector&quot; globals enough for me-- any objections, Nicolas &amp; Jamie?
|Patch Set 12:

(1 comment)
|Patch Set 9: Code-Review+2

(1 comment)

Were there missing formats other than OES_texture_half_float that I missed? (Assuming no, LGTM.)

I was initially wary of this because of the complications we've seen with the interactions between ES2 extension formats and the ES3 specification-- but this isn't really affected by those, I don't think. A format's validity is dependent on client version &amp; extension publication, and can't change in a call lifetime. As long as we're correctly doing all validation at the entry point, this should be fine.

(Also did a pass through of the WebGL 1.0.2 suite with this locally in the course of checking out viewport behavior in the following CL, and it had no regressions for me.)
|Patch Set 10: Code-Review+2
|Patch Set 4:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2

(1 comment)

Tiniest nit evar, but LGTM
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+2

Should we check the support flag just in case we need to disable PBO support on some subset of systems, or leave that for if and when that happens? +2 in any case.
|Patch Set 7:

(3 comments)
|Patch Set 12: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+1

(1 comment)

One minor item.
|Patch Set 2:

Nevermind the file renaming request-- I see it's handled elsewise.
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 6:

Er, presumptively marking +2 'cause the issue Geoff raised was addressed...
|Patch Set 2:

(2 comments)

Comments just on the running threads in patch set 2; haven't finished looking at patch set 8 yet.
|Patch Set 2:

(1 comment)
|Patch Set 9:

(2 comments)

Mostly thumbs up! One other Q-- have you by any chance done any eyeballing of GPU process memory usage before &amp; after the patches in this set? I don't see any problems in your changes, but this area of the code makes me especially paranoid.
|Patch Set 9:

(2 comments)
|Patch Set 10: Code-Review+2

I think I'm good with this-- the FramebufferAttachmentImpl is the one that goes away later in the patch, right?
|Patch Set 8: Code-Review+2
|Patch Set 9: Code-Review+2
|Patch Set 10: Code-Review+2
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 11:

(3 comments)

I think this is a particularly elegant way of solving this, and like it a lot. Comments are pretty minor.
|Patch Set 12: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

Mind adding the link to the commit message?
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 7: Code-Review+1
|Patch Set 4:

(4 comments)
|Patch Set 5: Code-Review+2
|Patch Set 5:

Does the GN file need to be updated?

Also echo Jamie on the mixed uint8_t/byte types in the Image*.cpp files.
|Patch Set 5:

(And like the others, 2nd reviewer feel free to bypass me with +2 as long as you're satisfied.)
|Patch Set 2: Code-Review+1

Can this get a comment noting that there's no 32 bit integer depth format in d3d11 to back it with?
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 8: Code-Review+1
|Patch Set 1:

(3 comments)
|Patch Set 2:

The attrib enum names are kind of an unfortunate concatenation of prefix and suffix-- they're prefixed with EGL_PLATFORM_ANGLE due to the name of the extension that introduces them (which properly should be EGL_ANGLE_platform_angle, actually-- the extension name, that is, not the prefix), and they're suffixed with ANGLE because it's a vendor-specific extension, so the enums it introduces get suffixed with the vendor name. That's why we have the silly-sounding EGL_PLATFORM_ANGLE_ANGLE while X11 gets EGL_PLATFORM_X11_EXT/EGL_PLATFORM_X11_KHR-- it's a cross-vendor, and later Khronos-ratified, extension, while the ANGLE one is ANGLE-only.

The prefix for platform extensions isn't a codified rule (I don't think), but we didn't want to buck the convention set by the X11 extensions, which are the only platform extensions so far to introduce enums other than the platform argument enum itself.
|Patch Set 1:

(3 comments)
|Patch Set 1:

(1 comment)
|Patch Set 4:

Did you remove the wrong extension? The list I'm seeing for patch set 4 has ANGLE_platform_angle_software but not ANGLE_platform_angle_opengl.
|Patch Set 5: Code-Review+2

LGTM.
|Uploaded patch set 1.
|Patch Set 1:

WebGL 1.0.2 passes at 100%, no regressions in angle_tests.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

Derp, fixed.
|Patch Set 3: Verified+1
|Change has been successfully cherry-picked as afeeda9391c1f3fc0c35c04fbc448480177059d8
|Patch Set 2: Code-Review+2
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

(2 comments)

I'm apparently the nitmeister this week.
|Patch Set 2: Code-Review+2

Ah, yeah, I was looking at the merge diff. If you feel like taking care of those, go ahead, otherwise I'll bug Geoff. (Actually, I thought I did bug him about the max anisotropy ones...)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2

(2 comments)

Just a nit from me. I think Jamie caught all the real stuff!
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2

Ah, I'd forgotten we'd added EXT_color_buffer_float support.
|Patch Set 4: Code-Review+2
|Patch Set 5:

(4 comments)

I think before we go much farther in the refactor, we should consider the naming scheme for the Object owns ObjectImpl, ObjectImpl is specialized by Object9 and Object11, because as they proliferate, there's considerable potential for confusion as to what Object9/11 inherit from.
|Patch Set 6: Code-Review+1

I'm good with everything aside from the question open for Geoff.
|Patch Set 6: Code-Review+2

Ok, that makes sense. I definitely agree for this case that querySingleParameter is more of a validation level function than an innate service of the VertexAttribute struct/object. I do want to avoid having all-global-everything-all-the-time, but in the case of validation, it's currently living as globals, so migrating that function in that direction I think makes sense. (We may want to consider objects for the validation layer as we go forward-- especially once we get to the point of adding different independent validation schemes. Objects may make managing those much simpler.)

The specific case I'm personally interested in avoiding is one where we keep most or all of the GL state as classes or structs with their data exposed for examination by globals-- it defeats a lot of the point of OO and member access control, I think. It might just be bad luck that the first things I really interacted with were caps and vertex attribs, but I wanted to confirm that wasn't the direction this is going overall.

+2ing for commit; we can (really briefly) determine our overall disposition towards struct declaration order tomorrow, and create a ticket to sweep the current code &amp; standardize.
|Change has been successfully cherry-picked as 5bf98290459ca4ccab2f5be62f5fba2337fe8b7a
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as fb8394756ea5940cf41e8276a81d54bacdceb5a6
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as 3dc8020ac2f878997d71558d87c1efa3278aaa13
|Uploaded patch set 1.
|Patch Set 1:

Not sure if this variable is destined for some use in the future?
|Patch Set 1: Verified+1
|Change has been successfully cherry-picked as f26ecc81cf58b831042db6701a1ed3448caf83cd
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 2:

My only hesitation is that the client version check becomes implicit just for the clear buffer API. It makes it less obvious that we're performing the check, especially if the version check is explicit in other entry points...
|Patch Set 3: Code-Review+2

Yup, that's what I meant. That works for me-- my only issue would have been if it looked like we were doing it some places but not others. If essentially every entry point ends up with a validation function named for it, I'm cool.
|Patch Set 2: Code-Review+1

Works for me if it works with Geoff's direction for reduction in pass-through members on classes.
|Patch Set 1: Code-Review+1

Super-nitty-- can the comment be a little clearer about the fact that we don't call resize for buffers that are already larger than the needed size?
|Patch Set 2: Code-Review+1

Thank you!
|Patch Set 1: Code-Review+2
|Patch Set 1:

Echoing Nicolas on the issue thread-- it should get fixed on master as well, so +ing here as well.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

Do we have -Werror on for all platforms? Brandon, what platform are you working on for MANGLE?
|Patch Set 3:

We talked off-thread, but for documentation purposes, I suspect there's a difference in the warnings-as-errors compile flag between the ANGLE-in-Chrome build and the standalone ANGLE build.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Before landing on a chrome release designated branch, we should verify that they'll accept the merge there.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

Sorry, was checking whether a -1 would still gate the submit if there was also a +2. (It won't.)
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 6: Code-Review+2

We should use std::copy in libGLES for extension string generation as well, if we do it here. (In a follow-on ticket.)
|Patch Set 2: Code-Review+2

+2 as long as it's short term as described.

Do we have a way of conditionally enabling workarounds for specific drivers, the way Chrome does? Should we consider it? Repacking the targets may be something we want to avoid for Nvidia drivers after the fix.
|Topic set to MANGLE
|Patch Set 3:

(2 comments)

The architectural choices &amp; interface separation are good-- I like the layered approach for the BufferImpl &amp; BufferD3D interfaces for the children to inherit. I think there was some question how much the VDM was really going to be needed for D3D11 buffers, and whether they could be confined to the D3D9 side, but I think this setup leaves us in a good place to handle either outcome.
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+1

Oops, preemptive plustwo.
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+2

This has two +1s, promoting to +2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2:

No worries; none of us caught it until I tried a build from my laptop, since most of us are using the gyp-generated build files.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)

My only comments are quasi-nits. 2nd reviewer please feel free to +2 in my absence once you're satisfied.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)

The commit message sounds scarier than this is, hehe. This actually makes things considerably simpler, I think. One nit.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2:

Rebased
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

I agree as well. Changed; PTAL.
|Patch Set 3:

Actually I think I've still got an issue with the refcounting for VertexArray.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

I changed State's VertexArray pointer to a binding pointer, and also changed the vertex array map management in context to use addRef and release, which it wasn't previously.

Passes WebGL 1.0.2 conformance, regressionless on 1.0.3.
|Uploaded patch set 5.
|Patch Set 4:

And constified Framebuffer::id().
|Patch Set 5:

XFB will continue to be used as long as they're active (see sec D.1.3, Deletec Object and Object Name Lifetimes), so they can live past deletion, similar to Query objects. VAOs, I think, don't have any situation where they can survive past deletion, though.
|Uploaded patch set 6.
|Patch Set 5:

Removed RefCountObject inheritance from VertexArray. Verified passing 1.0.2 conformance, 1.0.3 regressionless.
|Patch Set 6: Verified+1

Last comment intended for Patch Set 6.
|Uploaded patch set 7.
|Patch Set 6:

(3 comments)
|Patch Set 8: Patch Set 7 was rebased
|Patch Set 8: Verified+1

Rebased.
|Uploaded patch set 1.
|Patch Set 1:

This moves the framebuffer target validation to be entirely at the entry-point level. Part of why I did this was because it'll be moved into State, and I didn't want to be doing validation/including the validation headers from there, but if an assertion is preferred inside getTargetFramebufferHandle, I don't mind adding one &amp; depending on the validation headers for it.
|Patch Set 1: Verified+1

Tested regressionless w/ WebGL 1.0.3 conformance.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Sorry, prior patchset wasn't intended for review, just got uploaded automatically when I put up the follow-on. All comments are addressed in patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

Rebased
|Uploaded patch set 6.
|Patch Set 5:

Moar rebase.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 1:

Moar rebase
|Uploaded patch set 9.
|Patch Set 8:

Rebased. Again.
|Patch Set 10: Patch Set 9 was rebased
|Patch Set 10: Verified+1

...
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

With this refactoring patch, we were attempting to validate sampler draw state before the uniforms were applied, causing collisions when samplers of differing types were used within the same shader, because they appeared to all be associated with texture unit 0. We'll need to be more cautious about validation of draw calls in particular, as much of that validation relies on state which we cache and only apply at draw time to avoid redundant state setting.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 3:

Thread on 390412 already updated; bugdroid also sees changes from ANGLE when tagged with crbug IDs.
|Patch Set 2:

(1 comment)

Only comment is to concur with Jamie. (Feel free to +2 without me, Jamie.)
|Patch Set 6: Code-Review+2
|Patch Set 2:

(1 comment)

Good test case, thank you.

I'm a little confused about what times the updateSamplerUniforms logic is intended to happen. I was going to ask about whether it's a potential problem or performance penalty to have it happen both during validation at the beginning of the draw call, and again directly from Context::draw&lt;Stuff&gt;, but then I noticed it's getting called again during applyShaders. Are the uniforms really supposed to keep getting reapplied like that?
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

State refactor CL. As the title suggests, this is a WIP. At this point it passes WebGL 1.0.2 conformance, and introduces no regressions to the samples or angle_tests. I'm still in the process of cleaning it up-- significantly (I've likely missed some items that still need shuffling)-- but wanted to make it visible early.

Note that shifting to STL types instead of implementation-defined-const-sized arrays for items like sampler textures is not part of this CL; that will come in a follow-on.
|Uploaded patch set 2.
|Patch Set 2:

(Still a WIP, just updated the commit message to be useful, did some tidying of State's header, and did better separation of which detach operations have to be managed in Context versus State.)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Ready for review. As noted above, this CL does not include moving to STL containers instead of implementation-constant-sized arrays.

I took the opportunity to do a couple of cleanup items:
  - reorganized the declaration order for methods on State (formerly methods of Context), so things should be a bit easier to find and more uniform. Within each section, I tried to have a set order-- 1) enablement query, 2) setters before getters, 3) ID manipulators before object manipulators. I'm not dead set on the order if there's a particular reason to use another, just wanted to make it uniform.
  -- renamed the getCap and setCap functions to distinguish them from the newly-added Caps object
|Patch Set 5:

Reposting for readability:

Ready for review. As noted above, this CL does not include moving to STL containers instead of implementation-constant-sized arrays.
I took the opportunity to do a couple of cleanup items:
&gt;reorganized the declaration order for methods on State (formerly methods of Context), so things should be a bit easier to find and more uniform. Within each section, I tried to have a set order: 1) enablement query, 2) setters before getters, 3) ID manipulators before object manipulators. I'm not dead set on the order if there's a particular reason to use another, just wanted to make it uniform.
&gt;renamed the getCap and setCap functions to distinguish them from the newly-added Caps object
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6:

Addressed whitespace and indentation issues (VS 2013 seems to be even more unfriendly to deal with when it comes to our odd switch indentation, argh) and rebased.
|Uploaded patch set 7.
|Patch Set 7:

Rebased.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

Last rebase, I promise. Please give an eyeball to the patch set 7/9 diff-- there were conflicts that needed resolving and I want to make sure I did them right.
|Patch Set 9: Verified+1
|Patch Set 3:

(1 comment)

One comment/request.
|Patch Set 4:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+1

(1 comment)

Basically just +1 to Jamie's comments. I personally prefer the renaming to the comment on the texture cap var names.
|Patch Set 2: Code-Review+1

Ouch. Apologies for not catching that in review.
|Patch Set 1: Code-Review+2
|Patch Set 6:

(2 comments)
|Patch Set 7: Code-Review+2

I'm good with this, but had a thought-- we might want to have an enum or constant defined for use when something really should be unused (like the max element counts), ala 0xdeadbeef, if that doesn't interfere with other checks.
|Patch Set 8: Code-Review+2
|Patch Set 9: Code-Review+2
|Patch Set 6:

(2 comments)
|Patch Set 7: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 6: Code-Review+2

LGTM. Should we update the coding standards doc to make clear the preference for size_t &amp; uint8_t for sizes &amp; bytes of data respectively?
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2

(1 comment)

Minor comment nits.
|Patch Set 7: Code-Review+2
|Patch Set 5: Code-Review+2

(4 comments)

+2ing because all I have is nits and commentary, but would definitely like to hear your input on the commentary.
|Patch Set 6: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 1:

This is a bit of a disappointing move considering the engineering effort that went into unifying the build system so we no longer had to maintain both the MSVC projects and gyp.
|Patch Set 1:

Shouldn't be doing which? We provide MSVC projects in our repository to reduce the barrier of entry for non-Chromium contributors, and the ANGLE team itself develops within MSVS. We are a third party project, and Chromium is not our only user.

Prior to our recent changes to the gyp file, the gyp files were maintained exclusively for the use of Chromium, and we had to remember, when adding new files to the project, to do so in both places. We spent some time unifying our process so that gyp could directly generate the MSVC files, requiring only one set of build files to be maintained. Duplication of the file listing in the gyp and GN files defeats that effort to some degree.
|Patch Set 3:

I understand the purpose of the patch, and yes, it does simplify the task of keeping the two sets of file in sync. My commentary should probably have been made at the time that the GN file was introduced to the repository (and actually I think I did comment to that effect); the addition of the comment about the identical portions of the GN and gyp files is what drew my attention this time.

Please note I'm not -1ing the change, and I realize it's necessary if Chromium is going to continue to build ANGLE given that the build system there is going to change. I just want the tradeoffs within our project to be noted.
|Patch Set 4: Code-Review+2
|Patch Set 4:

(5 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+2

Eh, given that the error type is encapsulated in the error itself, having separate methods on context to set each one of them feels odd, like if there were separate functions for SetTextureWrapRepeat, SetTextureWrapClampToEdge, etc. I like the error construction helpers mentioned, though.
|Patch Set 4:

(1 comment)
|Patch Set 4: Code-Review+2

After online discussion, yeah, I don't think there's a less ugly way to do this...
|Patch Set 4: Code-Review+2
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+1

Looks OK from here. Technically this isn't the API layer, but the state layer-- but index range caching can't go any further up, since it relies on internal state.
|Patch Set 4: Code-Review+1

Re +1ing rebase, pinging Geoff for review.
|Patch Set 6: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

I duplicated the result, status, and type members in the 9 and 11 implementation classes, because I'm not sure it's worth it to create a common base at the D3D level just to unify them, but I can be convinced otherwise.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6:

Does the GL object need to keep a separate copy of the type? I've implemented it here with the GL object just retrieving it from the impl, but can go either way.
|Patch Set 6: Verified+1

(No regressions in WebGL 1.0.3 suite or dEQP occlusion query tests)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7:

Updated with //TODO as discussed offline.
|Patch Set 8: Patch Set 7 was rebased
|Patch Set 8: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

Thanks! I'll open a bug for the EGL_BAD_MATCH issue.
|Patch Set 1: Code-Review+2

I concur with Jamie's nit, but LGTM otherwise.
|Patch Set 2:

(2 comments)
|Patch Set 1: Code-Review+2

Cherrypick to m37 branch approved.
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Default project build has been broken since commit e740addb. In general, if the .gypi changes, please either run generate_projects, or ask a Windows user to regenerate the projects.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Tested with conformance test in question, and also ran it through Maps and Brandon's monkey heads instancing sample. Full WebGL 1.0.3 conformance running now; will retract verified if unexpected regressions occur (but all instancing tests contained in suite pass in isolation.)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)

Will need to be re-LGTMed with whitespace change.
|Patch Set 2: Verified+1
|Patch Set 3: Reverted

This patchset was reverted in change: Ib30c51b2c905e87973c73b06baa4b8ebba31d210
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1

+2ing my own revert to turn the bots green
|Patch Set 1: Code-Review+1

Thank you for catching this, and also for the other recent contributions! I'm working through a bit of a review backlog, but should be getting to those soon.
|Patch Set 1:

ANGLE has a two-reviewer policy, so Geoff will also need to review this change. After that, it needs to be verified/tested, and the &quot;verified&quot; option checked. In general, if you have tested the change using a publicly available method, you can check &quot;verified&quot; yourself, and add a comment describing what tests were used. (Otherwise, we'll pull the change, run it through the ES and WebGL conformance suites, and check verified ourselves. This process should be automated at some point in the future, but is currently not.) After that, one of the project committers can land it in the repository for you.
|Patch Set 1:

Ah-- one other minor thing: Microsoft Open Technologies, Inc. should also get added to AUTHORS.
|Patch Set 1:

You should be able to amend your commit and re-push, and it will appear on this review page as another patch set, as long as you have the commit hook installed in your repository. (It looks like you do-- I believe the Change-Id in the commit message was generated by the hook. That id is how the review system identifies an individual commit and associates it with a review page.)
|Patch Set 1:

It looks as though it made separate commits-- did you use &quot;git commit --amend&quot; to include the new changes in your previous commit? If you do that, and then use &quot;git push origin HEAD:refs/for/master&quot;, it should create a new patch set on this review page, instead of creating a separate review.
|Patch Set 2: Code-Review+1

Looks great, thank you!
|Uploaded patch set 1.
|Patch Set 1:

Posting fix just for ES2 functionality, as this urgently needs fixing before m37 makes it to stable.
|Patch Set 1: Verified+1

Tests regressionless with WebGL 1.0.3 conformance suite.
|Patch Set 1:

http://www.khronos.org/registry/webgl/sdk/tests/conformance/glsl/misc/shaders-with-uniform-structs.html

The last test case uses a nameless struct to specify gl_Position.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1

Confirmed DX9 and DX11 pass WebGL 1.0.3 without regressions, and fix the nameless struct test.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Relanding fix; problems seem before were the result of uninitialized TranslatedAttributes causing false positives in the divisor != 0 check. See follow-on CL for the fix to that issue.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Adding Jamie &amp; Brandon as reviewers-- I'd like to get input from you guys, especially given that Texture is currently in flux for the MANGLE effort.
|Uploaded patch set 1.
|Patch Set 1:

Merge to 2062-- had to be done manually, as the header generation code has been split out into multiple files and functions.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Confirmed that layout qualifiers can't be used in any of the same places as nameless structs in any of the GLSL versions we support. Figured it was worth clarifying comment as to why it's OK to skip qualifier checking for nameless structs. I think they can be used together in desktop GLSL 410 and forward (layout qualifiers are allowed on input variables to all stages at that point), but that's pretty well outside our purview at this point.
|Patch Set 1: Verified+1
|Patch Set 2:

I do think we need to clean up that area of the codebase, whether or not we add compile-to-bytecode.
|Uploaded patch set 1.
|Patch Set 1:

Follows on to Cooper Partin's CL at https://chromium-review.googlesource.com/#/c/211203/

Please double check my reading of EGL 1.4 sec 3.7.3, pg 47: &quot;If ctx is EGL_NO_CONTEXT and draw and read are not EGL_NO_SURFACE, or if draw or read are set to EGL_NO_SURFACE and ctx is not EGL_NO_CONTEXT, then an EGL_BAD_MATCH error will be generated.&quot;

The first clause is potentially ambiguous, in that it could mean &quot;if ctx is NO_CONTEXT, and both draw and read are something other than NO_SURFACE&quot;, or &quot;if ctx is NO_CONTEXT, and draw and read are not both NO_SURFACE&quot;. I think my interpretation (the first one) is required because of the second clause.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 3: Code-Review+2

I'm not crazy about the names of some of the functions, but I think that's a compiler-in-general problem, rather than a this-CL problem.
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 5:

(3 comments)

Just a couple of comment nits
|Patch Set 8: Code-Review+2
|Patch Set 2:

The spec explicitly defines the namespace for shader and program names to be all unsigned integers (ES 2.0.25 spec, sec 2.10.1, pg 27). The application would have access to this name as it's returned from glCreateProgram as a GLuint (sec 2.10.3), so I don't think the logic holds that it's invalid because glGetInteger can't retrieve a uint.
|Patch Set 3:

Which test was it that was expecting these errors? The negative_api.shader.uniform* tests all look like they're passing when I run them, and all the failures in negative_api.shader look unrelated to program IDs.
|Patch Set 3:

These tests look like they're failing because we're not performing the entire prescribed check on the value of &lt;program&gt;. From the ES 2.0.25 spec, sec 2.10.1: &quot;Commands that accept shader or program object names will generate the error INVALID_VALUE if the provided name is not the name of either a shader or program object and INVALID_OPERATION if the provided name identifies an object that is not the expected type.&quot; This appears to be a longstanding oversight. We should correct it. For an example of the appropriate check, please see, e.g., glAttachShader.
|Abandoned

Abandoning; issue fixed in https://chromium-review.googlesource.com/#/c/228560/
|Patch Set 3: Code-Review+2

The conditions in link() would be true any time the application attempted to link a program without shaders attached or with shaders attached which haven't been compiled. That shouldn't result in a validation error-- it's just a failed link, so the graceful check-and-return-false is correct in those cases.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 6: Code-Review+2

(1 comment)

LGTM if issues mentioned are handled in a separate CL.
|Patch Set 6: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 7: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Abandoned

Didn't intend to upload.
|Patch Set 1:

Also, if it's feasible at this point, it might be a good idea to break this commit up into smaller chunks-- perhaps separate changes each for creating a static libGLESv2 build target/associated build system changes, adding implementation unit tests, and the actual refactor. Gerrit is able to track interdependent changes, so it's not necessary to squash large sets of changes into one for review, and making changes incrementally will both make it easier for reviewers to see the process and review the code, and allow any potential regressions discovered later to be isolated to smaller chunks of changes. (This is the main reason ANGLE is maintained in git and gerrit instead of svn and rietveld.)
|Patch Set 2:

(1 comment)

Will +2 this once the minor item Geoff mentioned is addressed, &amp; it's rebased and thoroughly run through the tests again. Anyone want to take care of tests &amp;c on this one? Would be good not to let it sit too long, as ProgramBinary changes will probably make rebase more painful as time goes on.
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 7:

(2 comments)
|Patch Set 10: Code-Review+2
|Patch Set 1:

One nit: you should add yourself to the Intel section of the CONTRIBUTORS file.
|Uploaded patch set 1.
|Patch Set 1:

@Jamie -- correct; the trace system is the only other thing to use it so far, and strings were being implicitly constructed from const char *s via trace() and output() there. I think this reduces the overall number of copies/c_str()/string constructor calls.
|Patch Set 6:

(2 comments)
|Patch Set 6:

(2 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 10: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 7:

(1 comment)
|Patch Set 10: Code-Review+2
|Patch Set 8: Code-Review+2

(1 comment)

I'm good either way on Jamie's nit.
|Patch Set 8:

(1 comment)
|Patch Set 10: Code-Review+2
|Patch Set 11: Code-Review+2
|Patch Set 8:

(6 comments)
|Patch Set 10: Code-Review+2

Ideally the release responsibility change would go in before this, but I can deal with it as long as that CL isn't much delayed.
|Patch Set 11: Code-Review+2
|Patch Set 8: Code-Review+1
|Patch Set 9:

(1 comment)

One nit, LG otherwise.
|Patch Set 12: Code-Review+2

Good rearranging.
|Patch Set 9: Code-Review+1
|Patch Set 2: Code-Review+2

(1 comment)

One very nitty nit
|Patch Set 3: Code-Review+2
|Patch Set 2:

(2 comments)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 5: Code-Review+2

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)

LG with one comment request
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 6: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 8: Code-Review+2
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+2

LGTM, as long as those are spaces and not tabs
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

We don't have a CQ in place (yet). If this has been tested, please mark it Verified+1, and a committer can manually commit the CL for you.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2

Going to go ahead and +2 this, as it's a trivial fix to a pretty awful oversight.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 6:

(3 comments)
|Patch Set 8: Code-Review+1

The commented-out param is exceedingly gross. Is that getting refactored away eventually? If we don't already have plans to do that, we should. +1 in any case.
|Patch Set 6:

This is a fairly minor amount of work to defer until first draw, and it only gets done once, but couldn't we still keep it out of the draw overhead entirely by having a Blit9::initialize() function called from the renderer's init function?
|Patch Set 7: Code-Review+2

That works for me. The EGL bootstrapping code does have an error return of its own, so the error could be detected at init, but I don't think it matters that much.
|Patch Set 7: Code-Review+1

Erps, I'm first reviewer this time.
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

NB: This CL is meant to stick the stuff needed solely for dEQP testing purposes behind include guards, but I do not have dEQP on my current system to test with, and won't be able to +1 Verified this until Monday.
|Patch Set 1: Verified+1
|Patch Set 1:

Finally verified. Note that to turn on all of these defines at once, if you're doing so by editing the code directly, it's necessary to #define ANGLE_TEST_CONFIG in debug.h, so that the define propagates to both test projects. We could also add test configs to make this simpler.
|Patch Set 1:

LG here, too. Feel free to land when it's approved for merge.
|Patch Set 2:

(5 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)

I like the renamings a lot! Much clearer. Just a couple more questions...
|Patch Set 3:

(1 comment)
|Patch Set 4:

(3 comments)

I like this approach, it's definitely cleaner code. Thank you! Just nits left from me now.
|Patch Set 4:

(1 comment)
|Patch Set 6: Code-Review+1

This style works for me, as the getResult() call still clears the errors. Very nittily, I might call it getError(), because it's mirroring the GL's paradigm of clearing errors on a get call (and get calls otherwise might be assumed not to have side effects).
|Patch Set 7: Code-Review+1
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 1: Code-Review+2

Could we stick a comment somewhere to remind the reader that the DX D24etc formats are FP? I always forget, anyway.
|Patch Set 2: -Code-Review

Sorry, was mixing it up with D24FS8.

So why do we want to expose DEPTH_COMPONENT32_OES if we can't represent all the possible values in the range of that type?
|Patch Set 2:

I think this is mostly a matter of a confusing interaction between versions of the spec.

The OES_depth_texture spec does explicitly say &quot;As per the OpenGL ES spec, there is no guarantee that the OpenGL ES implementation will use the &lt;type&gt; to determine how to store the depth texture internally. It may choose to downsample the 32-bit depth values to 16-bit or even 24-bit.&quot; 

ANGLE_depth_texture doesn't carry this text over, but it could be considered implied by the ES 2.0 specification text-- there are no sized internal formats, and component resolutions are not discussed other that to say that the GL may use resolutions of its own choosing.

The ES 3.0 specification, on the other hand *does* have minimum required component resolutions (such as in table 3.14 of the 3.0.4 spec). These don't cover DEPTH_COMPONENT32_OES, because the 3.0 spec defines only a 32F format, but I don't think the implication that we can downsample is necessarily present in that version of ES, so we should definitely not expose ANGLE_depth_texture or OES_depth_texture in ES3, and we should document in the code why this is allowable against ES 2.0 and only ES 2.0.
|Patch Set 2:

Additionally-- do we have a way to prescribe fallback formats? Shouldn't we try to use D32 if it's available, and fall back to D24S8 only if not?
|Patch Set 2:

After checking the last cardcaps.pdf I can find that was issued... yeah, I think we're safe passing on D32. Heh. Please do plaster this thing with comments about why we're justified in downsampling, though.
|Patch Set 2:

Additionally-additionally-- heyyyyyy, this seems like a good opportunity for a unit test...
|Patch Set 3:

Sorry to keep picking, but the comment could really use some citation, because it's not explicitly laid out in the core spec. Could you reference ES 2.0.25 sec 3.7.1 in the spec (&quot;internal component resolutions of its own choosing&quot;), mention that OES_depth_texture explicitly states that this allows for downsampling (though we don't pull in OES_depth_texture from there), and that ANGLE_depth_texture does not add minimum required resolutions, as ES3 does. What I'm trying to avoid here is anyone in the future looking at it and going either a) &quot;Wait, why are we backing a 32 bit texture with a 24 bit format? That seems wrong.&quot; or b) &quot;Oh, we back a 32 bit depth format with 24 bits in ES2. We can just do that in &lt;whatever future version of ES or GL&gt; to avoid dealing with &lt;whatever format we don't have a corresponding DX format for&gt;.
|Patch Set 5: Code-Review+2

LG, thanks for the amendments.

On the subject of other formats we allow to be renderable-- I don't recall in the case of BGRA, but for floating point textures, we definitely allow rendering to them without that capability being explicitly added by extension. WebGL relies on this capability, though, so it's one we decided not to walk back some time ago. This should get addressed correctly with EXT_color_buffer_float and EXT_color_buffer_half_float in ES 3.
|Patch Set 6:

WebGL's requirements for FP renderability:
- Floating point textures are added via OES_texture_float; historically this included optional support for FP textures as FBO attachments, but this feature is now considered to be added by WEBGL_color_buffer_float, implicitly or explicitly
- WEBGL_color_buffer_float specifies that renderbuffers can be created in the RGB32F and RGBA32F formats. This... seems especially confusing, because EXT_color_buffer_float specifies that RGB32F is a texture-only format. Also, WEBGL_color_buffer_float specifies that it's written against EXT_color_buffer_half_float, which is almost certainly in error, as WEBGL_color_buffer_float concerns 32 bit formats, not 16 bit, as are specified by EXT_color_buffer_half_float.
|Patch Set 6:

Added kbr@ as an FYI, in case the oddities in WEBGL_color_buffer_float were unknown.

In any case, we should not drop any current FP renderbuffer support without first verifying with Chrome/WebGL folks that they're not relying on it.
|Patch Set 6:

Ah, I see; thanks for the clarification-- I'd missed the 32bit/16bit swap at the bottom of the extension spec. What an odd extension.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2:

Administrative note: this should be gated from landing until chromium merge approval.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 7:

(1 comment)
|Patch Set 10: Code-Review+2

+2 conditional on stuff mentioned in above comment.
|Patch Set 11: Code-Review+2

That jives with my memories of the code going in. Thanks for tracking that down!
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 3:

(2 comments)
|Uploaded patch set 6.
|Patch Set 5:

(2 comments)
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 8: Patch Set 7 was rebased
|Patch Set 8: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Verified+1
|Patch Set 4:

(4 comments)

These questions might all be moot/to-be-handled-in-a-later-patch. Apologies if that's the case.
|Patch Set 7: Code-Review+2

I'm ok with this as an intermediate step, but if there are further changes incoming, that's fine as well.
|Patch Set 6: Code-Review+2
|Patch Set 2:

(14 comments)

This looks like a simple, clear abstraction. Thank you! Most of my comments are just style issues.

The one overarching comment I have is-- I'm not sure that common/ and common/win32/ are the right home for these. We're in the process of refactoring ANGLE to add non-D3D rendering backends as well, so the EGL internals are going to have the d3disms factored out and segmented off into Windows-specific directories, and I think that the desktop/Windows Store distinction can probably be handled analogously. Geoff, I'd like to get you to weigh in on what would make sense here, since you've been planning the EGL refactoring work.
|Patch Set 3:

About the Verified flag-- that's an indication that you have tested it to your satisfaction, so it's helpful to us if you comment with what tests you used to verify. For new functionality, it would be good to add unit or feature tests to the sets in tests/ -- this isn't a requirement at the moment, but may become one in the near future.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2

merge to ANGLE branch approved
|Patch Set 2:

(Though this looks as though it's applied against master.)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

Discussed this with Geoff ahead of the implementation-- I've opted to store the minimum information required by State. Ideally, we'll eventually remove any dependence after initialization on Caps values.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3:

I'm aware of the Program object's statically sized array; this patch series is solely for the State object. Other objects will be attended to in a forthcoming patch set.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review-1

Intermediate patch set. Do not review.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 3:

(4 comments)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(2 comments)
|Uploaded patch set 10.
|Patch Set 9:

(1 comment)
|Uploaded patch set 11.
|Patch Set 11: Verified+1
|Patch Set 12: Patch Set 11 was rebased
|Patch Set 12: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Patch Set 11: Verified+1
|Patch Set 2: Code-Review+1
|Patch Set 7:

Making sure this thread is up-to-date, Vangelis advised that Tibor should submit changes as a corporation. (Also, though it's a moot point, English alphabetizes prefixed last names by prefix, so &quot;den Ouden&quot; would go in the Ds, &quot;O'Hara&quot; in the Os, &quot;d'Artagnan&quot; in the Ds, &quot;von Trapp&quot; in the Vs, etc.)
|Patch Set 2:

(1 comment)
|Patch Set 2:

To the question about testing-- ANGLE's testing approach is still being built, and is so far only automated at the point of integration with Chromium. The tests/angle_implementation_unit_tests directory contains the beginnings of the unit test framework, and the tests/angle_tests directory contains a set of feature-by-feature tests. The intention is that these will become part of automated continuous testing for ANGLE. (jmadill@ might have more detail on that; I will add him as a reviewer.)

For manual regression testing, building Chrome with ANGLE and running it through the WebGL conformance suite is recommended. The ES2 conformance suite is also useful if you have access, but it takes a bit of work to get it working with ANGLE.
|Patch Set 5:

Added a link to the CodeReviewProcess wiki page from the ContributingCode page.
|Patch Set 1:

Hi Prabindh -- have you (or your employer, if you're contributing on their behalf) signed the CLA?
|Patch Set 1:

Thank you! You'll also need to add yourself to the AUTHORS and CONTRIBUTORS files.
|Abandoned

We never got the details straightened out on these changes, and they would need to be reworked to apply post-MANGLE in any case.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

Good by me. On struct member/function declaration order-- we keep going back and forth on these, and I thought we'd talked about declaring a required order in our coding standard, but don't have that recorded anywhere.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

This solution works for me.
|Patch Set 1:

I'm slightly hesitant to use more EGL-wide enumerants from our currently limited allocation for features with a testing-only use case-- especially for feature level 9_3, which may not be capable of providing a fully conformant implementation. Do you anticipate this being needed in production for any reason?
|Patch Set 1:

Adding Geoff, since he's one of the authors for the ANGLE platform extension.

The GL paradigm for extensions is generally to develop to the core specification, and provide additional paths which rely on extensions, which can be taken at runtime if the extension is detected to be present-- the hardware provides the feature set, rather than the application dictating a specific feature set. I don't think that the platform extension was really meant to subvert the GL extension model in this way.

If the use case is solely for developers to be able to test and develop on less capable hardware, shouldn't the responsibility lie with the hardware emulator to present an artificially limited capability set/feature level to the software running on top of it?
|Patch Set 1:

I would also support compile-time limitation of feature level, FWIW.
|Patch Set 1:

&gt;&gt; Would EGL_PLATFORM_ANGLE_VERSION_MAJOR/MINOR be added to EGL_ANGLE_platform_angle?

Yep. The GL extension paradigm allows for revision of extensions by adding issues to the bottom of the extension spec, raising the question why the revision need to be made, and describing the result.

&gt;&gt; Would we remove EGL_PLATFORM_ANGLE_TYPE_D3D11_WARP_ANGLE? How does the ANGLE project treat breaking changes like this?

I've actually been holding off on submitting the extension for listing in the EGL registry, since there were still questions like this open on it, so it's technically still in draft and not a shipping extension. The only user (to my knowledge) of the Warp enum is Chromium, and as long as the relevant folks there are OK with it, it can be changed there to conform to the revised extension spec. I suspect it should be fine, as it's just a syntactic change. I'll cc luken@, who did the Warp enablement, to keep him in the loop.
|Patch Set 1:

luken@: For FYI purposes, we're considering a syntactic change to EGL_ANGLE_platform_angle. It'd mean a slight change for how Chromium requests a Warp backend, but no functional difference.
|Patch Set 3:

Is this abandonable at this point?
|Patch Set 1:

Added kbr@ because I think this is relevant to his interests.

Jacek, have you signed the CLA? Are you contributing this CL on your own behalf or on behalf of Mozilla?
|Patch Set 1:

Ah-- please ignore the previous question, I see you have. Please do add yourself to the AUTHORS and CONTRIBUTORS files, however.
|Patch Set 2: Verified+1
|Patch Set 2:

Verified build via ninja &amp; MSVS pregenerated projects; going to assume you've verified it with mingw/gcc.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Verified+1
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2

Great, thank you!
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

Nicolas, do you remember whether the device loss check in Renderer9::sync is purposefully only done for blocking calls?
|Patch Set 3: Code-Review+1

Ok. That looks to preserve the behavior, to me. This has a small amount of code duplication versus the prior structure, but I personally don't mind it, because I think this is slightly clearer. That said, I don't think we actually *have* to change the structure from the original-- Error object generation should be possible without changing that, unless I'm missing something-- so I'm willing to yield to other opinion on that point if there's strong objection.
|Patch Set 2: Code-Review+2
|Patch Set 3:

For the validation question-- it does seem like it's something that should be factored upwards, just retrieving the information needed to perform the validation from the backing implementation if not everything is available at the GL level.

Is it possible that we may end up leaving some part of link validation to the native linker on GL-backed renderers? I think even if it's the case we probably need to be *able* to perform the validation regardless of the renderer, so I'd say move it upwards...
|Patch Set 6:

(1 comment)

Adding Geoff as reviewer momentarily partly because Jamie's OoO currently, and partly because he's probably got useful input on the question of what lives on the Impl and whether we want to maintain the plumbing between objects and their impls.
|Patch Set 6:

Oh, wait, he's already here. Carry on then!
|Patch Set 6:

Forgot to mention previously-- I think the default projects need regenerating as well, as there are changes to .gypi.
|Patch Set 6:

Have you done a gclient sync recently? The gyp version was recently updated.
|Patch Set 1:

It looks like you've added yourself as a corporate contributor, but signed the individual CLA. To contribute on behalf of TI, you'll need to get yourself added to TI's roster of contributors-- we can only accept changes from the people they've designated as contributors.
|Abandoned

We never got the details straightened out on these changes, and they would need to be reworked to apply post-MANGLE in any case.
|Patch Set 1:

You still should go in CONTRIBUTORS, actually, but as yourself, rather than your company.
|Patch Set 2: Code-Review+2 Verified+1

It looks like some of the previous individual contributors did not add in both places, yes. There's a blurb at the head of CONTRIBUTORS which explains the purpose of the two files (AUTHORS is the more important one to remember to add one's self to), but we should probably also add this to the wiki.

Thanks for the edits!
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+2 Verified+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Verified+1

Corrected merge issue, landing.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

Already talked offline, but so that I remember that we did-- fixed typo in coding standard, and we don't return references to items within member containers (I'd argue that's probably a bad idea), but we do return non-const references to member containers rather than implementing indexed setters; I've clarified that in the wiki as well.
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 4:

(1 comment)
|Patch Set 4:

(Sorry to have added this reply after you've already made changes-- it took me some time to check back through all the specs and originating extensions for the UBO interfaces.)
|Patch Set 5:

Ah, understood. That works for me, then!
|Patch Set 5: Code-Review+2

No additional feedback from me.
|Patch Set 11: Code-Review+2
|Patch Set 9: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Agreed with Geoff, would prefer to use the existing calling convention macros.
|Patch Set 4: Code-Review+2
|Patch Set 1:

For the most part I think this CL should just be used as the treasure map for where the remaining unrefactored parts of ANGLE are. It looks like we're doing fairly well-- there are a few places we knew about (EGL-related window and surface bits, program binary, framebuffer), and a few hanging threads we hadn't planned for (TLS stuff, endian-specific image loaders). Let's make sure we prioritize all of these items above other MANGLE work.
|Patch Set 1:

Have we taken care of all the points uncovered in this CL? If so, it can be abandoned.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)

An incomplete review, but I wanted to get comments back to you as I made them, rather than making you wait until I'd had time to review the entire thing.
|Patch Set 11: Reverted

This patchset was reverted in change: Ica2abd2e557a4fd9852d85b7fc018e3d272b6edf
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 7: Code-Review+1

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 9:

Style guide and review process docs have been updated to reflect today's consensus motion not to require standing style issues to be fixed in bugfix CLs. (I would +2 this CL in light of that, but I was the +1, so someone else must.)

Good call on expanding the error text search. Ty.
|Patch Set 10: Code-Review+2
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

I originally intended to try to eliminate all uses of GetAttachmentRenderTarget, but I don't think that would actually result in cleaner code in the cases of Renderer::blitRect and Image::copy. Invalidate, on the other hand, is being invoked directly on the underlying rendertarget, so that made sense to me to plumb through in any case-- but if people feel otherwise, I could be persuaded.
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 1:

Going to land this since it's a bugfix, it's already +1 verified, and Jamie's OoO currently
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1

WIP, still requires editorial pass.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Ready for review.
|Uploaded patch set 4.
|Patch Set 3:

(8 comments)

Some questions; will implement the fixes for those once I know where it's going...
|Uploaded patch set 5.
|Patch Set 3:

(2 comments)
|Patch Set 5: Verified+1
|Uploaded patch set 6.
|Patch Set 6: Verified+1

And that could apparently have been pushed at least a week ago. All testing failures I'd been seeing were flake.
|Uploaded patch set 7.
|Patch Set 6:

(2 comments)
|Patch Set 7: Verified+1
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Patch Set 9:

Blarg. Didn't refresh before submitting-- will catch those in the Framebuffer refactor.
|Patch Set 9: Reverted

This patchset was reverted in change: I4134ebe5ef6b8f509f4cc5cc22a2d526ec43ef6d
|Patch Set 1:

(11 comments)

Friendclassing isn't my favorite thing in the world, but after looking at the prior implementation, I think I agree that it's the cleaner way to go.
|Patch Set 5: Code-Review+2

(2 comments)
|Patch Set 7:

We generally try to get the reviewers to re-+2 after failed rebases, just because otherwise the commit message makes it look like you approved your own change, which might lead to grouchiness on the occasions when chrome bugs get bisected to an ANGLE revision. (I know that the author/committer difference from the old TG-generated commits has caused confusion before.) It's definitely welcome to poke the reviewers for an immediate re-plustwo.
|Patch Set 2: Code-Review+1
|Patch Set 7:

(6 comments)
|Patch Set 8:

(2 comments)
|Patch Set 9: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 4: Verified+1
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5: Verified+1
|Patch Set 3:

This looks good to me, but I'm having trouble verifying the ninja build, which may be unrelated. I'm continuing to investigate what's causing intermittent errors for me, but if someone else is able to verify that this CL can build and run successfully via both MSVC and ninja, please feel free to +2 it.
|Patch Set 3: Code-Review+2
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Verified+1
|Patch Set 1:

Passes angle tests and WebGL 1.0.3 conformance.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Cherry pick to m38 branch.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2

LGTM, with bug tag fixed.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Clean cherry-pick from chromium/2125
|Patch Set 1: Verified+1
|Patch Set 6:

Nicolas, can I defer plustwo to you on this one?
|Patch Set 7:

(16 comments)

A few high-level questions:
- The native window classes live entirely outside of a namespace. Why?
- I'm very wary of shared_ptr and enable_shared_from_this as far as Chromium's allowed C++ feature list goes.
|Patch Set 9:

(2 comments)

Great, thank you for all that cleanup!

A couple other questions:
- IInspectableNativeWindow retains the 'I' prefix from the motivating interface, but SwapChainPanelNativeWindow doesn't. Any reason? If not, can we drop the 'I' for IInspectibleNativeWindow as well? It seems kind of odd to be intermingling I-for-interface and Impl-for-implementation class name decoration within the ANGLE codebase.
- There are a bunch of global functions floating outside namespaces. We've generally tried to avoid this, either by putting them into the namespace for the values they handle, or using a utility namespace. Would these global functions work inside one of the already present namespaces?
|Patch Set 11:

(2 comments)

Just a couple of last minor requests. Apologies for all the back-and-forth on style in already-landed code, just trying to make sure everything's tidy.
|Patch Set 12: Code-Review+2

Thanks for addressing all that! LGTM.
|Patch Set 2: Code-Review+2

Ditto the testing recommendation
|Patch Set 1: Code-Review+2
|Patch Set 3:

(7 comments)
|Patch Set 7:

(6 comments)
|Patch Set 7:

(2 comments)
|Patch Set 9: Code-Review+2

(1 comment)

One very minor text nit in the extensions. Looks good to me otherwise. I'm comfortable with +2ing this, since it's been gone over fairly thoroughly, but if you'd prefer to get an additional +2 from another project member, that's fine too.
|Patch Set 10: Code-Review+2
|Patch Set 4: Code-Review+2

This is a good way to go about this-- it moves D3D assumptions out of EGL at the same time as allowing nonconformant configs to be flagged. Thanks!
|Patch Set 4:

Ping-- these patches still need to be +1 Verified
|Uploaded patch set 5.
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 6: Code-Review+2 Verified+1

Performed manual rebase, re-verified (angle_tests, WebGL CTS D3D9 &amp; D3D11).
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

1) Determine whether there are other tests which are also subject to rounding error.
2) Identify the difference between tests which do and do not require fuzzy matches, so that we can reliably require new tests to use the correct match logic.
3) Determine what fuzz range is appropriate to apply vs. overly lenient, define a constant that identifies that range, and use it in the expect-near tests instead of numeric literals, so that we're being consistent across our test set.
|Patch Set 2: Code-Review+2

Awesome, ty!
|Patch Set 3: Code-Review-2

(2 comments)

This is a change we'd potentially be interested in supporting, but communication with project members about its implementation would be highly recommended.

If this is to be supported via a new extension-- which may not be necessary-- the specifications need to be considered and written, first and foremost.
|Patch Set 5:

(3 comments)

This looks like a much better approach; thank you. One thing that still needs to be addressed is advertising the extension. The extension should only be advertised when the shared resource type flag is set for keyed mutex (I might suggest having a single ENABLE macro that both sets the resource type macro and compiles in the addition of the extension string), and D3D11 is in use.
|Patch Set 6: Code-Review+1

(2 comments)

This looks good, thank you. Adding another reviewer, for ANGLE's two-reviewer policy.
|Patch Set 7:

Adding Jamie as well so that this doesn't slip off the radar. Would like Geoff to at least glance at it though, since he's recently dealt with extension semantics.
|Patch Set 9:

Thanks for the update. Please keep us in the loop-- Chrome won't be using this extension initially, so it won't get the benefit of all the associated testing infrastructure on our side, which makes it especially important for you guys to be confident in it. (For ease of communication, you could mark this as Code Review -1 until you're comfortable with us landing it, and remove the -1 when you are.)
|Patch Set 9:

Hey Jeff-- is this likely to get further attention?
|Patch Set 9:

No worries-- thanks for the update; I'll keep it open.
|Patch Set 10:

(1 comment)
|Patch Set 1: Code-Review+2

LGTM!
|Patch Set 1: Code-Review+1

Yeah, it doesn't trip any compilation issues for me, either. It still achieves the purpose of avoiding accidental ifdef-when-we-mean-if-nonzero cases, so I'm cool with it, but I'mma just +1 it so Geoff can weigh in, in case he had something more on this strategy.
|Patch Set 1:

Causing D3D9 breakage.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Verified+1

Rebasing failed revert, +2ing to stop tree redness.
|Patch Set 1: Code-Review+1

Looks sensible to me. To your question from email-- I'm not sure what our enum allocation for the shader/compiler API is, but if we're not constrained, is there any reason to reuse the discarded values? It probably won't cause a problem since the values are part of a separate enum, but using fresh ones seems like the safest thing to do.
|Patch Set 1:

I meant to add to that that Jamie likely has more valuable input than me on the enum value subject, so I'd wait for him to weigh in either way.
|Patch Set 1:

I don't see any comments on that review from Daniel about enum values, but yes-- these values aren't exposed via GL, so I'm not sure I see the pressure to recycle. That said I don't think there's harm in it.
|Patch Set 1:

Ah, that rationale makes sense. TY!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

D3D9 test failures in the prior version of this CL were due to improper tracking of render target serials-- they were issued per-RenderbufferD3D, but with the changes to set storage repeatedly on a single renderbuffer, rather than create a new one each time the storage was changed, they need to be issued per-rendertarget instead.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1
|Patch Set 3:

Verified with 
angle_tests on Intel GPU
WebGL 1.0.3 Conformance tests, DX9 and DX11, on Intel &amp; Nvidia GPUs
(no regressions)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 6:

(4 comments)

My other comment here would be-- is the validation to prevent integer formats being used with samples &gt; 0 being done in both the ES2 and ES3 cases? ANGLE_framebuffer_multisample does not specify this error (as integer formats don't exist in ES2 without EXT_texture_integer), so it should only be applied in ES3. The implemented fix is still needed for the ES3 case, but it shouldn't come up at all in ES2.
|Patch Set 7:

Can this also get a fix for the integer-format-check-should-be-ES3-only issue mentioned in my overall comment for the prior patchset?
|Patch Set 8:

The issue is that the extension does not specify the constraint-- we're applying it out-of-spec.

I'd argue that we shouldn't be checking to see if the extension was called, and only applying the ES3-specific logic there, but instead separating the ES3 logic into an ES3-specific (not extension-negative) version of the call.

That said, EXT_texture_integer is at current a desktop-only extension (and will likely remain that way, as the functionality is present in ES3), so there should indeed be no way to trigger the check in ES2. If Geoff and Jamie think we should keep the out-of-spec enforcement, then I'll drop the objection, but still request a comment be added that the enforcement is technically not specified.
|Patch Set 10:

(3 comments)
|Patch Set 14:

(2 comments)
|Patch Set 15:

(2 comments)
|Patch Set 17: Code-Review+2

LGTM, thank you!
|Patch Set 18: Patch Set 17 was rebased
|Patch Set 18: Code-Review+2 Verified+1

Verified: angle_tests, WebGL CTS D3D9 &amp; D3D11.
|Patch Set 2:

I'm very wary of the proliferation of #ifdef'ed-in and #ifdef'ed-out code in Renderer. Is there a cleaner way to do this? Could there be a Windows-Store-specific renderer, maybe as a child class of Renderer11, so as to be able to reuse most of the implementation, but add platform-specific capabilities and restrictions as appropriate, without desktop Renderer11 needing to be aware of it?
|Patch Set 4: Code-Review+2
|Patch Set 6:

(4 comments)

Just nits, one of which isn't necessary actionable.
|Patch Set 7: Code-Review+2
|Patch Set 2: Code-Review+1

Looks fine to me-- adding Jamie &amp; Geoff for plustwoage.
|Patch Set 1:

Geoff's already rebased the other one and landed, so this will need to be rebased once again. To make sure it updates this change instead of adding a new one, make sure you have the commit hook installed: https://code.google.com/p/angleproject/wiki/ContributingCode (&quot;Getting Started with Gerrit for ANGLE&quot;, step 6)
|Patch Set 2: Code-Review+2 Verified+1

Bypassing +1 for trivial change.
|Patch Set 2:

I think this will require the default projects to be regenerated with ./generate_project.py (IIRC, that script only works properly on Windows, though).
|Patch Set 2:

(+1 from me otherwise; if you don't have easy access to Windows for regenerating the script, let me know and I can generate it.)
|Patch Set 10: Code-Review+2

I like this-- it simplifies things in several places.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

This should address the bug mentioned in https://chromium-review.googlesource.com/#/c/213814/

Verified that this does address the issue seen in dEQP (although the tests in question still fail for other reasons, after this fix).
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1

Verified no regressions:
WebGL 1.0.3 CTS, DX9 &amp; DX11, debug build, vs. DEPS DLLs
angle_tests, debug build, vs. ToT
|Patch Set 3: Verified-1

This appears to provoke failures in the following WebGL CTS tests:
conformance/canvas/buffer-offscreen-test.html: 2 tests failed
conformance/canvas/buffer-preserve-test.html: 1 tests failed
conformance/canvas/to-data-url-test.html: 45 tests failed
conformance/rendering/gl-scissor-test.html: 32 tests failed
conformance/rendering/gl-scissor-fbo-test.html: 8 tests failed
conformance/rendering/gl-scissor-canvas-dimensions.html: 1 tests failed
|Patch Set 3:

I ran the tests again; here's what the results look like for me:

A direct pull of this CL has the following novel failures:
conformance/glsl/bugs/array-of-struct-with-int-first-position.html: 3 tests failed
conformance/glsl/constructors/glsl-construct-mat2.html: 2 tests failed
conformance/glsl/constructors/glsl-construct-mat3.html: 2 tests failed
conformance/glsl/constructors/glsl-construct-mat4.html: 2 tests failed
conformance/glsl/misc/shaders-with-invariance.html: 5 tests failed
conformance/glsl/samplers/glsl-function-texture2dprojlod.html: 48 tests failed
conformance/glsl/variables/gl-fragdata-and-fragcolor.html: 1 tests failed

Rebasing this CL onto ToT (which rebases cleanly):
conformance/canvas/buffer-offscreen-test.html: 2 tests failed
conformance/canvas/buffer-preserve-test.html: 1 tests failed
conformance/canvas/to-data-url-test.html: 45 tests failed
conformance/rendering/gl-scissor-test.html: 32 tests failed
conformance/rendering/gl-scissor-fbo-test.html: 8 tests failed
conformance/rendering/gl-scissor-canvas-dimensions.html: 1 tests failed

ToT doesn't provoke any unexpected failures.
My setup is: Windows 7, NV Quadro 600, 341.05 driver, WDDM 1.1
|Patch Set 3:

(Jamie or Geoff-- can you replicate the failures?)
|Patch Set 7: Reverted

This patchset was reverted in change: Ie1806db36b13f8b03dc1a1ae10f237260c99de7b
|Patch Set 7:

Had to revert-- the same test failures were seen on the build waterfall as I'd seen above. It would be good to figure out what the key difference between the systems seeing the problem and those not. AFAIK, Geoff and Jamie and I at least should all have the same set of platform updates &amp; service packs applied.
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+1

I have a very vague worry about exposing Display from Renderer, but no quantifiable issues.
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+1

Oops, jumped ze gun
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 4: Code-Review+1
|Patch Set 1:

jam@ - are these two CLs intended for review?
|Patch Set 1: Code-Review+1

NB: This will affect the change that scottmg@ is processing to update our SDK/compiler dependency. It may be wise to delay landing until after that one relands (or at least coordinate with scottmg@ on landing order).

Adding second reviewer.
|Patch Set 1: Code-Review+2
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)

This is kind of cherry-on-top thing, but what would you think of writing a very brief comment block at the beginning of each test describing the test procedure? (For new tests; we don't necessarily have to go back through for all the ones already in the repo.) It might make the &quot;is this testing what I think it's testing&quot; question a little easier. The downside is that, like all block comments, we'd need to remember to update them if we update the test.
|Patch Set 2: Code-Review+2
|Patch Set 1:

I think moving to the Win8.1 SDK should be fine, as we already require VS2013, which includes it.
|Patch Set 3:

As a heads up, most of the folks with +2 permissions on ANGLE are in ET-- if you need anything +2ed or reverted in this codebase this evening, you'll probably want to either ping me via chat (I tend to have my phone on me until late), or try kbr@ or zmo@.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Agreed that automated maintenance for this file would be an improvement, but would prefer not to hold up publishing formalized testing requirements on the implementation thereof.

Changed to direct copypasta, PTAL.
|Patch Set 2: Verified+1
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1
|Patch Set 3:

Adding reviewers/potentially interested compiler folks.
|Patch Set 2:

Jamie: Can you do plustwo review on this one?
|Patch Set 1: Code-Review+2

Please add a line to the commit message mentioning the removal of the TSymbol copy constructor, if that's being done in this same CL.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

This patch is applied against a version of the ANGLE tree that's over a week old. validationES2.cpp has moved to another directory entirely. Please resubmit this patch against the current master branch.

I was just the committer, not the author, on the CL you reference-- I'll add the patch's actual author as a reviewer.

One thing to be aware of is that the BGRA-to-RGBA copy support in ANGLE is a hacky workaround we added at the time because, IIRC, Chrome was still using D3D9 backbuffer surfaces, which are BGRA-only, while the D3D11 version of ANGLE uses RGBA textures directly, rather than backing RGBA textures silently with BGRA, which we had to do in D3D9. The behavior (allowing copies from BGRA to RGBA) is out of spec, which is likely why we added only the necessary footprint to allow Chrome to make copies from the backbuffer. Ideally, Chrome should stop using BGRA/D3D9 backbuffer surfaces at some point; D3D11 has been available for some time now.
|Patch Set 2:

As mentioned before, I think this may not be the right way to go around this, as the already-present ability to copy from a BGRA is out-of-spec. Rather than drive Chromium &amp; ANGLE further out of spec, is there a way that this can be done in-spec (i.e., a way that does not add a CopyTexSubImage call from a BGRA backbuffer to an RGBA texture)? 

kbr@ -- I think you had some interest in this CL as well?
|Patch Set 2:

For clarification, the language in the spec that disallows this behavior is the disallowance of conversion by CopyTexSubImage itself, regardless of whether BGRA is allowed as a backbuffer format.

The TexSubImage and CopyTexSubImage joint definition language says: &quot;The same constraints and errors apply to the TexSubImage commands’ argument format and the internalformat of the texture
array being respecified as apply to the format and internalformat arguments of its TexImage counterparts.&quot;

The referenced TexImage language says: &quot;...internalformat, which must match format; no conversions between formats are supported during texture image processing&quot;

CopyTexImage allows channels to be dropped, but doesn't say anything about ordering, and the BGRA texture extensions add BGRA formats as targets only for TexImage/TexSubImage, so I don't think the prohibition is technically relaxed even for that command. (And this would not apply to CopyTexSubImage even if it were, since that command explicitly inherits the no-conversion restriction from TexImage.)
|Patch Set 2:

Actually, let me correct that-- CopyTexSubImage may inherit its restrictions from CopyTexImage (the &quot;counterpart&quot; language is distressingly unclear, and it doesn't make sense that CopyTexImage could drop channels but CopyTexSubImage could not), but this still doesn't provide allowance for CopyTex(Sub)Image to convert formats in any way aside from dropping channels, IMO.
|Patch Set 1:

Unfortunately, the extensions that add BGRA support add it as a valid parameter for Tex(Sub)Image (EXT_texture_format_BGRA8888), and for ReadPixels (EXT_read_format_bgra), but not for CopyTex(Sub)Image. There's no support for copying from a BGRA buffer to a BGRA texture in any current extension, to my knowledge. I think Chromium has run into this issue before: https://chromiumcodereview.appspot.com/9968113/
|Patch Set 1:

I'm going to be away from the machine on which I originally saw the failed tests for the next week, but I tried on my laptop (which is also WDDM 1.1), and this CL does pass the canvas &amp; rendering tests that were failing before. There are cascading failures when I try running the entire test, but those happen both with the shipping Canary DLLs and with ToT ANGLE, so I suspect that issue is in Chrome.
|Patch Set 1:

(1 comment)

I think you're quoting the reference pages, not the ES specification. The ES 3.0.4 spec (https://www.khronos.org/registry/gles/specs/3.0/es_spec_3.0.4.pdf) uses the following language:

&quot;If SAMPLE_BUFFERS for the read framebuffer is one, no copy is performed
and an INVALID_OPERATION error is generated if the formats of the read and
draw framebuffers are not identical or if the source and destination rectangles are
not defined with the same (X0, Y 0) and (X1, Y 1) bounds.&quot;

That language definitely makes it more clear that the error condition is generated  if ((SAMPLE_BUFFERS == 1) &amp;&amp; (format mismatch &#124;&#124; bounds mismatch)). The reference pages should likely be clarified.

Also adding other reviewers; I'm mostly not a code reviewer anymore, but do tend to step in on spec-related issues.
|Patch Set 2:

As you are not a committer, you will not be able to submit the CL yourself. ANGLE does not have automated submits or CQ, so testing is required before submission. Marking &quot;Verified +1&quot; indicates that you have tested ANGLE as described here: https://code.google.com/p/angleproject/wiki/ContributingCode (See &quot;Get Your Code Ready&quot; step 3). It is best to also state in a comment that you have tested it, e.g.: &quot;Tested with angle_tests and WebGL CTS in Chrome Canary on Windows. Passed with no regressions.&quot;

Once the CL is marked &quot;Verified +1&quot;, it is up to the project committers to submit the CL. I will add documentation to our project pages to more clearly outline this process.
|Patch Set 10:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

An example demonstrating the performance difference between TRIANGLE and TRIANGLE_FAN. I'm not sure if it's the optimal example-- for example, the vertex data is static, which theoretically should be optimizable vs. dynamic, although we still show a noticeable difference between the two. My construction of the buffers might also be a bit clumsy. Additionally, I'm not sure whether we want to add benchmarks as ANGLE samples, or do something which would be more easily added to the target repo.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Topic set to microbenchmarks for webgl
|Patch Set 3: Verified+1
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4: Verified+1
|Patch Set 1: Code-Review+2

CLA issues resolved.
|Uploaded patch set 1.
|Topic set to microbenchmarks for webgl
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(Gregoire, please let us know if you'd rather be listed by a different spelling/name order/etc)
|Patch Set 1:

How does instanced pointsprite emulation interact with Transform Feedback/StreamOut? It's a moot point for the original intended case, since FL&lt;10 doesn't get StreamOut, but if it's being considered for FL10+ (although at a glance, it looks like perf is equivalent), it's definitely a question that needs to be answered. (And if the answer is &quot;it interacts badly,&quot; we need to make sure that we're appropriately restricting it to FL&lt;10 only, and include comments for the benefit of future readers to reinforce that.)
|Patch Set 1:

Sorry, didn't mean to cause the tangent-- it was a &quot;be aware of the potential interaction if we're interested in that use case&quot; rather than an objection.

(I have had at least one person ask if we'd evaluated alternative approaches to geometry shaders before, FWIW)
|Patch Set 2:

(1 comment)
|Patch Set 1:

Related to Jamie's comment-- would be good to include in the commit message that it's for Win10 project generation.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Allowing BGRA formats in the CopyTex(Sub)Image commands is explicitly outside the allowances of the spec (see https://chromium-review.googlesource.com/#/c/232411/ for a lengthy discussion), so this is functionality we should not add without a compelling use case that cannot be handled within spec (and usually still under moderate protest from me). What is this being added to support?
|Patch Set 1:

Unfortunately, D3D9 doesn't have RGBA backbuffers-- that's how the few places we quietly allow those copies ended up in the codebase. We can't switch to RGBA everywhere until we no longer need to support D3D9.
|Patch Set 2: Code-Review+2

Ok with landing if it's still desired with glFinish out of the new tab path.
|Patch Set 2:

What's the motivation for this change? The GL spec places no restriction on and makes no guarantees about the ordering of texture handles. Client code should not rely on getting any specific texture handle from a call to GenTextures.
|Patch Set 2:

Sorry, what is meant by create-on-bind? As far as GL is concerned, textures are always created by BindTexture (sec. 3.8.1, Texture Objects-- &quot;A new texture object is created by binding an unused name...&quot; and &quot;[GenTextures] returns n previously unused texture names in &lt;textures&gt;. These names are marked as used, for the purposes of GenTextures only, but they do not acquire texture state and a dimensionality until they are first bound, just as if they were unused.&quot;)

ANGLE has traditionally had a policy of following least-forgiving interpretation of the spec where possible, to avoid masking such issues. I'll leave it to Geoff &amp; Jamie to make a decision on whether we should allow this, but caution against blanket behavior in the API to alleviate application-side bugs. A targeted/optional workaround might be a better strategy.
|Patch Set 2:

Ah, yes-- that was a bug. Bind without Gen is spec'ed and should have been supported.
|Patch Set 2:

That's a good question. The spec gives the texture handle namespace as &quot;the unsigned integers,&quot; with 0 reserved, which sounds like max GLuint should be valid. Jamie-- what was the reason for making it max() - 1? Is there a dEQP test that max() fails?
|Patch Set 2:

One request, if the workaround isn't optional-- in addition to a regression test for this behavior, please add a comment indicating that strict sequential IDs are not required by the spec, but provided as a workaround for a bug in a widely-shipping application.
|Patch Set 1: Code-Review+2

Verified that Shawn is on the CLA for MS.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

Should we consider upstreaming these definitions to Khronos? (I note we never did for the Windows Store ones, either.)
|Patch Set 1:

Can you please add the message from &quot;topic&quot; to the commit message itself?
|Patch Set 3:

(1 comment)

LGTM. The assignment alignment is particularly nice. Thanks for getting this in (and thanks everyone for managing to keep the codebase so clean through manual effort for so long)!
|Patch Set 7:

Could someone add it to the &quot;contributing code&quot; wiki/md page?
|Patch Set 2:

Thank you!
|Patch Set 1:

(17 comments)

Apologies for long commentary-- doc clarity is a particular interest of mine.
|Patch Set 2: Code-Review+2

(5 comments)

One remaining spelling error, and one whole-word typo. The other comments aren't actually things that I think need to be changed before committing-- I just included them in case you wanted the full &quot;picky copy editor&quot; treatment. :)

Feel free to commit once &quot;dependent&quot; and &quot;from&quot; are fixed. Thanks for documenting this!
|Patch Set 4:

Looks great! Thank you very much!
|Patch Set 2:

Are we enforcing the restrictions on all ES 1.00 shaders? They're not optional in WebGL 1, but they are in ES 1.00. Should we also allow the restrictions to be disabled for ES 1.00 shaders conditionally? It's not an error to enforce them, but it's also not an error to allow the shaders through &amp; let the compiler barf or hang.
|Patch Set 2:

Ah-- I didn't mean to suggest we should allow the restrictions to be lifted for ES 1 in Chrome, ever. Just wondered if we'd considered allowing other, non-browser users of ANGLE to turn the restrictions off if they wanted to allow shaders to attempt to use those features. (Or if we apply these restrictions only when evaluating WebGL shaders-- which it sounds like is the case? If so, then the point is moot, since non-browser users would not be restricted from using the additional features in the first place.)
|Patch Set 2:

Yes, my question is answered and this LGTM as well.
|Patch Set 1:

Good find! It looks like GetShaderInfoLog and GetShaderSource have the same problem. Could you fix those as well, either in a separate CL or in this one?
|Patch Set 2:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 2:

I don't think the value change is unintentional. The param* argument to glGetIntegerv() is a GLint, which is a signed integer. According to the 3.0 specification, sec 6.1.2 &quot;Data Conversions&quot;:

&quot;If a value is so large in magnitude that it cannot be represented with the requested type, then the nearest value representable using the requested type is returned.&quot;

For a uint being retrieved as an int, this means clamping to max integer. Without this clamp, tests in the dEQP ES 3.0 test set fail. The change to implement the clamp was reviewed here: https://chromium-review.googlesource.com/181780
|Patch Set 2: Code-Review-1
|Patch Set 2:

Sorry for the delay-- the notification skipped my inbox. I need to update my filters.

Corentin has EGL_ANGLE_x11_visual in progress, which uses 0x33A3-- these enums will need to get incremented by 1. (This extension will have dibs on 0x33A4 &amp; 0x33A5, though, so no one will snag those out from under you.)
|Patch Set 5:

Yep, those values are free-- I'll consider them allocated to this extension.
|Uploaded patch set 1.
|Patch Set 1:

This adds tables to document the support by platform &amp; API, so I'd like someone to eyeball this for correctness before I land it.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 3: Tryjob-Request+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 8:

(2 comments)
|Patch Set 10:

(1 comment)
|Patch Set 6:

^ What Jamie said. I'm usually only pulled in to resolve spec-related questions &amp; allocate enums.
|Patch Set 5: Code-Review+1

CLA status now LGTM.
|Hi Simon,

As the fifo level is different for different channels I used a static variable to get it at runtime. Otherwise I need to use either a local variable or #defines to get the fifo lvl at runtime and as spi_xfer and spi_flush_fifo run in loop, every time it has to calculate the fifo_lvl. If still it is better to remove this variable I will go ahead and do that.
|I will rework on this comment and will get back ASAP.
|I can't pass PERIPH_ID_UART0 because it takes the device index which is different based on the opted uart port and each uart port has different src_bit and div_bit.
|dev_index and the uart periph id are same as  PERIPH_ID_UART0 is first in the list. So I used the dev_index. If still it is required to change I will change it.
|The old api that used to get the i2c clk frequency didn't pass any i2c bus number.  So I just used the first i2c bus number here.
|error should be %d in debug.
|I tried putting this in the resume but audio didn't play after resume. So when I moved to startup function it worked fine. startup and shutdown functions gets called for every new audio stream playback.
|Actuvally to support suspend to resume only saving the Audio sub system clocks and setting the software reset control bit are enough. This we can keep in probe itself.
|All revisions of 5250 User Manuals I had showing this bit as software reset control bit.

Set this to 1 after I2S clock is stable.
0 = Resets I2S module (default)
1 = Reverses I2S module reset
Before reading SFR of I2S, set this bit.

I think this bit is undefined in older platforms. So this quirk is introduced to support older platforms. This bit also required to set after every resume.
|The chapter you were looking is for I2S contoller 1 and 2 but we are using I2S controller 0. Please verify page 35-21, section 35.9.1.1. I put the s/w reset part in i2s_startup function and I changed the commit message accordingly.
|Okay. Agreed and uploaded new patch by removing the clk part
|I will submit a patch to remove pm_runtime_ctrl(put_sync,get
_sync) as it is already handled in soc-pcm.c(open and close).
|If the built-in chip select feature is always available, what is the purpose of having a seperate gpio for this toggling? Is it some thing should be supported at slave side also for this? Please explain me.
|I think we can even do this in the dts file. Like in the below link
https://gerrit.chromium.org/gerrit/#/c/56189/3/arch/arm/boot/dts/cros5250-common.dtsi. I am not sure about adding stream name and codec_dai_name in the dts. I found only one adding like this in the mainline(arch/arm/boot/dts/spear1340-evb.dts)
|I will check this.
|Yes. We don't need this.
|ok
|I made a patch on 5420 to rename &quot;oscclk&quot; to &quot;fin_pll&quot; so that I can use the same in audio subsystem driver. But not posted yet.
|ok
|ok
|ok
|If we add the gates here and if don't get that clock any where in the code then that clk will be gated by default. So I am not sure where to get the remaining clks and gating the remaining bits will anyway effect audio(need to verify)
|Last two we use to set the audio clk hierarchy in the daisy machine file(daisy_max98095.c).
|Okey. I will remove in my next patch set.
|Hmm, they are basically i2s0 base clocks. So I added them here so that any user can get by using the alias names we added here instead of depending on the dev_name of the clk.
|ok
|Yes. It works.
|Ok. I will add in the next version. Waiting for some more comments.
|This function is able to handle all epll and vpll frequencies. I didn't see any issue having this code here. Let us wait for some more comments.
|BARM??
|As per the communication from H/W Team the parent of adma clocks is &quot;dout_srp&quot;. This what I got from H/W team.

&quot; so, ADMA performance is affected by BUS_CLK also.
  parent clock is SRP_CLK, but, ADMA access the memory, so, BUS clock also used for ADMA.
  It seems like two parent.&quot;

But parent of dout_aud_bus is again dout_srp. I think we can specify &quot;dout_srp&quot; as parent.
|I requested H/W team about this. Will let you know if I get any info.
|I think i2s_opclk1 is not required as it doesn't have any mux like i2s0(refer 10th bit in i2s_mod of i2s0) for rclksrc. i2s_opclk0 may be enough to pass.
|Do we need these alias names here?  Can't we make it like 5250? Any way we don't use them outside dt.
|Do we need these two entries or can I delete? 180MHz entry is there 4210 but not there in 5250. Table 35-4(Root clock table) in Exynos5250 also not showing this frequency.
|I think we can delete this function as we are not using it.
|Uploaded patch set 8.
|Patch Set 8: (1 inline comment)


|Patch Set 8: (1 inline comment)


|Patch Set 9:

I tested this patch on board and it's working fine.
|Patch Set 1: Abandoned

Abandon. Not needed now.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 7: Abandoned

since DRM HDMI patches are ready for review, abandoning V4L
|Uploaded patch set 2.
|Patch Set 2: Abandoned

By mistake. This patch shouldn't come with this change id.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned

With James Miller's new clock_set_rate() this patch set is not needed. Hence abandoned.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 6: Verified; Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2:

I am sorry. It's by mistake.
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: Verified


|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: Verified


|Uploaded patch set 6.
|Patch Set 6:

WIP audio power management patches are dependent on this patch and this patch is not yet merged. So submitted the same patch again.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Patch Set 7:

Hi Jon and Dylan,

I just seperated the patch into two. Can you give +2 so that it will get merged.

Thanks
Padma
|Patch Set 1: Verified


|Patch Set 1:

when we play 8,22.05,32KHz, it's throwing error in codec master clk frequency.
Playing WAVE '22050.wav' : Signed 16 bit Little Endian, Rate 22050 Hz, Stereo
[   46.181425] **********************exynos5_epll_set_rate:rate:45158400*************
[   46.190779] max98095 7-0011: Invalid master clock frequency
[   46.194905] asoc: machine hw_params failed: -22
Stream error -22

The src clk of MAX98095 MCLK as per schemata is xtal clk but in glue file I2S cdclk has been set.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Patch Set 1: Verified


|Patch Set 1: Fails; I would prefer that you didn't submit this

This patch is tested on snow board. Power to MAU is disabled after probe and enabled upon audio playback. But sound is not audible after power to MAU is enabled. All clock and I2S controller registers are looking fine. Took the dump of codec registers and compared with working setup. Codec register dump also looking fine. But Sound is audible on TV. So looks like I2S Path is working. But codec side not working. What could be wrong after power disable and enable.
|Patch Set 1: Abandoned

This patch is not required.
|Patch Set 1: Abandoned

This patch is not required.
|Patch Set 1: Abandoned

This patch is not required.
|Patch Set 2:

I tested this patch and works fine after suspend and resume. But I am not sure about the code change so better to post in mainline.
|Patch Set 1: Verified


|Patch Set 1:

Hi Jon and Dylan,

This is just seperated patch.
can you please give +2.

Thanks
Padma
|Patch Set 1:

Hi Jon,

The startup function gets called for every new audio stream playback. I already tried adding this code in resume but audio playback after resume didn't work. So I added this code in startup. 

Thanks
Padma
|Uploaded patch set 2.
|Patch Set 2:

Changed the commit message.
|Patch Set 2: Verified


|Patch Set 1:

Hi Dylan,

I tested your patch and it's not working after resume.
|Patch Set 2:

Hi Dylan,

there are two use cases.
1)suspend while playing the audio
2)suspend with out playing audio or after playback is over 
If I suspend the board while playing audio it's resuming fine along with audio playback(with dma_prepare patch submitted by you).

But in the second case it's not playing audio after resume.
Thanks
Padma
|Patch Set 2:

In the first case it's working fine with or without my patch.
|Patch Set 2:

Hi Dylan,

I tested aplay in the background and arecord parallelly with out your patch. with this setup aplay played fine and arecord also recorded fine using microphone. But as per your comment it seems you are expecting to record what ever you are playing in gchat. I don't have this setup.
|Patch Set 2: (1 inline comment)


|Patch Set 1: Verified; Ready


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Patch Set 1: Looks good to me, but someone else must approve; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: Looks good to me, but someone else must approve

Need to check about power domain. Otherwise everything looks good to me.
|Patch Set 1: Looks good to me, but someone else must approve

Looks good to me.
|Patch Set 1:

Patch looks good to me other than Bryan inline comment. I will check with AP team if any DMA channel available for ISP SPI.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve; Verified

The user manual has both of the statements
Before software reset using SW_RST, you should channel off and
software reset of SPI must be performed before PACKET_CNT reloaded.
So the order seems fine.
But the patch set didn't solve crosbug.com/p/9657, the SPI DMA off by one issue
|Patch Set 1: Verified


|Abandoned

Not required as this change was added in Rajeshwari's patches for spi word transfer support
|Uploaded patch set 2.
|Patch Set 2:

There is no change in this patch. But it is required for my patches to post. I think now these patches are in order as requested by Doug.
|Patch Set 1:

Hi Doug,

This patch is dependent on the patch &quot;ARM: dts: add pin state information in client nodes for Exynos5 platforms&quot;
which is not yet merged in the mainline. So as per Mark I couldn't post the patches that can't be applied now. So I will post in a new patch in gerrit kernel-next.
|Uploaded patch set 2.
|Patch Set 2:

Added the link to this patch in the mainline and added the platform name in the subject.
|Uploaded patch set 2.
|Patch Set 2:

Just added the link to this patch in the mainline in the commit message.
|Patch Set 1:

No Change in this patch. But my patches are dependent on this patch. There is a merge conflict with &quot;UPSTREAM: ARM: dts: Add disable-wp for sd card slot on smdk5250&quot;, So resolved the conflict in dw_mmc.
|Patch Set 1: Abandoned

This patch not required as Doug re-uploaded the same.
|Patch Set 3:

It's my mistake. I overlooked the conflicts. Thanks for correcting this.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

Sorry. Posted by mistake.
|Patch Set 5: Looks good to me, but someone else must approve

Hi Andrew,

We can also pass audio routing information from dt like it is done for Tegra in the mainline. If you are okey I will upload a patch.

Thanks
Padma
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Sorry. Posted by mistake.
|Patch Set 5: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Sorry. Posted by mistake.
|Patch Set 4: Abandoned

Abandoned.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 5.
|Patch Set 5:

Sorry. Posted by mistake.
|Patch Set 7: (5 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 5.
|Patch Set 5:

Sorry. Posted by mistake.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 5.
|Patch Set 5:

Sorry. Posted by mistake.
|Patch Set 7: (1 inline comment)


|Patch Set 7:

yes. These clks has bindings at Documentation/devicetree/bindings/clock/clk-exynos-audss.txt.
I will add the description in the next version.
|Patch Set 7: (1 inline comment)


|Patch Set 7: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Sorry. Posted by mistake.
|Patch Set 4: Abandoned

With Andrew set of patches this patch is not required.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Sorry. Posted by mistake.
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: (2 inline comments)


|Patch Set 1: Abandoned

This patch is not required as Vikas posted generic way of pll set rate
|Patch Set 1: Abandoned

This was posted by mistake. This patch have to be posted along with another UPSTREAM patch which were already there in peach-alpha branch.
|Patch Set 1:

I was intended to post this patch. But forgot that I have some unmerged patches in my local tree. Sorry for the chaos.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 3: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 3: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 2: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 2: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 2: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 4: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 3: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 2: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 1: Abandoned

will push final version of patches for peach,snow and smdk.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

Thomas Abraham has made a patch for deferred probe in clk. I will post this patch in gerrit tomorrow. I think with deferred probe we may not need these changes.
|t_halt given as argument is always 0 or 1, specifying if transaction halt should be set or not. On line 298, if t_halt is 1, it is replaced by LOCAL_STATUS_THALT, 0x10 that is (bit 4 set). If bit 4 has already the value requested by t_halt (set or cleared) we don't have to do anything, otherwise we set it or we clear it as requested by t_halt, in both the local_status and SCB_CONTROL_REG.
Does it make sense now?
|This happened due to the fact that repeated start transactions (the scan transactions are repeated start transactions) were not handled properly. I've modified it in the new code.
|Yes, you are right, I've removed it in the new code.
|Done
|Initially I put the hardware description in a substructure because, as you said, it makes more sense. In this version I thought it might be better to keep the mappings structure similar to the one in Depthcharge. 

And it makes sense to have a function called &quot;get hardware&quot; that returns a board ID map entry when that entry contains the hardware description :).

Anyway, I agree it looked better before.
|Yes, it could be done from inside init_extra_hardware, but I placed the call here as I thought it would be more clear to show the hardware init work flow: perform basic initialization, obtain information about hardware based on board ID, initialize additional hardware.
|Done and it returns directly a pointer to the entry in board_id_map.
|As far as I know the udelay is not necessary. There's no delay in the Coreboot/Deptcharge/bootrom code so it's verified that it works ok without the delay.
|On second thought it's best to keep it for other boot loaders (JTAG load script or other secondary bootloaders).
|I'm not sure this temporary check is actually necessary, because due to the identity mapping in the firmware it would work no matter if it receives a physical or KSEG0 address. Therefore it doesn't actually need a temporary workaround.
|Done
|No, don't mind that, as I said, that's just temporary. I cared more about having the interfaces specified correctly for Urara and Concerto, than for the compatibility strings, as we hadn't defined how those were suppose to be yet.
|I've changed the values here, so they would correspond with the current equivalent mapping in Coreboot.
|The values here should be: 
{0, 3, 0, 1, &quot;img,pistachio-fpga&quot;},
{1, 0, 0, 58, &quot;img,pistachio-bub&quot;}

Also, we would need another entry for Concerto, which should be: 
{2, 3, 0, 1, &lt;compatibility&gt;}, but I'm not sure there is a dts submitted for Concerto in the kernel repository.
|In the Depthcharge patch that takes into account the board id to setup the hardware (https://chromium-review.googlesource.com/#/c/257181) the matching board-board ID was:
0 - FPGA
1 - Bring up board
possible 2 - Concerto (see comment). 
Therefore, we either take into account the FPGA here also, or drop it in Depthcharge.
|Yes, that was hidden in this comment here. I should have made it more clear.
|Yes, I think it's better for it to be this way, for clarity, because BL8 it's not actually a mask, it's just the value that decides if certain bits are set.
|It was there before, it's not there now :). The code is more consistent without it. The comments separate the code enough.
|Yes, it's the correct value. The case removed was the one with UMCTL_INIT=1 (which was not used as UMCTL_INIT was defined as 0). So from the previous code only the &quot;else&quot; branch was kept. 
Bit 18 tells the PHY that uMCTL will be doing memory initialization (therefore needed in UCMTL_INIT=1). In the way it's set here the PHY is doing memory initialization and the other bits that are controlling initialization and training are set.

What's wrong here is the comment :).
|If you look over the wait_for_completion function you'll see that it does not wait only for the bits in the provided value to be set, but it expects an exact identity with the provided value. If any of the error bits are set it will continue the wait loop and result in timeout.
|These two include directives are not necessary.
|Can you tell me why did you want to map SRAM also? In my opinion (verified opinion) it's only necessary to map DRAM. SRAM and GRAM accesses can be kept in KSEG0, for all stages.
|Yes, but in my opinion, who might decide to use this in other stages will be able to add it to the stage themselves. I think a good practice is not to add unused code to a stage. But I think the other firmware guys can better say what's good practice for this so I'm not holding you to this change.
|You don't need to include this in romstage as the mapping is done in bootblock only and it's not modified or remapped in romstage (or ramstage for that matter).
|The same here as above.
|All the code here looks good. Maybe it would be better to group defines for configuration register reads and writes separate from defines for mask and shift values as it's a bit difficult to understand the code.
|The Interaptiv manual says that this register specifies the boundary between wired and random entries. As I understand, this will hold the index of the last wired entry. Starting from n = 0 (you have set wired to 0 in bootblock.c), you will be writing the current values to TLB entry with index n and writing n+1 to wired. This is a problem when you reach the last of the TLB entries and you will write a value equal to the no. of TLB entries to wired. And &quot;The operation of the processor is undefined if a value greater than or equal to the number of TLB entries is written to the Wired register.&quot;
|Sorry for this, it's a mistake left from moving thing around.
|This is no longer necessary here. It was used before for UART0. But I've applied your suggestion to the I2C0 code.
|Done
|Done
|Done
|Done
|Same here.
|There is also this change. We either leave it as it is (it's enough for now) and it will be equal to the limit imposed by src/boot/commandline.c line 81, or we can up it to 3*CmdLineSize and modify that limit to 12288. Or we do it properly and have a correlation between those values.
|Yes, you are right. I removed it from this patch.
|No, I just forgot to remove this.
|initially:   previous = 0, total = 0

1st: current = 1 -&gt; total = 1, previous = 1

2nd: current = 2 -&gt; total = 2, previous = 2

3rd: current = 3 -&gt; total = 3, previous = 3

4th: current = 0 -&gt; total = 4, previous = 0

5th: current = 1 -&gt; total = 5, previous = 1

This is what happens both in my implementation and yours. 
Your implementation is not wrong but your scenario is wrong: when you enter the function, you cannot have previous = 2 and total = 3 because previous will always be equal to the least significant part (either 32 bits or 2 bits) of total. So if total was 3, previous was 3, current is 1 -&gt; total will be 5 and previous will become 1.
|What I did was to set to 0 the least significant part for total_ticks and increase with 1 the most significant 32 bits of total_ticks. And I added the current value (which is the value it got to after being reset to 0). 
It's the same thing, and it only works with positive numbers (meaning (current_ticks - previous_ticks) would be negative or 0 in your implementation). I have a thing with mixing positive and negative values when working with unsigned variables.
|I think it's best to have this right above the kernel, and this value should change with the relocation of the kernel from 0x80a00000 to 0x81000000.
|Sure. I'll do that as soon as the fix to the clock setup code is merged and I can re-upload this based on the new code.
|Done.
|Done
|Done
|Done
|Done
|It actually does not matter, because the functions above only set up the dividers and the devices will only be clocked after sys_pll_setup (clock source) and MFIO setup (routing of lines), where is needed. So even if one of the functions above fails, we won't be able to print an error message, and if it fails silently the order won't matter any way because it would get to execute the UART setup and it will carry on.
|No, we'll have UART after uart1_mfio_setup. 
But yes, there should be at least error checking for init_clocks().
|Done
|Done
|Done: Don't worry about the formatting. It's a very good idea :).
|Done
|Done
|Done
|Done
|Done
|Done
|Done: an improper input value (here and in the functions above) will be due to a programming error. I've called assert for all input values.
|I can add a short delay here but considering that the lock time is so short, I don't think is really necessary.
|Done
|Done
|Done
|Yes, an alternative solution would be to check in the interrupt status register if the TX buffer is full at every 4 bytes. If it is not full, I can write the following 4 bytes (or less). Checking for the interrupt status register means performing 2 operations (write in the SPFI_INT_CLEAR_REG_OFFSET and read from SPFI_INT_STATUS_REG_OFFSET). From an analysis with a scope I've seen that read operations are more costly so introducing here additional reads would decrease the performance. 

I will recheck this and make sure we have the optimal solution in Depthcharge.
|Done: It has been finalized on the 26th so I've modified the wait_status function accordingly.
|Done: changed from 10 ms to 500 ms.
|Done
|Done. 
Also, %s/initialized/initialised/
|Done
|Done
|Done
|The bits in the 'SPFI Read Interrupt Status Clear' (see TRM) were designed as 'sticky bits'. Meaning 'if the source of the interrupt is still set, a fresh new interrupt will be generated right after a clear operation'. There is a note about this at page 27 of the TRM.

This should be a while waiting for FIFO to be empty because it writes blocks of 64 bytes, it waits for the FIFO to become empty, and then it writes the next 64 bytes, and so on.
|Done
|Done
|Transmit and receive are separate operations and they are clocked separately with no need to continue to send data in order to be able to receive.
|Done
|Changed to 
spi_write_reg(base  + port * 4, SPFI_PORT_0_PARAM_REG, spim_parameters) because the spi_write_reg macro will concatenate '_OFFSET' to the second parameter. The alternative would be to replace calls to the spi_read/write_reg macros to calls to read32/write32 directly.
|I do have to initialize it because the first spi_write_reg_field call will use the old value of reg, modify the target bits in it, and return the new value.
But I will replace it with u32 reg = 0;
|Done
Replaced everything of this kind either with if(var) or if(!var) for consistency.
|Every SPFI transaction has command bytes, address bytes, dummy bytes and data bytes. In this transaction register you can specify the number of bytes for each of them. Considering that here we don't know how the transactions are structured this is always 0.
|No, it's my mistake.
|Done
Yes, it's redundant. I removed the chip_select field in the transaction description structure.
|No, the command mode, together with the data mode below, specify that the transaction is a single mode one, a x2 mode one, a dual mode one, a x4 mode one, or a quad mode one. 
Please see CMD_MODE and DATA_MODE enumeration in spi.h.
|Done
|Done
I moved this to spi_init because it's more clear for somebody looking over the code to see it in the init function.
|Done
|Done
|Done
|Done
|Done
|1. I will add a more detailed comment. 
2. I only checked for one bit being set because usually the wait is done on an interrupt status register , which sets one different bit for each different event. 
You will never have to wait for more than one bit being set. That mask will always have only one bit being set. To make this clear I'm going to use SHIFT instead of MASK and eliminate reg and put directly SPFI_INT_STATUS_REG_OFFSET.
3. I used the delay here to cover a normal case scenario. Even if it does not find the bit set at the first check, after the specified delay, different depending on the event, it should find the bit set at the second check. The TIMEOUT_COUNT covers the worst case scenario in which if the device did not set the bit (signal the event) in TIMEOUT_COUNT*delay, it means there was a problem and it should signal an error. 
500ms is too much in my opinion.
|Done
|The controller issues clocks according to the values I set up in the transaction register. If I have a receive of 'size' data, I will set the TSIZE part of the transaction register to 'size' and the block will issue the clocks in order for me to receive that data. 
The block also handles overruns and it does not allow any data to be received if the RX FIFO is full.
|If the receive FIFO is full the controller won't clock the bus until the receive FIFO is drained. 
For example if software requests 128 bytes of data to be read, but it does not take the data out of the RX FIFO, the controller will clock the bus until 64 bytes are received to fill the RX FIFO and then stop clocking the bus until some data has been taken out of the FIFO. Then it will continue clocking the bus until all data has been read.
|What I meant with the calculations above was that if the SPFI block has as input a frequency of 52 Mhz, this is divided by 8 (when configured with a bitrate of 64)(TRM page 33) =&gt;actual freq = 6.5Mhz =&gt; 6.5/8 = 0.8125 bytes per us (or 1.23 us per byte). This being the worst case scenario. 

But you are right. This is too big for normal behaviour. I'll change this. 

Regarding the second comment,  &quot;wait_status() should not be invoked inside the loop&quot;, this would result in incorrect behaviour if invoked outside the while loop. 
The correct behaviour is: 
 - clear INT_STATUS
 - wait for 4 byte data to be received (GDEX32BIT bit in INT_STATUS to be set) 
 - read the 4 bytes
 - clear INT_STATUS
 - wait for the next 4 bytes to be received (GDEX32BIT bit in INT_STATUS to be set)
 - read these 4 bytes
and so on. 

Therefore the wait should be done inside the loop for both this while loop and the one below.
|In a worst case scenario: 52MHz (64 bit rate = division by 8) = 1.23 us per byte.
In a good case scenario: 400 MHz (128 bit rate = division by 4) = 0.08 us per byte. 
Therefore, I chose some values to cover more the worst case because for the good case it won't even have to wait because it will already have found the bit set up in the interrupt register.
|I explained the options for this in spi.h on the comment for the transfer_desc structure.
|Done
|Done
|Done
|Done
|What I said below applies to the cmd_len, addr_len and dummy_len also. These have the same values all the time (1, size-1, and 0) and therefore I can remove them completely from this structure. 

Let me know if you want me to do this. I usually like to have generic code which is being configured in one place only even if I end up hard-coding some of the values.
|Logically, this should be defined per buffer, or at least per write-read transaction because you can have one transaction which is done in single mode, one done in dual mode, one in quad, and so on. This is the generic way. 

But considering that I'm hard-coding the command mode and data mode here, these two can be moved in img_spi_slave or removed completely and hard-code them directly when I write them to the control register. 

How do you prefer this to be done?
|Is this the way you'd rather have it done? Because I'm not sure I understand. 

static int wait_status(u32 reg, u32 shift)
{
    struct mono_time start; 
    struct rela_time elapsed; 

    timer_monotonic_get(&amp;start);
    while (!(read32(reg) &amp; (1 &lt;&lt; shift)){
        elapsed = current_time_from(&amp;start);
        if(rela_time_in_microseconds(&amp;elapsed) &gt; SPI_TIMEOUT_VALUE_US)
            return -SPIM_TIMEOUT;
    }
    return SPIM_OK; 
}

with SPI_TIMEOUT_VALUE_US defined as 10000 (10ms)
|Done
|Done
|No, I'm not able to use those functions because those functions work with multiple of sizeof(unsigned long) (4 bytes) and the given addresses are not aligned. MIPS uses lw/sw instructions that require the given addresses be aligned by 4 bytes.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done: moved it to xcompile for now.
|Done
|I've seen that all the other platforms initialize this with a default value. 
This value should be overwritten when calling get_cpu_speed below.
|When calling get_coreboot_info, this structure should be filled with information about the memory range of the coreboot table (see payloads/libpayload/libc/coreboot.c: cb_parse_memory).
This table is created by coreboot: src/arch/mips/tables.c: write_tables. 

If this cannot be found, a default memory range is reserved with a size of 1MB.

As I've seen the MAX_COREBOOT_TABLE_SIZE is 8KB, but for all the other platforms a bigger size is reserved (1MB).
|Done
|Yes, we don't need any of the flags you mentioned below. I used the default with only few flags added.
|Done
|Yes.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|There should not be any implications for other platforms because this is a section that is specific to MIPS. This was necessary because I would get linking errors (&quot;don't know how to handle processor specific section `.tramp.reginfo'&quot;) when building Depthcharge. I'm not sure yet if this is the best way to solve this issue.
|There is no &quot;-mpreferred-stack-boundary&quot; option for MIPS to attempt to keep stack aligned. This is a x86 options only. Therefore, I dropped the entire branch for MIPS as there are no other specific options for it (so far).
|Done
|Done
|Ok. Will do..
|Yes, as said before it's better to make sure the size of the data is a multiple of 4. Adding this padding at the end of the binary is just a precaution that would not have a negative effect  (overwrite data), at least for the purpose it's used now, considering that the ROM stage will begin at an address that is divisible by 4. It will just ensure that we always read chunks of sizes that are multiple of 4. I think making sure the bootblock.raw has always a size divisible by 4 can be done in the linking process but I'm not very sure how to do that. The padding might be already added by objcopy but I'm not sure.
|Ok. I saw that later when working on the GPIO driver. I'll change this for consistency but usually it helps me see things better when separating declaration from initialization.
|I removed bus/imgtec_spi all together because we only need the base address.
|Done
|Yes, there are too many 'only's in that sentence.
|No, it's just one &quot;and&quot; where it should be none.
|Done
|No, it won't work here because I cannot call container_of on spi_ops before I verify if spi_ops has been initialized. But I will change it to bus, because it's shorter.
|Yes, I put a reset in both because when you claim the bus you must make sure you have everything in a well defined state (which is the one after soft reset) and not rely on the release function. Also, when you release the bus you want to make sure you return to the well defined state from the beginning (make absolutely sure you don't leave the SPFI block in a pending state).
|I checked this now and yes, the parameter registers are reset at soft reset, so this must be done every time we claim the bus.
|I think soft reset resets the parameter registers also. I'm not sure now as I cannot find this information in the TRM, but that was my impression when I wrote the code.
|Yes, it would be good to have the operation mode passed to the driver from the outside and I will add support for dual and quad mode in another patch.
|This is the same as above. I cannot call container_of before I've checked spi_ops.
|Done
|I removed this branch also because it's no longer necessary.
|Yes, I'll remove this as this is a value left by mistake from a previous version I was trying.
|Done
|No, as it was with TIMEOUT_RELEASE error, this is a left-over from trying another approach. I was using this on the FPGA as a bare-metal driver and this value here was used as a counter in that implementation. 
I should not count in any case because this is a timeout for worst case scenarios, but it's good to have consistency between the drivers.
|Done
|Done
|Done
|Done
|Yes, this limits the scope of the cache operation. It only invalidates the cache lines involving the addresses for the next stage. This is just an optimization considering that you don't have to invalidate the entire cache.
|Yes, that would make sense too and it would save some operations.
|Initially I left them as they are because invalidating L2 caches has an additional operation (clear_L2tag()) and during testing I kept modifying one or the other. Also, the first argument of cache_op has to be an immediate value, so if I introduce an argument operation of a generic function, I will have to &quot;switch&quot; it and call cache_op with an immediate value. But considering that it will reduce the code, I've made a generic function, with the cache operation as argument and an additional call to clear_L2tag for operations involving L2 caches.
|Done
|Done
|Because, considering that we have stage specific files, I thought it is better to handle it in a stage specific file where I already had or could obtain the information I needed (stage name and based on that, stage load address and size). Considering that the stage is already loaded and the only the cache lines involving the addresses for this stage are invalidated, nothing sane added here could mess with what was done in the stage specific file.
|Done
|Done
|Done
|I'm looking into this alternative solution now. I'll come back with the implementation or comments later this evening/morning :).
|Fair point. Thank you for that.
|Yes, each of the cases mirrors the variable operation, and this switch here would be pointless, and I could just put cache_op(operation, start) if the cache_op function (and the CACHE instruction it holds) would not require that argument 0 be an immediate value. Therefore argument 0 of cache_op cannot be a variable.

The operation code will always be formed of a cache operation and the cache type it applies to. Bits 0-1 specify the cache type (I,D,L2) and bits 2-4 specify the operation code (which here it's always the same (b101): fill for I cache and hit writeback/invalidate for D/L2 cache). I will make it more clear in the code. 

I could make a macro but it will be a pointless ugly thing considering that it will probably never expand to more than it is now.
|I don't understand what you mean by this? See if the new version makes more sense.
|Yes and done!
|I've moved the assembly functions to cache.c (as they should be private and only be used from cache.c) and I've left the defines in cache.h with the public interface.
|Why do you say that cache invalidation is done way to late? It should be done just before jumping to payload to make sure it's executing the proper code with the proper data.
I didn't modify the load stage/payload functions because I did not want to change architecture independent code to add a callback function that only the MIPS architecture would use so far.

Would you say it would be better if I added a sync function to the cbfs_media structure and I used a custom cbfs_media for each stage with this function defined? I think this could work for coreboot stages but for loading the payload, the default cbfs media is used for all architectures by default (bs_payload_load). 
Please give me more details about your suggestion and/or let me know if I'm missing something in the way I understand the framework.
|Yes, my bad. But I think a 4K page size alignment should be enough.
|Done
|Done
|Done
|I don't think I understand what you mean. So given a pin number (a GPIO number), pin/16 will give us the control register (see all GPIO_CTRL macros) and pin%16 will give us the offset within that register (the from the lower 16 bits) to use in order to control that pin,
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It can only fail if it is given an argument it cannot recognize. Having it masked by CACHE_TYPE_MASK covers programming errors (it makes sure it only receives a value between 0 and 3). The default branch there should correspond to all unsupported types of caches. I think the better approach will be to add support for tertiary caches (all caches supported by the architecture) and have cache invalidation functions (the ones that call perform cache_operations) implemented per SOC (easier) or better per CPU ( a bit more work). 
What do you think?
|I've changed the implementation based on your recommendation. I've used cache operations that require addresses for separate clean and separate invalidate, and I've used index operations for both clean and invalidate as it works faster. There is no operation using indexes for separate clean. I could use store tag for separate invalidate but I'm not sure it's worth adding more code for it.
|I'm not sure we can. Maybe we can have some generic MIPS support library that can be included in both coreboot and libpayload, as there is a lot of duplicate code between coreboot and libpayload, especially for cache operations, timers, MMU, but that would be a bigger exercise.
|Done
|Done
|Done
|Done
|Done
|Done
|What I see with the debugger is consistent with these values, so I'm going to keep this as it is until I get an answer on how this should be.
|Yes, the formula is more generic. But at the moment, although placed in arch/mips, the cache operations and constraints are more specific to interAptiv. As you see there's no support for tertiary caches and all constrains are as per the MIPS interAptiv manual, as discussed with Vadim in the other comments. A future plan would be keep cache operations in arch/mips, both in libpayload and coreboot, and have constraints and clean/invalidate operations defined per processor. But I suppose that's a bigger exercise also, than the current time allows.
This is already added to a list of improvements I'm considering :).
|It's strange, because I have these values in the interaptiv manual. 
4 -&gt; 32
5 -&gt; 64
|Yes, I agree it's ugly, but I have no other choice but to do it like this because the first argument of cache_op has to be an immediate value and not a memory location (variable, as operation is). That's the only reason for this switch here. I welcome other ideas :).
|Done
|The same response applies here.
|Sure! I'll make a separate function and combine both switch statements, from here and above, and try to optimize it as much as possible.
|1. Yes, you are right. Done!
2. I've cleaned both this code and the one in Coreboot (https://chromium-review.googlesource.com/#/c/250792/)
|This is exactly as before due to line 298.
|I haven't tried this on the modified version of the driver too see if there are any problems, but as far as I see in your code, you should first disable all interrupts, clear the old ones, and then read and verify the new status. Otherwise, you might other interrupts triggered after you clear the previous ones.
|Do you want me to keep this in the official driver?
In the current version it keeps printing this message when scanning.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 6: Patch Set 5 was rebased
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 9: Patch Set 8 was rebased
|Patch Set 10: Published edit on patch set 9
|Patch Set 11: Patch Set 10 was rebased
|Patch Set 11: Verified+1
|Uploaded patch set 14.
|Uploaded patch set 16.
|Patch Set 17: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

It's not finished (and properly tested) yet but I've added it for you to know it's in progress.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 5: Published edit on patch set 4
|Uploaded patch set 6.
|Patch Set 7: Patch Set 6 was rebased
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Patch Set 8:

Please let me know what you think of the code. I'm going to add a more detailed description of the block and the tests performed in the meantime.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 10: Patch Set 9 was rebased
|Patch Set 11: Published edit on patch set 10
|Patch Set 11: Verified+1
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 14: Published edit on patch set 13
|Uploaded patch set 16.
|Patch Set 15:

(3 comments)

Vadim, I fixed the repeated start code, which was causing problems before, and with this new version I'm not seeing problems during and after scan. The only remaining issue is scanning address 0. I will look into that next. Let me know how this version works for you.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 19: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1 Verified+1

Good catch!
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2:

It does not have to be included in bootblock. But it is part of mainboard initialization and until now there was no reason not to have it here. Logically, it should be either here or in board.c (Depthcharge) as both locations are board specific and they do part of the mainboard initialization, but I thought that maybe it's best to keep all clock and MFIO setup in the same place. Do you think it should be moved to Depthcharge?
|Patch Set 2:

Yes, you're right. I suppose we need to talk with the TPM earlier in Coreboot for early firmware selection.

The change is more extensive because, in order get the board ID, we need SPIM set up, and preferably UART for UART output in case of errors. Therefore, I divided the initialization in 2 parts (one setting up the basic hardware we need: SPIM and UART) and one setting up everything else, according to board ID.

I'm not sure what other hardware differences are between the boards, but in my opinion is best to have, for non-basic hardware, the possibility to set it up according to board ID.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)

Thank you for the review and let me know what you think of the new version.
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 3: Verified+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 1:

(1 comment)

It looks good. Thank you for working on this. I'll test it on the bring up board tomorrow.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2:

(1 comment)

This is just temporary (to be able to test both Urara Bub and Concerto) until we decide on a list of supported boards and compatible strings.
|Patch Set 2:

(1 comment)

Therefore, you are free to modify them (as long as you keep the values for the interfaces used).
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Code-Review+1 Verified+1

The code looks good. I've verified it on Urara Bub with both I2C0 and I2C3. 
The commit message should be changed because the latest version does not have any Concerto board but some versions of Concerto. 
Good job!
|Patch Set 4:

Yes, that's OK with me.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1
|Patch Set 4: Patch Set 3 was rebased
|Abandoned

Not needed as it was added to the I2C driver implementation.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)

Thank you for the review! I'll address your comments in the clean up commit for DDR so we can have all the stack merged.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(4 comments)
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 4: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 11.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 3.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 2: Code-Review+1 Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 2: Verified+1

(2 comments)

The implementation looks really good!
|Patch Set 3: Code-Review+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 2: Verified+1

(4 comments)

Except for that small issue with the wired register you've implemented an awesome solution here. Very good done!
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)

I've updated the description. Please let me know if there's anything else you'd like to know.
|Patch Set 5: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 5: Published edit on patch set 4
|Patch Set 2:

(2 comments)
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: -Verified
|Uploaded patch set 2.
|Patch Set 3: Published edit on patch set 2
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)

Yes, good catch. Somehow it stuck to my mind that there were 6 bit dividers and I made everything comply with that.
|Patch Set 2: Verified+1
|Patch Set 2: -Verified
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1

I've rebased this code for it not to depend on the audio and UART0 changes.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

As I said (regarding the audio clock setup), these changes were made just to have the same changes as the ones in the setup python script, and have everything set up for chip sort tests.
|Abandoned

I've abandoned this as it's no longer necessary.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Verified
|Abandoned

I've abandoned this as it's no longer necessary.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 17.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 3: Published edit on patch set 2
|Patch Set 4: Published edit on patch set 3
|Patch Set 4:

With these latest changes it boots the kernel properly. I will now work to clean these up and have them submitted done the right way.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Patch Set 6:

With this commit (https://chromium-review.googlesource.com/#/c/247642/) changes to the SPFI driver are no longer necessary.
|Patch Set 6:

(1 comment)
|Patch Set 7: Published edit on patch set 6
|Patch Set 6:

(1 comment)
|Patch Set 8: Published edit on patch set 7
|Patch Set 7:

(1 comment)
|Patch Set 8:

Dan, I think you can go ahead and abandon this change as all the fixes have been implemented separately and there is no need for this patch.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Verified+1
|Patch Set 3: Verified+1
|Patch Set 3: Verified+1
|Patch Set 4: Verified+1
|Patch Set 4: Verified+1
|Patch Set 4: Verified+1
|Patch Set 4: Verified+1
|Patch Set 4: Verified+1
|Patch Set 4: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Yes, I also checked it does not cause any trouble. I added Julius and Lin as reviewers also, as they have developed and reviewed the original DWC2 driver to make sure they agree with this change.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2:

There are also some timer functions in Coreboot and Libpayload that consider the CPU frequency 550 MHz but I'm not going to modify those for the moment as the value is close to 550 (even better, is slightly higher) and that code will be modified in the future to compute the CPU frequency and not use hardcoded values.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

You can find the base address in the functional specifications document at page 35.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Abandoned

This patched was split and uploaded properly.
|Uploaded patch set 1.
|Patch Set 1:

I had an issue at some point with spi_context not being set to 0, and triggering an exception later on. I have not been able to reproduce this now, but I'll abandon the change (as it's not a good solution any way) and I'll debug the issue more thoroughly if it re-surfaces.
|Abandoned

This patch is no longer necessary.
|Patch Set 2: Published edit on patch set 1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

This is no longer necessary as this change has the same functionality: https://chromium-review.googlesource.com/#/c/243883/
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 8: Published edit on patch set 7
|Uploaded patch set 9.
|Patch Set 10: Published edit on patch set 9
|Patch Set 10: Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Patch Set 7: Verified+1

I've modified the kernel start address to 0x81000000, the start address for the decompresser, as per established with Andrew.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Done and verified. Thank you for the review.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 6.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Patch Set 12: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Patch Set 11: Code-Review+1 Verified+1

Vadim, I changed this commit from a &quot;generate defconfig&quot; to a &quot;create defconfig&quot; as I removed the initial defconfig file from the commit having MIPS architecture support.
|Uploaded patch set 12.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 13: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3:

Yes, you are right. The script is too specific to depthcharge to have it in libpayload and having it in src/arch is a better option. I tried to find a solution to include the architecture specific parts only but the region and symbol that are needed must be placed at certain locations in memory and I could not find a way to obtain that without having multiple INCLUDE calls throughout the original linker script. Please let me know if you know of a better way to do this. The linker script for MIPS can be found here: https://chromium-review.googlesource.com/#/c/243273/.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3:

(1 comment)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

An alternative solution was found.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Abandoned

An alternative solution was found.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

This solution seems good to me. I'll abandon the alternative version.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned

An alternative solution was implemented, with UART interface selection done at board level and not driver level.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(18 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2:

You can go ahead with this change. I moved Depthcharge to the last 16MB of available memory, and I can change this at any time. 
Therefore, you need not worry about Depthcharge.
|Uploaded patch set 1.
|Patch Set 1:

(22 comments)
|Patch Set 1:

Vadim, I cannot have the same fix as the the one you did for Qualcomm here. This is related with the same problem of not being able to control directly CS. For this block, when communicating with a flash device, separating a transaction with size &gt; 64KB in multiple transactions of size &lt;=64KB, would mean asserting and de-asserting the CS between transactions. For flash devices this can be done only by re-issuing the read/write command, with a modified address on the device. This means modifying the content of the buffer being sent, and a pretty ugly hack.
|Patch Set 1:

The driver with the current logic can have the following: 
 - write != NULL, read == NULL, write_size &lt;=64KB (dealing with both flash and generic SPI devices, but constraints imposed by flash): this cannot be changed to support write_size &gt; 64KB because we cannot know if the transaction is for a flash or a SPI generic device and we cannot modify the content of the buffer. 
 - write == NULL, read != NULL, read_size &gt; 0, only for dealing with SPI generic devices; support for this can be added. 
- write != NULL, read != NULL: 
    - write_size &lt;= 8, read_size &lt;= 64KB, dealing with both flash devices and SPI generic devices, but constraints imposed by flash(write only requests data); this cannot be otherwise.
   - write_size &gt; 8, read size &gt; 0, dealing only with SPI generic devices; support for this can be added. 

Therefore, we either work around these constraints on the upper layers for flash devices (repeat write/read only blocks of 64KB data) or I can try an alternative solution (using the continue bit (see TRM) which will allow me to control the CS but might also cause some issues and will require thorough testing.
|Uploaded patch set 2.
|Patch Set 2:

(13 comments)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 3:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5:

I've added the clock and MFIO information. It might be too much information for a commit message so please let me know what should be left in the commit message and what to take out. I've added support in spi.c/spi.h/cpu.h for SPIM0 also, although it won't be used in Coreboot.
|Uploaded patch set 6.
|Patch Set 5:

(3 comments)
|Patch Set 6:

Vadim, 

I've made some additional changes to those requested by you. 
1. As per this commit https://chromium-review.googlesource.com/#/c/219719/, I've enabled HAVE_MONOTONIC_TIMER and GENERIC_UDELAY in Kconfig and added the definition for timer_monotonic_get in timestamp.c.

2. I've used the new timer API: https://chromium-review.googlesource.com/#/c/219492
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(18 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 5.
|Uploaded patch set 14.
|Uploaded patch set 17.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Patch Set 13:

(4 comments)

Thank you for the review. I apologize for the delayed reply.
All your comments are valid and everything is already modified starting with patch set 19.
|Uploaded patch set 21: Patch Set 20 was rebased.
|Uploaded patch set 22.
|Patch Set 20:

(1 comment)
|Uploaded patch set 23.
|Patch Set 20:

(1 comment)
|Patch Set 23: Verified+1

Aaron, David, do you think this commit is ready to be merged?
Please let me know if you have any other suggestions regarding the code.
|Patch Set 23: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 13: Commit message was updated.
|Patch Set 10:

(1 comment)
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17.
|Patch Set 17: Verified+1

David, please review this commit again. I removed the defconfig file as it should be committed in another CL and I made a few changes to the commit message.
|Patch Set 17: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+1 Verified+1

The code looks good and I verified that it works properly. I've also asked Zdenko to review this. He designed the BIMG format and he can recheck this.
|Patch Set 5: Code-Review+1 Verified+1
|Patch Set 5: -Code-Review
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15: Commit message was updated.
|Patch Set 15: Verified+1
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17.
|Patch Set 15:

(16 comments)
|Patch Set 17: Verified+1
|Patch Set 15:

(1 comment)
|Patch Set 17: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 4:

(8 comments)
|Uploaded patch set 6.
|Patch Set 5:

(6 comments)
|Patch Set 5:

(1 comment)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7:

(2 comments)

And.. done! ( I'm referring to splitting into 2 CLs, one generic and one MIPS specific)
|Uploaded patch set 9.
|Patch Set 8:

(2 comments)
|Patch Set 9: Verified+1
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1

I took it out of stack in order for it to be merged.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 4:

The difference between the generic 8250 UART and the IMGTEC one is that the IMGTEC one has the register offsets shifted by 2. Also the generic one (8250.c) has a lot of values hard-coded (register offsets included) and that makes adapting it to our requirements a bit harder. I thought it was better to have an additional simpler version specific to this UART.
|Abandoned

This change is no longer necessary.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)

I've also separated the changes related to board id information.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 9.
|Patch Set 9: Verified+1

David, please review this again. I took the patch out of the stack, re-verified and made a small correction to the commit message, so the functional content is the same. Thank you!
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+1 Verified+1

Ezequiel, I took this patch out of the stack in order to be merged and modified the TEST field in the commit message. I think it's ready to go it. 
What do you think?
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

I took this commit out of the stack and I think is ready to be merged. Please let me know if you have any comments or questions on this new layout.
|Patch Set 6: Verified+1

Awesome! I was just about to do the same.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

David, Aaron, yes, this did not have any reviewers yet because I wasn't sure which of the solutions we were going to go with in the end.
|Abandoned

I've abandoned this since we're going with an alternative solution.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1

I also took it out of the stack of patches in order for it to be merged.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1 Verified+1

Looks good! This solution is definitely better.
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

This is a duplicate created by mistake.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Patch Set 3:

(11 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue
|Patch Set 6:

(9 comments)

Thank you for the review and I apologize for the delay. I'll verify the new version and push it in a few minutes.
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 7: Verified+1
|Patch Set 6:

(4 comments)

Thank you for the review! I'll upload the changes during the weekend as I'm not able to test it today.
|Uploaded patch set 8.
|Patch Set 9: Published edit on patch set 8
|Patch Set 9: Verified+1
|Abandoned

Thank you for the comments, Kevin. I'll abandon this commit here and address your  questions in the commit I'll be pushing to upstream coreboot.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 5: Published edit on patch set 4
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 8: Published edit on patch set 7
|Patch Set 9: Published edit on patch set 8
|Uploaded patch set 10.
|Abandoned

No longer necessary.
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 5: Published edit on patch set 4
|Abandoned

No longer necessary.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3:

No (or at least not as far as I know). I added this because we are using firmware+kernel for some chip tests and for the moment (also as far as I know) these are not set up in the kernel and they won't be for a while.
|Patch Set 4: Published edit on patch set 3
|Abandoned

No longer necessary.
|Patch Set 1:

(3 comments)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned

Thank you for the comments, David. I'll abandon this commit here and address your  questions in the commit I'll be pushing to upstream coreboot.
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Abandoned

This commit will be submitted to upstream coreboot and discussed there.
|This initial state has to be based on ROP_EC_RSMRST_L (GOPI63). PMIC_DPWOK is unpopulated.
|No sure if SUS will be available while going from G3-&gt;S5. It is available only after GPIO_PCH_RSMRST_L is asserted.
|we can get to S3S5 at once or transition step wise basically S3S0-&gt;S3-&gt;S3S5
|GPIO_PCH_SLP_S3_L is low here.
The logic here seems correct for warm reset. In S0 we turn off GPIO_PCH_SYS_PWROK since IN_ALL_S0 was lost. we recheck for SLP_S3 in S3 state as it will be set during warm reset.
|I understand it is confusing. we went through this as well. There are only few signals in Braswell compares to other SOCs. IN_PGOOD_ALWAYS_ON is the signal coming from platform/board. This is expected to be always on else we have to shutdown the system. To transition from S0 to other states as necessary signal like( IN_ALL_PM_SLP_DEASSERTED ,IN_PGOOD_ALL_CORE) = IN_ALL_S0 ) were lost. I separated them out.
|We will clean up some of the naming convention.
|That is a different issue Kevin. it is related to wedging and not related to multiple port support.
|You will have to hold all the controller mutex before we start scan as we wont know which one is already held. so not sure how this could be feasible.
|I might be missing something here. But what I meant is in scan console command which can happen when in middle of xfer..

static void scan_bus(int port, const char *desc)
{
	int a;
	uint8_t tmp;

	ccprintf(&quot;Scanning %d %s&quot;, port, desc);

	/* Don't scan a busy port, since reads will just fail / time out */
	a = i2c_get_line_levels(port);

you see to get the i2c_get_line_levels... we alter the port.
|I feel there is likely hood that we will intercept one controller to another. Say we are in the middle of a transaction. if from a console command we execute say scan then in scan we will select the port / alter the port and then check if bus is free.

This is like a race around. to check if bus is idle we need to change the controller.
|yes.. we will correct this. But wrt the issues we are seeing this will not matter as this will come into place for software sync feature which is not enabled yet.
we will alter the patch anyway to the right size.
|Yes. I will re-visit this as part of sw sync patch.
|agreed. But this file was deleted in the last commit and longer exist. All the required functions are moved to flash_external. If pstate is not needed. all of the related we will alter.
|The starting page boundary had to be 256-byte page boundary. The highest common divisor to so less number of SPI transactions was used.Not sure if the same is applicable to winbond. Atmel needed this. will need to validate software sync with winbond.
|get_base() returns the base memory location where the code start execution.
get_base_external() returns the location of the SPI flash start address where the RO/RW code resides.
|if we move them to flash_internal and flash_spi then this function will have to still use the CONFIG_FLASH_EXTERNAL as this function is used for vboot hash calculation
|will allocate another small buffer for version. they will intercept as console is interrupt driven.
|will change
|will do
|I will re-evaluate this one again without the wait. there were some changes at SPI driver needed as well. so not completely sure if this is still needed.
|When successive writes are happening.. if previous was not completed the spi_flash_write_enable was returning with an error and timeout.. SO I had added this wait before we attempt to do write enable
|Vboot calculations were done for image that was residing in internal flash. In case of Mec the Flash is external and hence SPI transactions are needed to get the code and then perform Hash calculations. 

Vic: This file changed can be made part of comon/vboot_hash.c. with a compile time option. Shall I go ahead and do so?
|will do
|yes. a different name is better.
|can be removed
|This has to be removed
|pstate was persistent memory trying to replicate actualt flash. Since we are using actual flash set and get protection logic for an SPi flash will be different and pstate will not be needed. This was Randall's Comment and I feel that is correct.
|same comment as above
|can be removed
|info / offset will be different
|Sheng: WHat ever you are suggesting has to be made part of this section. It will be applicable to all ECs not just Mec. Just FYI.
|Please Note: This end byte added to end of RW image was removed because SW sync would always show Hash mismatch as coreboot RW image did not have this. Not sure how other products worked. Please advice.
|Ok.. The SHA 4 bytes will have to be accessed by ec.lds.S and be inserted. Then it will have to be checked here to conclude if the Image is RO. Will have to see how to get this done.
|The requirement is to have a way to differentiate RO image to an RW image. yes I agree 0xEA alone is weak.but may be just 4byte unique number predefined should be enough right? need not have to vary for every compilation. just a thought.
|I will be uploading the architecture patch with this change once the flash patch gets merged in.
|Ideally I think spi_enable should be done is spi_flash.c file functions?
This one is a common folder file and hence didnt want to alter it.
The other place which is specific to this ec would be in chip/mec1322/flash.c. But if we add it only in this file then console commands in spi_flash.c wouldn't work. any thoughts?
|Yes agreed for the loader we should enable and disable around the loads of image. in case of the RO/RW image the Flash is accessed only Via Host commands and Flash write is done in mutliple chunks. will have to enable and disable for each Host command access.
|Yes. Agreed
|Will do
|Vincent any comments?
|In Braswell Refence design the inversion is handled in the software
|Will remove it
|Can be removed
|This is the only file related to braswell power sequencing. Please give more details on what duplication meant
|We can. We just followed how samus was set up.
|will be changed to 4 usec
|Yes this needs to be cleaned. Had added this during Power On. Needs to be fine tuned and cleaned up
|will be changed to 4 usec
|Will fine tune and reduce the delay.
|will do
|We haven't validated it. Took it from lm4/lpc.c I guess.Also, The comment in this function explains about SERIRQ and we are using GPIOs. Will need to validate this.
|Oops merge problem..
|This is enabled when Mec SRAM architectural change is uplloaded. we can remove if you wish. I have just disable it here and enabled in the next commit.
|Thought about it but the line was looking too long anyways will do it.
|If we should not change this. then how about we add
CDRAM (rx) : ORIGIN = CONFIG_CDRAM_BASE + CONFIG_RO_MEM_OFF , LENGTH = CONFIG_CDRAM_SIZE

in the ec.ld.s file ?
|Do you want to add back HOOKS_SYSJUMP ? I will keep your old implementation back.
|Coderam enabled code is building RO + RW images. Loader/lfw has its own ld.s file. RO and RW images base address is 0x100000 + 0x1000 ( lfw size) hence this is correct. when you open the ec.bin in hex editor it is clear the RO / RW images are not configured with right addresses.
|Its not including.. I have viewed the binary address in the generated ec.bin. all the function addresses are offset by 0x1000. without this system is not booting.
|If flashwrite is with an i.. I think to maintain commonality an i and a for loop is ok here.we will need to change for write as well then.
|May not be but since we know these are some time consuming it is safe to add it.
|Done
|Kept it same it was initialized in other projects and included in include/system.h
|Done
|we also send the copy to of image type as a parameter. You will need to have 2 functions doing these 2 items them.
|When CODERAM_ARCH is enabled the base for MEC for RO and RW will be same. 

Instead of sending base in here how about we send copy and locally lculate the base?

In npcx also sending base and calculating inage type and then re evaluating the base again seems like a round about method
|sorry about the quick liner.. I do see that its needed for npcx.
|I don't think these new ORIGIN is any different from FLASH (rx) feels like we have just added 2nd level of referencing to do the same thing as before then with new naming. 

Just an opinion at the first look. If you have any new architecture for which this makes sense which I am not aware of then we need this.
|This is not a valid address for MEC to do an SPI transaction to get actual version. The address calculated here is still the storage off. we will need to add the actual SPI base adrress to this storage offset to do the flash_read
|when we want to version of RO and RW, in case of MEC we will be just showing the image that is Running. as the CONFIG_R*_MEM_OFF are same.
|In case of MEC version console command will not give the actual version of RO and RW. it will just give the version of the image executing in CODERAM
|They were to make sure code is readable. As you want shawn.. will just change it.
|will do.
|The code will not look readable. Hence added a comment.
|Erase is also going to invalidate.
|Done
|Done
|I think we will need to abort in flashread also but we will not need to invalidate. The reason being if vboot hash reads and flashrom flash reads happen simultaneously then we will repeatedly run into priority inversion case if vboot hash grabs the mutex first. This will also result in longer flashread.
|Not sure at this point what the best way is to implement this. vboot_hash_in_progress() is checking for in_progress variable which is again checked in vboot_hash_abort() before aborting the hash.

will go ahead and add the else.
|To retain value between sysjumps we can use VBAT registers as well.Just a suggestion
|In FAB3 The PMIC fault/shutdown is caused due to 1.8A(de-asserted by SLP_S4) and 1.8U(deasserted by SLP_SUS) are not meeting the timing requirement as per the volume PMIC. This masking of emergency shutdown is needed in FAB3 as SLP_SUS directly goes to PMIC. Hence making the fault helping reboot and shutdown in FAB3.

The crosbug TODO comment mentioned here is confusing. 

In FAB4 SLP_SUS is routed to PMIC Via EC. So to fix the fault 
1.we can either have EC make sure the timing needed between the 1.8A and 1.8U which is 32msec can be met by EC. OR 
2.We can keep this mask as is. 
One of the above options help Shutdown / G3 to work. But for reboot since the HW requirements are going thr some changes this masking is not applicable for reboot.

This patch will unblock reboot and shutdown issues in FAB3 and only shutdown in FAB4(if we go with option2). It will be good if we can get this merged in.
|I was confused too Shawn. But the parameter getting passed is actually the controller, not the port hence used controller. Yes, will use Port.
|Ideally as per the smbus spec master cumulative timeout is 10msec and slave cumulative timeout is 25msec. We have confirmation from the TI charger buys that if the master hold the clk low for ~20msec then their controller gets reset. which is what our test results show. Hence we conservatively programmed the slave cumilative timeout timeout to 15msec

So to answer your question. depending on the peripheral tolerance we can choose to change. programming it to 15msec we are assuming if a transaction does not complete within 15msec we most likely will end up with an erroneous transaction.
|Shawn, the problem is the caller does not have port info.. it has only controller.Will see how to get port info in the caller.
|wait_byte_done and config_controller call the port_is_smbus() function. Both have only controller info. Will see how to clean it up and send port info.
|The datasheet I was given mentioned the Charging Voltage to be 13050. The hardware engineer confirmed the value to be right.
|I got 9100mv as the number to be programmed from the hardware engineer
|We have done the measurements and found the difference to be &lt; 1mW
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 8:

(2 comments)
|Patch Set 2:

Please rebase to the latest braswell.c.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

This is easy to maintain. If we have to create the right size image then every Tool flashrom,mosys.. should know the EC right size used for the board. ALso Software sync will need the right location of RW offset which means coreboot and depthcharge should know the right offset as well. 

The rest of the SPI is anyway not used. so reading writing erasing those location is just going to increase updates.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 4:

(1 comment)
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1

Just a Note: logically this is ok but when a bus is busy 
if (a != I2C_LINE_IDLE) {
		ccprintf(&quot;: port busy (SDA=%d, SCL=%d)\n&quot;,
			 (a &amp; I2C_LINE_SDA_HIGH) ? 1 : 0,
			 (a &amp; I2C_LINE_SCL_HIGH) ? 1 : 0);
until it gets freed we will see spur of prints 	. Well nothing much can be done I guess.
|Patch Set 3:

(1 comment)
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4:

(1 comment)
|Patch Set 6: Commit-Queue+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

will do.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 4: Verified+1
|Patch Set 5:

Sorry missed out on the &quot; CONFIG_FLASH_MAPPED --&gt; flash is memory-mapped to EC's address space (that is, hashing code can directly read it)&quot; 
yes, flash_spi can be moved to chip/mec1322/flash.c .The code itself does not have any chip specif stuff in it but the since the functionality itself is very specific to MEC. 
The common/flash.c will still have to be split into flash_common  and flash_mapped(or something else) so that mapped has pstate (not needed) and protection which is different for MEC.
|Abandoned
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

Will enabled another patch to support software sync.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated
|Patch Set 3:

(3 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

Yes, chip/mec1322/flash.c can move to common layer. how to we name it so it does not create confusion with the existing flash.c. 

This file can be common/flash_ext_spi.c and the existing flash_ext_spi can just be added to the common/flash.c with relevant address mapping changes ?
|Patch Set 3:

The common/Flash_ext_spi.c feature difference from common/flash.c would be:

1. Address manipulation   
2. Protection Log and sequence.
3. Console commands to do flash read.

TO have the difference in a single file and #define will compromise the readability. 

but yes chip/mec1322/flash.c feature can be moved to common/flash_ext_spi.c. 

open to change...and discussions
|Patch Set 3:

(1 comment)
|Patch Set 3:

Agreed!.. Will upload the new patch.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(6 comments)
|Uploaded patch set 8.
|Abandoned

splitting them into smaller chunks. Adding code for review on strago-mec branch
|Uploaded patch set 1.
|Patch Set 1:

Randall,

   Shawn has mentioned to keep pstate implemenation. I think we dont need it as you had mentioned earlier. whats the decision on that?
|Patch Set 1:

sorry for interpreting it wrong. Looks like your suggestion can be done. will upload the patch with this change and we can take a look.
|Abandoned

splitting into smaller patches
|Uploaded patch set 1.
|Patch Set 1:

(7 comments)
|Abandoned

Too many patches with same support. Adding the patches on Strago-mec branch for review
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 1:

Sheng I will upload this patch and we can review it again.
|Patch Set 1:

(1 comment)
|Abandoned

Will be re uploaded with updates
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1

sp
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1:

s
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned

Clean up needed. Will re-submit the changes.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(8 comments)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned

Hardware not supported.
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(7 comments)
|Uploaded patch set 10.
|Patch Set 10:

(2 comments)
|Patch Set 10:

(1 comment)
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

Will https://chromium-review.googlesource.com/#/c/274434/ rebase the patch and make the changes once this patch is merged as CODERAM cannot be enabled without this patch.
|Uploaded patch set 13.
|Patch Set 13: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 14.
|Uploaded patch set 16.
|Patch Set 16: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue -Verified
|Patch Set 4:

Vincent can I CQ this one? Do you have more review to do comments? As Kevin mentioned we did try adding the fix to HOOK_SYSJUMP but since interrupts are disabled before sysjump hook is called and I2C transaction waits for completion interrupt this will result in watchdog.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 4:

Sorry.. Yes this should work. as Flashread itself handles the actual offset.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue -Verified
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 8: Code-Review+1
|Patch Set 8: Verified+1
|Patch Set 8: Commit-Queue+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

https://chromium-review.googlesource.com/#/c/273710/ this was already +2 and Since it was having a dependency I was trying to add it as a new patch so that it is available for testing. Looks like buildbot already picked up https://chromium-review.googlesource.com/#/c/273710/ for merge.
|Abandoned

https://chromium-review.googlesource.com/#/c/273710/ is a duplicate and hence abandoning it
|Patch Set 1:

Its my bad. we should be able to read byte by byte. only when we ran FAFt test some test failed and we realized this condition was causing it to fail.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 4:

Shawn.. More testing is needed with this patch. Please hold review on this for now.
|Patch Set 6:

Can you also tell me what time it takes for reads.
|Patch Set 6:

Can you also explain why other projects also have watchdog_reloads while doing SPI transactions?
|Patch Set 6:

May be some inputs will help
|Patch Set 6:

From datasheet as per Andrey 
Max Write time can come upto &gt;2sec
Max Read time ~ .5sec  
Need to check Flashread. 
we have Host command coming in continuously and in between these   chargertask and port80 which are higher priority tasks kick in as well.Hook being the least priority task watchdog reload will be starved? Can you please explain more on why usleep should be able to reload watchdog?
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 10: Verified+1
|Patch Set 10: Commit-Queue+1
|Patch Set 1:

Shawn,
  
This was introduced https://chromium-review.googlesource.com/#/c/273956 

Hopefully we did not enable something you fixed
|Patch Set 1:

This was the same file which was part of https://chromium-review.googlesource.com/#/c/272000/15

I did not add it in the end as we had the write protect implemented. But unfortunately looks like WP needs more validation. It will be helpful if we unblock flashrom.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 5:

Shawn.. This patch will need clean up depending how we want to upload little FW. we cannot have Spi_enable.. disabled everywhere and just enable it only in little FW. little FW is not getting updated via flashrom so this is dangerous at this point of time
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Patch Set 1:

I will change the naming but moving it to upper layer.. Not for this patch. There is enough testing done for this patch and I would not want to theoretically predict any behavior and change the timing. I can move it later and we have BKC testing on a regular basis. so we will upload a tested code.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

Yes you are right. Sorry had not seen that. I will go ahead and vboot_abort instead of invalidate which does abort conditionally. 
I will check if its vboot is in progress and abort.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Abandoned

Handled in 
https://chromium-review.googlesource.com/#/c/282111/
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1
|Abandoned

Not needed anymore
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

https://chromium-review.googlesource.com/#/c/283605/

Once this lands we can mark this verified
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

https://chromium-review.googlesource.com/#/c/283605/

Once this lands we can mark this as verified.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Verified+1
|Patch Set 1:

Is it ok if I add 
#define CONFIG_USB_PORT_POWER_SMART
#define CONFIG_USB_PORT_POWER_SMART_SIMPLE 
as part of this CL itself?
|Patch Set 1:

Never mind I will rebase this as it has merge conflict. will upload a new patch with enables
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

Please change this to mec1322 instead of BCRD
|Patch Set 1:

Alec,  Can you help us get this reviewed and merged.
|Uploaded patch set 2.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

Thanks for the comment..Yes I do see that we are enabling and disabling the USB ports as part of power/braswell.c and dont have full knowledge at this point on if these are covered in the SMART power control. I will get back to you on that.

Can we have this merged in and I will get back with removing stuff as another patch?
|Patch Set 1:

You are right. we don't need to have the USB enabled in power/braswell.c. HOOK_CHIPSET_RESUME and HOOK_CHIPSET_SHUTDOWN take care of enabling and disabling the USB in the appropriate power states. 

But HOOK_CHIPSET_RESUME  is happening in S3-&gt;S0. and currently we are enabling the USB ports in S5-&gt;S3 which means if we remove them USB is powered down during S3.

USB is a wake source in S3 ? I see that its a config option in Rambi CONFIG_USB_PORT_POWER_IN_S3 and this is enabled.
|Patch Set 1:

From the power state flow S0 we have USB enabled. S0-&gt; S3 USB will be kept enabled. In S5 USB is disabled. There is no state where we go from S5-S3 and stay there. So I will remove the USB enabled/Disable in power/braswel.c
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

Done as part of 

https://chromium-review.googlesource.com/#/c/283593/3/power/braswell.c.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

So expected behaviour is:

From PG3 -&gt; when AC is detected and Lid is closed -&gt; we go to S0 -&gt; AP determines Lid close -&gt; S5 ?
|Patch Set 1:

Just curious..
When Ec can decide if we need to exit G3 state or not why do we need to boot all the way an then shut down again?
|Patch Set 1:

Please explain first 'Real Boot'
|Patch Set 1:

Lid open is a wake event from PG3 so system will start from RO and SW sync will happen. if Hashes dont match. 

From PG3 we stay in G3 until the lid is closed. when lid is open we exit G3 to S0. So can you please let us know what is a difference in expectation.
|Abandoned

Not an expected behaviour. Hence abandoning the patch.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1:

We do know where in acpi the locked mutex is not released. we will upload that as well. This patch was to make sure we Charger task will still continue charging and does not get locked up.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch firmware-strago-7287.B as commit f12961a809d5681ff128d8933e73cbf060e84cb2
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

This will affect Kunimitsu also right?
|Patch Set 3:

(1 comment)
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch master as commit f578ffac05ae1417db8e1d22401f70f4c6110d53
|Patch Set 1: Cherry Picked from branch firmware-strago-7287.B.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

Shawn,

Please note we will continue to work in parallel to root cause this issue.But we are doing our best we can for Cyan and its deadline. We will post our findings soon on crosbug when we have more data on the root cause
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1:

Please disable the Als_task if Als init fails.
|Patch Set 3:

Shawn,
Setting this to LOW from EC side will make it HIGH on SUS5 as there is an inverter.
HIGH on SUS5 translates to :
'1' : No override
'0' : Flash descriptor override is set.
So setting it to '1' will enable Lock.
|Patch Set 5: Code-Review+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

(2 comments)
|Uploaded patch set 9.
|Patch Set 9:

Shawn,
chipset_get_ps_debounced_leve I feel will not be needed , as the whole point of the defferred function is to detect the level of SLP_S0 and determine if we need to exit S0ix state seeing the SLP_S0 level. we dont need to detect the exact state on every transition of the SLP_S0.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1:

system_is_locked() seems to return 0 always and overrides the charge_prevent_power_on() and gets the system to boot up under 0% battery . Could you please let us know what is the expected behavior for system_is_locked() ?
|Patch Set 1:

Can we combine the logic of Charge limit initialization and 1% battery ?
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 1.
|Abandoned
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch firmware-glados-7820.B as commit 8d4043aef7ab35ff357a5a7423d6cc0998f20391
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Code-Review-1
|Patch Set 1:

We should be able to do this in the HOOKS that already exist
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Removed the following votes:

* Commit-Queue+1 by Divya Jyothi &lt;divya.jyothi@intel.com&gt;
* Verified+1 by Divya Jyothi &lt;divya.jyothi@intel.com&gt;

|Patch Set 6: Code-Review+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch firmware-cyan-7287.57.B as commit 632c8d7186c72b58f9f795b0688cca42b5093ffd
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch firmware-glados-7820.B as commit 0b03e74999d918d4ddf7d57c60c101ed1e8e5218
|Patch Set 1: Cherry Picked from branch master.
|Abandoned
|Restored

Sory.. Felt me and Divagar Cherry Picked them.Restoring it back
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch firmware-glados-7820.B as commit 61442b959d5ae8e9bcd89a9198dfb7c3b0022aff
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 4: Code-Review-1
|Patch Set 4:

Ryan, Please hold on. we are in talks with DTPF approach still. Once we get a clear go we can go with EC based approach.
|Patch Set 2:

Ryan,

   Why is this reverted? We will need ALS to alter the PWM value of the Keyboard backlight which is part of some Lars skews right?
|Patch Set 2: Code-Review-1
|Patch Set 1:

Ryan,
   Why is this reverted? We will need ALS to alter the PWM value of the Keyboard backlight which is part of some Lars skews right?
|Patch Set 1: Code-Review-1
|Patch Set 3:

(1 comment)
|Patch Set 3:

Not sure how to put the code behind a #define CONFIG_POWER_S0IX
This will be common configuration for S3 and S0ix.
|Patch Set 3:

Ok makes sense. will add the compile time option in entry and exit of deepsleep.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 6: Cherry Picked

This patchset was cherry picked to branch master as commit 99625a2ae1ebb6afeeb029f998eb47c59d7736b9
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1:

Duncan,

  Please +2 the branch patch as well.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch firmware-glados-7820.B.
|Patch Set 1: Commit-Queue+1 Verified+1
|I should probably update this so that if is_async is True, the use_signals must be False.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I don't understand your comment.  What is wrong with my git settings?
|Will Do.
|typo:  cros/master
|remove extra space
|remove extra space
|remove extra space
|&quot;Silence&quot;
|silence
|silence
|making this
|Why do you need to insert the slash here?  We've already previously verified that FLAGS_remote_file begins with a slash.
|Same as previous comment.
|I think I prefer doing it in the cleanup routine.
|No...what would really be best (probably) would be if there were some way to cause the .gdbinit file to be deleted after the user exits from gdb; that way it would only exist if the user ran the gdb_remote script and entered gdb from it (which implies that gdbserver is running on a remote device and the remote_connect command must succeed).  I'm not sure how to do this...
|If you do this, then every time the user starts up the cross gdb by hand, it will automatically try to connect to gdbserver, even if the user is not running the gdb_remote script...I don't really like this.
|Adding 'other helpful gdb commands' is fine (please do specify that they are gdb commands), but I would really prefer that you leave the original wording for the remote_connect command.  The user it not trying to reestablish a remote connection; the user is trying to get gdb to find/connect to the already running gdbserver process, for the first time, on the remote device.
|I'd be happy to, but I'm not sure how to do that?  What change, precisely, do you suggest?  (I originally went to change the gdb ebuild file, but Mike Frysinger said that I should make the change her instead...)
|Why shouldn't this be:

sudo ln -s /usr/local/usr/lib/debug ... (notice the second 'usr') ?
|Yes, this is supposed to be an underscore.  (Due to difficulties creating CLS, another story, I've had to re-do these edits about 5 times, and I made a typo here.  I'll fix and re-submit).
|I thought this was necessary here; I will try removing it and see if the build still works.
|This *is* the same location where gcc-libs installs them.  

I just tried removing this file from my chroot, then tried running setup_board for a  new board, and setup_board failed trying to find this non-existent file:

ERROR   : Fatal: Missing upgrade hook for 60

How do I make my chroot forget the file ever existed?  And how do I remove a file from an uploaded CL?
|Ok.
|This file was copied directly over from the gcc ebuild file, then the unnecessary parts were deleted (i.e. I did not write this part).
It appears that this allows faster access to the gcc sources by checking them out from the git mirror site rather than from the svn site.  This appears to be disabled by default.
|This is for one of the configuration flags that is passed to the compiler during its configure/make build process.  I will add a comment to that effect.
|Either the src_configure that is run automatically is not the one in this file; or it gets called at a different time.  If I comment out this call to src_configure, the build dies.
|Ok.
|Format fixed; comments removed (this was accidentally left over from something else).
|I don't understand this comment.
|Ok. I'll fix this.
|I'll fix this.
|I'll fix this.
|Could you be more explicit?  How would I go about doing this?
|I'll fix this.
|I didn't write either this code or this comment, so I can't expound on it.
|I do not know (I did not write this); I am guessing it's a reference to a bug number.  I can remove the  comment if you wish.
|If I make that change I get complaints when I try to emerge-stumpy gcc-libs:

[ebuild   R   ~] sys-libs/gcc-libs-9999 to /build/stumpy/

The following keyword changes are necessary to proceed:
#required by gcc-libs (argument)
&gt;=sys-libs/gcc-libs-9999 ~amd64

NOTE: This --autounmask behavior can be disabled by setting
      EMERGE_DEFAULT_OPTS=&quot;--autounmask=n&quot; in make.conf.

Use --autounmask-write to write changes to config files (honoring CONFIG_PROTECT).
|Just asking for clarification:  Delete the entire &quot;DEPEND&quot; definition?  If not the whole thing, then which part?
|Ok, I will try to fix that.
|It is test_that that splits up the arguments.  I have no control over that.
|We can (and do) control the order of the arguments, from crosperf, and currently in crosperf we are forcing the profiler args to be the last argument.  Since, as I mentioned in the previous comment, it is test_that that splits up the arguments, I don't think this can be fixed (certainly not by us) at the moment.

Aviv, how hard would it be to fix test_that to respect the quoted args within args? What is currently getting passed to test_that is:
--args=&quot;iterations=1 test=octane pageset=octane.json profiler=custom_perf profiler_args=&quot;'record -a -a -e cycles,instructions'&quot;&quot;
|Yes, crosperf does exactly what Simran describes above, so if this is invoked correctly via crosperf them /tmp/chrome_root will exist.  The check is here in case this autotest was not properly invoked.
|Ok.
|What do you mean by &quot;a mailing list for toolchain&quot;?  
AUTHOR=&quot;cmtice@chromium.org c-compiler-chrome@google.com&quot; ?
|I'm sorry, I don't understand this comment.  Could you clarify please?
|Probably nothing....I started by copying a different autotest.
|Ok, will do.
|No, I can't do that.  That is what I tried originally and the tests fail.  For some reason, you have to be IN the /var/cache/distflles/target directory in order to run the run_benchmark script successfully (using the relative path name).  If you are somewhere else and try to run it with the full path name, telemetry fails.
|I will change that.
|It's already a constant string here...  Why would pulling it out of a constant string just to put it back inside the constant string be a good idea?
|Is the fix in my new patch acceptable?
|Ok will do.
|utils.run does not have a cwd argument.  chromeos_test/common_utils.RunCommand does have a cwd argument.  I don't enough about autotest to be sure if it would be ok to change the utils.run command here to use the common_utils.RunCommand, or if that would be a problem.

Could someone from the test team please comment on this?
|Simran, could you be more specific? What do you think the problem with doing a 'cd' might be?
|Won't this die horribly if the user didn't pass 'profiler_args' in the args list?  Shouldn't there be some default value for p_args?
|If you call profilers.add with None for p_args, will that be OK?  If so, then I think the default should be None...
|type: &quot;Firs&quot; -&gt; &quot;First&quot;
|It looks like self._minimal_telemetry will always be true.  Is that what you intended?
|Maybe you should change/remove the '@google.com' email?
|I think maybe you should use double quotes here?
|typo: creage_gcov =&gt; create_gcov
|Is this the right githash?  Should we maybe use &quot;svn-mirror/google/gcc-4_9-mobile&quot;?  (I don't know for sure which is right, I'm just asking...)
|Same comment as other file:  Is this the right githash to use, or should be we be using &quot;svn-mirror/google/gcc-4_9-mobile&quot; (I don't know which is right)?
|same as previous comment
|Done
|Done
|Done
|I don't understand your comment here.  Is it about the double quotes, or is there some other function you think I should be calling?
|I don't think is has to be True; I'll set it to False.
|Done
|Done
|Done
|Done
|Yes. Done now.
|Done
|Yes (sorry!).  It's gone now.
|Ditto.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I had not sync'd my repo for a couple of week. I have sync'd it now and fixed this.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I'm not sure I understand what you are requesting here.  Do you want me to pass ping=False to ChromeOSDeviceHandler, and then call the ping myself?  (In which case, I don't understand why).
Or do you want me to add &quot;--no-ping&quot; as an option to cros_gdb.py, in which case I still don't understand:  Why would I ever not want to verify that the remote is alive and well before attempting to attach to it?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Not quite, but the whole list is now on one line.
|Done
|Done
|Done
|Done
|Done
|Since I originally was also making a similar change for getting the pids from the machine (which is used in cros_gdb.py), it seemed appropriate to make this change as well.  But I don't mind removing this change. Will do.
|I am trying to put remote-access-type functions in remote_acess.py.  In an earlier review you said that it would be appropriate to ask a remote device for a list of processes running on it, but that the displaying of the data was not appropriate for remote_access.  Here I have tried to break it up so remote_access.py has the function to actually query the device about running processes, and the code here calls that function and displays the results.
|Ok, I'll put back the calls to gdb_remote for now.   I don't understand the rest of your comment.  What gdb-related functions do you think should be here and why do you think this might be a better place for them than the cros_gdb.py script?
|Ok, will do.
|I disagree with you on this point.  Although the function is only being called from cros_debug at the moment, it is a general function relating to the what's going on on a remote device; there is nothing debug-specific about this function, so I believe it belongs here with the other general remote device functions.
|Ok.  I'll make this CL depend on your CL.
|What is wrong with using cros_build_lib.Die a lot?  And why is it better to create and exception class and raise exceptions?  I personally prefer using cros_build_lib.Die because I find it a lot cleaner and less confusing (from a user point of view):  It gives me a clear error message without cluttering my screen with a lot of backtraces that make it look like there was an error in the Python program rather than a user error (which is what most of my calls to cros_build_lib.Die are).
|I'm only catching the ping error that remote_access automatically raises; that way I can give a nice clean error message to the user (the device you're trying to use is not up) rather than giving a messy exception backtrace (see my response to your comment about cros_build_lib.Die versus exceptions).
|Except that it doesn't just nicely tell the user this; it also dumps a backtrace on the screen, which I prefer to avoid if the cause is bad user input.  I'm just catching the exception and then only printing out the error message before exiting.
|Except that that does not work across method boundary lines.  I use the agent/device that I initialize here in the methods FindRemoteProcess and StartGdbServer, as well as here.
|See my previous responses about catching/handling ping errors.
|Ok, will do.
|Please clarify (I found your comment ambiguous):  Are you saying it's ok for me to check for the missing port and tack it on, as long as I allow users to enter it directly (via the standard parsing script).  Or are you saying that I must not tack on the VM port if users omit it?
|I still need it for setting the special remote port number for VM's but I will not set the port forwarding stuff here.
|Again, I have to disagree with you.  I will implement the remote logic that allows users to enter &quot;localhost:9222&quot; as a remote.  But allowing them to do so will not force them to do so.  In the case where the user only specifies &quot;localhost&quot; I still will need to tack on the correct VM port myself.
|Done
|Function is gone. So is the comment.
|Done
|Done
|Done
|Done
|Done
|Done
|I launched the port forwarding process via os.execvp:

sys.exit(os.execvp(port_forward_command[0], port_forward_command))

After reading your comment above, I have been playing with this trying to figure out how to get a process handle out of the command, for later use in killing the process, but I have not been successful.  How do I get a handle to use for killing the process?
|This function is gone now. So is the comment.
|Done
|ok.
|ok; removed.
|Done
|Ok, will do.
|No, the board cannot always be detected automatically.  In those cases where we are specifying remote debugging, then it can, but in those cases where we are doing local board-specific debugging (with or without qemu) there is no way to automatically detect which board we are supposed to use.  Therefore I still think this should be a required option.
|Since the proper way to invoke this script is via 'gdb-lumpy' or 'gdb-daisy' or 'gdb-peppy', etc., the board should really always be there and be supplied by the gdb-%{BOARD} script that calls this under the covers.  Since that is the case, if the --board flag is missing for some reason, then I think it should be a real error.
|I did not realize that; will do.
|The problem is that there are two programs actually being executed (gdb and the program being debugged) and they can BOTH take arguments.  So no matter what, additional arguments to one of the two must be specified by a flag, and additional arguments to the other just come naturally at the end of the command line.  As I have implemented it, arguments to the program being debugged are specified by a special flag, and extra arguments to gdb itself come at the end of the command line.  I can switch the two and make gdb arguments be the ones specified by a command line flag, but I can't get away from having to use a flag to collect arguments for one of the two programs.

At the moment, the name of the program to be debugged is considered to be an argument for gdb, so right now 

gdb-lumpy  /tmp/foo

just works.  If I switch the flags, then the name of the program being debugged would have to be shifted to 'arguments-to-the-program-being-debugged' (i.e. arguments to itself), which seems a bit weird to me, but could be done.
|Done
|I'm sorry but I really don't understand your comment here; could you explain a bit more?  What is broken?  What arguments do you think it should handle that it can't right now?
|Done
|ok.
|Since this script was supposed to be a replacement for gdb_remote (among other things), I was trying to keep the same flags and interface as much as possible.
|Again, thinking about the non-remote-debugging case, I think it is better to leave this flag as --remote_pid, to avoid confusing people doing local debugging into thinking this is how to specify a pid for local debugging.
|Done
|Done
|I tried to follow your (Mike's) suggestion and embed this directly in the logging.info command below, but I could not find any way of formatting it that made the linter happy.
|Done
|Done
|Done
|Done
|I've re-set my git config --global user.email.  I don't know whether or not it will take effect for this CL.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|If I remove the except clause altogether I get a python syntax error.  I will try to modify this to just pass the exception along.
|if self.remote and self.remote == 'localhost':
      self.remote_port = 9222
      self.ssh_settings.append('-L%s:localhost:%s' %
                               (self.gdbserver_port, self.gdbserver_port))
    try:
      self.cross_gdb = self.GetCrossGdb()
#    except Exception as e:                                                               
#      raise e                                                                            

  def VerifyAndFinishInitialization(self, device):
    &quot;&quot;&quot;Verify files/processes exist and flags are correct.&quot;&quot;&quot;
    if self.remote:


When the 'except' and 'raise' lines above are not commented out, the script works just fine.  When I comment them out I 
get the following python syntax error:

Traceback (most recent call last):
  File &quot;/mnt/host/source/chromite/bin/cros_gdb&quot;, line 142, in &lt;module&gt;
    commandline.ScriptWrapperMain(FindTarget)
  File &quot;/mnt/host/source/chromite/lib/commandline.py&quot;, line 873, in ScriptWrapperMain
    target = find_target_func(target)
  File &quot;/mnt/host/source/chromite/bin/cros_gdb&quot;, line 128, in FindTarget
    module = cros_import.ImportModule(target)
  File &quot;/mnt/host/source/chromite/lib/cros_import.py&quot;, line 43, in ImportModule
    module = __import__(target)
  File &quot;/mnt/host/source/chromite/scripts/cros_gdb.py&quot;, line 100
    def VerifyAndFinishInitialization(self, device):
    ^
IndentationError: unexpected unindent

It looks like python is trying to read the next method definition as part of the try clause...(i.e. without the 'except' statement it can't find the end of the 'try').

If I remove the 'try' statement altogether then there is nothing to catch/handle the exceptions, since this __init__ method is not inside a try-block at a higher level.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I don't understand this comment?  Where else is this logic?
|This needs to be sorted rather than just returning an error, because (for example), when looking for the main chrome browser process, there *will* be multiple /opt/google/chrome/chrome processes running on the DUT, and the one the user really wants is the 'main' one, which is the first one, which is the one with the lowest pid.
|Ok, I will find an alternate way to identify the correct pid.
|Done
|Done
|Ok, I will check the tables before adding an entry.
|Yes, every time you start gdbserver.  I am not aware that this does any harm.  If you know of a good way of checking to see if this has already been done, I would be happy to do that.
|Done
|Done
|Done
|Except that self.sysroot is not '/' in the self.remote case, so I can't merge them.  (If we are using self.remote, then self.sysroot == /build/$BOARD).
|ok will do.
|Removed duplicate assignment.
|Fixed.
|Done
|Done
|Done
|Done
|This file contains a lot of stuff that has nothing to do with remote debugging, as well as the remote debugging things.  It is designed to be the one-and-only local-as-well-as-remote debugging script for ChromeOS users to run when the want to debug something. (The non-remote parts have already been committed; this particular CL was modifying the existing script to add the remote parts).

It does contain all the old functionality from gdb_remote (which is a shell script, not a python script), as it is intended to replace gdb_remote.

I can look at trying to extract some of the remote bits, especially those that it has in common with cros_debug.py, into a separate library module that both this script and cros_debug.py can use.  But my understanding is that this script needs to remain, and do argument parsing and gdb stuff.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I don't understand this comment (my ignorance, I'm sure):  What does build-id have to do with finding the *.debug file under /build/{board}/usr/lib/debug ?
|Done
|Done
|Done
|Done
|Done
|Done
|Why not?  We have this in gdb_remote. It also complements the options --attach=renderer and --attach=gpu-process...
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|We are now catching and translating the value before we do any calls to urlparse, so there is no need to look at parsed.netloc now.
|Using value.strip().lower() now.
|No.  If I delete this and the user tries plain 'localhost' for connecting to a local VM (for example), the user is faced with a messy and not-to-useful error message.  If I leave this in, then the user gets a nice clean error telling him/her what has been done wrong.   I do not understand why you have a problem with giving a nice error message to the user when he/she has done something wrong.
Or is it *ever* correct to not specify a port for localhost?
|I could delete the comment about VMs; would people ever ssh into localhost for any other reason?  

Also, if this really is not the right place for this warning, where would be the right place to put it?
|Done
|This isn't supposed to be a restriction; it's error checking, and as such seems appropriate for parsing.  If we don't do this here, then everybody who calls this is going to have to do their own version of this error check. Doesn't it make more sense to have a single common error check here instead?
|Done
|Done
|2015
|laszio?  (not me)
|You should probably update the comment to explain that this actually runs the tests on the DUT.
|Just curious...did you test this with the profiler to make sure that works too with your changes?
|This may be confusing as to which value was the old value and which one is the new value.  I would prefer that your message make that more explicit.
|&quot;Instantiating&quot;
|&quot;Instantiating&quot;
|What happens (or should happen) if the compiler is clang?
|Done
|what is 'hostname'? I don't see it anywhere else in this script...is it a constant with a particular meaning?  a variable?  where does it get it's value?
|why is this 'llvm' instead of '_llvm_grouped'?
|Done
|Fixed (due to mis-reading of patch at first; thanks for catching this).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I don't understand your comment here; what do you want me to do?
|I don't know. I didn't pick the link; it was done automatically by the script that builds the json file.  I've looked at that web page, and I'm not sure any of the entries on the page are really correct, but the continuous builder looks as close as any of them (to me).
|I set &quot;important=True&quot; because when I was reading the code in GetSlavesForMaster (in config_lib.py), it looks like 'important=True' is a requirement in order for a builder to be marked as a slave:

 for build_config in self.itervalues():
      if (build_config['important'] and
          build_config['manifest_version'] and
          (not build_config['master'] or build_config['boards']) and
          build_config['build_type'] == master_config['build_type'] and
          build_config['chrome_rev'] == master_config['chrome_rev'] and
          build_config['branch'] == master_config['branch']):
        slave_configs.append(build_config)


If I remove 'important=True', then will llvm-toolchain still be a slave of master-toolchain-release?
|What is the correct way for me to fix this?  (As in 'please give me the actual syntax &amp; where to make the changes')
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

I am writing a gdb script that wants to be able to debug Chrome running in a ChromeOS in KVM on your local machine (i.e. you did image_to_vm.sh , launched the resulting image, and now want to debug it).
In order to have gdb on your desktop communicate with gdbserver running inside the KVM session, there must be a port-forwarding process running while the gdbserver &amp; gdb processes connect &amp; talk to each other.  I was trying to do this using the existing chromite library functions, but this process has to run in the background, and I couldn't find any way of launching such a job, so I modified RunCommand...

Here's what the background job looks like:

cmtice    4163  0.1  0.0  71516  3252 pts/30   Sl+  17:00   0:00 ssh -i /tmp/ssh-tmp1rPFQN/testing_rsa -N -o StrictHostKeyChecking=no -o CheckHostIP=no -o BatchMode=yes root@localhost -p 9222 -L 12345:localhost:12345 &amp;
|Patch Set 1:

BTW, I'm happy with using BackgroundTaskRunner instead of this CL, if it will do what I need..
|Patch Set 1:

I have spent most of today trying to get this to work, and I have run across a problem that I can't figure out how to solve, so I am hoping you can maybe advise me:

My main script, cros_gdb, after various bits of setup, has the following code in a function:

    child = os.fork()
    if child == 0:
      gdb_args = [gdb_cmd] + ['--eval-command=%s' % x for x in gdb_commands]
      if self.cgdb:
        gdb_args = ['cgdb'] + gdb_args
      sys.exit(os.execvp(gdb_args[0], gdb_args))
    else:
      status = self.StartGdbserver(self.inf_cmd)
      if status != 0:
        cros_build_lib.Die('Error occurred; unable to start gdbserver on'
                           ' remote device.')

    _, status = os.waitpid(child, 0)


The function StartGdbserver is the one where I originally wanted to call RunCommand with 'is_async'.

It now contains the following code instead:

      command = ['/usr/local/bin/gdbserver', '--attach',
                 'localhost:%s' % self.gdbserver_port,
                 '%s' % self.remote_pid,
                 '&gt;', '/tmp/gdbserver.out', '2&gt;&amp;1', '&amp;']
        port_forward_command = ['ssh', '-i', private_key_file, '-N', '-o',
                                'StrictHostKeyChecking=no', '-o',
                                'CheckHostIP=no', '-o', 'BatchMode=yes',
                                'root@localhost', '-p', '9222', '-L',
                                '%s:localhost:%s' % (self.gdbserver_port,
                                                     self.gdbserver_port)]
        with parallel.BackgroundTaskRunner(cros_build_lib.RunCommand,
                                           processes=1) as queue:
          # Start the port forwarding command in the background, then            
          # execute the gdbserver command.                                       
          queue.put([port_forward_command])
          status = self.agent.device.RunCommand(command).returncode


This is *almost* doing what I need, except for one problem.  The Background task is running indefinitely (which I want, up to a point), but the with clause above is never exiting.  So in the main function, after I exit from gdb, I am hung forever waiting for the port forwarding background task to finish; only it's the kind of task that never finishes; so I end up having to grep for the pid and kill it.  But I can't even add code to the main function (after the wait command), because the function StartGdbserver NEVER FINISHES SO IT NEVER RETURNS  (I have verified this with strategically placed print statements).  Help???  I'm back to needing to be able to call RunCommand with 'is_async' unless I can find a nice way to make StartGdbserver finish/return....
|Abandoned

Not needed; was able to use BackgroundTaskRunner instead.
|Patch Set 2:

It looks to me like you are applying this to both the gold and the bfd linker, but I thought we only wanted to do this for the gold linker?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

I do not think this is needed any more.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

I just used the cros_portage_upgrade script and it pulled them in.  Do you want me to delete them from the patch?
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Trybot-Ready+1
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Code-Review+2

Carry forward previous +2.
|Patch Set 4: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Carrying forward +2.
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 3: Code-Review-1

When I cherry-pick this patch into a chroot and try building packages for lumpy or x86-alex, they both fail building dev-python/imaging.  The failure message is:
 * python2_7: running distutils-r1_run_phase python_install_all
install: cannot stat â€˜Sane/CHANGESâ€™: No such file or directory
!!! dodoc: Sane/CHANGES does not exist
install: cannot stat â€˜Sane/READMEâ€™: No such file or directory
!!! dodoc: Sane/README does not exist
install: cannot stat â€˜Sane/sanedoc.txtâ€™: No such file or directory
!!! dodoc: Sane/sanedoc.txt does not exist
 * ERROR: dev-python/imaging-1.1.7-r5::portage-stable failed (install phase):
 *   dodoc failed
 * 
 * If you need support, post the output of `emerge --info '=dev-python/imaging-1.1.7-r5::portage-stable'`,
 * the complete build log and the output of `emerge -pqv '=dev-python/imaging-1.1.7-r5::portage-stable'`.
 * The complete build log is located at '/build/lumpy/tmp/portage/logs/dev-python:imaging-1.1.7-r5:20150313-004529.log'.
 * For convenience, a symlink to the build log is located at '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/temp/build.log'.
 * The ebuild environment file is located at '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/temp/environment'.
 * Working directory: '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/work/Imaging-1.1.7/Sane'
 * S: '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/work/Imaging-1.1.7'
 * QA Notice: file does not exist:
 * 
 * 	dodoc: Sane/CHANGES does not exist
 * 	dodoc: Sane/README does not exist
 * 	dodoc: Sane/sanedoc.txt does not exist

&gt;&gt;&gt; Failed to emerge dev-python/imaging-1.1.7-r5 for /build/lumpy/, Log file:

&gt;&gt;&gt;  '/build/lumpy/tmp/portage/logs/dev-python:imaging-1.1.7-r5:20150313-004529.log'

 * Messages for package dev-python/imaging-1.1.7-r5 merged to /build/lumpy/:

 * ERROR: dev-python/imaging-1.1.7-r5::portage-stable failed (install phase):
 *   dodoc failed
 * 
 * If you need support, post the output of `emerge --info '=dev-python/imaging-1.1.7-r5::portage-stable'`,
 * the complete build log and the output of `emerge -pqv '=dev-python/imaging-1.1.7-r5::portage-stable'`.
 * The complete build log is located at '/build/lumpy/tmp/portage/logs/dev-python:imaging-1.1.7-r5:20150313-004529.log'.
 * For convenience, a symlink to the build log is located at '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/temp/build.log'.
 * The ebuild environment file is located at '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/temp/environment'.
 * Working directory: '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/work/Imaging-1.1.7/Sane'
 * S: '/build/lumpy/tmp/portage/dev-python/imaging-1.1.7-r5/work/Imaging-1.1.7'

If I undo the cherry-pick (git checkout -- &lt;file&gt; for each file), then dev-python/imaging builds just fine.
|Patch Set 3:

I have verified that patch set 3 fixed the problem I was having.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Since platform2 is in a different git repository, changing platform2_unittest.py will require a different CL (I think).  So let's put qemu.py into chromite/lib with this one, then once this is in place, update platform2_* to use it.
|Patch Set 2:

Ping??
|Patch Set 2:

Ping?  Hello?
|Patch Set 2:

(8 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

(4 comments)

please fix minor typos.  Approved with that.
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

I am requesting a code review for changes I would like to make.
|Patch Set 1: Abandoned

This is replaced by change 6610
|Patch Set 1: Abandoned

I need to do this whole thing differently.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as a59473b72fc8346cde5d2573c6972953ac8d57c9.
|Patch Set 1:

Yes, this change is necessary.  If the 7.2 case of the case statement is taken (and the code is downloaded from the git repository), then the patches do NOT need to be applied, because the code in the repository already contains the patches.  But if the other cases are taken, then the patches DO need to be applied.  As I have written it, I believe I get this desired behavior..
|Patch Set 1:

I feel like either you or I are missing something here:  I can't set it just above DESCRIPTION=... because it could/should have different values, depending on what the value of PV is (i.e. which case of the case statement gets taken).  Sometimes it is correct for it to be &quot;1&quot; and sometimes it is correct for it to be &quot;&quot;.  If I set it after the case statement, i.e. just above DESCRIPTION=... it will always have the same value, which will be wrong in some cases...
|Uploaded patch set 2.
|Patch Set 2:

I've changed the gdb-7.2-r1.ebuild file to (hopefully) match Mike's request, and re-emerged and re-ran all Smoke suite testsuite.  Please review the patch for me.
|Uploaded patch set 3.
|Patch Set 3:

I think I have fixed the spacing issues, and I have re-emerged and re-run all the tests.  Please review my latest changes.
|Uploaded patch set 4.
|Patch Set 4:

Patch changed as requested.  Please review again.  (Note even if everyone approves, I won't be committing this until tomorrow).
|Patch Set 4: Verified

Verifying and attempting to commit this change.
|Uploaded patch set 5.
|Patch Set 5:

I had to merge/rebase and re-upload the patch, because when I tried to do the commit I was told it could not be merged due to a patch conflict.

I have not actually changed anything (other than doing the git fetch &amp; git rebase), but please review/approve this patch again. Thanks
|Patch Set 5: Verified


|Change has been successfully cherry-picked as ef8c444aabe49c09124c08b44d5a63ad81060cf8.
|Patch Set 1: Verified

Verifying and committing (I hope).
|Change has been successfully cherry-picked as 196c0eb03b07a27e9316021efb3f290ff7db2ba4.
|Patch Set 1: Verified

Verifying and submitting.
|Change has been successfully cherry-picked as 8e163830a1ca56e065e4b4bda95dd793055d5885.
|Patch Set 1: Abandoned

I'm going to abandon this submission and re-try with a different one (I don't know how else to remove files once they have been added &amp; uploaded).
|Uploaded patch set 2.
|Patch Set 2:

I think I've fixed all the issues.  I re-tested this version and it works just fine.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Change has been successfully cherry-picked as 671dc9d7b78c376a4c9338673c4c53dd95318148.
|Patch Set 1:

I understand that the gdb_wrapper script may end up being put in a different directory, but I would appreciate people putting that aside for now and looking at the content of the changes.
|Patch Set 1: Abandoned

Change in CL 7955 will be installed via a different path; no change to setup_board after all, so this will be abandoned.
|Patch Set 1:

This is roughly the same script that I was submitting with setup_board before, but now that I've put it into platform/dev, I can't submit it in the same change as setup_board.  I've modified this, as requested, to use flags rather than interactive prompts.  Also, as requested, setup_board no longer actually generates any scripts; since this script takes flags for everything, that's no longer required.  Instead, once this is committed, I will modify setup_board (in the other change, #7737) to create a soft link in /usr/bin pointing to this script, so that users can find it.
|Uploaded patch set 2.
|Patch Set 2:

Given the final decision to keep this as a shell script, I have attempted to address all the previous review comments.  Please look at this again.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Ping?  Could somebody else review/approve (or not) this patch?  Thanks!
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Does anyone else have any comments, or should I verify and submit this?
|Patch Set 8: Verified


|Change has been successfully cherry-picked as 3250e19560346472bd01170c1836acd21c02ad29.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

I have tried to fix everyone's concerns, as much as possible.  As I mentioned previously, I cannot replace
the sleep and pgrep commands with '$!', because '$!' gets the wrong pid.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Change has been successfully cherry-picked as cce25bd9d90b35e95c09e7f327d4a342d0ebc43a.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 22563d6740845eb37696255c6b99a019b71fa9a8.
|Patch Set 1:

I'm not sure I understand your comment.  There are 3 different remote options for this script:  remote_ip_address, remote_file. and remote_pid.  I don't think it makes sense to change remote_ip_address to just &quot;remote&quot;, but maybe I'm not understanding what you are suggesting?
|Patch Set 1:

I am willing to do whatever most people believe is the right thing to do with the flags.  My original reasoning was that the script did some work locally and some work remotely.  Since there could be pids and filenames in both places, it made sense to me to clarify, through the flag name, that the filename and pid to be specified were the ones on the remote device (or VM).  The other flags (port, ip_address, and board would not vary from local to remote, so there seemed no need to lengthen the names with the 'remote' prefix.  I was unaware that other scripts used &quot;--remote&quot; to specify an ip address.  Anyway, that was my reasoning.  I repeat I will do whatever the consensus thinks is the correct thing to do.
|Patch Set 1:

After further discussion with Bhaskar, my current plan is for the flags in question to be:
 --remote   for the ip_address
 --remote_file for the filename on the remote machine
 --remote_pid for the PID on the remote machine (for attaching)

If anyone has any objections to these, please speak up soon; I'd prefer to not keep iterating on flag changes. I'll wait until tomorrow morning before actually submitting these changes.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 6dc72015f80c02c9bb4af75edec1e7b058b964dc.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as 7fdbfa731c3c2051b845455ec4c1053ea499a277.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 24f4875d9be04cc99c049abebaa83554407f5563.
|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved

It looks good to me; just wondering if you tested it with the VM as well as with a remote device.  Approved, assuming it passes with the VM.
|Patch Set 5: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 6: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as e9d87b73a59b04d345248240f918030c9e25aac5.
|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

I have a small requested text change.
Also, you don't say if/how you tested this.  Please make sure you tested it both with a real remote device and with the VM.
It would also be good to test it both attaching to the browser and attaching to a non-browser process...
|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified


|Change has been successfully cherry-picked as a20188fead053a3127e5241dc693182ca0663646.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

The cross-built version of gdb is currently not among the pre-built binaries (I believe).  It would be nice if it were added, but I have no control over that.
|Patch Set 5: Verified

The trybot run passed.
|Uploaded patch set 6.
|Patch Set 6: Verified; Ready


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: (1 inline comment)

The 'ln' command looks to me like it might be wrong? (See inline comment)
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1:

It doesn't demangle; that's why I've put it there.

$ c++filt _ZTVN21enterprise_management10PolicyDataE__vtable_map
_ZTVN21enterprise_management10PolicyDataE__vtable_map
|Patch Set 1:

On further discussion with C++ experts, the format of the variable name will be changing slightly, to make it properly demangle.   I will submit an updated patch when we have this completely ironed out.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3: Ready


|Patch Set 1:

Did you test building gdb with the revised ebuild file?
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve

You misspelled 'mounted_gcc' in the comment. Other than that, LGTM.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1:

Please add the 'mounted_sources' use case (see the gdb 7.2 ebuild file), for when we want to work with a debug the gdb sources directly.
|Patch Set 1:

We are working in the R25 branch because we wanted to pick a stable, reliable chroot in which to do our work.
|Patch Set 1: (2 inline comments)


|Patch Set 1: Abandoned

This change has been superseded by 
https://gerrit.chromium.org/gerrit/43352
|Uploaded patch set 2.
|Patch Set 2:

Question:  Do you mean delete all three lines (if, BUILD_DEFINES, fi) or just the if-fi lines (leave the line in the middle)?
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 1: Abandoned

Change was based on old sources.  Throwing it all away. Will create a new CL from TOT.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Change has been successfully cherry-picked as e539be0567f5159e11107580df4d55c292577e15
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

This CL has been successfully tested with the trybot and is now ready for review.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Patch Set 16:

Ping?
|Patch Set 16: Ready; Verified

Thank you for the re-approval.  The reason the patch was re-posted was that I had to change the commit message, which automatically re-submits the patch.  Once a patch has been re-submitted, previous approvals go away.
|Patch Set 16: Commit-Queue+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 17.
|Patch Set 17: Code-Review+2 Commit-Queue+1 Verified+1

Had to re-upload because of repository upgrade.  Patch should be identical to previously approved patch.  Re-applying approvals.
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 18.
|Patch Set 18: Code-Review+2 Verified+1

Due to repo issues, threw away old branch, re-created work on new branch.  Uploaded same work.  Patch itself has not changed.  Re-applying previous approval.
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18:

Does anybody understand why the Commit Queue is giving me this error message?  It seems to be claiming that Change 60303, on which this CL depends, is not marked Commit-Ready.  But it IS.  You can see that if you go to the CL:

https://chromium-review.googlesource.com/#/c/60303/

Has anybody seen anything like this before?
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11:

These Cls have been successfully tested with the trybots.  They are now ready to be reviewed.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14:

Ping?
|Patch Set 14: Ready; Verified


|Patch Set 14: Commit-Queue+1
|Patch Set 14: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 15.
|Patch Set 15: Code-Review+2 Commit-Queue+1 Verified+1

Had to re-upload change because of gerrit-&gt;googlesource change.  Patches themselves should be identical to previously approved patches; re-applying approvals.
|Patch Set 15: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 15: Commit-Queue+1
|Patch Set 15: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 16.
|Patch Set 16: Code-Review+2 Verified+1

Due to repo issues, had to throw away old branch.  Created new branch, re-applied same patches. Patches have not changed. Re-applying previous approvals.
|Patch Set 16: Commit-Queue+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 16: Commit-Queue+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 16: Commit-Queue+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 17.
|Patch Set 17: Code-Review+2 Verified+1

Updated common.sh, to pick up recent changes in the repo.  The patches themselves are unchanged, so I'm re-applying the previous approvals.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 17: Commit-Queue+1
|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Question:  How do I remove a file  (i.e. the gcc-libs-r1.ebuild symlink) from a patch once I've done the 'git add; git commit; repo upload'?
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

This CL has been successfully tested with the trybot and is now ready for review.
|Patch Set 6: (14 inline comments)


|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14:

I think this will fix the x86-64 fails (it was already passing on daisy &amp; x86-alex).  I think this also deletes the &quot;extra&quot; stuff that was being installed.  I am currently running remote trybot tests with these patches, for lumpy, daisy &amp; x86-alex.  I will let you know if all three remote trybots pass.
|Patch Set 15:

I'm not sure that it does ignore the per-board compiler settings.  I believe those would be set in CFLAGS_FOR_TARGET and CXXFLAGS_FOR_TARGET, which do not get ignored or overridden, as far as I can see.  Or am I missing something?
|Patch Set 15:

To answer Bhaskar's question: we are building differently because the reviewers determined that a lot of the build options were not necessary in this case and requested that they be removed.
|Patch Set 15: I would prefer that you didn't submit this

Further investigation of the differences between the way sys-devel/gcc and sys-libs/gcc-libs build the shared libraries indicates that:

--enable/disable-openmp does not make any difference to the libraries.

--enable-shared and --enable-threads=posix are not being passed to either build at the top-level, but are being automatically determined by the system and passed to BOTH builds further down.

However, two differences that Mike missed in his spot check ARE important:

In gcc-libs, the latest patch adds --disable-nls.  This flag controls Native Language Support.  Normally it is enabled.  Disabling it changes the way the exception handling mechanism in libstc++ outputs its error messages.

In gcc-libs, the latest patch also changes --enable-libgomp to --disable-libgomp.  This turns off some parallelism, and causes 5 files to not be compiled and included in libstdc++ (they are compiled and linked into the sys-devel/gcc build of the libraries).

The rest of the flag changes in the new patch do not make any difference to the way the libraries are built.  None of the flag changes affect libgcc_s.so. 

This patch should be changed to remove the --disable-nls configuration flag, and to change --disable-libgomp back to --enable-libgomp.
|Patch Set 15:

While there is a lot of merit in what you say, I think it is important, at least initially, that sys-libs/gcc-libs and sys-devel/gcc build the libraries in the same say.  But I also do not think we should expand this CL, at this time, to start changing sys-devel/gcc as well.

If you want to change the flags that sys-devel/gcc uses (and thus the flags that sys-libs/gcc-libs uses) then I think it makes more sense to open a separate issue for that, and create a different CL, after this initial sys-libs/gcc-libs CL has been committed.
|Uploaded patch set 16.
|Patch Set 16: Commit-Queue+1 Verified+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 16: Commit-Queue+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 16: Commit-Queue+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 17.
|Patch Set 17: Code-Review+2 Commit-Queue+1 Verified+1

Had to bump the revision number of the symbolic link file.  Re-applying previous approvals.
|Patch Set 17: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 18.
|Patch Set 18: Code-Review+2 Verified+1

Due to repo issues, had to throw away working branch, create a new branch and re-apply the work.  Re-applied patches.  Patches have not changed.  Re-applying previous approvals.
|Uploaded patch set 19.
|Patch Set 19: Code-Review+2 Verified+1
|Uploaded patch set 20.
|Patch Set 20: Code-Review+2 Commit-Queue+1 Verified+1

Updated commit message; re-applied previous approvals.  Passed the trybot, so setting the commit ready bit.
|Patch Set 20: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 20: Commit-Queue+1
|Patch Set 20: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 20:

I have read the logs and I have been trying to figure out what is going wrong and reproduce it on my machine so I can fix it.  It did not reproduce in my chroot, so I was hoping (the first time) that it was one of the other patches in the CQ that had caused the failure.  The second time I was forced to conclude it really is something about my patches that is the problem, but I STILL have been unable to reproduce the problem locally.  I have tried copying the setup board command (from the daisy_spring log) and the setup board and build packages commands from the daisy log, and they all work just fine in my chroot.  Any help or suggestions would be appreciated at this point.

The error message in the log files appears to be:
gcc-libs-0.0.1-r1: make[1]: Entering directory `/build/daisy/tmp/portage/sys-libs/gcc-libs-0.0.1-r1/work/build/gcc'
gcc-libs-0.0.1-r1: TARGET_CPU_DEFAULT=&quot;&quot; \
gcc-libs-0.0.1-r1: HEADERS=&quot;auto-host.h ansidecl.h&quot; DEFINES=&quot;&quot; \
gcc-libs-0.0.1-r1: /bin/sh /mnt/host/source/src/third_party/gcc/gcc/mkconfig.sh config.h
gcc-libs-0.0.1-r1: TARGET_CPU_DEFAULT=&quot;TARGET_CPU_generic&quot; \
gcc-libs-0.0.1-r1: HEADERS=&quot;options.h insn-constants.h config/dbxelf.h config/elfos.h config/gnu-user.h config/linux.h config/linux-android.h config/glibc-stdint.h config/arm/elf.h config/arm/linux-gas.h config/arm/linux-elf.h config/arm/bpabi.h config/arm/linux-eabi.h config/arm/aout.h config/arm/arm.h config/initfini-array.h defaults.h&quot; DEFINES=&quot;LIBC_GLIBC=1 LIBC_UCLIBC=2 LIBC_BIONIC=3 DEFAULT_LIBC=LIBC_GLIBC ANDROID_DEFAULT=0&quot; \
gcc-libs-0.0.1-r1: /bin/sh /mnt/host/source/src/third_party/gcc/gcc/mkconfig.sh tm.h
gcc-libs-0.0.1-r1: /bin/sh /mnt/host/source/src/third_party/gcc/gcc/config/arm/genopt.sh /mnt/host/source/src/third_party/gcc/gcc/config/arm &gt; \
gcc-libs-0.0.1-r1: 	/mnt/host/source/src/third_party/gcc/gcc/config/arm/arm-tables.opt
gcc-libs-0.0.1-r1: TARGET_CPU_DEFAULT=&quot;&quot; \
gcc-libs-0.0.1-r1: HEADERS=&quot;auto-host.h ansidecl.h&quot; DEFINES=&quot;&quot; \
gcc-libs-0.0.1-r1: /bin/sh /mnt/host/source/src/third_party/gcc/gcc/mkconfig.sh bconfig.h
gcc-libs-0.0.1-r1:  (null)*(null) (null)ACCESS DENIED(null):  open_wr:      /mnt/host/source/src/third_party/gcc/gcc/config/arm/arm-tables.opt
gcc-libs-0.0.1-r1: /bin/sh: /mnt/host/source/src/third_party/gcc/gcc/config/arm/arm-tables.opt: Permission denied
gcc-libs-0.0.1-r1: make[1]: *** [/mnt/host/source/src/third_party/gcc/gcc/config/arm/arm-tables.opt] Error 1
gcc-libs-0.0.1-r1: make[1]: *** Waiting for unfinished jobs....
gcc-libs-0.0.1-r1: make[1]: Leaving directory `/build/daisy/tmp/portage/sys-libs/gcc-libs-0.0.1-r1/work/build/gcc'
gcc-libs-0.0.1-r1: make: *** [all-gcc] Error 2

It looks like the build is maybe trying to write the file in the wrong place? (In /mnt/host/source...?)  Why is this only a problem on the paladin, and not in my chroot (or in the remote trybot, which also succeeded without a problem)?
|Patch Set 20:

Among other things, if this problem only reproduces in the commit queue builds,  how can I test a fix (assuming I can suggest one) before trying to commit it?
|Patch Set 20:

My best guess as to a fix for this problem is to remove the following line from the gcc-libs ebuild file:

CROS_WORKON_OUTOFTREE_BUILD=1

1).  Does anybody see a problem with that?
2).  Does anybody know how I can test whether or not this fixes the actual problem before marking it commit-ready and sending it through the commit queue?
|Uploaded patch set 21.
|Uploaded patch set 22.
|Patch Set 22:

Oddly enough, the daisy remote trybot succeeded on Friday, but failed today (with the same patches!).  I will try the trybot with this updated patch; if it succeeds I will try it in the commit queue again. (Unless somebody violently objects to the change I made?)
|Patch Set 22:

The remote trybots now succeeded with the three patches on daisy-full daisy_spring-full, x86-alex-full and lumpy-full.

Mike is this change OK?  Can I submit this to the commit queue now?
|Patch Set 22:

Ping?
|Patch Set 22:

After discussing this with Mike, it appears that this is a 'bug' in both GCC and gcc-libs, in that neither of them can build out-of-tree at the moment without this problem cropping  up.  The GCC ebuild does not currently attempt to buid GCC out-of-tree.  To fix this issue in gcc-libs so that it can build out-of-tree, we would have to fix the GCC sources to also handle this case, since gcc-libs uses the GCC sources to build.

I have suggested that bugs be filed against GCC to fix this issue (we are due to roll a new version of GCC soon, and this fix could to into it); and also against gcc-libs to build out-of-tree, once GCC is fixed to allow building out-of-tree.

However I would like, for the moment, to keep this change in gcc-libs which allows it to build in-tree, and ought to fix the commit queue issue, so that the gcc-libs patches can be committed.

Comments?
|Patch Set 22:

While the fix itself is probably small, making changes to the GCC compiler and getting the compiler rolled into ChromeOS is a long, time-intensive process (there is a LOT of testing and verification necessary to get any compiler changes approved).

We will fix these issues; I have created two Chromium bugs for them:

https://code.google.com/p/chromium/issues/detail?id=284836
https://code.google.com/p/chromium/issues/detail?id=284838

I will fix them as soon as I can (I have other things I am working on also).

Given our commitment to fix these issues separately, do you think you could approve this CL so we can get the gcc-libs patches committed?
|Patch Set 22:

I did not say we could not respond to a simple build fix; I said it would take time, due to verification.  I agree that the testing process is taking a lot of overhead; I cannot say whether it is too much or not.

All of that is getting a bit off topic.  The topic here is that this patch should not have to wait for the other fix to go into GCC.  Given that we will be fixing the issue in GCC (and then revising the gcc-libs build as you wish), is this patch ok to commit for now?
|Patch Set 22:

Adding comments from Bhaskar Janakiraman, as it did not make it into the CL from his email:

On Sep 4, 2013 5:34 AM, &quot;Caroline Tice (Gerrit)&quot; &lt;noreply-gerritcodereview-7rbiFrEwOXaWZtcLZYFqWg@google.com&gt; wrote:
&gt;
&gt; Caroline Tice has posted comments on this change.
&gt;
&gt; Change subject: Build GCC libraries on a per-board basis.
&gt; ......................................................................
&gt;
&gt;
&gt; Patch Set 22:
&gt;
&gt; While the fix itself is probably small, making changes to the GCC compiler and getting the compiler rolled into ChromeOS is a long, time-intensive process (there is a LOT of testing and verification necessary to get any compiler changes approved).
&gt;
We are planning a gcc4.8 roll late Sept. If the change is simple, perhaps we can get that in there? It can be a local patch in the mobile branch until upstream accepts it.

&gt; We will fix these issues; I have created two Chromium bugs for them:
&gt;
&gt; https://code.google.com/p/chromium/issues/detail?id=284836
&gt; https://code.google.com/p/chromium/issues/detail?id=284838
&gt;

If its an upstream problem,, shouldn't these be upstream bugzilla issues?

&gt; I will fix them as soon as I can (I have other things I am working on also).
&gt;
&gt; Given our commitment to fix these issues separately, do you think you could approve this CL so we can get the gcc-libs patches committed?
&gt;

Is there a significant downside to getting this fix in (as in a user visible effect)? I also saw some previous comments about mounted gcc not working, which could be problematic..
|Patch Set 22:

In response to Bhaskar's comments:

Yes, we were looking at trying to get this change into the gcc 4.8 roll in late September.


No, I don't think this is an upstream problem, so I doubt they would take our fix.  The issue arises due to a combination of things that are fairly ChromeOS-specific.

I do not believe there is any end-user visible effect to this fix.  The ARM compiler developers will be helped, because for ARM, both gcc and gcc-libs have some issues with   USE=mounted_gcc.   Non-GCC developers would not be using this flag and would not see the issue.
|Patch Set 22:

When we fix the issue we can certainly try to get the patch(es) accepted upstream as well.

Is this CL okay to commit (if so, would you please mark it as approved Mike)?
|Patch Set 23: Code-Review+2
|Patch Set 23: Commit-Queue+1 Verified+1
|Patch Set 23: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 23: Commit-Queue+1
|Patch Set 23: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 23: Commit-Queue+1
|Patch Set 23: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 23: Commit-Queue+1
|Patch Set 23: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 23: Commit-Queue+1
|Patch Set 23: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 23: Commit-Queue+1
|Change has been successfully cherry-picked as 19696a697681a7320fda570f3ee0e937bdc3db3f
|Change has been successfully cherry-picked as 13bb86a1d05a75cfca6e4c8b499b79fa8174c59e
|Change has been successfully cherry-picked as ed83839a56746532080e57026e2b6a9a65c1f4d1
|Change has been successfully cherry-picked as 5fdf776fe7eabb0492636ae52d4809ebdbe8a25e
|Change has been successfully cherry-picked as 4f9a801615c5866ecb7978f24af4433774a263d8
|Change has been successfully cherry-picked as cbdd21c5ea76aa93ba4619a6d253697765f4de1f
|Change has been successfully cherry-picked as 2ad995328f44f5b01d185bebdfa693b9c4b26988
|Change has been successfully cherry-picked as 31dd5cc26fb54f8b249c0b015d450aa246ce5bf1
|Change has been successfully cherry-picked as e28abcd8890325db3492fa1fa6f1e42ad9a6bb59
|Uploaded patch set 2.
|Patch Set 2: Abandoned

This is a duplicate of 60303.
|Patch Set 1: Abandoned

This is a duplicate of 60303.
|Change has been successfully cherry-picked as ad4959e07c799906898d4ced7ebb8cd32080a736
|Change has been successfully cherry-picked as 13e36cd8c9bbad66dbd3c4f5c05ae4cd2153da22
|Change has been successfully cherry-picked as 9d79171c42a308081874fd136712798427544a05
|Patch Set 4:

The Commit Queue failed to apply your change in https://uberchromegw.corp.google.com/i/chromeos/builders/Pre-CQ%20Launcher/builds/1234 .  Patch gabeblack:66769:fd2f8f51 depends on I75dbdebccbbb5e7394a1bbd9092efdd88c715b56 which has an error: gabeblack:66767:4643ce09 isn't committed, or marked as Commit-Ready.

Commit queue documentation: http://www.chromium.org/developers/tree-sheriffs/sheriff-details-chromium-os/commit-queue-overview
|Change has been successfully cherry-picked as 32a630851fbb67e8297739fff71165f5acc78751
|Change has been successfully cherry-picked as f3525ca9908ccda3a251f1878f676893dd3f16bf
|Patch Set 1: Looks good to me, but someone else must approve


|Change has been successfully cherry-picked as 4223d21c5fa9906583311c68f74c78a28383dda3
|Change has been successfully cherry-picked as b05c242505451bc2007085e243372937007890c0
|Change has been successfully cherry-picked as ad348e1e23812a9fbf415bc1d32cb35c533a1340
|Change has been successfully cherry-picked as 451a941fb0d7bd7c5d242cc2dccdca826c877cce
|Change has been successfully cherry-picked as 1681cb051cf146cbc2d9e6005288de62e50b21ab
|Change has been successfully cherry-picked as f4cd69ce89378e90ece103ec91cef600b2e88240
|Change has been successfully cherry-picked as fcd388df8eef2f723cb4ff7277fa44d3754bb966
|Change has been successfully cherry-picked as 3f4899b6b0e97d6fca4cde0a9bb44c98c258a012
|Patch Set 1:

The Commit Queue failed to submit your change in https://uberchromegw.corp.google.com/i/chromeos/builders/mario%20paladin/builds/1234 . This can happen if you submitted your change or someone else submitted a conflicting change while your change was being tested.

Commit queue documentation: http://www.chromium.org/developers/tree-sheriffs/sheriff-details-chromium-os/commit-queue-overview
|Change has been successfully cherry-picked as 58d8a739b2f55be8c0c9a5cf38265733048e0742
|Change has been successfully cherry-picked as 22d82ffa3f5500fbc1b785e343add25e61f4f194
|Change has been successfully cherry-picked as d142ccdcd902a9d6ab4d495fbe6cbe85c61a5f01
|Change has been successfully cherry-picked as aae330a979e6849dac67e03c49402a00e63a04ea
|Change has been successfully cherry-picked as 2e8e8b6bf0cbf3949267ba138bd932cb9dd7fb1d
|Change has been successfully cherry-picked as fb358ede60bb7987cb4eec9de69d2d07aaf1ec2e
|Change has been successfully cherry-picked as 527c313a1dbeda96dfecf35913a65b72eea956e1
|Change has been successfully cherry-picked as 94d63b71a3ef6fbb3d272a09aec68064ff59eeb8
|Change has been successfully cherry-picked as b02580d48543117e9acc0ce7e16e8db94e64f8e9
|Change has been successfully cherry-picked as 0ea574243058068702e3f6bc7355098745d16880
|Change has been successfully cherry-picked as d2364586c1c749a08395e89f28307bbfaf045801
|Change has been successfully cherry-picked as 36cf13839604c349692865475f3011afd08965b4
|Change has been successfully cherry-picked as d550bec944736dfa29fcf109e30f17a94af03576
|Change has been successfully cherry-picked as 322338934add36a5372ffe7d2a45e61a4fdd4a54
|Change has been successfully cherry-picked as 6ecda4b0f1ea6c9aa6c1c249d1dcd4ace87cbda0
|Change has been successfully cherry-picked as de1e5c1e939ac3709c82e80b789b184283c6c0e6
|Change has been successfully cherry-picked as be162559a61dd88d7a6152555fc142cd62892e00
|Change has been successfully cherry-picked as 575e910127dc74416018f182ef27ef223e61daef
|Change has been successfully cherry-picked as a795b1ffe05a7c7f41f66783b711c332dd92bfb0
|Change has been successfully cherry-picked as ec3d78ffd0c684592be6420093f41c513b6dfa46
|Change has been successfully cherry-picked as 402988a38a9fa52f55382478e7a7147c0c7a4969
|Change has been successfully cherry-picked as d76c609b35fdb09d494d8cadae9bf751867f2f1d
|Change has been successfully cherry-picked as 38b96520bafb01011ffe6fe2210222e6fde9c1d6
|Change has been successfully cherry-picked as 1db5f1c9e74bc6554ad0c50576c1690881d531a7
|Change has been successfully cherry-picked as 9feefe437be7d138fef7ca6d623425251cf59aae
|Change has been successfully cherry-picked as 685765e5da32c1508e1a60b205e42fd15c866d9f
|Change has been successfully cherry-picked as 4f633edad3aee9c4f2e469de4aa422481c0de966
|Change has been successfully cherry-picked as 47573eb1d3d586937facf4bdb93cb253e3676cbb
|Change has been successfully cherry-picked as 9b993bb2161feed007cb909310d9617564aa6edc
|Change has been successfully cherry-picked as 80eebd5bc0dbb9fabf81f46c25dcd5c5d5747579
|Change has been successfully cherry-picked as 04bbaf5d8e125166dd689f656d5b37776be01fb1
|Change has been successfully cherry-picked as d23e2a6c489e8006783084da1c555de2ce54a17b
|Change has been successfully cherry-picked as 9cddabb5983933059e0bf4ff2692a8cbfdc5291b
|Change has been successfully cherry-picked as 650dba32cb217414c422907398f68e784e5720e8
|Change has been successfully cherry-picked as e09b50fbf7736181210c59648077675bd3ca94c8
|Patch Set 1:

This is not finished yet; there is still an issue with the results.  When I run this I get results like:

-------------------------------------------
Summary
-------------------------------------------
Benchmark:  octane;  Iterations: 1 
              keys                          vanilla 
              Keys Completed Amean  StdDev StdDev/Mean 
                           1   PASS      ?           ? 
            retval         1   0.00   0.00        nan% 
telemetry_Crosperf         1   PASS      ?           ? 




and I ought to be getting results like:

Benchmark: octane; Iterations: 1
keys	 vanilla
Keys	 Completed	 Amean	 StdDev	 StdDev/Mean
index.html?auto=1 Box2D (score (bigger is better))	 1	 12503.00	 0.00	0.0%
index.html?auto=1 CodeLoad (score (bigger is better))	 1	 9829.00	 0.00	0.0%
index.html?auto=1 Crypto (score (bigger is better))	 1	 12285.00	 0.00	0.0%
index.html?auto=1 DeltaBlue (score (bigger is better))	 1	 15372.00	 0.00	0.0%
index.html?auto=1 EarleyBoyer (score (bigger is better))	 1	 19447.00	 0.00	0.0%
index.html?auto=1 Gameboy (score (bigger is better))	 1	 18750.00	 0.00	0.0%
index.html?auto=1 Mandreel (score (bigger is better))	 1	 12525.00	 0.00	0.0%
index.html?auto=1 NavierStokes (score (bigger is better))	 1	 13626.00	 0.00	0.0%
index.html?auto=1 PdfJS (score (bigger is better))	 1	 9630.00	 0.00	0.0%
index.html?auto=1 RayTrace (score (bigger is better))	 1	 21808.00	 0.00	0.0%
index.html?auto=1 RegExp (score (bigger is better))	 1	 2807.00	 0.00	0.0%
index.html?auto=1 Richards (score (bigger is better))	 1	 15639.00	 0.00	0.0%
index.html?auto=1 Splay (score (bigger is better))	 1	 8117.00	 0.00	0.0%
index.html?auto=1 score (score (bigger is better))	 1	 12009.00	 0.00	0.0%
retval	 1	 0.00	 0.00	nan%
|Patch Set 1:

Any help/suggestions on figuring out why the results are not coming out properly would be greatly appreciated!
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2:

Even though profiling isn't working quite right yet, everything else seems to be working properly with this, so I would like to get it reviewed and committed, and I can continue working on getting profilers to work properly after that.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

There's still a bit of work needed to get the profilers working properly, but I'm happy with the rest of this.  I would appreciate it if we could get this reviewed and in soon.  Thanks!
|Patch Set 4:

(3 comments)

Aviv, how hard would it be to fix test_that to respect the quoted args within --args? What is currently getting passed to test_that is: --args=&quot;iterations=1 test=octane pageset=octane.json profiler=custom_perf profiler_args=&quot;'record -a -a -e cycles,instructions'&quot;&quot;

It would be great if test_that did not split the profiler_args  up since they are within a quoted string...
|Patch Set 4:

Or is there a different format we could use when passing the arguments to test_that, to get it to respect profiler_args value as a single entity?
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

Ping?
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

In addition to addressing review comments, updated this to use run_benchmark, which automatically determines the page set to use, rather than run_measurement.
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Answering the inline comment:

Line 56:         format_string = ('cd %s; ./src/tools/perf/run_benchmark '
what happens when this fails? I'm just a bit concerned about cd-ing in the middle of a test.


Inside the chroot, if I do 

$ /var/cache/distfiles/target/src/tools/perf/run_benchmark --browser=cros-chrome --remote=172.17.128.238 --pageset-repeat=1 octane

I get the failure below.  If I do

$ cd /var/cache/distfiles/target/chrome-src-internal
$ ./run_benchmark --browser=cros_chrome --remote=172.17.128.238 --pageset_repeat=1 octane

then the test works just fine.  Here's the failure I get:

Traceback (most recent call last):
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/run_benchmark&quot;, line 13, in &lt;module&gt;
    sys.exit(test_runner.Main())
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/test_runner.py&quot;, line 221, in Main
    return command.Run(options, args)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/test_runner.py&quot;, line 141, in Run
    return min(255, self._test().Run(copy.copy(options)))
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/test.py&quot;, line 52, in Run
    results = page_runner.Run(test, ps, expectations, options)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/page/page_runner.py&quot;, line 298, in Run
    possible_browser, results, state)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/page/page_runner.py&quot;, line 204, in _PrepareAndRunPage
    results_for_current_run, finder_options)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/page/page_runner.py&quot;, line 407, in _RunPage
    test.Run(finder_options, page, tab, results)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/page/page_test.py&quot;, line 176, in Run
    self._test_method(page, tab, results)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/page/page_measurement.py&quot;, line 54, in _RunTest
    self.MeasurePage(page, tab, results)
  File &quot;/var/cache/chromeos-cache/distfiles/target/chrome-src-internal/src/tools/perf/benchmarks/octane.py&quot;, line 19, in MeasurePage
    util.WaitFor(_IsDone, 300, poll_interval=5)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/core/util.py&quot;, line 50, in WaitFor
    res = condition()
  File &quot;/var/cache/chromeos-cache/distfiles/target/chrome-src-internal/src/tools/perf/benchmarks/octane.py&quot;, line 18, in _IsDone
    return bool(tab.EvaluateJavaScript(js_is_done))
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/core/web_contents.py&quot;, line 55, in EvaluateJavaScript
    return self._inspector_backend.EvaluateJavaScript(expr, timeout)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/core/backends/chrome/inspector_backend.py&quot;, line 191, in EvaluateJavaScript
    return self._runtime.Evaluate(expr, timeout)
  File &quot;/var/cache/distfiles/target/chrome-src-internal/src/tools/perf/../telemetry/telemetry/core/backends/chrome/inspector_runtime.py&quot;, line 53, in Evaluate
    raise exceptions.EvaluateException(res['result']['result']['description'])
telemetry.core.exceptions.EvaluateException: ReferenceError: completed is not defined
|Patch Set 3:

(4 comments)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

I realized that /var/cache/distfiles was a sym link to /var/cache/chromeos-cache/distfiles.  Apparently something in telemetry is using relative paths, and it didn't work with used /var/cache/distfiles.

Replaced that path with the full path, /var/cache/chromeos-cache/distfiles/target/ and now I no longer need to do a 'cd' to make Telemetry work.

I also addressed all the other review comments, I believe.
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

I believe the latest patch fixes everyone's concerns/comments.  Please take a look when you have a moment.
|Patch Set 5:

Ping, Mike?  Does this look Ok to you now?
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: Code-Review+2
|Patch Set 4: Code-Review+1
|Patch Set 1:

Two quick questions:  1.  What does the 'tree' command that you are deleting do?  2.  Shouldn't you make this change in the gcc-libs-0.0.1-r2.ebuild file also?
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

Hi Simran,

I apologize about that; I didn't mean to rush it through without your input.  I agree that it would be good to fix this for all server-side profilers, at least those that use 'perf' (are there profilers that don't use perf?).    I would appreciate your help doing this, as my grasp of how this all works is still pretty shaky.
|Patch Set 2: Code-Review+2
|Patch Set 6: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

I was given to understand that if I requested csv (or any other output format, so that the &quot;RESULT ...&quot; lines did not come out in stdout), then test_that would not be able to find the test results...
|Patch Set 1:

If you look at comments 18-26 in this issue 

https://code.google.com/p/chromium/issues/detail?id=280754

you will see that the RESULT lines need to be in standard output in order for the keyvals to be created.  If the keyvals are not created, the keyvals are used to generate the keyval file (which is what this current CL is all about).  The final report/output that we look at is generated by the script generate_test_report, which looks for and parses that keyval file.  SO until generate_test_report is updated to look for and parse some other file in some other format, it seems to me that we need to keep generating the old keyval file and therefore we need the results to continue to be written to stdout.

Unless I am missing something?
|Patch Set 1:

typo: &quot;If the keyvals are not created, the keyvals are used to generate the keyval file&quot;

should say &quot;If the keyvals are not created, the keyvals are NOT used ..&quot;
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

WIP?  Does that mean work-in-progress? (I hadn't seen that one before and didn't understand it... :-( )
|Patch Set 1: Code-Review+2
|Patch Set 6: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

I would prefer to stop disabling movbe at another time.

&quot;you'll need to make some nominal change to the gcc ebuild to trigger a revbump.  like delete the (c) in the copyright header.&quot;

I don't understand this comment.  Why do I need a revbump?
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

The gcc-9999.ebuild file does not have (c).

I tried just adding the '(c)' to the copyright line, but the repo upload command rejected the CL because the EAPI version must be 4 or higher... That being the case, I don't see how I can make a &quot;harmless&quot; tweak to any of the gcc ebuild files, just to get a revbump.  Is there any other way to do this?
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Created CL to re-run tests with remote trybots.  Original commit was reverted by

https://code.google.com/p/chromium/issues/detail?id=374796

but if I'm reading that correctly, they are ready for this to be committed again, if it passes the remote trybot runs.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

link-release and falco-release trybots passed with this.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2:

Thanks for pointing that out.  I will update the gcc-9999.ebuild and create a new CL for it (since this one already got committed).
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2

This patch definitely fixes the problem.  In the meantime I will work on trying to patch GCC, to remove the need for this workaround.
|Patch Set 1: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

After downloading and using your patch, I get the following:

$ /usr/bin/test_that  --board=daisy --args=&quot; test=sunspider&quot; 172.17.129.204  telemetry_Crosperf
INFO:root:Identity added: /tmp/test_that_results_gJoi8D/testing_rsa (/tmp/test_that_results_gJoi8D/testing_rsa)
INFO:root:Realpath /mnt/host/source/src/third_party/autotest/files/site_utils/test_that.py, site_utils_path /build/daisy/usr/local/build/autotest/site_utils
11:49:12 INFO &#124; Running autotest_quickmerge step.
11:49:12 INFO &#124; quickmerge&#124; 11:49:12: INFO: RunCommand: sudo -- /usr/bin/python2.7 /mnt/host/source/chromite/bin/autotest_quickmerge '--board=daisy'
11:49:12 INFO &#124; quickmerge&#124; 11:49:12: INFO: RunCommand: find /build/daisy/usr/local/build/autotest/ -path /build/daisy/usr/local/build/autotest/ExternalSource -prune -o -path /build/daisy/usr/local/build/autotest/logs -prune -o -path /build/daisy/usr/local/build/autotest/results -prune -o -path /build/daisy/usr/local/build/autotest/site-packages -prune -o -printf '%T@\n'
11:49:12 INFO &#124; quickmerge&#124; 11:49:12: INFO: RunCommand: find /mnt/host/source/src/third_party/autotest/files/ -path /mnt/host/source/src/third_party/autotest/files/ExternalSource -prune -o -path /mnt/host/source/src/third_party/autotest/files/logs -prune -o -path /mnt/host/source/src/third_party/autotest/files/results -prune -o -path /mnt/host/source/src/third_party/autotest/files/site-packages -prune -o -printf '%T@\n'
11:49:13 INFO &#124; quickmerge&#124; 11:49:13: INFO: RunCommand: rsync -a --no-p '--chmod=ugo=rwX' -u -i '--exclude=**.pyc' '--exclude=**.pyo' '--exclude=** -&gt; *' '--include-from=/mnt/host/source/chromite/scripts/autotest-quickmerge-includepatterns' '--exclude=*' /mnt/host/source/src/third_party/autotest/files/ /build/daisy/usr/local/build/autotest/
11:49:13 INFO &#124; quickmerge&#124; 11:49:13: INFO: Updating portage database.
11:49:14 INFO &#124; quickmerge&#124; 11:49:14: INFO: RunCommand: touch /build/daisy/usr/local/build/autotest/.quickmerge_sentinel
11:49:14 INFO &#124; quickmerge&#124; 11:49:14: INFO: Quickmerge complete. Created or modified 1 files.
11:49:14 INFO &#124; Re-running test_that script in /build/daisy/usr/local/build/autotest copy of autotest.
11:49:14 INFO &#124; Bootstrap command is: ['/build/daisy/usr/local/build/autotest/site_utils/test_that.py', '--board=daisy', '--args= test=sunspider', '172.17.129.204', 'telemetry_Crosperf']
INFO:root:Identity added: /tmp/test_that_results_rS1XR6/testing_rsa (/tmp/test_that_results_rS1XR6/testing_rsa)
INFO:root:Realpath /build/daisy.gcc4-9/usr/local/build/autotest/site_utils/test_that.py, site_utils_path /build/daisy/usr/local/build/autotest/site_utils
11:49:14 INFO &#124; Running autotest_quickmerge step.
11:49:14 INFO &#124; quickmerge&#124; 11:49:14: INFO: RunCommand: sudo -- /usr/bin/python2.7 /mnt/host/source/chromite/bin/autotest_quickmerge '--board=daisy'
11:49:14 INFO &#124; quickmerge&#124; 11:49:14: INFO: RunCommand: find /build/daisy/usr/local/build/autotest/ -path /build/daisy/usr/local/build/autotest/ExternalSource -prune -o -path /build/daisy/usr/local/build/autotest/logs -prune -o -path /build/daisy/usr/local/build/autotest/results -prune -o -path /build/daisy/usr/local/build/autotest/site-packages -prune -o -printf '%T@\n'
11:49:14 INFO &#124; quickmerge&#124; 11:49:14: INFO: RunCommand: find /mnt/host/source/src/third_party/autotest/files/ -path /mnt/host/source/src/third_party/autotest/files/ExternalSource -prune -o -path /mnt/host/source/src/third_party/autotest/files/logs -prune -o -path /mnt/host/source/src/third_party/autotest/files/results -prune -o -path /mnt/host/source/src/third_party/autotest/files/site-packages -prune -o -printf '%T@\n'
11:49:14 INFO &#124; quickmerge&#124; 11:49:14: INFO: The sysroot appears to be newer than the source tree, doing nothing and exiting now.
11:49:14 INFO &#124; Re-running test_that script in /build/daisy/usr/local/build/autotest copy of autotest.
11:49:14 INFO &#124; Bootstrap command is: ['/build/daisy/usr/local/build/autotest/site_utils/test_that.py', '--board=daisy', '--args= test=sunspider', '172.17.129.204', 'telemetry_Crosperf']
INFO:root:Identity added: /tmp/test_that_results_ctHZXM/testing_rsa (/tmp/test_that_results_ctHZXM/testing_rsa)
INFO:root:Realpath /build/daisy.gcc4-9/usr/local/build/autotest/site_utils/test_that.py, site_utils_path /build/daisy/usr/local/build/autotest/site_utils
11:49:15 INFO &#124; Running autotest_quickmerge step.
11:49:15 INFO &#124; quickmerge&#124; 11:49:15: INFO: RunCommand: sudo -- /usr/bin/python2.7 /mnt/host/source/chromite/bin/autotest_quickmerge '--board=daisy'
11:49:15 INFO &#124; quickmerge&#124; 11:49:15: INFO: RunCommand: find /build/daisy/usr/local/build/autotest/ -path /build/daisy/usr/local/build/autotest/ExternalSource -prune -o -path /build/daisy/usr/local/build/autotest/logs -prune -o -path /build/daisy/usr/local/build/autotest/results -prune -o -path /build/daisy/usr/local/build/autotest/site-packages -prune -o -printf '%T@\n'
11:49:15 INFO &#124; quickmerge&#124; 11:49:15: INFO: RunCommand: find /mnt/host/source/src/third_party/autotest/files/ -path /mnt/host/source/src/third_party/autotest/files/ExternalSource -prune -o -path /mnt/host/source/src/third_party/autotest/files/logs -prune -o -path /mnt/host/source/src/third_party/autotest/files/results -prune -o -path /mnt/host/source/src/third_party/autotest/files/site-packages -prune -o -printf '%T@\n'
11:49:15 INFO &#124; quickmerge&#124; 11:49:15: INFO: The sysroot appears to be newer than the source tree, doing nothing and exiting now.
11:49:15 INFO &#124; Re-running test_that script in /build/daisy/usr/local/build/autotest copy of autotest.
11:49:15 INFO &#124; Bootstrap command is: ['/build/daisy/usr/local/build/autotest/site_utils/test_that.py', '--board=daisy', '--args= test=sunspider', '172.17.129.204', 'telemetry_Crosperf']
INFO:root:Identity added: /tmp/test_that_results_gdFnhO/testing_rsa (/tmp/test_that_results_gdFnhO/testing_rsa)
INFO:root:Realpath /build/daisy.gcc4-9/usr/local/build/autotest/site_utils/test_that.py, site_utils_path /build/daisy/usr/local/build/autotest/site_utils
11:49:16 INFO &#124; Running autotest_quickmerge step.
11:49:16 INFO &#124; quickmerge&#124; 11:49:16: INFO: RunCommand: sudo -- /usr/bin/python2.7 /mnt/host/source/chromite/bin/autotest_quickmerge '--board=daisy'
11:49:16 INFO &#124; quickmerge&#124; 11:49:16: INFO: RunCommand: find /build/daisy/usr/local/build/autotest/ -path /build/daisy/usr/local/build/autotest/ExternalSource -prune -o -path /build/daisy/usr/local/build/autotest/logs -prune -o -path /build/daisy/usr/local/build/autotest/results -prune -o -path /build/daisy/usr/local/build/autotest/site-packages -prune -o -printf '%T@\n'
11:49:16 INFO &#124; quickmerge&#124; 11:49:16: INFO: RunCommand: find /mnt/host/source/src/third_party/autotest/files/ -path /mnt/host/source/src/third_party/autotest/files/ExternalSource -prune -o -path /mnt/host/source/src/third_party/autotest/files/logs -prune -o -path /mnt/host/source/src/third_party/autotest/files/results -prune -o -path /mnt/host/source/src/third_party/autotest/files/site-packages -prune -o -printf '%T@\n'
11:49:16 INFO &#124; quickmerge&#124; 11:49:16: INFO: The sysroot appears to be newer than the source tree, doing nothing and exiting now.
11:49:16 INFO &#124; Re-running test_that script in /build/daisy/usr/local/build/autotest copy of autotest.
11:49:16 INFO &#124; Bootstrap command is: ['/build/daisy/usr/local/build/autotest/site_utils/test_that.py', '--board=daisy', '--args= test=sunspider', '172.17.129.204', 'telemetry_Crosperf']
INFO:root:Identity added: /tmp/test_that_results_yXhmfC/testing_rsa (/tmp/test_that_results_yXhmfC/testing_rsa)
INFO:root:Realpath /build/daisy.gcc4-9/usr/local/build/autotest/site_utils/test_that.py, site_utils_path /build/daisy/usr/local/build/autotest/site_utils
11:49:17 INFO &#124; Running autotest_quickmerge step.
11:49:17 INFO &#124; quickmerge&#124; 11:49:17: INFO: RunCommand: sudo -- /usr/bin/python2.7 /mnt/host/source/chromite/bin/autotest_quickmerge '--board=daisy'
11:49:17 INFO &#124; quickmerge&#124; 11:49:17: INFO: RunCommand: find /build/daisy/usr/local/build/autotest/ -path /build/daisy/usr/local/build/autotest/ExternalSource -prune -o -path /build/daisy/usr/local/build/autotest/logs -prune -o -path /build/daisy/usr/local/build/autotest/results -prune -o -path /build/daisy/usr/local/build/autotest/site-packages -prune -o -printf '%T@\n'
11:49:17 INFO &#124; quickmerge&#124; 11:49:17: INFO: RunCommand: find /mnt/host/source/src/third_party/autotest/files/ -path /mnt/host/source/src/third_party/autotest/files/ExternalSource -prune -o -path /mnt/host/source/src/third_party/autotest/files/logs -prune -o -path /mnt/host/source/src/third_party/autotest/files/results -prune -o -path /mnt/host/source/src/third_party/autotest/files/site-packages -prune -o -printf '%T@\n'
11:49:17 INFO &#124; quickmerge&#124; 11:49:17: INFO: The sysroot appears to be newer than the source tree, doing nothing and exiting now.
11:49:17 INFO &#124; Re-running test_that script in /build/daisy/usr/local/build/autotest copy of autotest.
11:49:17 INFO &#124; Bootstrap command is: ['/build/daisy/usr/local/build/autotest/site_utils/test_that.py', '--board=daisy', '--args= test=sunspider', '172.17.129.204', 'telemetry_Crosperf']
INFO:root:Identity added: /tmp/test_that_results_B2jido/testing_rsa (/tmp/test_that_results_B2jido/testing_rsa)
INFO:root:Realpath /build/daisy.gcc4-9/usr/local/build/autotest/site_utils/test_that.py, site_utils_path /build/daisy/usr/local/build/autotest/site_utils
11:49:17 INFO &#124; Running autotest_quickmerge step.
11:49:18 INFO &#124; quickmerge&#124; 11:49:18: INFO: RunCommand: sudo -- /usr/bin/python2.7 /mnt/host/source/chromite/bin/autotest_quickmerge '--board=daisy'
11:49:18 INFO &#124; quickmerge&#124; 11:49:18: INFO: RunCommand: find /build/daisy/usr/local/build/autotest/ -path /build/daisy/usr/local/build/autotest/ExternalSource -prune -o -path /build/daisy/usr/local/build/autotest/logs -prune -o -path /build/daisy/usr/local/build/autotest/results -prune -o -path /build/daisy/usr/local/build/autotest/site-packages -prune -o -printf '%T@\n'
11:49:18 INFO &#124; quickmerge&#124; 11:49:18: INFO: RunCommand: find /mnt/host/source/src/third_party/autotest/files/ -path /mnt/host/source/src/third_party/autotest/files/ExternalSource -prune -o -path /mnt/host/source/src/third_party/autotest/files/logs -prune -o -path /mnt/host/source/src/third_party/autotest/files/results -prune -o -path /mnt/host/source/src/third_party/autotest/files/site-packages -prune -o -printf '%T@\n'
11:49:18 INFO &#124; quickmerge&#124; 11:49:18: INFO: The sysroot appears to be newer than the source tree, doing nothing and exiting now.
11:49:18 INFO &#124; Re-running test_that script in /build/daisy/usr/local/build/autotest copy of autotest.
11:49:18 INFO &#124; Bootstrap command is: ['/build/daisy/usr/local/build/autotest/site_utils/test_that.py', '--board=daisy', '--args= test=sunspider', '172.17.129.204', 'telemetry_Crosperf']
INFO:root:Identity added: /tmp/test_that_results_rTjP4K/testing_rsa (/tmp/test_that_results_rTjP4K/testing_rsa)
|Patch Set 1:

Yes; I have multiple &quot;daisy&quot; build trees that I want to be able to switch between, so I've made /build/daisy into a soft link:

$ ls -ld /build/daisy*
lrwxrwxrwx  1 root root   12 Oct  7 15:47 /build/daisy -&gt; daisy.gcc4-9
drwxr-xr-x 23 root root 4096 Sep 29 16:05 /build/daisy.49.work
drwxr-xr-x 23 root root 4096 Sep 29 21:48 /build/daisy.gcc4-8
drwxr-xr-x 23 root root 4096 Sep 29 16:05 /build/daisy.gcc4-9
|Patch Set 1:

$ ls -ld /build/daisy*

lrwxrwxrwx  1 root root   12 Oct  7 15:47 /build/daisy -&gt; daisy.gcc4-9

drwxr-xr-x 23 root root 4096 Sep 29 16:05 /build/daisy.49.work

drwxr-xr-x 23 root root 4096 Sep 29 21:48 /build/daisy.gcc4-8

drwxr-xr-x 23 root root 4096 Sep 29 16:05 /build/daisy.gcc4-9
|Patch Set 2:

Patch set 2 fixed my problem!
|Uploaded patch set 1.
|Patch Set 1:

I'm in the process of testing this CL now; I'll let you know when I'm sure it's ready for use.
|Abandoned

We now have a compiler patch to fix the problem; this temporary CL is no longer needed.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Abandoned

This is not the right way to test the new compiler.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 2:

Please fix the commit message to be clear which branch/version of GCC this patch is going into (the text makes it look like you are patching GCC 4.9).
|Uploaded patch set 1.
|Abandoned

Wrong branch.
|Uploaded patch set 1.
|Abandoned

still not right with branches.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Is there any easy way to fix them?
|Patch Set 1:

Ok, I've done that now 

https://chromium-review.googlesource.com/229752

I'd like to abandon this CL, but I don't see an 'abandon' button...
|Uploaded patch set 1.
|Patch Set 1:

The original input is a dictionary of two dictionaries, which gets fed to the function perf_uploader._format_for_upload (the function actually being tested).  The function returns the result, with the data having been changed from a dictionary of dictionaries to a list of dictionaries, which gets compared against an expected list of dictionaries.  Under GCC 4.9, the order of the dictionaries going IN to _format_for_upload is different than under GCC 4.8, so the string coming back has the dictionaries in the list in a different order.  So the comparison with the expected list fails.

Where/how would you like me to change a comment?
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(3 comments)

Please don't commit this yet; I want to ask Yunlian a question first.
|Patch Set 1: Code-Review+2

Ok, I talked with Yunlian. LGTM.
|Patch Set 1: Code-Review+1

The change in sysroot wrapper looks good to me; I don't know if you actually need to uprev the ebuild file or not...
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

This isn't ready for review yet; I just wanted to share it with you.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

I am planning on submitting this upstream separately, and also planning on pushing this into our gcc 4.9 mobile branch.  But changes in neither of those places go into the live ChromeOS compiler code.  As far as I know, this is the only way to change the live ChromeOS compiler.
|Uploaded patch set 4.
|Patch Set 4:

Ok, I will let you know when the upstream patch goes in.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Ping?
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

moving script to different git repository
|Uploaded patch set 1.
|Patch Set 1:

I've tried to make all the requested changes, and it all seems to work, but 'repo upload .' is failing; any suggestions how to fix this?  (My guess is that it's not happy with something I did when removing the old files and adding the new (changing board-specific-gdb to cros_gdb):

 $ repo upload .
Repo must run the script:
  /mnt/host/source/src/repohooks/pre-upload.py

Do you want to allow this script to run (yes/yes-never-ask-again/NO)? yes

Upload project chromite/ to remote branch refs/heads/master:
  branch board-gdb ( 2 commits, Fri Dec 12 10:50:14 2014 -0800):
         a70d7bf5 Basic version of board-specific gdb.
         94ae2496 Basic version of board-specific gdb.
to https://chromium-review.googlesource.com (y/N)? y
Counting objects: 9, done.
Delta compression using up to 32 threads.
Compressing objects: 100% (9/9), done.
Writing objects: 100% (9/9), 6.24 KiB &#124; 0 bytes/s, done.
Total 9 (delta 7), reused 0 (delta 0)
remote: Resolving deltas: 100% (7/7)
remote: Processing changes: refs: 1, done    
To https://chromium-review.googlesource.com/p/chromiumos/chromite
 ! [remote rejected] board-gdb -&gt; refs/for/master (duplicate request)
error: failed to push some refs to 'https://chromium-review.googlesource.com/p/chromiumos/chromite'

----------------------------------------------------------------------
[FAILED] chromite/       board-gdb       (Upload failed)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Ping?
|Patch Set 3:

(13 comments)
|Uploaded patch set 4.
|Patch Set 4:

Please review the latest patch when you have a few minutes. :-)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2

Carrying previous +2 forward.

Removed &quot;!&quot; from &quot;#!&quot; at start, and added  os.environ['TERM'], as requested.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue -Verified

Ok, that's what I originally thought, but then your request made no sense to me.  You want me to remove the entire line?
|Uploaded patch set 6.
|Patch Set 6:

Removed the whole first line now.  May I +2 it again?
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Ping?  Is anybody looking at this?
|Uploaded patch set 3.
|Patch Set 3:

Ping?

Is anybody looking at this (if so, just let me know and I'll stop bothering you)?  Is there anybody else I need to ask to review this?  Is there something missing that needs to be done to get this reviewed?
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(22 comments)
|Uploaded patch set 5.
|Patch Set 5:

(10 comments)
|Uploaded patch set 6.
|Patch Set 6:

DO NOT REVIEW THIS YET!!

I've updated the patch to remove the changes to RunCommand in cros_build_lib.py, but the rest of this is not ready to be reviewed yet; I am continuing to work on previous reviewer comments.
|Uploaded patch set 7.
|Patch Set 7:

I think I have addressed all the previous comment and that this patch is ready for review.
|Patch Set 7:

Ping?
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 8:

Ping?  Anybody?  Is there some reason why nobody is reviewing this?
|Patch Set 8:

Ping?

Yiming has told me, via email, that he has made all the comments he wants to and does not feel competent to review the rest of the patch.

Mike, do you have any further comments you wish to make?

David? Prathmesh?
|Patch Set 8:

(32 comments)
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Patch Set 8:

(1 comment)
|Patch Set 8:

(3 comments)
|Patch Set 9:

(6 comments)

I'm working on the other comments, and I expect to be submitting an  updated patch soon.  However I have a question about this comment from Prathmesh:

Try to obtain a free port using GetUnusedPort https://cs.corp.google.com/#chromeos_public/chromite/lib/remote_access.py&amp;l=104

I could update the script to call GetUnusedPort every time I wanted a port for communicating with a remote/gdbserver, but then every time I get a different port number I will be adding it to the iptable on the remote device.  Mike indicated that growing this table might be a bad thing, in which case using a hard-coded port number for doing remote debugging might be a better way to go.  Comments?

Another question:  I want to create a unit test for this script as well.  Since this CL is already pretty big (and hopefully nearly done), would it be better to finish this CL with just the cros_gdb.py script, and create a separate CL for the unittest, or should I add the unittest to this CL?
|Uploaded patch set 10.
|Patch Set 10:

About the iptables stuff;

I tried commenting out the calls to SetUpIptables and CleanUpIptables, and enabling port forwarding for all remote connections, and I am not able to get gdb to connect/work without the iptables setup:

On the DUT:

localhost ~ # ps auxx &#124; grep gdbserver
root     13088  0.0  0.0   1612   636 ?        S    15:35   0:00 /usr/local/bin/gdbserver --attach localhost:35700 1701
root     13178  0.0  0.0   1428   508 pts/0    S+   15:37   0:00 grep --colour=auto gdbserver
localhost ~ # /sbin/iptables --list
Chain INPUT (policy DROP)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             anywhere            
ACCEPT     icmp --  anywhere             anywhere            
ACCEPT     udp  --  anywhere             224.0.0.251          udp dpt:mdns
NFQUEUE    udp  --  anywhere             anywhere             NFQUEUE num 10000
ACCEPT     tcp  --  anywhere             anywhere             tcp dpt:ssh

Chain FORWARD (policy DROP)
target     prot opt source               destination         

Chain OUTPUT (policy DROP)
target     prot opt source               destination         
NFQUEUE    udp  --  anywhere             239.255.255.250      udp dpt:1900 NFQUEUE num 10001
ACCEPT     all  --  anywhere             anywhere             ctstate NEW,RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             anywhere            

On my desktop machine:

$ ps auxx &#124; grep &quot;:localhost:&quot;
cmtice    4879  0.0  0.0  37340  2336 pts/21   S+   15:35   0:00 ssh -i /tmp/ssh-tmpGUxUFd/testing_rsa -N -o StrictHostKeyChecking=no -o CheckHostIP=no -o BatchMode=yes root@172.17.210.35 -p 35700 -L 35700:localhost:35700 &amp;
cmtice    4910  0.0  0.0  30992   924 pts/30   S+   15:36   0:00 grep :localhost:
$

$ ps auxx &#124; grep gdb
cmtice    4826  0.0  0.0 100516 14780 pts/21   S+   15:35   0:00 /usr/bin/python2 /mnt/host/source/chromite/bin/cros_gdb --board=daisy --remote=172.17.210.35 --attach=browser
cmtice    4878 10.1  4.8 3437772 3168360 pts/21 S+  15:35   0:38 armv7a-cros-linux-gnueabi-gdb --eval-command=set sysroot /build/daisy --eval-command=set solib-absolute-prefix /build/daisy --eval-command=set solib-search-path /build/daisy --eval-command=set debug-file-directory /build/daisy/usr/lib/debug --eval-command=set prompt (daisy-gdb)  --eval-command=file /build/daisy/opt/google/chrome/chrome --eval-command=target remote 172.17.210.35:35700

AND...running the script inside my chroot:

 $ gdb-daisy --remote=172.17.210.35 --attach=browser
15:35:49: INFO: RunCommand: ping -c 1 -w 20 172.17.210.35
15:35:53: INFO: RunCommand: file /build/daisy/opt/google/chrome/chrome
...
Reading symbols from /build/daisy/opt/google/chrome/chrome...Reading symbols from /build/daisy/usr/lib/debug/opt/google/chrome/chrome.debug...done.
done.
172.17.210.35:35700: Connection timed out.
(daisy-gdb) target remote 172.17.210.35:35700
ssh: connect to host 172.17.210.35 port 35700: Connection timed out
172.17.210.35:35700: Connection timed out.
(daisy-gdb) target remote 172.17.210.35:35700
172.17.210.35:35700: Connection timed out.
(daisy-gdb) 

When I add back in the calls to SetUpIptables and CleanUpIptables, it all works properly for me again.

In the case where I removed the calls to the iptable work, is there some other additional piece of set up work that I need to do to make it work properly?  Are you absolutely sure that in the case where it worked for you, you didn't have an entry for the tcp port in your iptables?
|Patch Set 10:

It works fine without the iptables stuff, for me too, when trying it in a VM. But it still fails to be able to connect without the iptables work when I'm using a real DUT.  Have you tried without the iptables with a real DUT?  

I will be happy to remove the iptables stuff if it's really not necessary, but until I can get debugging a real DUT to work without it, I can't remove it.
|Patch Set 10:

(18 comments)

Thank you for explaining more fully.  I have successfully removed the iptables stuff now, and I've implemented most of the rest of your suggestions.  I had a few questions/comments about some of them (see inline responses).

I need to test the changes I've made before uploading the latest patch.
|Patch Set 10:

(1 comment)

Never mind the last comment; I figured out how to get the process id/handle.
|Uploaded patch set 11.
|Patch Set 11:

(6 comments)
|Uploaded patch set 12.
|Patch Set 12:

(3 comments)
|Uploaded patch set 13.
|Patch Set 13:

Ok, I have created a separate CL to handle the 'vm' alias, and I will make this one depend on that one and remove the special vm handling from this script;.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15:

(19 comments)
|Uploaded patch set 16.
|Patch Set 15:

Mike, I have made all the changes you requested.  In the interests of speeding up this process, maybe we should schedule a meeting and review the code together?  What do you think?
|Patch Set 16:

(9 comments)
|Uploaded patch set 17.
|Patch Set 17:

(7 comments)
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Patch Set 20:

(2 comments)
|Uploaded patch set 21.
|Patch Set 21: Commit-Queue+1 Verified+1
|Patch Set 21: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 21: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Current patch doesn't quite work. Wait until I upload next patch for further reviews.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

Mike, The patch you reviewed was version 3 not version 4.  Please review the latest version of the patch.
|Patch Set 4:

Ping?
|Patch Set 4:

(3 comments)
|Patch Set 4:

Ping?

If my previous reply was too abrupt, I apologize.  I hoped to continue the discussion, not to halt it in its tracks.  Is it ever correct to try to ssh into the localhost without specifying a port?
|Patch Set 4:

(1 comment)
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(4 comments)
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1

(4 comments)

Mostly just needs comment fixes, as far as I can tell.  The code looks good to me, but since I am  not an autotest expert, I am adding a couple of autotest people to the review list to give this a sanity check.
|Patch Set 3:

Just FYI...when we generate the perf data &amp; perf reports with crosperf/telemetry we do not attempt or expect to upload it to the perf dashboard; these are reports we generate for our own use, so that should not be a problem.
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1

Just curious, did you test the old method (not running directly on the dut) to make sure it still works?
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Just an FYI comment:  This fixes a problem with the compiler for aarch64 where sometimes in the function epilogue the stack pointer was being incorrectly used for a load after it had been re-set for the calling function.  We haven't been seeing this error much in ChromeOS because the compiler sysroot wrapper script usually adds the -fstack-protector-strong flag, which also prevents this erroneous behavior.  But for aarch64 code that is compiled without the stack protector flag, we definitely need this fix.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Here's the patch I've made with the cherry-picked revisions that we want.  The next ChromeOS branch looks like it's happening on Oct. 2; I don't know if we want to wait until then to push this through or not...I'm still doing a bit of testing on oak.
|Abandoned

Creating a new CL.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

This CL is still being tested.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 2: Code-Review+1

(3 comments)

A couple of minor edit suggestions.
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Do not review this yet; I'm still running the tests.  (I needed to create the patch in order to do use it for trybot runs).
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

I have finished all the testing.  Everything looks good. Please review this CL now.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

I don't understand your comment.

1).  What upstream mailing list?
2).  Who posted the patch where for review?  As far as I know, this is the only patch and the only posting...
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

Patch has also been submitted upstream, and link to email is in the commit message.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

I think this is ok, but I'd appreciate confirmation from someone else.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+1

It would be best to wait (at least a bit) for the upstream patch to be approved before committing this -- if they reviewer requests changes, we want to have those changes in your patch.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

I did 'bin/cros_show_waterfall_layout' and it does not show my new config anywhere.  It shows the toolchain-llvm config in the chromiumos waterfall.
I've double-checked with the team about the internal/external thing.  We did put it in the external manifest intentionally, because initially we thought it might be rather flaky and we were under the impression that sheriffs did not like flaky buildbots in the internal waterfall.  However we have no particular need for it to be external.  All the slaves should be the same (either internal or external), but we will defer to your judgement as to which of these would be more appropriate.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

Carrying forward the previous +2's.
|Patch Set 3: -Code-Review

Removing +2 pending investigation of pre-cq unittest failures.
|Patch Set 3:

The chromeos_config_unittest fails with the following errors:

======================================================================
FAIL: [chromite.cbuildbot.chromeos_config_unittest] CBuildBotTest.testConfigTypesComplete
Verify CONFIG_TYPE_DUMP_ORDER contains all valid config types.
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/mnt/host/source/chromite/lib/timeout_util.py&quot;, line 158, in TimeoutWrapper
    func(*args, **kwargs)
  File &quot;/mnt/host/source/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 492, in testConfigTypesComplete
    (config_name, 'config_lib.CONFIG_TYPE_DUMP_ORDER'))
AssertionError: master-toolchain did not match any types in config_lib.CONFIG_TYPE_DUMP_ORDER

======================================================================
FAIL: [chromite.cbuildbot.chromeos_config_unittest] CBuildBotTest.testSyncToChromeSdk
Verify none of the configs build chrome sdk but don't sync chrome.
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/mnt/host/source/chromite/lib/timeout_util.py&quot;, line 158, in TimeoutWrapper
    func(*args, **kwargs)
  File &quot;/mnt/host/source/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 248, in testSyncToChromeSdk
    'Config %s: has chrome_sdk but not sync_chrome.' % build_name)
AssertionError: Config master-toolchain: has chrome_sdk but not sync_chrome.

======================================================================
FAIL: [chromite.cbuildbot.chromeos_config_unittest] TemplateTest.testConfigNamesMatchTemplate
Test that all configs have names that match their templates.
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/mnt/host/source/chromite/lib/timeout_util.py&quot;, line 158, in TimeoutWrapper
    func(*args, **kwargs)
  File &quot;/mnt/host/source/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 826, in testConfigNamesMatchTemplate
    self.assertTrue(name.endswith(template), msg % (name, template))
AssertionError: master-toolchain should end with release to match its template

----------------------------------------------------------------------
Ran 62 tests in 2.157s

FAILED (failures=3)

I really don't quite understand what I've done wrong or how to fix these.  Does anyone else know?
|Uploaded patch set 4.
|Patch Set 4:

Now it passes the chromeos_config_unittest.  I hope the changes I made were right...
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4:

Help?  The Commit Bot says that nearly all the paladin builds did not start or failed...

Is this likely or even possibly because of this CL?  How can I tell?  What could I possibly have done wrong?
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

I believe they are referring to our nightly test builds/runs.  The reason they are working without your patch is because they are using an old version of Chrome/Telemetry.  (I talked about this with Luis offline).
|Patch Set 1:

The nightly tests are not failing...but they should be...I'm looking into this.
|Patch Set 1:

Ok, the problem has been resolved. Now the nightly tests are failing properly. ;-)
Please submit this CL.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 3:

There's a chromeos_config_unittest.py in that directory; make sure it passes with your changes...otherwise the pre-commit queue will fail.
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

I believe this CL is ready for review now.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2

Carry forward Yunlian's +2.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10: Trybot-Ready+1
|Patch Set 10: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 11.
|Patch Set 11: Trybot-Ready+1

Do NOT commit this CL yet; I'm seeing some testing oddities I want to work out first. :-(
|Uploaded patch set 12.
|Patch Set 12: Trybot-Ready+1
|Patch Set 12:

still testing; I think I'm almost there now.
|Patch Set 12: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(13 comments)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2:

Fixed merge problems.
|Patch Set 2:

Does this need to be reviewed again, or can I just carry forward the +2?
|Patch Set 2: Code-Review+2

Carrying forward +2
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

This is the backport for the R48 branch.
|Uploaded patch set 1.
|Patch Set 1:

This is the backport for the R49 branch.
|Patch Set 1: Code-Review+1
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

We do want those three builds happening under the one (slave) builder...
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 1:

Ok, I've removed 'important=True'.

Can someone please tell me how to figure out: 1). If toolchain-llvm is now a slave of master-toolchain-release or not?  2). If not, what I need to do to make it a slave?  3). How to move toolchain-llvm from the chromiumos waterfall to the chromeos waterfall?
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)

I did a git pull to get the latest changes in the master branch, then rebased my patch so it should be up-to-date now.
|Uploaded patch set 6.
|Patch Set 6:

I'm getting conflicting reviewer comments: Daniel Jacques has asked me to name the builder &quot;llvm-toolchain-group&quot; and Aviv Keshet has asked me to name it &quot;toolchain-llvm-group&quot;.

Which one should I use?
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8: Commit message was updated.
|Patch Set 8:

OK, I've updated the commit message to reflect our decided-upon naming scheme.
|Patch Set 8:

Ping?
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

This CL is in the process of being tested and is not ready for review yet.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 2d511e935a49006ef2e3ce505f0639c49d13f501 by Caroline Tice
|veyron_jaq
|We should move this to line 22
|We should move this to line 22
|We should move this to line 22
|We should move this to line 22
|We should move this to line 22
|We should move this to line 22
|We should move this to line 22
|wificell_preflight
|wificell_preflight
|to the
|Does Google style doc say anything about: '\n\n\nInfo to be ...\n'
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|As in the following?
self.set_content_of_text_field_by_id('Ssid', ssid);
ssid = self._ssid
|Done
|Done
|Done
|Done
|If 'SsidBroadcast' is found, I want to select the broadcast to Enable. Else, the 'SsidBroadcast' element was not found so I'd want to return an Exception (or RuntimeError?). Took away the wait_for_xpath.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The countdown to save settings is 60 seconds.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Nope. Deleted line 79
|I added a while loop to check for the countdown of seconds. Should I have the while loop end when the countdown is at 2 seconds, as we did for DLink DWL2100? 

while (self.object_by_id_exist('show_second') and
         int(timer.text) &gt; 2):
    time.sleep(1)
|Done
|Done
|Done
|get_ap_name(
|Done
|Done
|Done
|This one is a little more difficult because there are a lot of number sequences in the result_str (time, date, etc) so I kept it a bit complex to only capture the firmware version.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Looks like the debug output names 'kernel_version' as 'kernel_ver'
|You're right! Was looking at old logs. Will +1 right now.
|Replace , with % for example: logging.info(&quot;Page did not load or %s&quot; % str(e))
|Oops, hm. It's weird that when printing in Python, we must use a percent sign instead of a comma, but with logging, it seems interchangeable. Sorry about that!
|Replace , with %
|nyan_blaze is currently in pool:wificell_preflight and will be included in the next CL.
|Done
|Yes, McCloud, Panther, and Zako are Atheros AR9462.  Tricky is WP2.
|Looking at the suite_scheduler.ini, wificell_preflight is &gt;=36 so I grouped those two boards together. Swanky's FSI delivery is on 8/5 on M36 and Gnawty (non-touch)'s FSI is TBD and Gnawty (touch)'s FSI is also TBD but on M36. Should we change the suite_scheduler to &gt;=37?
|Done
|Was working on outdated file, thanks for the catch
|stumpy release version is actually 6398.0.2014_10_23_1452. panther release version correctly ends in *_1505
|Include this function in this file (or add to shared logic file and reference to this function)
|space after # &amp; typo were &quot;defult&quot; should be &quot;default&quot;
|We should include wifi_release as well. Our sanity testing includes this test.
|Small syntax nit - let's follow convention and not use commas
|Done
|Done
|Done
|Done
|Nit - indent to left paren
|Nit - indent backwards to line up with &quot;poll&quot;
|Nit - indent to &quot;lambda&quot;
|Google has a style convention that lines end after 80 characters. There's also a style convention that commit messages begin with a tl;dr one-sentence, new line, then more content if needed.

I'd suggest:

&quot;&quot;&quot;
Updated release suite with new boards.

Added orco, sumo, ninja, lulu, banjo. Also deleted gizmo from release suite and moved jerry to list 11.
&quot;&quot;&quot;
|Please move veyron_jerry to list_11.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Hmm, why packet_capture?
|Done
|Done
|Done
|Done
|Since there is only one disconnect_trigger, we can use &quot;elif&quot; instead of &quot;if&quot;
|Same for the following &quot;if&quot; statements
|What does this really mean? :O Is there a way to clarify this error message or add a comment for easier debugging?
|'Config %s allows multiple boards.'
|Done
|Without this, I fail CBuildBotTest.testConfigTypesComplete with &quot;AssertionError: wificell-pre-cq-group did not match any types in config_lib.CONFIG_TYPE_DUMP_ORDER&quot;
|Done
|Am I missing an &quot;internal&quot; here?
|Done
|Done
|We only have two wifi tests in the suite right now and will gradually trial-and-error our way with more tests :)
|Hmm in chromeos_config.py at HWTestList.WiFiCellPoolPreCQ, we refer to constants.WIFICELL_PRE_CQ for the suite name. Should I hard-code this value instead?
|Done
|Done
|I added 'base' to images=['test'], otherwise I'd fail this unittest:
FAIL: [chromite.cbuildbot.chromeos_config_unittest] CBuildBotTest.testImageTestMustHaveBaseImage
Verify image_test build is only enabled with 'base' in images.
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/Work/chromiumos/chromite/lib/timeout_util.py&quot;, line 158, in TimeoutWrapper
    func(*args, **kwargs)
  File &quot;/Work/chromiumos/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 205, in testImageTestMustHaveBaseImage
    build_name)
AssertionError: Build veyron_jerry-wificell-pre-cq runs image_test but does not have base image
|Done
|Do you mean alphabetical order? If so, it is in alphabetical order.
|Updated this and some other param descriptions.
|Done
|Hmm it's cleaner, but this current version makes more sense to me.
|Done
|Done
|Done
|Done
|Done
|Done
|Hmm you're right - GoogleGuest is NOT hosted on our WiFi rack, but this network service is part of our daily testing. I changed the test description.
|Hmm I'm not sure what you mean - I believe that's what I am doing now, in terms of pulling params out of each test_case.

I cleaned up the hardcoded strings of each control file to use the testname field of the namedtuple.
|Thanks! I was wondering where the style guide lived.
|Done
|Done
|Done
|Yes, your instinct is correct! Great idea, thank you.
|Done
|Good idea!
|results is a text file though, not a directory. I could add the suffix to '.txt' if that makes more sense.
|Done
|Done
|This might be better structured as a map of usernames to namedtuples of credentials or other metadata.
|This does not throw an error, but I can change this to &quot;timeout=3&quot; and &quot;time.sleep(SHORT_TIMEOUT)&quot;. When scanning for networks, especially on the WiFi Rack, it takes ~30 seconds to get all WiFi networks since the DUT is in open space and not in a wificell.
|Ideally, this line would cancel the control file test and move onto the next control file. Instead, it fails the entire server side test.
|Convention looks like this - PTAL at https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/client/cros/networking/shill_xmlrpc_server.py&amp;q=set_service_order&amp;type=cs&amp;l=309
|Convention looks like this - PTAL at https://cs.corp.google.com/#chromeos_public/src/third_party/autotest/files/client/cros/networking/shill_xmlrpc_server.py&amp;q=set_service_order&amp;type=cs&amp;l=309
|Constant variable as something like:
SCAN_AP_TIMEOUT=30
|You're right, it does with &quot;TestError: Could not lock a device with labels ['webdriver']&quot;
|Move this below the summary description.
|Done
|Done
|Is this supposed to be aligned with the other &quot;if&quot; statement below?
|This particular AP did not allow me to change the security to wpa2. Believe me, I tried multiple times.
|This particular AP did not allow me to change the security to wpa2. Believe me, I tried multiple times.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Makes sense
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

Congrats on your first CL!
|Patch Set 1: Code-Review+1

Leaving the last +2 to Roshan, if the output looks fine to him.
|Patch Set 1: Code-Review+2

(1 comment)

It's actually veyron_jaq and not &quot;jag&quot; :) 

Aside from this, LGTM if the release suite runs against this CL
|Patch Set 1:

(7 comments)
|Patch Set 1: Code-Review+2
|Patch Set 5:

(2 comments)
|Patch Set 8: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Here's to hoping this finally merges.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Fifth time's a charm? If the reviewers are in favor of a chump, please let me know. Looking at errors of the failed builds, I'm 99.9% sure this CL is irrelevant to those.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

TEST=Passed wifi_perf*

*in the sense that I don't see this error message anymore

02/03 18:22:45.820 ERROR&#124; interface:0173&#124; Device vendor/product pair DeviceInfo(vendor='0x8086', device='0x095a') for device 0x095a is unknown!

As to why the tests themselves aren't passing, it's most likely unrelated to this CL.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

Here's to hoping this finally merges.
|Patch Set 1: Code-Review+2

TUFM - Thumbs up for me!
|Patch Set 4:

(2 comments)
|Patch Set 5: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(9 comments)
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 2:

This is for a test that is run manually, chumping.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1:

(1 comment)
|Abandoned

Moved both files under another CL (193498)
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1 Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(10 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Verified+1
|Abandoned

Forgot one more small change - don't need so many patches
|Restored

Nevermind, restored change
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Verified+1
|Patch Set 4: -Code-Review
|Patch Set 4: Code-Review+1
|Patch Set 4:

(9 comments)
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Verified+1
|Patch Set 5: -Code-Review Commit-Queue+1 -Verified
|Patch Set 5: Code-Review+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+1 Commit-Queue+1 Verified+1

Created a new branch on ToT with repo sync'ed.
Modified chaos_dynamic_ap_list.conf file to include dir505l.
Uploaded with same commit message.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Patch Set 2: Verified+1
|Patch Set 2:

Sample debug logs uploaded to https://code.google.com/p/chromium/issues/detail?id=352008
|Patch Set 3: Patch Set 2 was rebased
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(7 comments)
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 7: Verified+1
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 3:

Chumping change
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Abandoned

Didn't verify
|Patch Set 2:

Tricky FSI is due M36 7/38 and Delivery on M36 8/1
|Patch Set 2:

Getting too excited about trying to finish this CL.

Tricky FSI is due M36 7/28.
|Restored

Does 'Abandon Change' delete all patches and not just one? Hm, let's find out.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 4:

Chumping because this test is run manually. Code changes have been verified against multiple branch and build combinations.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

@Bindu - I believe a device isn't considered in preflight when its FSI occurs in a branch &lt; ToT branch. Correct me if I'm wrong, Kris.

@Kris - Yep, already changed the labels before this CL!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 3:

Chumping - manually run suite
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 3:

Carried Kris' +2; chumping
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

Carrying +2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

Carrying +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Crediting @wiley as co-author of this CL.

Carrying Peter's +2.
|Patch Set 2: Code-Review+2
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1

No problem!
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1

Looks like a lot of files were renamed (updated to revision +1) hence the need for a rebase.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Yes, the wifi_matfunc looks green for the hosts (alex, glimmer, falco, squawks) of the stumpys I updated.
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+1

A trial run on a R40 build that picks up and schedules jobs for Samus would be solid verification for this CL.
|Patch Set 1: Code-Review+2
|Patch Set 1:

LGTM
|Patch Set 2:

(2 comments)
|Patch Set 1:

Host4:
---------------------------------------------------------------------------------------------------------------
/tmp/test_that_results_09NUWx/results-1-network_WiFi_VerifyAttenuator                               [  PASSED  ]
/tmp/test_that_results_09NUWx/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator [  PASSED  ]
---------------------------------------------------------------------------------------------------------------
Total PASS: 2/2 (100%)

Host5 with
---------------------------------------------------------------------------------------------------------------
/tmp/test_that_results_7StSNT/results-1-network_WiFi_VerifyAttenuator                               [  FAILED  ]
/tmp/test_that_results_7StSNT/results-1-network_WiFi_VerifyAttenuator                                 FAIL: Expected connect to fail, but it was successful.
/tmp/test_that_results_7StSNT/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator [  FAILED  ]
/tmp/test_that_results_7StSNT/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator   FAIL: Expected connect to fail, but it was successful.
/tmp/test_that_results_7StSNT/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator   11/17 17:39:46.012 ERROR&#124;network_Wi:0067&#124; Failed to connect to AP 1 on attenuator 0
---------------------------------------------------------------------------------------------------------------
Total PASS: 0/2 (0%)

Host6 failed with
---------------------------------------------------------------------------------------------------------------
/tmp/test_that_results_Ct24eV/results-1-network_WiFi_VerifyAttenuator                               [  FAILED  ]
/tmp/test_that_results_Ct24eV/results-1-network_WiFi_VerifyAttenuator                                 FAIL: Expected connect to fail, but it was successful.
/tmp/test_that_results_Ct24eV/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator [  FAILED  ]
/tmp/test_that_results_Ct24eV/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator   FAIL: Expected connect to fail, but it was successful.
/tmp/test_that_results_Ct24eV/results-1-network_WiFi_VerifyAttenuator/network_WiFi_VerifyAttenuator   11/17 17:38:35.850 ERROR&#124;network_Wi:0067&#124; Failed to connect to AP 0 on attenuator 2
---------------------------------------------------------------------------------------------------------------
Total PASS: 0/2 (0%)
|Patch Set 1: Code-Review+2

Temporarily locked host2, host5, and host6 from running while we get host1, host3, and host4 back up and running.
|Patch Set 1: Code-Review+2

Once we give your patch a trial run and verify Candy is picked up, LGTM
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1

Makes sense to me.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

LGTM, but might need more input from those with more experience in TPMs than me!
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Looks like TIME = 'MEDIUM' will cause the first connection attempts to fail. Permission to change back to TIME = 'LONG'?
|Uploaded patch set 4.
|Patch Set 4: Verified+1

-------------------------------------------------------------------------------------------------------------------------------------------------------
/tmp/test_that_results_Zd_IJ7/results-1-network_WiFi_ChaosConnectDisconnect.jetstream                                                       [  PASSED  ]
/tmp/test_that_results_Zd_IJ7/results-1-network_WiFi_ChaosConnectDisconnect.jetstream/network_WiFi_ChaosConnectDisconnect.storm_a_ch48_wpa2 [  PASSED  ]
/tmp/test_that_results_Zd_IJ7/results-1-network_WiFi_ChaosConnectDisconnect.jetstream/network_WiFi_ChaosConnectDisconnect.storm_g_ch5_wpa2  [  PASSED  ]
-------------------------------------------------------------------------------------------------------------------------------------------------------
Total PASS: 3/3 (100%)
|Patch Set 4: Commit-Queue+1

Spoke to krisr@ - carrying his +2 to submit to CQ
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Abandoned

Created a new CL here: https://chromium-review.googlesource.com/#/c/239281/
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Lesson Learned: Don't upload two commits from the same branch if you plan on submitting only one of those commits. There will be an automatic CL dependency between commits from the same branch.

I cherry-picked the changes from CL:238077 and uploaded from a new branch. Changes are the same so I'm carrying the +2's from the previous CL to this CL. Verified+1, Code-Review+2, and Commit-Queue+1.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

There are overlaps between wifi_matfunc running nightly and the weekly wifi_matfunc that was set up (likewise for network3g). Should we delete the entries for weekly runs since we're running nightly for &gt;=tot-2?

Also, I changed network_nightly to run &gt;=tot-2 despite being in pool: suites. IMO, the autofiled bugs were valuable.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Since network_nightly belongs to pool:suites, we'll leave that unchanged. This suite should run on TOT nightly and TOT-2 weekly.

wifi_matfunc and network3g_* should run TOT-2 nightly, as test team manages pool:wificell and pool:cellular.
|Patch Set 2: Commit-Queue+1

Carrying harpreet@'s +2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

Should we remove M40 from network3g suites as well?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

This CL changes how we invoke Chaos tests through test_that. Unfortunately there are issues running unit tests for new dynamic AP configurators with (and without) these changes.

There are some deletes and some add-ons, so please feel free to question my logic and make suggestions.
|Abandoned

New CL: https://chromium-review.googlesource.com/#/c/275144/
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

Thanks for the catch!
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

Once calibrated, will update these numbers. We should keep these grovers locked until then.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

FYI this CL also contains recalibration for grover 5.
|Abandoned

Outdated
|Patch Set 1:

Oops, I think you uploaded the Intel patches from yesterday's debugging.
|Patch Set 1: Code-Review+2

Otherwise, LGTM
|Uploaded patch set 1.
|Patch Set 1:

Here is a sample run with the latest code.
https://pantheon.corp.google.com/storage/browser/chromiumos-test-logs/bugfiles/misc/ChaosVMAutomation/

As you can tell, the total pass is 58/76 (76%), which is very low compared to usual Chaos open runs (90+%). Only one was an actual failed connection attempt. The rest are ChaosConfigFailures.

I'll look through the APs that failed configuration because I am theorizing that there are 3 issues: 1) my URL updates to chaos_dynamic_ap_list.conf may have messed something, 2) the VM was too slow in bringing up the URl, and/or 3) AP configuration via dynamic_ap_configurator was truly wrong.

I'll file appropriate bugs for updating failed AP configurators.
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1 Trybot-Ready+1
|Patch Set 5: Code-Review+2 Commit-Queue+1

Woohoo! Carrying +2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1

Carrying +2
|Patch Set 2: Code-Review+2

(3 comments)

Small nits (krisr@ taught me the art of indenting Google style). Otherwise, feel free to carry the +2.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1

Let's see if this invokes HWTests.
|Patch Set 2:

Hmm I don't see any HWTest instances in the build log.
|Patch Set 2:

Ahh I got too excited. It's running now.
|Patch Set 2:

:( It's right here: http://cautotest.corp.google.com/afe/#tab_id=view_host&amp;object_id=3530

Unless I missed a step somehow?
|Patch Set 2: Code-Review+2 Verified+1

DUT is back up. Invoking a pre-cq run again.
|Patch Set 2: -Verified
|Patch Set 2: -Trybot-Ready
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2:

Just curious, why would it break the CQ?
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)

Please add sumo, ninja, lulu, banjo
|Patch Set 2: Code-Review+2

(1 comment)

After this change, LGTM
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1

(6 comments)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Verified with test runs; carrying wiley@ +2
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Carrying +2
|Patch Set 1:

(3 comments)
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)

Also added SUITE= due to presubmit hook
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 6:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Trybot-Ready+1

Not sure if the fails were flakes. BinhostTest failed on only snow builder, and UnitTest failed on only rambi builder.

Aviv/Don - am I correct on this hunch?
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1

Thanks Aviv - updated 'snow' to 'daisy'. Let's see how this rolls.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Trybot-Ready+1

The second failed BinhostTest and UnitTest was fired off before this second patch. Setting Trybot-Ready+1 to catch patch 2.
|Patch Set 2:

Aviv, just curious - what would be a bad combination of boards that can't run simulanteously? (Would it possibly be boards of the same family? If so, I had chose veyron_jerrys and veyron_speedys.)
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Commit-Queue+1

I was going to wait for the new wificell-pre-cq config CL to land, but I'm also very curious about this suite. CQ+1.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Code-Review+2 Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2

I think verifying this CL after the other patch goes in will be nice. Once that's ready, feel free to carry over my +2.
|Patch Set 1:

The only other way I can think of is creating a cautotest job from AFE and editing the control file. dshi@ might have more ideas if you want to loop him in, Eric.
|Patch Set 2: Trybot-Ready+1

Sending this through the wificell-pre-cq trybot. I'll add on my +2 after this passes. Thanks Eric!
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+1

The refactoring LGTM, but I'm not as familiar with these files as the other reviewers so someone else should +2.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

Just this one question; otherwise +2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1

Launching trybot to see if previous failures from crbug.com/519858 were flakes.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2:

Locked chromeos1-shelf5-host3 and host5 to check if it's device-specific problems causing HWTest to fail.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Abandoned

All works well.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2:

It doesn't look like test images were created in the artifacts. Instead, ImageTests were run.
|Uploaded patch set 3.
|Patch Set 3: Trybot-Ready+1
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3:

This CL did the job of finding out what flags would create test images in archives.
|Abandoned

This CL did the job of finding out what flags would create test images in archives.
|Patch Set 2:

Just curious, Paul - did you run against ht20_aes? That was the only test that I could repro with the failure.
|Patch Set 2: Code-Review+2 Verified+1

Ran patch and passed on ht20_aes.
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)

Just curious - if you had the assert in the second case, can you confirm the wificell-pre-cq config fails?
|Patch Set 2: Code-Review+2

Wonderful, thank you!
|Uploaded patch set 1.
|Patch Set 1:

I'm not sure where to place &quot;constants.WIFICELL_PRE_CQ&quot;. The previous config had this param, but I run into this SyntaxError when I try to add it as a param to AddTemplate.

Traceback (most recent call last):
  File &quot;./chromeos_config_unittest&quot;, line 142, in &lt;module&gt;
    commandline.ScriptWrapperMain(FindTarget)
  File &quot;/Work/chromiumos/chromite/lib/commandline.py&quot;, line 893, in ScriptWrapperMain
    target = find_target_func(target)
  File &quot;./chromeos_config_unittest&quot;, line 128, in FindTarget
    module = cros_import.ImportModule(target)
  File &quot;/Work/chromiumos/chromite/lib/cros_import.py&quot;, line 43, in ImportModule
    module = __import__(target)
  File &quot;/Work/chromiumos/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 14, in &lt;module&gt;
    from chromite.cbuildbot import chromeos_config
  File &quot;/Work/chromiumos/chromite/cbuildbot/chromeos_config.py&quot;, line 2384
    constants.WIFICELL_PRE_CQ,
SyntaxError: non-keyword arg after keyword arg
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

Also removed &quot;wificell-pre-cq&quot; from config_lib.py
|Uploaded patch set 5.
|Patch Set 4:

(4 comments)

Also added 'base' to images=['test'], otherwise I'd fail this unittest:

FAIL: [chromite.cbuildbot.chromeos_config_unittest] CBuildBotTest.testImageTestMustHaveBaseImage
Verify image_test build is only enabled with 'base' in images.
----------------------------------------------------------------------
Traceback (most recent call last):
  File &quot;/Work/chromiumos/chromite/lib/timeout_util.py&quot;, line 158, in TimeoutWrapper
    func(*args, **kwargs)
  File &quot;/Work/chromiumos/chromite/cbuildbot/chromeos_config_unittest.py&quot;, line 205, in testImageTestMustHaveBaseImage
    build_name)
AssertionError: Build veyron_jerry-wificell-pre-cq runs image_test but does not have base image
|Patch Set 5:

Poke!
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 6:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

LGTM
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2:

Is the board overlay veyron-speedy instead of veyron_speedy?


cros_setup_toolchains: Unhandled exception:
Traceback (most recent call last):
  File &quot;/mnt/host/source/chromite/bin/cros_setup_toolchains&quot;, line 142, in &lt;module&gt;
    commandline.ScriptWrapperMain(FindTarget)
  File &quot;/mnt/host/source/chromite/lib/commandline.py&quot;, line 913, in ScriptWrapperMain
    ret = target(argv[1:])
  File &quot;/mnt/host/source/chromite/scripts/cros_setup_toolchains.py&quot;, line 1132, in main
    bricks_wanted, root=root)
  File &quot;/mnt/host/source/chromite/scripts/cros_setup_toolchains.py&quot;, line 614, in UpdateToolchains
    targets.update(toolchain.GetToolchainsForBoard(board))
  File &quot;/mnt/host/source/chromite/lib/toolchain.py&quot;, line 60, in GetToolchainsForBoard
    buildroot=buildroot)
  File &quot;/mnt/host/source/chromite/lib/portage_util.py&quot;, line 186, in FindOverlays
    overlays = _ListOverlays(board=board, buildroot=buildroot)
  File &quot;/mnt/host/source/chromite/lib/portage_util.py&quot;, line 168, in _ListOverlays
    raise MissingOverlayException('board overlay not found: %s' % board)
chromite.lib.portage_util.MissingOverlayException: board overlay not found: veyron_speedy
|Patch Set 2:

Maybe akeshet@ or dshi@ would know?
|Patch Set 2:

Thanks for the response, David! I'll add reviewers to the CL in question (here: https://chromium-review.googlesource.com/#/c/295463/).
|Abandoned

All works well.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1

Good idea - updated the commit message with the pre-cq-configs flag.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2:

Alrighty. HWTest failing winky for unpingable router, no problem. I rebooted the router, and it's pingable again.

As for the failed VM tests, they fail same as before:
bin/ctest --board=daisy --type=vm --no_graphics --target_image=/b/cbuild/etc_master/src/build/images/daisy/latest-cbuildbot/chromiumos_test_image.bin --test_results_root=/b/cbuild/etc_master/chroot/tmp/cbuildbotJYZuV7/test_harness --only_verify --suite=smoke --whitelist_chrome_crashes --ssh_private_key=/b/cbuild/etc_master/src/build/images/daisy/latest-cbuildbot/id_rsa exited with code 1

Aviv once mentioned that VMTests were not necessary, though they provide additional coverage. Is this statement still valid?
|Patch Set 2: Trybot-Ready+1

Okay, let me spin that now, Don, thanks.

Once again with my CL.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)

Thanks David!
|Uploaded patch set 4.
|Patch Set 4: Trybot-Ready+1

Done and done! Removed 'base' images and disabled image_test. Unittests passed. Invoking Trybot-Ready now.
|Patch Set 4:

Hmm, I believe images=['test'] was needed to create test images in the Archive? Is that correct?
|Patch Set 4:

Btw, I don't see a builder for daisy in the Artifacts.
|Uploaded patch set 5.
|Patch Set 5: Trybot-Ready+1

(2 comments)

Thanks David!
|Patch Set 5: Verified+1

Interestingly enough, I can access the daisy Artifacts by manipulating the GS URL. Is this a bug that not all builders have their artifacts linked in the builder log?
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)

PTAL. Right now, a single failure from a control file causes the entire (server side) test to fail. Logs uploaded here: https://pantheon.corp.google.com/storage/browser/chromiumos-test-logs/bugfiles/misc/network_WiFi_RackConnect/
|Patch Set 2:

(1 comment)

Bindu, for client side code, PTAL at client/site_tests/network_RackWiFiConnect/network_RackWiFiConnect.py
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)

After discussing with wiley@, I'll be removing the server side and inside using the WiFi proxy to set the service order.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(5 comments)
|Uploaded patch set 7.
|Patch Set 6:

(11 comments)
|Uploaded patch set 8.
|Patch Set 6:

(2 comments)

Thanks wiley@!
|Patch Set 7:

(2 comments)
|Patch set 9: Published edit on patch set 8.
|Patch Set 8:

(1 comment)
|Patch Set 9:

Just so I have somewhere to note this - 

proxyAuth, captive portal, EAP-TLS require keyboard input; hence these were not automated.
|Patch Set 9:

(1 comment)

Thanks Bindu! 

Do you mean alphabetical order? If so, it is in alphabetical order.
|Patch Set 9: Verified+1
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1

Fixed spaces to tabs. PTAL.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch set 4: Published edit on patch set 3.
|Patch Set 4: Trybot-Ready+1

Ready for review, sending through Trybot
|Patch Set 4: Commit-Queue+1 Verified+1

Thanks!
|Patch Set 4: Code-Review+2

Carrying Kris' +2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2

Too bad wificell-pre-cq is blocked by crbug.com/535267 - otherwise this CL would be perfect to ensure no flakes!
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2

LGTM
|Uploaded patch set 1.
|Patch Set 1:

When I filter for jobs with &quot;release/R47-7500.0.0-test_suites/control.wifi_interop&quot;, there should only be 3 jobs created because there are only 3 DUTs running Chaos tests nightly (- and only these 3 have the 'chaos_nightly' label.) I had assumed autotest checks all dependencies before scheduling jobs, but it looks like autotest is picking 'chaos_dut' before checking the second label 'chaos_nightly'. Hence the swap in labels. If this doesn't help, I may remove the 'chaos_dut' label, as 'chaos_nightly' is only on DUTs right now.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

They won't fit on one line and be in the 80-char limit.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1:

I added network_WiFi_RoamSuspendEndToEnd because I thought testing suspend/resume WiFi issues was partly why we added servos in the wificell-pre-cq (aside from being able to bring DUTs back up). If that's not the case, I don't mind removing this test from suite:wificell-pre-cq.
|Patch Set 1:

I see that it fails sporadically: https://wmatrix.googleplex.com/wifi_matfunc?days_back=30&amp;suites=wifi_matfunc&amp;tests=network_WiFi_RoamSuspendEndToEnd

Mostly Connection Refused errors, and even a TestFail for a KI in that daisy will fail servo tests with &quot;Servo failed to set lid_open to no&quot;.

Looks like I didn't choose the right test for wificell-pre-cq purposes of quick verification. Kris and Bindu, would you have any qualms about me removing this test from suite:wificell-pre-cq until after we monitor servo health and tests are green nightly?
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1

Invoking wificell-pre-cq
|Patch Set 2: Verified+1
|Patch Set 2: -Verified
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

Didn't want CL to go through wificell-pre-cq debugging, so removed flag from commit message.

Verified by running .debug with all VMs locked, no VMs locked, VMs left powered on after a Ctrl+C.
|Patch Set 4: Code-Review+2

Sure! Carrying Bindu's +2 to chump. Chumping is justified as this would not affect general lab and only Chaos lab.
|Patch Set 4: Verified+1
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Trybot-Ready+1
|Patch Set 2:

Oh no I meant the Trybot-Ready+1 to invoke the mixed-wificell-pre-cq :) 

But as to why it is taking ~3 hours to finish, that is very perplexing ...
|Patch Set 2:

If I query for &quot;wificell-pre-cq/R48-7588.0.0-b57-test_suites/control.wificell-pre-cq&quot; in cautotest job list and dig into each individual job's Job History, the Provision step takes ~12 minutes. I'll ask infra if this could be faster.
|Patch Set 2: Code-Review+2
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch set 3: Published edit on patch set 2.
|Patch Set 3:

This is the first working batch of DSL APs. There were a few I didn't add because there were duplicated make/model, 2 APs in German, carrier APs, and a few problem ones. The problems ones will be the second batch I'll work on.
|Patch set 4: Commit message was updated.
|Patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Patch set 7: Published edit on patch set 6.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 2: Code-Review+2

(1 comment)

After nit in commit message, LGTM!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 2: -Code-Review Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

I didn't touch builder code. CQ+1 again.
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

Ping on this CL
|Patch Set 1: Commit-Queue+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch set 5: Commit message was updated.
|Patch Set 5: Verified+1
|Uploaded patch set 6.
|Patch Set 6: Verified+1 Trybot-Ready+1
|Patch Set 6:

PTAL!
|Uploaded patch set 7: Commit message was updated.
|Patch Set 7: Verified+1 Trybot-Ready+1

Hi Fang! Is there anything else that needs to be done for this CL?
|Patch Set 7: Commit-Queue+1

Thank you!
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

FYI - I'll fix upload a second CL for the remaining 5 broken dynamic APs, but I wanted these 12 to get in first so that I can unlock them from cautotest.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(2 comments)
|Patch Set 3: Trybot-Ready+1
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

Perfect - thanks Roshan!
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2

Carrying +2
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1

Unfortunately when running Chaos with an autotest bundle earlier than what this build lands in, you'll have to manually add this field in chaos_dynamic_ap_list.conf.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

PTAL!
|Patch Set 1: Commit-Queue+1

Thank you!
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 1:

A test run failed due to initializing timeout_min and delay_secs, which doesn't exist in __init__ for AFE. My bad. Retrying trybot run with new patch.

Failed run: http://cautotest/afe/#tab_id=view_job&amp;object_id=51999376
|Patch Set 2: Trybot-Ready+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Updated TEST= of commit message.

Test run could lock packet_capture and webdriver but aborted while running on an AP. May be unrelated to this change.
http://cautotest/afe/#tab_id=view_job&amp;object_id=52018190

Carrying fdeng@'s +2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

This CL does not touch on HWTests. CQ+1 again.
|Uploaded patch set 1.
|Patch set 2: Published edit on patch set 1.
|Patch Set 2: Trybot-Ready+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Trybot-Ready+1

Cool, good idea! It's possible the suite scheduler may not schedule the suite with the same build and skip if there is already a suite on the same build running/finishing, but we shouldn't expect the DUTs to run on the same build as they will be running for 24 hours anyway.

Changes to timeout and Copyright years (forgot it's 2016) made.
|Patch Set 4:

Trybot run looks good - PTAsecondL
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Carrying +2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Not at all! It was my mistake on the previous CL (https://chromium-review.googlesource.com/#/c/325341/), not running --sanity. Thanks for the +2, Dan!
|Patch Set 4: Trybot-Ready+1
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: Commit-Queue+1 Verified+1

Yeah! Maybe they were removed for devs to test against. We may have to do an audit, especially when we add in AC routers.
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2

That is very good to know!
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1:

These tests are meant to run in 6-8 wificells (one for each WiFi module chipset) dedicated to stress testing and especially for newer boards that are undergoing FSI. If the network_WiFi_SuspendStress tests move out of wifi_matfunc, there would be no coverage of SuspendStress across all platforms and only against a few devices at a time.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1

After talking to Dan and Kris, it looks like it would be possible to extract the suite name from the parent job, but it is conventional to create duplicated control files with small changes (for example, network_WiFi_SimpleConnect).
|Patch Set 2:

PTAL!
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Why it should be modified in coreboot, coreboot pass the Board ID from GPIO to Kernel, this process should be no mistake, rev1 for EVT, rev2 for DVT ...

	/* We started adding board IDs (from 0) with the rev1 board... m( */
	fit_set_compat_by_rev(&quot;google,veyron-pinky-rev%d&quot;,
			      lib_sysinfo.board_id + 1);
|CQ-DEPEND=CL:*175811 ? Need * ?
|maybe I should import test_ui, and self.ui = test_ui.UI() . right ?
|pinky_dimm_count means the number of channel,right?
|Done
|Done
|Done
|Done
|ramid 0b010 isn't stuff for Quawks'MP,
|if removed &quot;hold_cold_reset&quot;, maybe you should also modify firmware_test.py
logging.info('RECOVERY button pressed to switch to dev mode')
                self.servo.set('rec_mode', 'on')
                time.sleep(self.faft_config.hold_cold_reset)
                self.servo.set('rec_mode', 'off')
|Done.
|could you add chrome-os-partner:47884? thanks
|Done
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked from branch chromeos-3.14.
|Abandoned

no verify on tot
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R43-6946.B-chromeos-3.14 as commit 63d4813d1a8d76a0b77dccac724972b5fad7378e
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Cherry Picked from branch factory-veyron-6591.B.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch master as commit d0c7537f83311e78346775e5c8bba11daa0a2c38
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R42-6812.B as commit 328d503bcb6587f8cb3a01f0ef81d9f122d6dc43
|Patch Set 2: Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R42-6812.B as commit 42d849dae9ad1b8b2360b525beb39180bfd7a94a
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B as commit d0abff6610c58e3a04ab86c17a37c0801c158467
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R42-6812.B as commit b410cf22af95ea7548e7915f7a597f85051695ba
|Patch Set 1:

thanks.
firmware_FAFTSetup passed if no minnie.py, so we will run the whole faft
|Patch Set 1: Verified+1

verify ok
|Abandoned
|Patch Set 1:

(1 comment)
|Patch Set 11: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B as commit fee73e2160ca60dc9103aba29f2d308e0c3e6f6b
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Verified+1
|Abandoned

Modified change-id, changed to CL https://chromium- review.googlesource.com/#/c/244158/
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B as commit 10c7e99b05dc6102328299bfc6ef34ff94f841a5
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B as commit fb3b78d34e53daf7a217b3d5b3ed3177ae9d68ef
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B-chromeos-3.14 as commit 093f92eaca45f75672ac8357de84ed6a079ca0f3
|Uploaded patch set 1.
|Topic set to rambitest

rambitest branch
|Abandoned

rambitest branch
|Uploaded patch set 1.
|Abandoned

error
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5:

re-upload, depends on CL:189161, which isn't marked as Commit-Ready anymore.
|Uploaded patch set 6.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

verify OK.  Ready again
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned

disable R34
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(1 comment)
|Patch Set 2:

maybe I should import test_ui, and self.ui = test_ui.UI() . right ?
|Uploaded patch set 3.
|Patch Set 3:

I verified Ok on one unit, and we will verify it in the factory today. so I will set verified+1 later.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 6: Cherry Picked

This patchset was cherry picked to branch firmware-veyron-6588.B as commit f6b34d3b937bea7d64d3624f4ffd05f06aa64ac1
|Patch Set 1: Code-Review+1

verified
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch firmware-veyron-6588.B as commit 9c7b28d2c6d226d0d898e74d5a59ee3635c87454
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 5: Cherry Picked

This patchset was cherry picked to branch firmware-veyron-6588.B as commit 1d8c82fa235dd3a2dc629bf8faafd1182a5b7952
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch firmware-veyron-6588.B as commit 11b7aa5216a87e3d6e08bf46435db0d9c1ee2af4
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch master as commit e6d25013e0b7cfdf7c1e97a07c7832c9aabd8482
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B as commit cfab98c9162601aecde1fcbd18c7d4b169476075
|Patch Set 7: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B-chromeos-3.14 as commit 2302293a4c48e3a4f56d31ca20d04c1da1247fd1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-veyron-6591.B as commit ce0e83055aa3c0eaca2593971659c424199491ee
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(3 comments)

thanks
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)

https://chromium-review.googlesource.com/#/c/281023/ has merged, modify the veyron to no-ECs boards, and create a new parent class pinky for EC boards
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1

thanks
|Patch Set 5: Cherry Picked

This patchset was cherry picked to branch firmware-veyron-6588.B as commit f7f42c8fe4f63df0de6834878209b5c53252e285
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

verify on speedy
|Patch Set 1:

I didn't have access to chrome-os-partner:37027.could you like to review the
chrome-os-partner:42508
|Patch Set 1:

hi Bowgo, yes, it fixed the gray screen of issue 42508
|Patch Set 1:

https://chromium-review.googlesource.com/#/c/285682/ was merged
|Abandoned

https://chromium-review.googlesource.com/#/c/285682/ was merged
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

https://chromium-review.googlesource.com/290108
|Patch Set 1: Verified+1

ASUS EE verified , and passed the RF/EMI
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch master.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R46-7390.B as commit fcab8154c5d6d0f7bd18b0b6cce80eebf4f1ff58
|Patch Set 3:

(1 comment)
|Patch Set 1: Verified+1

completed 500 iterations, still running
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1:

Luke, this is the same as https://chromium-review.googlesource.com/#/c/307867/,right?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(1 comment)

Mickey only ship with Samsung and Elpida. and thanks for reminding modify DS. Done
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

rebase . please review
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch firmware-glados-7820.B as commit 846b5c0f642a04884cb0f62442ffcc0746d9f429
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch firmware-glados-7820.B as commit 9bc72a11cc8e3ff813831c8669759782505ac746
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|We should remove this for M43.
|This should be removed as well for M43.
|should it be stout?
|This should be marked as 'important=True'
|This should be marked as 'important=True'
|This should be True.
|Yes, they should be marked as important in this CL.
|This should be marked as 'important=True'
|But peppy is freon now.
|why is this removed? we need this to do any trybot jobs for releases.
|could we remove this?
|could we remove this?
|Are you pinning it for now?
|Do we have to remove this condition to make M46 a boardless master?
|Patch Set 1: Cherry Picked from branch chromeos-3.8.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-7060.B-chromeos-3.8 as commit 9e79488a3b2fb9179dfb611a80314bebc20f2cbb
|Patch Set 1: Code-Review+1
|Patch Set 1:

let it go through the CQ. BTW, does this need a restart?
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 8: Reverted

This patchset was reverted in change: I04cce714816988ed00b6067a7efe80af53c79348
|Patch Set 2: Reverted

This patchset was reverted in change: Ia7702f47c259e7f84d4e9e2f93c20c5051df8ba5
|Patch Set 1: Code-Review+1
|Patch Set 2:

(2 comments)

Please remove all the reference to stout-freon and quawks-freon for M43.
|Patch Set 1: Code-Review+2
|Patch Set 1:

Daniel, this is landing directly in M43 branch. Will this affect ToT?
|Patch Set 1:

It would be nice everything gets merged by end of this week. Testing team already raised that they won't sign off any builds if this isn't fixed before next dev release for M43.
|Patch Set 1:

sgtm! thank you
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+1
|Patch Set 2:

Just want to make sure that only stout and quawks builders(non-freon) will be marked as experimental and others as important.
|Patch Set 2:

(5 comments)

PTAL
|Patch Set 2:

(1 comment)
|Patch Set 4:

VMTests are now enabled. We can remove that restriction.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

Thanks for cleaning it up!
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

We are not building M40 anymore. We can abandon this change.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Cherry Picked from branch release-R42-6812.B.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Cherry Picked from branch release-R42-6812.B.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Cherry Picked from branch release-R42-6812.B.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Cherry Picked from branch release-R42-6812.B.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2

Thanks for fixing it so soon!
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-6812.15.B as commit 5fc7e67798be73869f671c4a2c7b08363762afe2
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-6812.15.B as commit 713f02cf0d5632a8150f6d9e7646e7fdf6f4b518
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-6812.15.B as commit ecd1683956c0a5389580bc54be2274385800ec48
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-6812.15.B as commit 5e055fcf3210f9b572b092f76db50fb9fd606014
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4:

dnj already has a patch to fix this. I'm not sure if we need this anymore. Please take a look - https://chromium-review.googlesource.com/#/c/254620/
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

We can abandon this CL. I'll create a different bug to track the progress of adding a chromebox to PFQ.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

We don't have parrot_ivb freon variant. Could you please remove it? thanks!
|Patch Set 1:

(2 comments)

I still see some more references to parrot_ivb_freon in .json file.
|Patch Set 3: Code-Review+2
|Patch Set 1:

Requesting Ben to review the fix.
|Patch Set 1: Verified

Requesting Ben to review the fix.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 092671df10f0ae10c29f95d686eaa03ebb385874
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 1873b44ec75bac237c9534b0134a763263f5151d
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 9b6d48ddf88281a902d21c85cd27e34dfd495528
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as b89a63edeb3005d6d4a5847888d98ffe634ec51b
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 9820a29340deb2f4fea7d686454f662c6d476198
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as dbed0f66ea37b3cdb5764b392b668deafe43fe2e
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 9e409a1fa0bc2be5812702adfe9f4c686bfad208
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as d24b51423a5990e940bcc0716afbf86aa38ab9b8
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 1df7491d98ef2cb7ae2f8ba0ceed88aa6094746a
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 9853f9697786299a4ff580ee66651eabe4f658d1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 1cc5f3a242cbaa767dcb74b145fb4bd549cd6033
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 6ea7f0c109bace9464f7d4ff08767d7a15498698
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 4abccd9b254302bb34fc34f141641df3cc8ce054
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 91e32532bfa2829819a16689f7b10f2e35c4f899
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-5696.B as commit abcb82cf6a934f540c0632cc085264410e09ec56
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as ad24fcbfdd49494f42b0f7eb45eab69b4132e1eb
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 52afd47c283b08499254c8224a903440b6569b00
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 6747f27abbead678a020cee9065d4a3008c97269
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 11692818885cb5a970e230776da6415f2e6f30c4
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-5712.49.B-chromeos-3.8 as commit 74d240474ba455585e296d1ce3ab12ba253323d9
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as a959166dd07f45ce8f7faffc87bf9a7db6c39b3d
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as ce6a7a68128e391c8f034c99c6b2468488bfde12
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 8f481a1f416c05b39a87ade274c14e88ecca0d69
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Verified+1
|Change has been successfully cherry-picked as 50b2fa48e9e3d2624c80272af416df12256286f0
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as de4c2ddeb8f582ffa3674641d2b0622a44697b01
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-5943.B as commit 10510eed9d9ea25b18fdb305f64decd63203b7b7
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch stabilize-5943.B as commit f3c1a41ec065484d615ac1136d9cc3638cd78474
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as 80d2e70a6e264222420d2963612b03eeab597e69
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as d8246c6c34b0f3f45fe85e0ce2759bff6f3e7a79
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Change has been successfully cherry-picked as d5f5f451267e4168aec8a0dd00073ff9850b5a67
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3:

This change depends on Chrome change - https://chromereviews.googleplex.com/63207016/
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 6.
|Patch Set 7: Patch Set 6 was rebased
|Patch Set 7:

PTAL
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

PTAL
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14: Commit-Queue+1 Verified+1
|Patch Set 15: Patch Set 14 was rebased
|Patch Set 15: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Change has been successfully pushed.
|Patch Set 1:

I accidentally did git push which got merged directly in master.
|Patch Set 1:

no it wasn't. I can revert it if this change needs review.
|Patch Set 1:

The previous change which I checked in (https://chromium-review.googlesource.com/#/c/208982/) traverses through DEPS which has a variable 'buildspec_platforms'. The old DEPS don't have this variable and hence started failing as

http://chromegw/i/chromeos_release/builders/x86-alex%20pre-flight%20release-R36-5841.B/builds/263/steps/SyncChrome/logs/stdio

This change is to catch the AttributeError.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R38-6158.B as commit 509cf54c9938792f2136f2d7876bf9a86819d1e5
|Patch Set 2: Reverted

This patchset was reverted in change: I4249da751d0b07c05405aa5e2a05a53c5f70c162
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R38-6158.B as commit 8d0f16667a9ad935c54399134bad4316bb99fc5b
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2:

Yes, I figured it out later :(
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Reverted

This patchset was reverted in change: I48060f81e8ee0cc712810d9c5e44a4a0db8cf114
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 3: Reverted

This patchset was reverted in change: Ie1f411e252fd41393e5030a893e60012c816a03a
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Reverted

This patchset was reverted in change: I2931e8dd65095743ee4c823fd5045188f1286163
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1:

Could we please include peppy_freon as well?
|Patch Set 2: Code-Review+2

Thank you!
|Patch Set 1:

Since you removed the lumpy part, I'm not very strong in reviewing this CL. Waiting for David's comment.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch stabilize-6480.B as commit 5f1e18914ad9c024c6cca052ebb5e77fa73be06c
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1:

Shouldn't we include mccloud and tricky to this?
|Patch Set 1:

Yes, Mccloud is a chromebox from Acer.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Reverted

This patchset was reverted in change: I9323207a90f432c3bb3f86c828b6b3e15d451f55
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

Please don't commit until the merge is approved for M43 in the bug.
|Patch Set 2: Reverted

This patchset was reverted in change: I11f2cfc7880163c28ce328f045239a058edbef6b
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Trybot-Ready+1
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Published edit on patch set 2
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

Yesterday I was in an offsite and from tomorrow I'll be on vacation. Let's talk about this on July 6th. thanks!
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

while you are here, could you please remove the commented -freon boards as well. May be we can create a different CL.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

&gt; It looks reasonable. Does the waterfall content dump mirror the
 &gt; builder set that you'd like to see?

Yes, it does.
|Patch Set 1: Commit-Queue+1 Verified+1
|It will come! :)
|considered
|attempts will be skipped
|failures are
|reset
|resumes
|a change in network selection (or maybe selected network changes)
|or after a period of time without failures after reconnection
|oops!  I wrote the bug right before writing the commit, it felt like I had just written all that. :)

Done
|Done
|Done
|Done
|yep!  done

i actually need to file a new bug to get a hint for what the previous state was (when possible).  otherwise the graph was assuming that the new state was the original state from the start of the log.

thanks for the reminder!  :)
|currently and endpoint
|(ugh...  lost my comment, try #2)

Just to make sure I have this right.  If a service is in the watched list and the new status is different, it is logged.  If it is not a watched service, but the new state is now active, it is logged.  Otherwise, the log statement - unchanged - is now done through SLOG.

One thing I am wondering.  I took a quick glance to check on who calls EnumerateCompleteServices and it looks like it is mostly by the manager.  Is this also done through SortServices?  I am wondering about the case where 2 updates come in back to back, when would the service get added to the watched list.  For example: (service 0: idle, service:0 assoc, service 0: assoc).
|oh, hello SortServicesTask.  :)  looks good!
|i wanted to do it before I left, but I had to rush out and now won't be able to concentrate since I am 1 on 2 at home. :)  i'll follow the trail after I get things calmed down.
|sounds good.  i wasn't sure what actually triggered the EnumerateWatchedServices call since I haven't had a chance to go following the code.
|grr...  I don't know why this is back.  fixing it again
|Done
|ah!  good to know!  Thanks!
|Done
|Done
|Done
|Done
|This is great!  Thank you!!!  I'll do that in the next CL since it will be a pretty big overhaul.  I think it could also help provide a better base for identifying sequences of log lines instead of a huge if/else mess. :)

Thank you!
|Ah, very cool!  I will do this in a follow-on cl right away!  Thank you for the great suggestions!
|Done
|Done
|Ah,  I'll check that out!
|I did a quick grep to make sure the innerHTML is gone and compared the output to the old version...  looks like it should work!  Thank you!
|ah, makes sense.  whoops!

I think it still needs to be written out to storage.  I will try getting that in and ask for help if I get stuck.
|For the first one.  I think it depends on the spirit of the threshold.  If it is intending to keep track of the total failures, then you could argue that the counter should be incremented before returning true because it had never connected.  I can also see where this is a counter for those particular credentials, so maybe the slate should be wiped clean by resetting the failure count.

I rewrote the comment to reflect what the code does without trying to capture what it used to do.
|done '.' and deleted the last fragment.
|Done
|Done
|Done
|Done
|Done

It did involve a change to service_sorter as well, but we chatted about that.  :)
|Done
|I was a little confused with this sentence.  Does this mean that it is disabled along with all other workarounds?
|Done
|Done
|Done
|Done
|Done
|Done
|Thanks!  It seemed like a good check.  :)
|Done

(When you suggested the phrase, I thought you meant shill::Service::Load  :) )
|Done
|Done
|Done
|Done
|Done
|Done
|yes, this method is used when retries are needed after a failure.  This method makes sure they are spaced far enough apart.
|Done
|I think i have this right...  but I might have you glance at it.
|Done
|Done

(If I would quit moving my data structures around....  :) )
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Here is where I am thinking of doing one more change.  When Result was defined in the Portal Detector it made more sense to have the number of attempts and if it was final.  Now that it is here, it makes less sense.  I was thinking of making the phase and status be in ConnectivityTrial (for use by the feature that is coming) and then adding the number of attempts and final in a class in the portal detector.  Do you have another idea/preference?
|yep, that is exactly what I was thinking!  :)  I almost just did it, but I thought it was better to run it by you first.
|sure thing.  I actually went to do it and didn't see those particular ones commented originally, then got sidetracked.  I never got back to it.  whoops!
|yep...  it did use time_, but then that was for a variable that wasn't used.  I forgot to clean out the time_ part when I pulled that other variable out..  though, it might end up staying once I address the other part with the start time in portal_detector.  I'll ping you if there is a question how to plumb that.
|that was a leftover from the old code...  it actually doesn't really even check that the number of attempts is correct.  When I redo the result structure, I will fix this as well.
|Done
|Done
|Done
|Done
|Done
|I wanted to go through the code where a retry is called after a retry.  The third failure is redundant, so I will reduce it to 2.  That way we get the original call (failure) retry (failure).
|Done

Thanks!  I'll read that part over in particular!  Thank you!
|Done
|Done
|Done

(it actually was a little different...  let me know if that wasn't the right way to tackle it.  :)
|I did the merge, should I leave this comment here too or go ahead and remove it?
|i have this mostly done...  just need to add a test and think about a corner case where the number of attempts is maxed out.

...ok, this is done now.  I also checked on the max attempts case, since the attempt count is reset to 0 after the result is set to final, that is not an issue.
|Done
|ah, that is true!  I had it testing the wrong way at first...  so now I can convert it over!  Great catch!  Thanks!
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|ah, good call.  I was thinking there might be a callback to signal it is done, but i think that will be in another location anyway.  i will take this one out.  thanks!
|Done
|Done
|Done
|I did this to avoid the extra stuff that verifies the password when it is loaded versus changed. The parts that verify the password use the error, if you are just loading it, you don't need the other path.  This also helped plumb through the reason a bit more directly.  I can switch it back or have Load call the internal method directly.
|Done
|added comment:
// Credential changes due to a property update are new and have not
  // necessarily been used for a successful connection.
|Done
|Done

also reworded slightly to (hopefully) make it more clear
|Done
|ah!  good call!  :)
|Done
|Done
|I went with option a.
|and by option a i mean option b...  i switched it up.  :)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I need to plan out with Paul about what to do in this situation, we were expecting the code to be called through GetFeedbackLogs but I discovered it was GetAllLogs.  You got to this review a bit faster than I intended!  The repeated code is pulled out now, but I still want to talk with pstew about how best to handle this.

Thanks again for reviewing this so quickly!  It will help us get it in!  :)
|Done
|Yeah, we have better coordination planned for later iterations but wanted a simple version for now.  I tried to use the shill code to grab the value, but it is not linked.  quiche and I talked about it and thought this was the best approach for the first go - we also thought pstew might have another idea.
|CreateConnectivityReport does not create any different information than the PortalDetector already creates and logs.  It is just rearchitected and allows us to reuse the connection test code for both purposes (test and set the connection state vs. report connection state for feedback since it might not show up in the log at that time)
|very minor..  the wording makes sense, but is odd on first read with the &quot;ing&quot; and &quot;ing&quot; - switch to Stopping connectivity testing or Connectivity test stopping?
|to be consistent with the other change from last round, i called this GetServiceRpcIdentifier.  We could also switch and make the calls GetObjectIdentifier.  It is a bit more vague, but would that be a better fit?
|Done.

I went with the second option...  I like that one a little better.
|Done
|Done
|i moved it over 2 spots to be consistent with the file name.
|Done
|Done
|Done
|Done
|done

let me know if the way i am storing it is ok!  we had debated on adding code to store names like this, but i can't remember why we voted against it (might have just been to get it through faster :) )
|Done
|heehee!  i believe that mukesh picked it...  when he did the wifi sample and i copied the code here and forgot to update it.  :)

done
|Done
|Done

ah, very good.  great catch!
|Done
|Done
|Done
|Done
|reorged the code a little...

Done
|Done
|Done
|Done
|Done
|Done.
|Done
|Done
|Done
|I did have that exact thought initially and we did discuss it...  that was awhile ago now and I don't remember the exact reason, but it didn't win the battle.  :)

Many of the classes don't use an assumed this (some object they hold is passed in.  But at the time this wasn't the reason.
|will create a new bug for doing this since it isn't trivial (Thank you quiche!).  Don't want to hold up this cl for another type of change.
|I just remembered I need to handle this as well, I will add that in the next upload (assuming there are some fixes to be made  ;) )
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|no rule..  just forgot them!  oops!

thanks!  :)

Done
|Done
|Done
|Done
|Done
|Done
|Done
|If I remember correctly...  I think this is the code I was looking at:
-------
	spin_unlock_irqrestore(&amp;adapter-&gt;mwifiex_cmd_lock, cmd_flags);
	ret = mwifiex_dnld_cmd_to_fw(priv, cmd_node);
	priv = mwifiex_get_priv(adapter, MWIFIEX_BSS_ROLE_ANY);
	/* Any command sent to the firmware when host is in sleep
	 * mode should de-configure host sleep. We should skip the
	 * host sleep configuration command itself though
	 */
	if (priv &amp;&amp; (host_cmd-&gt;command !=
	     cpu_to_le16(HostCmd_CMD_802_11_HS_CFG_ENH))) {
		if (adapter-&gt;hs_activated) {
			adapter-&gt;is_hs_configured = false;
			mwifiex_hs_activated_event(priv, false);
		}
	}

	return ret;
}
--------

I the case where the ret value is -1 from a failure, then the above code will still execute.  Could that lead to any issues?  If it just wakes up the card, then maybe that is fine, but if it could lead to inconsistent state, that would be an issue.
|This function itself looks fine, but I am wondering about the return value.  In a calling function (mwifiex_exec_next_cmd), the return value is passed back, but there are some commands in between that do not check what the return value was.  It looks like this might lead to odd states (I could be concerned about a case that wouldn't happen - but if you could check that would be great).
|Would the same problem happen again if two or more packets come in before the first packet is processed?  If only one thing could come in, then I think the simple flag would do the trick, but if more than one can come in, doesn't this just end up with the same problem since it is blindly set to false without checking if it is the last one?
|I see where it works for a single packet that is called and sets the more_task_flag, but what if another one comes in before the first thread in the main loop is done.  For example:
1 - thread starts superloop.
2 - while executing (like you described in the commit message) another thread tries to enter the loop - it cannot, so it sets the more_task_flag
3 - before 1 is done, another thread attempts to enter the loop but mwifiex_processing is true, so it sets more_task_flag (already true) to true.
4 - thread 1 finishes the first pass through loop, starts second pass, sets more_task_flag to false.  there were actually two threads that attempted to start the superloop, so there is more than just one thing to do.

I might have missed something in the superloop that gets all the queued work done, but just wanted to double check in case there is still a potential issue.
|ok - as long as the thread in the loop can clear out all the pending work, then this seems fine.  I just didn't want it to be in the same boat as the previous situation, just for additional calls.
|does this fall in the same boat?
|is set *by the user*
|no *user provided*
|alignment correct?
|nit - and unrelated...  but isn't the indentation wrong on this?
|over one?
|this one?
|this looks funny
|not sure how this should look
|again... ?
|nit: this
|forget one or just need to update the comment?
|Done
|Done.

went with:
... updated DisconnectReason to 0 (was 4)

(I also added a string update variable, the extra chars made the code pretty hard to read)
|yeah, I had been debating that.  I suppose it is tracking the supplicant state and really has nothing to do with a service - so it should be updated.  I'll fix that.
|now that the update is moved up in the function, I can also simplify this test and not worry about a service.  Would you prefer that or keep it the way it is?
|Done
|done - I also switched the log line so it is a little easier for post processing:

[INFO:wifi.cc(867)] WiFi wlan0 supplicant updated DisconnectReason 4
[INFO:wifi.cc(867)] WiFi wlan0 supplicant updated DisconnectReason 0 was 4
|Done
|Done
|Done
|was this all I really need to do?  Does the image need more testing before this update happens?  (I wasn't the one to make the image :) Wanted to double check before anything changes!)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|you are right!  thanks for catching it.  i should to back and find the test I based mine off of...  I think I copied what it did. :)

Done
|Done
|Done
|Done
|Done
|Thanks! :)

Done
|Done
|Done
|Done
|Done
|good catch!  I thought I might need it for tick alignment...  but I checked and I don't!  :)

Thanks!
|oops!  good catch!  thanks!
|i moved that one up and also modified the existing one to make it more clear what it is doing (if we don't find a lower time in the notes or we don't have any notes, this new note should be added at 0.
|I took out all of my debugging and forgot those!  thanks for catching them!  :)
|Done
|Done
|Done
|Done
|The CONNECTIVITY_CHANGE line is in the subsection above.  I am only utilizing the subsection bounded by:
'--------- beginning of main'
and
'[logcat: 0.530s elapsed]'
at this time.  Other subsections will come later. :)
|it does..  i was trying to stay in the character limit. :)

done
|Done
|oops, this should be used.  good catch
|Done - also updated netlogSummary and syslogSummary
|Done
|Done
|Done
|Done
|Done
|I'll leave it like it is.  I guess I just find it harder to read when the [0] is right after the function ')'
|restructured to clean it up.
|I think this was actually not needed.
|it was expecting an array - but I changed it.
|it was good as a check when logs were jumping around in time, android doesn't do that as much, so renamed.  (it was also holding the parsed time, changed the name to reflect that.)
|The use of time is a bit easier here because we do not have all the other parts (ie. timezone).  There was a bit more processing in the case of changing timezones for shill logs.  Will simplify.
|Done
|It was true for a manager, but not for WSM at this time - removed it.
|in this case it is 1 bc we know it is the first one being inserted.  When I have the correct log line for detecting a new WSM, it will be done using the length of the logSummary.wifiStateMachnes array.  That code will be in the handler for the regex matching the new WSM log line.
|ah, this was a leftover from debugging the time issue.  I had to use the '+' because it doesn't print properly with a ',' when running jasmine tests.
|another artifact of log times moving back - removed here.
|the type is the log line type used for deciding on the highlight color.  (basic = no color bc it is not a flagged log line)
|it is gone
|These are the regex + handlers for the lines we are flagging in logs.  This name is directly from the recommendation in the first review.  I can certainly change it, but I should also change it for shill logs to be consistent.
|The other declaration is now gone.
|That log line is not flagged, so it does not need an anchor mark for the link from the logSummary at the top portion of the page.
|Done
|Done
|Done
|Done
|Done
|Done
|I think I have what you were looking for with this, but to me it seems harder to read.  Let me know if I am confused.
|Done
|Done
|Done
|Done
|Done
|I will probably go with newStateUpdate.  This is used for both the log summary and also the graph.  Marker is confusing for me.
|Shill has a nasty habit of logging the same state many times. There is one in particular and it dramatically reduces the number of points.  I think it is a bit better now, but it was really bad before.
|It is, I have them all in pairs to mark the start and stop for a state.  This is useful for some of the graphing and also for when I (later) do things like highlight a portion of the graph with a hover or something like that.
|The return value is the tag used to highlight the color in the log display.  I can add a comment. (No tag means default highlight color.)  Oh, it is in the comment.  I'll make that longer.
|nope, i fixed this one and missed the other.  result of copying over my regex when testing it manually.
|supplicant is also 'x' and 'y', the updates here are passed to the addSupplicantState where they are processed and turned into 'x' and 'y'.  What I really need to do is fix the shill manager state tracking to also be 'x' and 'y' instead of copying and switching it to the graphdata object.  This will be a followon CL (and a biggie since I intend to generalize all state tracking and updates.  This should dramatically reduce the amount of code, but I want more testing and more experience processing different parts of logs before I make the switch.
|Done
|FYI - I updated this comment since Android logs do not have timezones.  :)
|grrr, yeah.  I think I was too good at simplifying the other tests. This sticks out like a sore thumb!
|I was just making sure the log message I am looking for is found in a 'log' where there is more than one line.  It is testing both the regex and the processLogLines function.  This makes sure the handler gets called only for the line I want.
|yep.  done
|This is similar to the discussion at 40.  I wanted to make sure that processing is handled properly.  I can take it out if you want.
|Done
|Done
|discussion at 40
|discussion at 40
|Done
|Done
|Done
|Done
|Done
|yeah, I actually had this thought as well and had gone back and looked at it for both shill logs and android.  I had pulled out the supplicant states because they were independent and did not impact any other part of state machine tracking.  The manager and WSM states can impact other parts of the state that I am tracking.  This will most likely be more apparent later when I am handling more states for WSM and attempting to do more &quot;interpretation&quot; of the logs.


Ultimately, I think I am gettng closer to a general structure so I won't need more than one processLines function and then I just hand it the correct tracking data structure.  I just have a few more kinks to work out.  (This would make adding another log type - say OnHub - almost trivial.


So, in many rambling words, I could also move this in (and I should then do it for shill logs as well) but I think then it is just in another intermediate state from where it should be.  I don't think this later state is all that far down the road.  I think I could do it without much trouble, but I want to make sure I have more test coverage first (since things are working pretty well right now).  :)
|yeah, I think it can...  I will try to move it over to LogHelper.
|done
|I decided to add a return here marking it as a supplicant line.  After scrolling through some logs, it was getting obvious that marking it with the supplicant color was easier to interpret quickly.
|done
|Done
|Alternate (that we discussed): create another update object and use better naming to make the intent much more clear.
|Done
|Done
|Done
|Done
|Done

(I think I got it)
|This is the convention I found for naming in all the d3 graph examples and tutorials.

I'll change it here since we don't need to stick to that.
|Done
|Done
|let me know if what I tried isn't what you meant.  some of the cases are treated like objects and functions.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I have a test that covers a single supplicant state, but if you mean that the supplicant states are added properly (a start and end for a single state) - that is tested in the other class.  ProcessLog only handles adding the final closing state and the other state updates are handled in the androidlog or netlog files.
|from what I read about mocking out calls with jasmine, this is how you do it.
|Done
|with chrome this seems to work fine, but jasmine does not seem to understand const.
|as we discussed after lunch - I am not changing the underlying data.  And yep, this does display properly.
|The path element has the element 'd' (from dashingd3js: The shape of an SVG Path element is defined by one attribute: d.
This attribute, d, contains a series of commands and parameters in the SVG Path Mini-Language.)



(Just to be sure I tried &quot;.data(&quot; and it didn't work because it couldn't read 'length' of undefined.)
|Done
|I missed some of these, will go back and fix.
|also working on a different alternative for this - will update when I know if it works.
|Done
|it is fine in my screen, i will have to come look at yours.  the last '&#124;' in line 135 should be under the last '+' in 131


I also checked git diff before committing, git show on the commit, reloaded gerrit and showed special characters in vim - they all look good.

* i did go back and make sure everything is spaces now, so if it is not looking better, please let me know.
|Will change the names.  Right now they are using the terminology of d3 with the technique to create a 'context' graph and a 'focus' graph.
|Note - This still adjusts to the ContextStateGraph - don't want to lose that connection.
|Which change in height do you mean?  This is the first check-in of this file.  There might be an object sizing I am forgetting about, so just let me know.
|Done
|Done
|Done
|Done
|Done
|similar to code at 251 - the alternative methods of inlining did not work.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The three options did not work (or at least how I tried them).  I attempted to add a comment about this from a couple of different sites.  When createSupplicantXAxis is called, it creates the lines, tics and labels according to the specifications.  The function call is used to draw these according to the current selection.
|Done
|Done
|Done
|Sorry I wasn't clear, I was replying to the comment about mocking.  Jasmine uses the spyOn function to do mocking.

I do not have d3 in jasmine set up yet, so it fails not knowing what d3 is.  (I can also fix that for jasmine - I was planning on doing that when I add the graph tests with the graphing overhaul down the road.)
|Done Thanks!
|Done
|also fixed this indent
|As we discussed offline:
1 - making a new class for the manager dbus properties
2 - creating a new bug/cl to address naming confusion with the current function (only handles device but the name implies general use)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|looked at a few tests with captures, they seemed to set based on frequency - switched to that.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

(1 comment)

Thank you!
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1

Thank you!
|Patch Set 4: Code-Review+2

we still need to make sure that everything is working in the newer version of chrome since I couldn't test it.  (I know it works bc I saw you demo it! :)   It is just good to double check.)  Good job!
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1

Thank you!
|Patch Set 2:

(7 comments)

just some nits in the commit message + the discussion about the timeout...  change from 5 min to 1 hour?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)

Thanks!  That looks better! :)
|Patch Set 2: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

Thank you!
|Patch Set 1: Code-Review+2
|Patch Set 18: Code-Review+1

Great job!!!

I think you can go ahead and remove the -d when uploading and add pstew as a reviewer.
|Patch Set 18: Code-Review+2
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1

Thank you very much!!!!!

(using the +1 and +2  :) )
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

2 typos
|Patch Set 1:

(1 comment)

I just have one question in there.  It might be handled by the SortServices call, or other service handling.
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)

i'll do this as soon as I can.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(12 comments)

Thank you!

For the braces on if/else, I looked over the style guide again and noticed the examples put them on all if statements, so I also tried to cover that.

Thank you!
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)

Patch set 4 fixed the tab.  I think my editor wasn't doing me any favors.
|Uploaded patch set 5.
|Patch Set 5:

Thanks again for the great suggestions!  PTAL
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1

Thank you!!!!!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

I decided to keep the line and add a comment.  I think it is better to have a consistent expected behavior.  I also did the refactor, please let me know if that wasn't what you were looking for!
|Uploaded patch set 3.
|Patch Set 3: Verified+1

That suggestion was a good one!  Thanks!
|Patch Set 3:

Mukesh - Did you get a chance to check this one?

Thanks!
|Patch Set 3: Commit-Queue+1

Thank you!  (Sorry for the confusion!)
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1

Thank you!  I fixed the problem and learned about USE=wimax for running unit tests.

Thanks!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

moved the change to the platform2/.gitignore

Ben - Thanks!
|Patch Set 2: Commit-Queue+1

Thanks guys!
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(6 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1

Thank you!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+1

(1 comment)

My first time looking at this code, so it is probably best for Mukesh to glance it it too.  (Though it seems good.  I just don't know about the implications of turning this workaround off and what happens if other workarounds are then in place/active.)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Well, good news and bad news.  The good news is that this seems to be working properly.  I installed the image and verified that the value is being read in and stored properly.  The bad news is that when ConnectToBestServicesTask is called, the value is again 0.  I need to debug that problem further.  This part of the issue seems correct though.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I also checked the other services but nothing jumped out.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

Thanks!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

&gt; Patch Set 1: Code-Review+2
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1

Thank you!!!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(29 comments)
|Uploaded patch set 2.
|Patch Set 2:

oops.  hold on for reviewing that...  I need to clean up one more thing.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

ran shill unit tests and also tried on peppy device.
|Uploaded patch set 4.
|Patch Set 3:

(8 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5.
|Patch Set 5: Verified+1

The build had failed for one of the boards due to a cast from int64_t to int.  I fixed this issue and realized I had forgotten to add comments for some private methods.  When I fixed that I found 2 methods that were in the header file and not needed.  This is all cleaned up.  Thanks!
|Uploaded patch set 6.
|Patch Set 5:

(3 comments)
|Patch Set 6:

(1 comment)

Thank you!!!!
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1

Thank you!
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

Thank you!!

Speediest review ever!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

This CL adds the main plumbing needed to get the connectivity test hooked up.

Thanks!
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)

Thank you!!!
|Patch Set 3: Commit-Queue+1 Verified+1

Thanks!
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

I am going to test this again tomorrow to confirm the odd behavior I saw while testing today was not related to this change.  I did see it operate correctly for each case twice (both when it should disconnect and keep the connection).
|Patch Set 1:

(5 comments)

Thanks!  I also added those other variable name fixes we chatted about.

Thanks!
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(4 comments)
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

Thank you!!!!
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

(6 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1

Thank you!!!!!
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

fixed merge conflict
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)

Thank you!  You got to this CL super fast! :)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1

Thank you!!!!
|Patch Set 1: Code-Review+2

(1 comment)

one minor wording nit.  thanks for figuring this one out and fixing it!!!
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

added comment to note that SLOG_IF needs to be updated as well.
|Uploaded patch set 5.
|Patch Set 4:

(37 comments)

i think I got everything...  probably have some merge conflicts but I have to take off and can do those at the same time after this round of changes.

Thank you!
|Patch Set 5:

(7 comments)
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Uploaded patch set 7.
|Patch Set 7: Verified+1

double checking the logs manually.  it looks like it is working.
|Patch Set 7: Commit-Queue+1

Thank you!!!!!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3:

rebased with regex change - also tweaked to add O (Online) or F (Failure) in the summary
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

just check the one I commented...  I hope I didn't miss any!
|Patch Set 2: Code-Review+2
|Patch Set 4:

i did a +2 on it again when I got home...  so I am not sure it really figured it out.
|Patch Set 4:

This is very odd...  it didn't say +2 for the follow-on patch sets until I just opened this last comment.  (I was logged in and everything.)  Then I clicked reply and then it showed up.  Very odd!
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)

one nit for a comment
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2

(1 comment)

just one nit for a comment
|Patch Set 5: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 3: Code-Review+2

(3 comments)

i noted a couple places where the indentation/alignment isn't consistent (the files i commented in have the most issues and I didn't note all of them).  not related to this fix, but maybe while you are in here.  :)
|Patch Set 3: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

double check the one commented
|Patch Set 2: Code-Review+2
|Patch Set 6: Code-Review+2
|Patch Set 3: Code-Review+2

(3 comments)

2 odd looking spots in comments
|Patch Set 6: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 6: Code-Review+2
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!!!!
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1

Thank you!!
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

i think the comment just needs updating...  but wanted to double check
|Patch Set 3: Code-Review+2

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)

i changed up the logging a little in combo with your suggestion.  Should make it easier on the log processor too
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)

One quick question in the unittest.

Thanks!
|Patch Set 3: Trybot-Ready+1
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)

Thank you!  I added the comment to the test and removed the mock service and all the EXPECT_CALLs that are no longer needed.

Thanks!
|Patch Set 4: Trybot-Ready+1
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 4: Trybot-Ready+1
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

you are rightfully confused!!  The testing is pretty basic and I was just making sure I hadn't messed anything else up.  Detailed testing was deferred until after the regex change (done) and moving to polymer (coming soon - I hope!).  I can add a test for this if you want.  Either way is fine with me!
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

PTAL - this is a fix for the other CL.  I had tested with the older log so the messages were not formatted properly.  I also added tests.  :)
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 2.
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

removing the trybot flag while the lab has issues
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1

created a test job on cautotest.  it ran on a leon and passed.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)

Thanks!  I also found an error with the indent on one of the checks..  fixed that too.

Thank you!
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1

Thanks!
|Uploaded patch set 5.
|Patch Set 5:

(17 comments)

Thank you!
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)

Thank you!
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)

Thank you!!!
|Patch Set 8: Commit-Queue+1 Verified+1 Trybot-Ready+1

inherited the +2

Thank you!!!!!
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 9: Commit message was updated.
|Patch Set 9: Commit-Queue+1 Verified+1 Trybot-Ready+1

updated the commit message to remove wificell-pre-cq flag due to infrastructure issues.
|Patch Set 10:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10:

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 3.
|Patch Set 3:

Related to testing with and without the change.  Without the change the new test fails:
[==========] Running 1 test from 1 test case.
[----------] Global test environment set-up.
[----------] 1 test from WiFiEndpointTest
[ RUN      ] WiFiEndpointTest.DeterminePhyModeFromFrequency
[ERROR:device.cc(1162)] IP flag write failed: 0 to /proc/sys/net/ipv4/conf/wifi/arp_announce
[ERROR:device.cc(1162)] IP flag write failed: 0 to /proc/sys/net/ipv4/conf/wifi/arp_ignore
[ERROR:device.cc(1162)] IP flag write failed: 1 to /proc/sys/net/ipv4/conf/wifi/rp_filter
[INFO:device.cc(219)] Device created: wifi index 0
Error: /var/cache/portage/chromeos-base/shill/out/Default/shill_unittest: failed with signal SIGSEGV(11)


The new test passes with the change.
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)

Thank you!
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)

Thank you!
|Patch Set 3: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Thank you!  (I also cleaned up a little bit of extra whitespace!)

carried the code review +2
|Uploaded patch set 1.
|Patch Set 1:

Friendly reminder to take a look at this one.  Thanks!
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1

Thanks!
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)

Thank you!  I definitely missed those when I was clearing out debugging log messages!
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(3 comments)

thank you!  ptal when you get a chance!
|Patch Set 3:

PTAL - Thank you!
|Patch Set 3: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

That one actually tripped me up when writing the test, I first thought it would be three lines too! :)
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)

Thank you!  Good suggestion!
|Patch Set 3: Commit-Queue+1 Verified+1

Thank you!!
|Patch Set 2:

Please test on snow. (For some reason there is a comment somewhere nagging my memory about issues with autotest and snow not on 11a.)
|Patch Set 2: Code-Review+2

sounds good!  thanks for the extra check!
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

(2 comments)

Thank you!
|Patch Set 2: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(25 comments)

ok, I think I got this all worked out!  Hopefully this looks better!
|Patch Set 2:

of the three remaining for the WSM graphing: this is 1/3
|Uploaded patch set 4.
|Patch Set 3:

(8 comments)

Thank you!
|Patch Set 4: Commit-Queue+1 Verified+1

Thank you!!!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

Thank you!
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+2

had to rebase - carrying the +2 from quiche
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)

This CL contains the logic to grab states for WSM and supplicant.  They are used in the display and are ready for the post processing for graphing.  That will be the next CL.
|Patch Set 2:

(24 comments)

I think one more round of comments and then I can upload all the changes.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

If I did all the rebasing correctly, this is 2/3 :)
|Uploaded patch set 5.
|Patch Set 4:

(6 comments)

Thank you!
|Patch Set 5: Commit-Queue+1 Verified+1

Thank you!!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

and this should be 3/3
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(19 comments)

I hope I got this right...  Thanks for the suggestions!
|Uploaded patch set 6.
|Patch Set 5:

(23 comments)

Thanks!  Please let me know if I missed anything.
|Patch Set 6:

(2 comments)

notes on missed generic param names and possibly an alternative to the var/func issue.
|Uploaded patch set 7.
|Patch Set 7:

I made a couple of fixes that slipped through on the last upload.  I also attempted an explanation of how the axis variables and call function work.
|Patch Set 7:

PTAL a chance!  Thanks!
|Patch Set 7:

Mitch - could you please take a look at the file called android_state_graph.js?  This is the d3 portion for the log processor.  Please let me know if you have any questions!  Thank you!
|Patch Set 7:

(3 comments)

Thanks!
|Uploaded patch set 8.
|Patch Set 8:

In patch set 8 I also fixed the labels/names for the data I am grabbing.  I am actually graphing the NetworkDetailed log messages, not wifi state machine states.  Those will come very soon and be shown in another graph.
|Uploaded patch set 9.
|Patch Set 7:

(1 comment)

Thank you!
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

Thank you very much!!!!

inheriting the +2 from quiche and the +1 from mwills

Thanks!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(15 comments)

please let me know if I missed anything.  The follow-on bug + cl will be very soon for renaming TemporaryDBusProperty

Thanks!
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)

Thank you!   Will inherit the +2
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!  (inherited +2 from quiche)
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

Note:  Waiting for a device to free up in the lab so I can run the test to verify this change did not break anything.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

Tien caught a lulu that was in the ready state and locked it for me!  Thanks Tien!!!!

I enabled wake_on_wifi for lulu, built a new image, flashed it to the DUT and ran the network_WiFi_WakeOnWiFiThrottling test..  that passed!
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)

Thank you!
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: Code-Review+2 Trybot-Ready+1

inheriting the +2 again after rebase
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1

Thank you!
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R50-7978.B as commit dfd07380ec2316cc78189a3ce8b5b68aaa79f9ff
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)

Thank you!  (will carry the +2 over)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

carried over CR+2
|The backlight will be enabled when &quot;fb_blank&quot; is called later. The backlight register the &quot;notifier_call&quot; of fb. From the test result, it is called after all the devices are resumed.
|Use the -&gt;has_gpu_clamps now.
|Maybe not necessary, I think. Because this function is not called by other functions but &quot;tegra_mc_flush&quot;. And &quot;tegra_mc_flush&quot; has applied lock/unlock around calling &quot;tegra_mc_flush_done.&quot;
|Thanks for comment. I will fix it in next update.
|Sorry about it, I'll fix it.
|This path is not executed for Tegra, so maybe we do not need to worry about the crash caused by not registering manager for VRAM, is that right?
|You are correct, and tegra has no VRAM.
|Got it, thanks. I'll update it
|These 2 functions are needed by the &quot;nouveau_platform&quot; driver for PM routine
|IIUC, if we fail suspend, the PM framework will not continue suspending, and it will resume all the devices including the suspended devices and the one causing fail.
Back to here, the PM framework will call &quot;nouveau_do_resume&quot; to bring back a good GPU if suspending Nouveau is failed. So we may not need to add another &quot;nouveau_do_resume&quot; here
|If it's failed here, the PM framework will resume it, and then it goes through the power up sequence
|IIUC, if we fail suspend, the PM framework will not continue suspending, and it will resume all the devices including the suspended devices and the one causing fail.
Back to here, the PM framework will call &quot;nouveau_do_resume&quot; to bring back a good GPU if suspending Nouveau is failed. So we may not need to add another &quot;nouveau_do_resume&quot; here
|Got it, thanks
|Thanks, you are correct. I will update it
|First, no one will request to toggle because no one can exactly detect this issue through SW method before the issue occurs 

Second, I am curious about why you think it will break existing platform ? In fact, AFAIK, some existing platforms, such as Benson's and mine, are rescued from broken status by this patch, and some other non-broken existing platforms are not broken by this patch. 

Third, if the &quot;clk_get_sys&quot; makes it like a HACK. I could add it into DT. However, I am still worried about that someone may said that the &quot;TEGRA210_CLK_FUSE&quot; in the &quot;gpu&quot; node is like a HACK....

Anyway, if you think it is like a HACK, I can change it.But may I know it is possible for this HACK to be landed ? Because I can not &quot;verified +1&quot; on the other GPU suspend/resume patches, some of which are &quot;codereview+2&quot;

Thanks !
|1) You said &quot;toggled only if it could be requested&quot;. I mean no one will request because this issue can not be exactly detected before it occurs. So it can not be requested.

2) I assume this code is only for Smaug, isn't it correct ? I understand your concern about the compatibility now.

3) Agree. 

Another question, I should create a new patch if I change the DT, right? Thanks
|Thanks. But is there any good way for &quot;dc&quot; to know whether the panel prefer one-shot mode?
|Sean,
dc must know whether the panel prefers one-shot mode because it need to call &quot;tegra_dc_commit&quot; to send a frame everytime if using one-shot mode. However, I do not find any way for dc to know whether the panel prefers, except using &quot;drm_display_mode&quot;, do you have any idea?
|That's fine
|Yes, it should be removed.
|You are correct. I'll add it as the &quot;set_nofb&quot; does.
|You are correct, thanks. I'll fix it.
|My logic is:
If it is not enabled, just enable it through calling &quot;drm_crtc_vblank_on&quot;
If it is enabled, do nothing
|Yes, it's used to tell whether the panel needs to be turned off. Refer to the https://chromium-review.googlesource.com/#/c/294043/
|Thanks.
|&quot;panel_self_refresh&quot; is used to tell whether the screen needs to be turned off.
&quot;ready&quot; is used to the initialization is executed twice because the &quot;set_nofb&quot; and &quot;enable&quot; does the same thing, and they are called continuously in the case of turning on screen.
&quot;panel_is_off&quot; means panel is off, so any update should not be run. Because I find there is a plane update after the &quot;tegra_dc_crtc_disable&quot; is called. In that case, the dc'clock have to be re-enabled again.
|OK, I'll remove commit.
|Sorry, I am not very familiar with some details about the drm framework. For example, what should be done in &quot;set_nofb&quot;, and what should be done in &quot;enable&quot;. In previous code, there is only set_nofb, and it does all. But I know it now, vblank should be enabled in &quot;enable&quot;, right?
If that is, where should I put &quot;tegra_dc_set_display&quot;, in set_nofb or enable? In my previous idea, the &quot;enable&quot; is used for the case that screen is always on but it need to be waked up from one-shot idle mode, and the &quot;set_nofb&quot; is used for the case that the screen is on from off.
|Agree. Your code is more simple.
Will not cause issue, but you have to write &quot;state-&gt;planes&quot; in another write.
|OK, that's fine
|The same as the dc. I assume that the &quot;enable&quot; function is just used by the case of turning off dsi/dc when screen is on but we need to scanout nothing. For the other case, the &quot;mode_set&quot; function will do all things.
|Hmm... 
The &quot;panel_self_refresh&quot; is not a feature for &quot;tegra_dc&quot; or &quot;tegra_output&quot;. It is just used to determine whether the panel is needed to be turned off when I am going to disable dc/dsi. It is to used in dc.c/dsi.c, so I think putting it into dc may be the simplest because it avoids getting repeatedly &quot;tegra_ou&quot;tput in the dc.c.
|Agree.
|I'll remove it.
|Hmm..., I tried using a lock before, but it showed there was potential deadlock. Doesn't the &quot;tegra-&gt;commit.lock&quot; make sense here? I see many functions are called with this lock.
|Agree.
|Hmm... exactly no any theory, and I just think trying 3 times is a compromise between waiting it out and try 1 time then return.
 
If waiting it out, it may be possible that it just get the lock before sending a frame. So it may increase the cost of turning on/off dc/dsi

If just trying 1 time, it may miss the closest chance to disable dc/dsi, and then wait another 100ms

So I choose to try 3 times, maybe it is not the best.
|Hmm... I do not know when I should turn off the vblank if not using the worker.

If not using the worker, another way to apply one-shot mode is enable all the things at the beginning of each commit, and disable them at the end of it. However, I do not think it is effect way in the case of high fps.

I think the worker should be added at the end of a commit that means the current frame has been scanned out.
|Hmm... some of them may be duplicated, and I think I could decrease the number of them
|You mean I do not have to call dpms, or call dpms with DPMS_OFF/ON instead of DPMS_SUSPEND/STANDBY?

I understand your logic. But I have a question, how dc operate on the tegra_output? What function can do &quot;dereference attached encoders to tegra_outputs&quot;? Thanks
|I set the &quot;static&quot; to the dc, so it should be NULL at first time of calling this function, right?
|Maybe not. Because I find sometimes there is no vblank interrupt even always call it.
|Agree. Adding a flags member to drm_panel is more direct.
|Thanks, I'll update it.
|Yeah, I'll update it
|If &quot;__clk_is_enabled&quot; is better solution, I am happy to use it.
|Yeah, I may need to directly return -ETIMEDOUT
|Yeah. The &quot;wait_for&quot; is waiting that the &quot;DSI_TRIGGER_HOST&quot; is changed from 1 to 0.
|Hmm..., the story may be:
1. &quot;tegra_dsi_transmit&quot; set the &quot;DSI_TRIGGER_HOST&quot; to 1, and then start transmission
2. The DSI transmission is timedout because of not seeing frame end, and the &quot;DSI_TRIGGER_HOST&quot; is kept to 1
3. &quot;tegra_dc_send_a_frame&quot; sends a frame, and starts waiting for that the &quot;DSI_TRIGGER_HOST&quot; is reset to 0 after transmission is finished.
|Sean told me that the dsi block will not send a command until a frame end occurs. So calling &quot;tegra_dc_send_a_frame&quot; here is not to set &quot;DSI_TRIGGER_HOST&quot;, but to let the dsi see a frame end and then it can send the command.
|You mean adding a print, such as &quot;dsi transmission is timed out&quot; , before continue? In fact, the &quot;err&quot; can be returned to the caller.
|That's fine
|You're correct. Thanks
|Agree.
|Done.
|IIUC, the &quot;old&quot; is not really old, and it means the &quot;current&quot;. The &quot;old_plane_state&quot; is obtained from:

struct drm_plane_state *old_plane_state =
			drm_atomic_get_existing_plane_state(old_state, plane);


The &quot;old_state&quot; is actually the &quot;state&quot; when calling &quot;drm_atomic_helper_commit_planes(drm, state)&quot; in the &quot;tegra_atomic_complete&quot; function.
|The &quot;old_state&quot; is just a argument name in the struct &quot;drm_plane_helper_funcs&quot;. In drm code, there are generally 2 state, &quot;old&quot; and &quot;new&quot;, for crtc/connector/plane.
I think the &quot;old&quot; means what is currently being used, and &quot;new&quot; means what is to be used. Please pointer out if I am wrong.
|The &quot;new&quot; crtc must be NULL once enter into &quot;tegra_plane_atomic_disable&quot; function, and we can not check whether &quot;new&quot; crtc is active or not.

In fact, what I want to do here is checking whether dc is powergated from &quot;crtc-&gt;state-&gt;active&quot;, just like in &quot;atomic_flush&quot; function. So I need to get dc from the &quot;old_state-&gt;crtc&quot;

If you have any concern about this check, do you have any idea for checking whether dc is powergated here? Use &quot;tegra_powergate_is_powered(dc)&quot; function instead?
|Correct.
|Agree
|Agree.
|Yes, enable it in &quot;set_nofb&quot;.
If not disable here, I need add a variant to check whether to enable clock when entering into &quot;set_nofb&quot;
|Sorry, I do not get the reason for moving the &quot;enable the clock&quot; into &quot;set_nofb&quot;. Is there anything better if doing the move? Or do you have any concern here?
|Thanks, done.
|Agree. Thanks
|Agree.
|Actually, the &quot;480000000&quot;  is not really used here, and it will be overridden to &quot;482498437&quot; in normal use. 

To be honest, I am not sure it is always correct for each soc. I planned to set the minimum rate that is available for dvfs, but I have not find such function to do this. Do you have any suggestion?
|Yes, we can get old emc bandwidth from old dc state. However, we may need to add a argument for &quot;tegra_dc_set_lantecy_allowance&quot; to pass the old dc state, or call &quot;for_each_crtc_in_state(old_state, crtc, old_crtc_state, i)&quot; instead.
Do you have any other idea?
|Correct, maybe I should use &quot;unused&quot;
|Oh.., you are correct.
|For 3 cases, we may need PRE/POST here.

1. DC's emc bw is increasing, but some plane's emc bw is decreasing.
2. DC's emc bw is decreasing, but some plane's emc bw is increasing
3. DC's emc bw does not change, but some planes' emc bw increasing or decreasing

For case 1, &quot;tegra_dc_set_latency_allowance&quot; is called in tegra_dc_update_emc_pre_commit, but we should use the plane's new emc bw if it is decreasing
For case 2, &quot;tegra_dc_set_latency_allowance&quot; is called in tegra_dc_update_emc_post_commit, but we should use the plane's new emc bw in advance.
For case 3, the plane whose emc bw is increasing should use new emc bw at pre_commit, but the one whose emc bw is decreasing should use new emc bw at post_commit.

So we may need a argument to tell us whether to use new emc bw for each plane in the tegra_dc_set_latency_allowance function.
|The update_la_ptsa is set to false, and there is no need to update it if it has been set to true. So I do not think directly updating it is more effective than checking whether it is false.
|Yes, maintaining a new member may incur new bug.
However, checking all planes with a loop is much less effective than checking a member, especially the checking needs to be done for many times.
Anyway, this is not a logic issue, let us discuss it later in case that other reviewers have any other suggestions
|Agree.
|A do not think checking planes in a loop is a more effective way than using a member.
|No, there is a chance that the LA/PTSA is set again in post commit if dc's emc bw is decreasing.
|Not make sense if adding check for &quot;crtc_h=0&quot; here.It will cause the black screen when swiping to play the next video.So need userspace take a look and give some suggestion
|I see the &quot;state-&gt;crtc_h&quot; is 0 in some case, but there is no kernel crash. However, maybe we should check it here as well
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2:

Fix the building error.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Code-Review Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1

Thanks for your nice suggestion, I have modified the commit message and make a rebase
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Tom, thanks for your comment. I have modify the code and please help reviewing it.
|Patch Set 5: Commit message was updated
|Patch Set 6: Commit message was updated
|Patch Set 6: Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Just for debugging and no need to review
|Patch Set 1:

Sorry, I got it now.
|Abandoned

Not needed now
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Patch Set 4: Verified+1
|Patch Set 4:

(1 comment)
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R38-6158.B as commit 2bde700cdfce3eb55301f566787411837b22748a
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R39-6310.B as commit 26df058a82a80e4d1e4a95f8726a3abb29747e4b
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch factory-nyan-5772.B-chromeos-3.10 as commit 6adfd18756e2c3d2ec1e26b1494fba086c1f74cc
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2:

Hi, Andrew

How should I get merge approval? Thanks !
|Patch Set 2: Commit-Queue+1
|Abandoned
|Restored

Is any possible for this patch going to R38? It is very important.If not including it, the OOM issue will occur.

Thanks !
|Patch Set 1:

If running suspend_stress_test, it will occur at 100~300.
|Patch Set 1:

If running suspend_stress_test, it will occur at 100~300 iterations
|Abandoned

No need anymore
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2: Reverted

This patchset was reverted in change: Ic5f01c356a19c09aef7963f420c12cf17adc89fa
|Patch Set 1: Code-Review+1
|Patch Set 1: Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 2:

Hi, Andrew

Thank you for your comment.

The patch has been approved on ToT branch.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

No, it will not affect resume time based on my observation
|Patch Set 1:

Hi, Andrew

We found that the EC crash will cause the unit to reboot when running &quot;suspend_stress_test&quot; test at crosh shell.
This patch changes the resume timing of gk20a and can fix this issue as a workaround though we have not find the root cause for the EC crash. So it is necessary here.

Thanks !
|Patch Set 1:

Hi, Andrew

Could you approve this patch? Compal is waiting for this change.

Thanks !
|Patch Set 1:

Hi, Andrew

Do you think set it as a HACK will be better? Or do you have any comment for #70 and #71 of the issue 32936?
|Patch Set 1: -Verified

OK, abandoned it.
|Abandoned

This is fixed by another solution, so abandon it
|Patch Set 1: Code-Review+1 Verified+1

Hi, Yen

My Bigs that have ever reproduce this issue all pass 7000 iterations.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 21: Patch Set 20 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 9:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 11:

(1 comment)
|Patch Set 13: Code-Review+1 Verified+1
|Patch Set 15: Code-Review+1

Thanks you Stephane
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 13: Verified+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch set 13: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 12: Code-Review+1

(1 comment)
|Patch Set 17: Code-Review+1 Verified+1
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 23: Verified+1
|Patch Set 24: Verified+1
|Patch Set 26: Verified+1
|Patch Set 30: Code-Review+1 Verified+1
|Patch Set 30:

Add a &quot;tegra_mc_flush_put&quot; function in the following new patch:

https://chromium-review.googlesource.com/#/c/290521/
|Patch Set 32: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 10:

(1 comment)
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 22:

(1 comment)
|Patch Set 23: Code-Review+1 Verified+1
|Patch Set 24: Verified+1
|Patch Set 26: Verified+1
|Patch Set 29:

(1 comment)
|Patch Set 29:

(1 comment)
|Patch Set 30: Code-Review+1 Verified+1
|Patch Set 32: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 10:

(2 comments)
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 23: Code-Review+1 Verified+1
|Patch Set 24: Verified+1
|Patch Set 26: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 10:

(1 comment)
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 23: Code-Review+1 Verified+1
|Patch Set 24: Verified+1
|Patch Set 26: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 13: Verified+1
|Patch Set 16: Verified+1
|Patch Set 18: Verified+1
|Uploaded patch set 19: Patch Set 18 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Patch Set 24: Commit-Queue+1 Verified+1
|Patch Set 24: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

Hi, Stephane
It is not lost during the system enter into LP0 (suspend to memory), and I have not verify the hibernate case (suspend to disk)
A stupid question, does the system support hibernate?
|Patch Set 2:

Hi, Stephane

When system is powered on, the &quot;pmuvm-&gt;vm&quot; is initialized in the &quot;gm20b_pmu_init_vm(ppmu)&quot;, and then it is kept in the memory. 

When system enter LP0, the &quot;pmuvm-&gt;vm&quot; and &quot;ucode_blob&quot; is saved in the memory, and so they can be found when system resumes

When system enter hibernate, the &quot;pmuvm-&gt;vm&quot;, &quot;ucode_blob&quot; and other things are lost, so I think it will go through the same sequence as power on procedure, and the &quot;pmuvm-&gt;vm&quot; will be initialized again and the &quot;ucode_blob&quot; will be re-prepared, too.

Could you please help to point out where I am wrong
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 17: Code-Review+1 Verified+1
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 23: Verified+1
|Patch Set 24: Verified+1
|Patch Set 26: Verified+1
|Patch Set 30: Verified+1
|Patch Set 32: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 17: Code-Review+1 Verified+1
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 23: Verified+1
|Patch Set 24: Verified+1
|Patch Set 26: Verified+1
|Patch Set 30: Verified+1
|Patch Set 32: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 19:

(1 comment)
|Patch Set 19:

(1 comment)
|Patch Set 20: Code-Review+1 Verified+1
|Uploaded patch set 21: Patch Set 20 was rebased.
|Uploaded patch set 22: Patch Set 21 was rebased.
|Patch Set 26: Verified+1
|Patch Set 27: Verified+1

Hi, Stephane, may I have your time to take a look at this? Thanks
|Patch Set 29: Verified+1
|Patch Set 33: Verified+1

Fixed it
|Patch Set 33: Code-Review+1
|Patch Set 35: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 20: Verified+1
|Uploaded patch set 21: Patch Set 20 was rebased.
|Uploaded patch set 22: Patch Set 21 was rebased.
|Patch Set 26: Verified+1
|Patch Set 26: -Verified
|Patch Set 26: Verified+1
|Patch Set 29: Verified+1
|Patch Set 33: Verified+1
|Patch Set 35: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Abandoned

Do not need this hack anymore
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Abandoned

We have find the fix this issue
|Patch Set 17:

It looks good to me.
|Uploaded patch set 1.
|Patch Set 1:

I should directly abandon it.
Thanks!
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Laxman, I have updated as you comment. Could you please take a look?

Thanks
|Patch Set 3: -Verified
|Patch Set 3:

Thanks for comment. I will update it
@Andrew: Yes, it's cleaner if all the patches are ready and can be directly cherry-picked from upstream now. But some patches have not been at upstream now, so we may need use these local changes first in order not to block verifying suspend/resume.
|Patch Set 3:

Hi, Andrew
I have checked the patches at the upstream. Considering reverting local changes may cause bisect issue, I will align the changes to upstream and update here.
|Patch Set 10: Verified+1
|Patch Set 10: -Verified
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Patch Set 21: Commit-Queue+1 Verified+1
|Patch Set 21: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+1
|Patch Set 7: Verified+1
|Patch Set 7: -Verified
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Patch Set 18: Commit-Queue+1 Verified+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+1
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Patch Set 18: Verified+1
|Patch Set 21: Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Patch Set 18: Verified+1
|Patch Set 21: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

Sorry, I did not consider so much because it may be the simplest way to call the &quot;tegra_fuse_readl&quot; to enable the fuse clock

Using clock API looks good to me, I will update.

During my test, just enabling/disabling fuse clk is just enough, and register read is not necessary
|Patch Set 1:

&gt;I'm mostly wondering about technical details of this hack. Because if &gt;on hardware level it is enough to just read a register and it doesn't &gt;depend on any timing conditions, then we probably don't need to &gt;bother with enabling the clock.

We are still working on the detail. Honestly speaking, what I am sure now is just enabling fuse clk for a while will fix this issue. 

I guess it may not be related with timing conditions because:
1. This issue only occurs on some smaug boards, and it occurs each time, not probably.
2. I tried many other methods, such as adding delay at each step in the powering up sequence, toggle regulator,..., but none of them is make sense.

Anyway, I will update if any new found.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 2:

Tomasz, I have changed to use clock API.

I have removed the &quot;HACK&quot; because it should be a correct way to fix this issue.

To enable fuse clk for a short while will allow the reset propagation in SOC internal logic. After that, the GPU rail is stable and GPU reset is valid.
|Patch Set 2:

(1 comment)
|Patch Set 2: -Code-Review -Verified

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

Updated.

The dt change is at https://chromium-review.googlesource.com/#/c/286490/
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4:

Tomasz, updated and could you please take a look again ? Thanks
|Patch Set 7: Code-Review+1 Verified+1
|Patch Set 8: Code-Review+1 Verified+1
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 4: Code-Review+1 Verified+1
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 3.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Verified+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1
|Uploaded patch set 10.
|Patch Set 10: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1
|Uploaded patch set 11.
|Patch Set 11: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: -Verified

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified-1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Verified+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Patch Set 10: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(4 comments)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1
|Patch Set 9:

(6 comments)
|Uploaded patch set 10.
|Patch Set 10: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1
|Patch Set 10:

(3 comments)
|Patch Set 10:

(1 comment)
|Uploaded patch set 11: Patch Set 10 was rebased.
|Patch Set 11: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Abandoned

Not use the dpms
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5: -Verified

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

Hmm..., there is no better solution at my side. However, I would like to get you experts's suggestion about this, because I am not sure whether there is better one.
|Uploaded patch set 10.
|Patch Set 10: Verified+1
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Patch Set 12: Verified+1
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 13: Verified+1
|Patch Set 13:

(3 comments)
|Patch Set 13:

(2 comments)
|Uploaded patch set 14.
|Patch Set 14: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4:

(2 comments)
|Abandoned

No good to use
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

I find that the value of &quot;private_flag&quot; is not passed through the drm framework, so I can not get the expected value at the dc.c/dsi.c.
|Patch Set 2:

I have the same though with you before. However, during my test, I find the &quot;private_flag&quot; is always 0 whatever I set it to. Then I trace it, and find that &quot;drm_mode_convert_to_umode&quot; is used, but the &quot;private_flag&quot; is not copied in this function, so I think I need to get &quot;private_flag&quot; from another path.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Patch Set 6:

(1 comment)
|Abandoned

Sean has provided a better version for one-shot mode, so abandon this
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Patch Set 6:

(1 comment)
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

In the &quot;atomic_begin&quot;, I see there is a check for &quot;crtc-&gt;state-&gt;active&quot;, so I do not add another.
|Patch Set 1:

Yes, I have the same thought with you at first, but in fact, the &quot;atomic_begin/atomic_update/atomic_flush&quot; are all called even if the crtc is inactive. I see checks for &quot;crtc&quot;, but not for &quot;crtc-&gt;state-&gt;active&quot; in the &quot;drm_atomic_helper_commit_planes. So I think we need to add these checks

For &quot;atomic_begin&quot;, I see there is a check, so I do not add it.

For &quot;atomic_update&quot;, I add the check for crtc-&gt;state-&gt;active,

For &quot;atomic_flush&quot;, I use the dc-&gt;dpms instead of crtc-&gt;state-&gt;active, because we need to call &quot;atomic_flush&quot; to trigger a frame during disable dc/dis (after &quot;crtc-&gt;state-&gt;active&quot; is set to false and before dc is set to DPMS_OFF). Refer to patch https://chromium-review.googlesource.com/#/c/302762/
|Patch Set 1:

Thanks for comment, I'll update it soon
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

In the &quot;tegra_atomic_complete&quot;, the code is as follows:

drm_atomic_helper_commit_modeset_disables(drm, state);
drm_atomic_helper_commit_planes(drm, state);

The dc/dsi is disabled first, and then the planes are committed.

In the &quot;drm_atomic_helper_commit_planes&quot;, the code do the following things:
1. If crtc is not NULL, call crtc's &quot;atomic_begin&quot; op
2. If plane-&gt;state-&gt;crtc is not NULL, call plane's &quot;atomic_update&quot; op
3. If crtc is not NULL, call crtc's &quot;atomic_flush&quot; op

From my print, both the crtc and the plane-&gt;state-&gt;crtc are not NULL when screen off, so the crtc's &quot;atomic_flush&quot; and &quot;atomic_begin&quot;, and the plane's &quot;atomic_update&quot; are will be called
|Patch Set 1:

There is the backtrace of calling &quot;atomic_flush&quot; when screen off:

[   42.321457] [drm:tegra_crtc_atomic_flush] *ERROR* dc-&gt;dpms == DRM_MODE_DPMS_OFF
[   42.328769] CPU: 0 PID: 170 Comm: surfaceflinger Tainted: G     U  W      3.18.0-07617-gc2429eb4f4a3-dirty #1219
[   42.338958] Hardware name: Google Tegra210 Smaug Rev 1+ (DT)
[   42.344619] Call trace:
[   42.347069] [&lt;ffffffc0002073ac&gt;] dump_backtrace+0x0/0x10c
[   42.352476] [&lt;ffffffc0002074c8&gt;] show_stack+0x10/0x1c
[   42.357529] [&lt;ffffffc000aa593c&gt;] dump_stack+0x80/0xb4
[   42.362588] [&lt;ffffffc000620e48&gt;] tegra_crtc_atomic_flush+0x3c/0x8c
[   42.368760] [&lt;ffffffc0005307cc&gt;] drm_atomic_helper_commit_planes+0x160/0x190
[   42.375809] [&lt;ffffffc00061ecc0&gt;] tegra_atomic_complete.isra.8+0x80/0x364
[   42.382505] [&lt;ffffffc00061f020&gt;] tegra_atomic_commit+0x7c/0xa0
[   42.388329] [&lt;ffffffc000551dfc&gt;] drm_atomic_commit+0x58/0x68
[   42.393989] [&lt;ffffffc000531610&gt;] drm_atomic_helper_connector_dpms+0xd8/0x144
[   42.401037] [&lt;ffffffc000545644&gt;] drm_mode_obj_set_property_ioctl+0x11c/0x1e4
[   42.408074] [&lt;ffffffc000545738&gt;] drm_mode_connector_property_set_ioctl+0x2c/0x38
[   42.415483] [&lt;ffffffc000538e30&gt;] drm_ioctl+0x378/0x430
[   42.420643] [&lt;ffffffc00032476c&gt;] do_vfs_ioctl+0x4b0/0x590
[   42.426044] [&lt;ffffffc0003248a8&gt;] SyS_ioctl+0x5c/0x88
|Patch Set 1:

No, the backtrace is turning on to off
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Verified+1
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Verified+1
|Patch Set 8:

(3 comments)
|Uploaded patch set 9.
|Patch Set 9: Verified+1
|Uploaded patch set 10.
|Patch Set 9:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 2.
|Patch Set 2:

(9 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+1 Verified+1
|Yes, the 16-bit vmlinuz portion is included in the kernel blob and it is signed.  My concern is that the sig-&gt;data_size check is done in VerifyData and it just throws an error if the sig-&gt;data_size is &gt; than the size of the kernel blob.  Ideally, I would think that it should make sure that the sig-&gt;data_size == size of kernel blob?  However, when I added this check it seems like the kernel preamble check fails.
|I left this for consistency reasons, but if you feel strongly about it, I can change all the printouts from ofs to offs ....
|Yeah, sorry, I didn't know the commit message requirements.  I changed it to reflect the summary followed by the description.
|This was an editor config issue and was not showing up for me.  I stole Furquan's .emacs file and fixed all the formatting issues and trailing whitespaces in the 2nd patch that I uploaded.
|Our assumption from our end is that if we're running BB, then we'll always be attached to servo V3.  Is this not an accurate?  We were not aware that BB with servo V2 would need to be supported.
|There are only two options for using flashrom:  On the host or on beaglebone.  If we're flashing from the host, then we'll use the default directory for openocd configs (ec/chip/lm4/openocd/).  If we're on BB (w/ servo v3), then all the configs are in /usr/bin/lib/.  I think that those are the only two options.  Am I mistaken?

We can add another check in lsb-release, but we would still need to check for the existence of the config files in /usr/bin/lib anyway...
|Yes, this was done because stat() was seg faulting on Android.
|I thought that this could be just the program name?  But I don't have a strong opinion about this, so full path it is :).
|region_file is used to contruct the RW_NVRAM:/tmp/flashrom_... filename below.
|same response as above.
|I did a git mv, but since I changed every line (CONFIG_PLATFORM_RUSH --&gt; CONFIG_PLATFORM_SMAUG), git detected 100% changes and changed this operation into a delete and add.  I suppose the solution to this would be to split this into two commits.  One for the mv and one for the modifications within the actual file.  Would you prefer this?
|David had asked that I removed the platform prefix as I see fit so that in the future it is easier to copy and paste these files when we get new boards.  I mainly removed the ones that I knew were local to the file (ie: static functions, etc.) and kept the ones that were referenced externally.
|I think so.  This is the callback that calls flashrom, which is needed for Ryu to modify the nvram values.  Previously it was doing it through the ec.
|I believe so.  At the very least it should be pushed down to the firmware_test object.  I see this code replicated in a lot of tests.  I'll do this in a separate CL.
|Actually, this function is misnamed; it's actually waiting for recovery to start and then exitting.  Then we wait for the DUT to get back into fastboot mode (signifying the end of recovery) with the wait_for_client_fastboot() function.
|good idea.
|Yes, we're waiting through the wait_for_client_finish_recovery (will rename this properly) and wait_for_client_fastboot functions.
|If you run enable_normal_mode_and_reboot followed by enable_dev_mode_and_reboot, the second will probably error out because &quot;adb devices&quot; will error out with no devices detected.  You're right.  we can probably encapsulate this better.  I'll take a look.
|It seems that there is some delay before volume_up:no occurs.  When I tried to move on, the power key is pushed/released before volume_down:no occurs.  I modeled this after power_key() in hdctools/servo/keyboard_handlers.py, which also waits for pwr_button to be released before moving on.  Are the order of servo commands maintained in a queue of some sort?
|Please check power_key() in hdctools/servo/keyboard_handlers.py for the pwr_button press/release implementation.  When I do not include the wait, it seems like the program does not wait for volume_down:no to occur before moving on.
|I ended up keeping this as short because I think that this is a relatively short test.  Basically, all it does is copy out the current kernel, reboot, reflash the kernel and reboot.  I think that it just takes a few minutes...
|I guess I always considered this a short test because it doesn't take that long to execute.  What would be the time limit for a 'SHORT' test vs. a 'MEDIUM'-timed test?
|I thought that you were not restoring gbb flags in order to speed up test turnaround times?
|Currently, this test is lying in both the faft_bios suite and the faft_normal/dev_ryu suites (which sounds analogous to the suggested faft_bios_a44?).  My intention of keeping it in faft_bios suite was to make it easier for the testers (so they can just run the faft_bios on any platform).  I can change this if this is not your preference though.
|I think that you're right; we don't technically have to wait for the DUT to go offline if we're expecting it to go into fastboot mode.  However, if we're expecting it to boot into OS mode, we need to make sure that it does something (like disconnect) before checking just in case it does nothing.
|I noticed that you do not reboot after your other call to reset_and_prioritize_kernel (in setup_kernel).  Is there a reason for this inconsistency?
|Seems like check_state really needs the True return in order to work.  Otherwise, functions will return None.
|Same as above.
|I contained it into a function for readability.  I can just drop it in the flash_flashrom function if you prefer though.
|You're right.  I accidentally dropped the return in the if statement during debugging!  Good catch.  New patch coming ....

RE: return.  I discovered that there's a trap that automatically calls cleanup() when a functions returns non-zero.  That's why I had to store the return value in a global variable instead.
|Would you like me to
|If I had to guess, I would say dshi@...  I think that he's the owner of suite_scheduler.  At the very least he should be able to answer your question.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

&gt; Is there a unit test for this that verifies we can create a kernel
 &gt; partition from a vmlinuz and then get the same vmlinuz back?  Seems
 &gt; like that would have caught this.

Yes, will definitely integrate a test for this (will check in separately so as not to block the fix from going in).  Thanks!
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Commit-Queue+1 Verified+1

LGTM+2 per Randall's last code review (after fixing comment).
|Patch Set 9: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+2 Commit-Queue+1 Verified+1

Had to resolve a merge conflict due to 2 files being deleted (cmd_dev_sign_file.c cmd_vbutil_kernel0.c).  The code changes have already been +2'ed by Randall earlier.
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 11.
|Patch Set 11: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

Hi Mike, Gerrit won't let me do it myself for some reason.  I've emailed Allie to update my profile name.  Thanks.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1
|Patch Set 9: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

Pinged lab people and the universal answer is that servo2+BB will not be a config used in the labs so it's safe to assume that if we detect we're running on BB, then we can safely assume that we're running servo V3.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review-1

Uploading patch for debugging purposes.  Not ready for code review yet.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5:

(4 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1

Only added comment to fstat() as David requested.  Forwarding David's +2 from last patch.
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

forwarding David's +2.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

forwarding David's +2 from earlier.  new patch due to rebasing.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1

Split this patch into two at David's request.  Forwarding his LGTM (+2).
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1

Split this off from another patch (Change 291011).  Forwarding David's LGTM (+2).
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Trybot-Ready+1
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1

This works for me.  Thanks!
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Yes, the code changes are done in another CL.  There are actually quite a bit changes and I didn't want to lose the history if the files differ too much.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

i don't think just moving these files to the server directory should cause the error.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Commit-Queue+1 Verified+1 Trybot-Ready+1

rebased so that this checkin was not blocked by another CL.
|Patch Set 5: Code-Review+2
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8:

I just had one of my officemates do a &quot;repo sync&quot; on the autotest/files directory and he only ended up with one firmware_FMap test in the server directory.  It sounds like maybe your repo didn't do a full update?
|Patch Set 8: Verified+1 Trybot-Ready+1
|Patch Set 8: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8:

(1 comment)
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Forwarding +2.  run_cmd will be cleaned up in another CL.
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1

This error seems like a networking issue, which isn't related to my changes.
|Patch Set 8: Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue Verified-1 -Trybot-Ready

halting check-in while I address Tom's comments.
|Uploaded patch set 3.
|Patch Set 3: Trybot-Ready+1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Changed the mapping of volume_up and volume_down to yesno.  This makes the code much, much cleaner and easier to understand than using the press/release mapping.
|Patch Set 5: Verified+1 Trybot-Ready+1
|Patch Set 5: Commit-Queue+1
|Patch Set 5:

I think that you can set multiple values at once (set_get_all function in server/cros/servo/servo.py?)
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1 Trybot-Ready+1

This is new functionality and should not even be tested at the moment.  Should not have caused the failure.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified-1

still wip.  Not ready for review yet.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1

Forwarding Tom's +2.
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5:

(1 comment)

Sorry, Tom.  I just realized that I never posted this comment that I made awhile ago.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9.
|Patch Set 9: Verified+1 Trybot-Ready+1
|Patch Set 9: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1 Trybot-Ready+1

reorder git checkins to remove blocking CL.
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2

forwarding Tom's +2.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9: Verified+1 Trybot-Ready+1
|Patch Set 9: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10: Verified+1 Trybot-Ready+1

reordered commits to remove blocking CL.
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Fixing typo in control from for ryu suite name.

Forwarding +2.
|Patch Set 5: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 5: Code-Review+2

Forwarding +2
|Patch Set 5:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 8:

(2 comments)
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+2 Verified+1 Trybot-Ready+1

forwarding +2.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+2 Verified+1 Trybot-Ready+1

forwarding +2
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Code-Review+2 Verified+1 Trybot-Ready+1

reordered commits to remove blocking commit.  Forwarding waihong@'s +2.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1

Removing print statement should not cause a build error.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

Is everyone ok with removing this test from FAFT (following Alec's suggestion)?
|Abandoned

disabling this test per Alec's request.  Will follow up on unit test.
|Patch Set 1: Verified-1

Unfortunately, setting dfu_en to on caused servod on beaglebone to crash (right after it tries to initialize dfu_en).  Once I reverted the changes to the XML file, servod starts up again as expected.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2

Forwarding Danny's +2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1

rebased to remove blocking CL.
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2

Thanks a lot, Shawn!
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Abandoned

duplicate fix to https://chromium-review.googlesource.com/#/c/314324/
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

Would you like me to pull it into glados instead?

 &gt; Let's change this in servo_strago_overlay? Then we won't need to
 &gt; change all of these derived boards.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: Verified+1 Trybot-Ready+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1 Trybot-Ready+1
|Abandoned

Intel has submitted a similar change in
https://chromium-review.googlesource.com/313928
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2

(1 comment)
|Removed Code-Review+2 by Shelley Chen &lt;shchen@chromium.org&gt;

|Patch Set 1:

Sorry, Tom overrules me :D.
|Uploaded patch set 1.
|Patch Set 1:

&gt; (1 comment)

Will this change from boot to boot?  We're seeing behavior where the stateful_partition gets corrupted and for some reason becomes read-only.  We are not sure why this happens, but I assume that it's always trying to mount the partition as rw.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Yes. I agree. Thanks.
|Look like intra_y_mode_mask has nothing to do with TX size in non-rd mode (speed 5 and 6). Maybe only use intra_y_mode_bsize_mask here instead of 2 masks.
|++i or i++ ? (consistent)
|i &gt; BLOCK_16X16
|If there are not enough registers to do all 16, maybe separate them in 2 or 4 groups, and still interleave the instructions. Also, not sure how much branching cost is added by for-loop.
|Done
|Done
|Done
|Could this actually pick up the noise since min/max is calculated by single pixel value?
|One more threshold is alright here since only sad is calculated.
|Can cpi-&gt;vbp_threshold_sad be derived from cpi-&gt;vbp_threshold_64x64?
|PLANE_TYPE_Y is right here. May modify this parameter, and use subsampling factor instead.
|Yes. But not sure if cm-&gt;base_qindex = 0 only happens in lossless case?
|Yes. The transform skipping happens more while the partition is large with small variance.
|For-loop doesn't terminate unless we already check at least 2 modes, and the best mode has best_early_term=1.
|Done.

No. It calculates variance for bsize, but also saves 8x8 intermediate results.
|Done
|Done
|Done
|Done
|Yes. Thanks.
|Done
|yes
|Done
|Done
|If the filter cost is added at the end, should the above line be removed also?
|So this_rdc calculated here is not needed, right?
|INLINE
|indent
|unpack
|unpack
|remove 1 blank line
|remove extra blank line
|add space after x10
|small core
|remove all tabs in this file.
|It is called in encoder.c
|Done
|It seems that y_mode and tx_type are calculated two times in these functions.
|Done
|It seems the mode and tx_type are calculated again in get_scan().
|Just checked - it seems vpx_quantize_b and vpx_quantize_b_32x32 are not used in Hignbitdepth case. Maybe we should remove these two here?
|I was wrong. They are still needed. Thanks.
|Thank you for fixing it!
|Done
|Done
|Done
|Done
|Right. Modified the test.
|Copy and add the copyright notice, and modify the year to 2015
|These 2 lines may only need to be done once per frame. In multi-thread case, each thread gets a copy of MB. Maybe move them to encode_frame_internal().
|You are right.
|Is this function the same as vp9_block_error_c now?
|Why not use punpckldq like you did in .highprec section?
|It is alright to focus on 64bit, but, 32bit build is still supported. Actually, there were several patches targeting 32bit performance improvement (especially on Atom devices) submitted by Intel this year.
|pshufd may be slow on some platforms. Should a shift work here?
|These instructions may have latency issues on small-core system.
|There are only 4 arguments. ssz should be in register already. (?)
|Even for 32bit, x86inc ABI loads arguments(the first 7) to registers. It is up to you to decide what to do.
|Can you use int here?
|You may want to put this checking somewhere else since it seems that vp9_set_speed_features_framesize_independent() is called once per frame.
|Similar to int_mv, can you use int_mv here?
|May need to be removed as you did before. This cleanup can be done in a future patch.
|same as above
|In case that the range check is failed, does the encoder/decoder just end with an error?
|Move to next line, and indent 2 spaces. Several more places need to be fixed similarly in this file.
|Add const for all const variables.
|Remove all printf()
|indent
|Add const to the above variables.
|same as above
|same here
|same here
|Add const to all constants in this file
|Add const for const variables in this file too.
|add const for const variables in this file too
|stage and input are not needed anymore?

Could you move get_max_bit() into assert(), so it won't be called when assert is not called.
|Add const to all constant variables in this file
|The above 2 should also be constant, right?
|The above 4 - const?
|const
|const?
|move i,j below the constants - normally, constants should be placed on the top.
|After modifying the c code, do you still need to modify assembly code?
|No, vp8cx_remove_encoder_threads() is only called by main thread.
|Want to ask why you need to include stdlib.h.
|Done
|Done
|Done
|There are several defines in this file. Will fix that in a future patch. Thanks.
|Done
|This config was used to decide the range of tiles to be decoded. I think I will need to double check how this is used to see if it can be removed.
|You probably shouldn't put sse2 function here. sse2 version tested should be the one in the code tree that is in one rtcd header file.
|Header files are included in alphabetical order. May move this line in front of #include &quot;test/util.h&quot;
|Could this be a const int?
|Same indent as above
|move this line above previous line
|move this one to the top?
|Is the above change needed?
|Maybe better to change it back to use separate lines.
|same as above
|same as above
|Maybe better to use separate lines
|same as above
|Uploaded patch set 1.
|Patch Set 1:

Thanks for letting me know it.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+1

(2 comments)
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Patch Set 1: Code-Review+2

Looks good to me. Nice improvement. May consider to get rid of the macro and interleave the instructions for better performance (especially on Atom processors).
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Patch Set 2 was rebased
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(3 comments)
|Uploaded patch set 8.
|Uploaded patch set 1.
|Patch Set 1:

speed &gt; 4 here means good quality speed 4, which uses rd code.
|Patch Set 1:

Ok. I see. Thanks.
|Patch Set 5: (1 inline comment)


|Patch Set 32: Looks good to me, approved

(1 inline comment)


|Patch Set 32: (1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 2: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (8 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (3 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved

re-apply +2
|Change has been successfully merged into the git repository.
|Change has been successfully merged into the git repository.
|Patch Set 2: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 5: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Change has been successfully merged into the git repository.
|Patch Set 1:

RTC set borg test showed that this fix didn't affect PSNR except for dark720p clip, which got +1.56% gain. That was great.
|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Change has been successfully merged into the git repository.
|Patch Set 2: Looks good to me, approved


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 3: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: (5 inline comments)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: (2 inline comments)


|Patch Set 1: Looks good to me, approved


|Change has been successfully merged into the git repository.
|Patch Set 4: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)

Thanks.
|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Code-Review-2
|Abandoned

Already checked in
|Abandoned

already checked in
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned

Another new patch was uploaded.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

Ok. Will check the unit tests.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

James, thank you for pointing it out. Yes, the 2 patches are similar. The test results from Frank's patch showed that 4-thread/4-tile performance got hurt a little on some platforms. We may want to re-test this idea, and hopefully solve it since we all saw gains in 2-thread/4-tile case.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)

Thanks.
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)

Thanks
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1:

Not sure if these changes should be checked in.
|Patch Set 8:

(1 comment)

The CL looks good overall.
|Patch Set 9: Code-Review+2

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3:

(3 comments)
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

Sounds good.
|Patch Set 4:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 4:

I agree that solution 3 may be better since the costs are calculated in that specific way. Talked to Deb about that too. Please add detailed comments in cost calculation functions as well as the avx function.
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

range_check cleanup can be done in a future patch.
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 5:

(3 comments)
|Patch Set 7: Code-Review+2
|Patch Set 7:

(4 comments)
|Patch Set 8: Code-Review+2
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3:

(6 comments)
|Patch Set 6: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Code-Review+2

Thanks for the fix. I think nothing should be needed for win32.
|Uploaded patch set 1.
|Patch Set 1:

Yes, I saw GET_GOT_SAVE_ARG, which was not used. I just thought that name couldn't represent what we wanted here. I think that one can be removed.
|Uploaded patch set 1.
|Patch Set 3:

Not sure this is the same issue, but I fixed a stack corruption bug a while ago in sub_pixel_variance function. Please take a look at &quot;variance_sse2.c&quot;. The part starts with the following comments:
// The 2 unused parameters are place holders for PIC enabled build.
// These definitions are for functions defined in subpel_variance.asm
|Patch Set 3:

Peter: Right. It is better not to modify the third party ABI. If you agree, I think you can solve it the same way as I did by passing 2 unused parameters. - kind of clear and less complicated.
|Patch Set 4:

(1 comment)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Abandoned

This is a duplicate patch
|Patch Set 2:

Go to: https://chromium-review.googlesource.com/#/c/320797/
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

In VP8 multithreading encoder/decoder, the process of a macroblock can only be started after its above macroblock is done, which guarantees the correct processing order. However, TSan couldn't understand that. I added synchronizations to thread-shared data to reduce the data race warnings, which causes unavoidable speed loss. But, several things were done to lower the overhead as much as possible.
1. Multiple mutexes were used, where 1 mutex was created for 1 macroblock row. So only the thread handling the above row (write) and the thread handling the current row (read) need to lock the mutex. Since the current macroblock has to wait for the above microblock - this won't cause much overhead.
2.x86_pause_hint();
  thread_sleep(0);
The above lines were used to implement the busy waiting mechanism. This was the original implementation in VP8, and was not modified in the fix.
|Patch Set 2:

(1 comment)

Here is the place that guarantees the processing order.
In sync_read():
mb_col &gt; (protected_read(mutex, last_row_current_mb_col) - nsync
The above condition guanrantees the current macroblock has to wait for the microblocks to finish in the above row.

Here is the place that I think TSan couldn't understand:
In thread_encoding_proc():
 if (mb_row == cm-&gt;mb_rows - 1)
    {
        sem_post(&amp;cpi-&gt;h_event_end_encoding); /* signal frame encoding end */
    }

We only ask the thread that handles the last row to post the end of a frame encoding since we know the rows above the last one are all done at this moment.
|Patch Set 2:

Thank you for looking at the code. I think there may be some misunderstanding here. I can clarify it.

vp8_encode_frame() is called by the main thread, and thread_encoding_proc() is called by created child threads. The main thread does row encoding just like the child threads.
if(mb_row == cm-&gt;mb_rows - 1)
  {
    sem_post(&amp;cpi-&gt;h_event_end_encoding); /* signal frame encoding end */
  }
is placed in 2 places, but the sem_post only happens once - the thread that processes the last row does sem_post that is ensured by the condition: if(mb_row == cm-&gt;mb_rows - 1), and it can be the main thread or one of the child threads.

The situation here is that we don't want to add extra semaphores for each thread that is unnecessary at all, but I can see TSan warnings shown because of this implementation.
|Patch Set 2:

The VP8 microblock processing order as mentioned before guarantees:
if the thread that handles the last row is done, all other threads are already done. The comment may not be very precise, but the implementation is correct.
|Patch Set 2:

No, I don't agree, and the sem_post()/sem_wait() pair in vp8_encode_frame() is necessary. Main thread needs to sem_wait() here to know that the whole frame encoding is done, and then it can continue with operations that would modify the frame such as frame filtering. Thus, one thread has to notify main thread(sem_post) the end of frame encoding. Hope this explanation helps.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Thank you for reviewing and verifying it!
|Uploaded patch set 1.
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2

I see.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Patch Set 16:

(5 comments)
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Patch Set 19: Code-Review+2

re-apply +2
|Patch Set 1:

(1 comment)
|Patch Set 1:

Hi Deb, the patch is ok. Also, please remove CONFIG_KEY_FRAME_TILE in vpxdec too.
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

Hi James, what do you think about using *.inc file for some common code in the test?
|Patch Set 5:

(4 comments)
|Patch Set 6: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

This CL will be integrated into nextgenv2 instead. This one will be abandoned.
|Abandoned

The patch was checked into NextGenV2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2

Rebase and re-apply +2
|Change has been successfully merged by Yunqing Wang
|Patch Set 9:

(7 comments)
|Patch Set 11: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Note: Encoding time for ice_cif was reduced from 98541 ms to 94999 ms. (3.5% time reduction)
|Change has been successfully merged by Yunqing Wang
|Honestly I don't know. Reset seems important.
|Checked datasheet, all of the numbers are reset value.
|My two cents here: i2c-vi needs VI partition to be powered up. It's in the same partition as VI, so that's probably the reason why new pm runtime code can break this.
|Done
|Done
|Done
|Done
|Is there a folder for non-V4L2 sensor driver?
|What is the correct path under uapi to put this file?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It is a kind of optimization
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It's only for non-zero error checking purpose.
|Done
|Done
|Done
|Done
|Will fix.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Added back. These two are needed as userspace will query using this IOCTL if FLASH is available.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|will keep this file untouched
|Done
|Done
|Done
|Done
|fixed naming
|will keep this untouched.
|Done
|Done
|Done
|Done
|Removed. MFI not enabled for A44
|Done
|Done
|Add check for first failure.
|maybe 32bit and 64 bit compatibility?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Added singleton guard.
|Done
|Is compat_ioctl always present?
|Done
|Done
|Done
|Removed.
|Done
|Done
|Done
|Done
|Done
|Not used in A44. Removed
|Done
|Done
|Done
|Done
|Done
|Non-related headers are removed
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Are we using this driver?
|Done
|Done
|Done
|Done
|Need to set 0
|Need to set 0
|Actually never mind, don't need it here.
|Need to add power_off if check failed then quit
|Done
|Done
|Done
|Ah..change it to ENODEV, it seems to make more sense (sensor not connected/wrong sensor connected)
|Done
|Done
|it doesn't matter which sensor it is. /dev/imx*** won't be generated. But I didn't test the back sensor.
|Done
|fixed. also fixed similar logic in IMX219
|Done
|Done
|Done
|Done
|Done
|This is done via pushbuffer(drm channel submit) from  userspace.
|Patch Set 1:

Is this change merged?
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 18.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 21: Patch Set 20 was rebased.
|Patch Set 22: Commit-Queue+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6:

i2c-tegra-vi is on different i2c bus
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7:

Hi Tomasz, I'm not sure if I understand correctly. Do you mean that we implement a general i2c-tegra interface and have 2 backend?
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 11:

(1 comment)
|Patch Set 11:

Hi Tomasz, thanks for your time to integrate this driver. Do you plan to continue looking into the fix for the HACK?
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Patch Set 17:

(1 comment)
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Uploaded patch set 21: Patch Set 20 was rebased.
|Patch Set 17:

(1 comment)
|Patch Set 22: Commit-Queue+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Verified+1
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 18.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Patch Set 3: Code-Review+1
|Patch Set 3: -Code-Review

(15 comments)

I'm working on the comments.Still in progress
Will upload a new patch soon.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Patch Set 4: Code-Review+1 Verified+1
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1

(1 comment)

Moved non-v4l sensor driver to misc.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Code-Review+1 Verified+1
|Patch Set 8:

As drm is under GPU, it sounds odd to add sensor driver under GPU.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 10: -Code-Review

&gt; But vic and isp are also under GPU, aren't them? And I believe
 &gt; those sensor and focuser drivers can be only used together with
 &gt; those drivers, so putting them anywhere else is confusing.
Okay. Will fix.
|Patch Set 3:

(46 comments)
|Uploaded patch set 13.
|Patch Set 13: Code-Review+1
|Uploaded patch set 15.
|Patch Set 16: -Code-Review

(4 comments)
|Uploaded patch set 17.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 4: Code-Review+1
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Verified+1

TODO: document
|Patch Set 5:

Will fix.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Code-Review+1 Verified+1
|Uploaded patch set 10.
|Patch Set 9:

(1 comment)
|Uploaded patch set 14.
|Patch Set 14: Code-Review+1

(3 comments)
|Uploaded patch set 16.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Patch Set 4: Code-Review+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+1 Verified+1
|Patch Set 9: Commit-Queue+1 Verified+1
|Patch Set 9: -Commit-Queue
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 2: Code-Review+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+1
|Uploaded patch set 12.
|Uploaded patch set 14.
|Uploaded patch set 16.
|Patch Set 1: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Code-Review+1 Verified+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+1
|Uploaded patch set 11.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 15.
|Patch Set 1: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Code-Review+1 Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 13.
|Uploaded patch set 15.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Abandoned

Partially Merged in https://chromium-review.googlesource.com/#/c/286956/
|Patch Set 2: Code-Review+1
|Uploaded patch set 3.
|Patch Set 2:

start working on the comments
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

This patch is a basic clean up. Will remove non-DT stuff and fix usage in next patch.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Code-Review+1 Verified+1
|Uploaded patch set 8.
|Patch Set 2:

(36 comments)
|Patch Set 2:

(7 comments)
|Uploaded patch set 12.
|Patch Set 12: Code-Review+1
|Uploaded patch set 14.
|Uploaded patch set 16.
|Uploaded patch set 18.
|Patch Set 15:

(9 comments)
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+1 Verified+1
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Uploaded patch set 11.
|Patch Set 11: Code-Review+1
|Uploaded patch set 13.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 17:

(1 comment)
|Patch Set 1: Code-Review+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 15.
|Uploaded patch set 17.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Patch Set 5: Code-Review+1

Shivdas, can we get this in?
|Patch Set 2: Code-Review+1

Let's get this into TOT?
|Patch Set 2:

the i2c-tegra-vi is folded into i2c-tegra.c
I will integrate this patch to the latest code. But TOT will also need https://chromium-review.googlesource.com/#/c/288388/
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

It's for NVJPG hw boot problem.
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch factory-smaug-7265.B-chromeos-3.18.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1

I think upstream need this as well if it has not been fixed yet.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch chromeos-3.18 as commit ebde6ec666053ba32134a1ab4ca7e4db0cac7037
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned

Covered in other patch
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 7: Commit-Queue+1
|Patch Set 1: Code-Review-1

Last week I tried https://chromium-review.googlesource.com/#/c/292062. Camera cannot launch with this. This patch looks very similar. Have you verified camera usecase?
|Patch Set 4: Code-Review+1

Tried front/back, video/still switch, start with front camera after reboot. No regression with this patch.
|Patch Set 1: Code-Review+1

didn't find power sequence timing diagram in ad5823 data sheet. Code change looks ok and delay looks reasonable.
|Patch Set 1: Code-Review+1

Matched with datasheet
|Patch Set 1: Code-Review+1

Matched datasheet
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Verified-1

Found sometime camera app will stuck at start screen, but not crash, just hanging there. Maybe related with turn off clocks.
|Patch Set 2: -Verified

Will verify again. Previous issue seems to related with stream configuration failure
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Patch Set 4: Code-Review+1
|Abandoned

merged in factory branch.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5: -Code-Review

(1 comment)
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 5: Verified+1

Ping, do we still need this?
|Uploaded patch set 6.
|Patch Set 4:

(2 comments)
|Patch Set 6: Code-Review+1 Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Patch Set 7:

Comments are addressed. Looking for Approval.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Code-Review+1 Verified+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 5.
|Patch Set 5:

Andrew, I revert the patch back to the original, as userspace change is reverted as well. I need get/set clk interface.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Code-Review+1 Verified+1
|Uploaded patch set 7.
|Patch Set 7: Code-Review+1 Verified+1

(4 comments)
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Code-Review+1 Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Code-Review+1 Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+1
|Patch Set 3:

(2 comments)

thx for the review. working on it
|Patch Set 2:

This patch will fix several camera stress failure, what's the next step?
|Patch Set 1: Code-Review+1

lol indeed
|Uploaded patch set 1.
|Abandoned
|why add this blank line?
|Patch Set 1: Ready; Verified


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 3: Looks good to me, approved


|Patch Set 3: Ready


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 2: Ready; Verified


|Patch Set 2: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Ready; Verified


|Patch Set 2: Ready; Verified


|Patch Set 2: Ready


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 5314902c25efae8022feb282d8ae380bc2b3b9bd
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as 571cb5a1f832e5fcc3f47f211936377636b5573f
|Patch Set 1: Abandoned

Please review https://gerrit.chromium.org/gerrit/#/c/36420/ instead.
|Patch Set 1: Verified


|Patch Set 1: Ready


|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|It'd be nice to add the following namespaces:

namespace bluetooth_media {
  // Bluetooth Media service identifiers
  // Bluetooth Media methods
  // Bluetooth Media errors
}

namespace bluetooth_media_endpoint {
  // Bluetooth Media Endpoint service identifiers
  // Bluetooth Media Endpoint methods
}
|Please add Bluetooth Media Transport errors:
org.bluez.Error.NotAuthorized
org.bluez.Error.Failed
org.bluez.Error.NotAvailable
|Change variable name to match media service.
s/kBluetoothMediaTransportServiceName/kBluetoothMediaServiceName
|ditto
|ditto
|I just removed it this morning:p
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Indeed, this check is repeated in three different descriptors. I can pull out the for loop into a helper function &#124;is_duplicate&#124;.
|Yes, it's too long.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|&#124;bInterfaceSubClass&#124; should be different for two settings, one for NCM (0x0D) and the one for MBIM (0x0E).
|Done
|Done
|I am going to leave it from now and do an upload. It might be better to do this on top of Ben's magic.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|You are right:) Instead of returning a list of indices, it's cleaner to return a list of descriptors and their indices, then we don't need a get_index() to go through the list.
|Done
|Done
|Done
|Since mbim extended functional descriptor is optional, so this check is to determine whether the following checking for it is needed or not.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Instead of adding suffix to these super long names, I prefer giving more explanation about these maps in the comments.
|You are right. But for bulk_in and bulk_out, the &quot;==&quot; comparison is not always true for every field when it comes to &#124;endpoint.bEndpointAddress&#124;.
|Done
|Let's keep our lambda function simple:)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|You will not see this file again:o
|Done
|Done
|Done
|Done
|Done
|Done
|Actually, we don't even need this variable. I shortened the name of descriptor, but I didn't catch this. Thanks:)
|Done
|Done
|Add TODO for new. I will start a new CL to stash the mbim functional descriptor and interrupt endpoint descriptor. Don't want to touch des_xx tests in this CL:)
|Done
|Can I stash these descriptors later? Don' want to touch des_xx tests in this CL:) After merging this CL, I'll create a new CL to handle this.
|Done
|Done
|I thought about this as well. The first reason is that it is clearer to map the fields to their format. The second is that if simply using the field names as arguments, I may need to import inspect to get the name of arguments, otherwise I have to use setattr() for each one of them. If using kwargs, we will need a list of field and a format string as well, and the number of kwargs need to be checked too. So I think it is nice to do it this way:)
|Done
|I did. Weird...this one was not catched.
|Done
|In the compliance test spec, this value is a constant. I will make this as a named constant:)
|Since the device in test_context.py is a &#124;Deivce&#124; object defined in usb/core.py, both &#124;is_kernel_driver_active&#124; and &#124;detach_kernel_driver&#124; can be used through the device.
|Done
|Done
|Done
|Done
|Since &#124;mbim_status_codes&#124; is how it is defined in the spec, I would like to follow the spec for now:)
|Done
|Done
|Done
|My plan is to leave them here for now. If we need them in other kind of sequence or tests, I will move them into a separate module:)
|Yes, it works. I will simplify them.
|Done
|Done
|Done
|?
|Done
|Done
|Done.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It seems like that a message may not be reused in most cases. So this method can be removed.
|Done
|I find that the outcome of struct.calcsize('LLL') is 24, where 12 is expected. The reference (https://docs.python.org/2/library/array.html) suggests that 4 is the 'Minimum size in bytes' for 'L'.
|Done
|Thanks for the verification:)
|Done
|Done
|Done
|This problem may be solved if I make each message type as a class.
|Done
|Done
|Done
|Removed. We don't need this if we go for 'one class for one message' approach.
|Nice catch.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Maybe open sequence is a good place to check, since open sequence is a precondition for most of the tests.
|Done
|Done
|Done
|Done
|Done
|Will do it in another CL:)
|Done
|Done
|Nope.
|Done
|Nope.
|I will move the corresponding assertion check to here.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think we don't that space.
|Instead of running two sequence, I should send two packets and receive their response all at once:)
|Done
|Done
|Done
|Done
|Done
|Continue should be used at this point.
|Done
|Will stash all these constants into &quot;mbim_constants&quot;.
|Once the information_buffer is handle separately, we don't need to subtract &#124;default.keys()&#124; anymore.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Will treat &#124;data_buffer&#124; as &#124;information_buffer&#124;.
|Done
|Done
|Done
|Done
|If you are curious enough, we can walk through this!
|Done
|Done
|Done
|This magic number helps us debug the structure to be attached. We can replace the magic number with what you suggest after correctness of the structure is verified.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Can we move this to bt_bcm4354 block which is more relevant?
|I meant bt_bcm4354 but not wifi_bcm4354.
|Return TRUE if the previous connection for a given UUID?
|Do we need to reset data-&gt;ag_retries as well?
|Since BTD_SERVICE_STATE_CONNECTING is not doing anything in your case, a &quot;break&quot; is preferable than adding a fallthrough comment.
|s/3_8/3_14
|Missing BUG and TEST.
|s/3_8/3_18
|s/3_8/3_10
|Patch Set 1:

(2 comments)
|Patch Set 4:

(3 comments)
|Patch Set 6: Code-Review+2

lgtm
|Patch Set 6: Code-Review+1
|Patch Set 1: Code-Review+2 Verified+1
|Abandoned
|Patch Set 6: Reverted

This patchset was reverted in change: I223b7476b7dd8a0c8df471ace58ed256be375be8
|Patch Set 1: Code-Review+1

lgtm
|Patch Set 1: Code-Review+2
|Uploaded patch set 13.
|Patch Set 13: Verified+1
|Patch Set 13: Commit-Queue+1
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Patch Set 8: Commit-Queue+1

WOO HOO!
|Uploaded patch set 1.
|Uploaded patch set 3.
|Patch Set 2:

(33 comments)
|Uploaded patch set 4.
|Patch Set 3:

(27 comments)
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

This CL has been split into three different CLs.
|Uploaded patch set 1.
|Abandoned

The base of Change-Id: I5fde2bf02a82de70097524a3fddc678e32726147
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Uploaded patch set 3.
|Patch Set 2:

(31 comments)
|Uploaded patch set 4.
|Patch Set 3:

(8 comments)
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Please ignore patch set 1, since I split patch set 1 into two CLs.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(14 comments)
|Uploaded patch set 6.
|Patch Set 5:

(12 comments)
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

In this CL, we would like to focus on mbim_control module:) If you want to make comments on mbim_open_generic_sequence module or on open_sequence module, please go to Change-Id: Ia1222e797b54327533138ef6df6661e7f2163fa5.
|Uploaded patch set 5.
|Patch Set 4:

(27 comments)
|Abandoned
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

Patch set 4 simply renames mbim_ctrl to mbim_control.
|Patch Set 5: Commit message was updated
|Uploaded patch set 6.
|Patch Set 4:

(15 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7:

Please ignore patch sets 6 and 7:)
|Uploaded patch set 9.
|Patch Set 9: Verified+1
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

To make the review order clearer for you, I listed the order as follows:
1. Implement MBIM Close Sequence and CM_10 test.
   CL:208974
2. Implement Validation of MBIM_OPEN_MSG.
   CL:209095
3. Fix a bug for mbim_compliance/mbim_control module.
   CL:209110
4. Implement MBIM_CID_DEVICE_CAPS sequence.
   CL:209111
Hope you find this useful:)
|Uploaded patch set 5.
|Patch Set 4:

(4 comments)
|Uploaded patch set 6.
|Patch Set 5:

(12 comments)
|Uploaded patch set 7.
|Patch Set 5:

Yes, it is ready for review. It's just that I forgot to post the reply.
|Uploaded patch set 8.
|Patch Set 7:

(3 comments)
|Patch Set 8: Verified+1
|Patch Set 8: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(13 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Uploaded patch set 3: Commit message was updated.
|Patch Set 1:

(1 comment)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Uploaded patch set 3.
|Patch Set 1:

(6 comments)
|Uploaded patch set 4.
|Patch Set 3:

(3 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4:

(3 comments)
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(4 comments)
|Uploaded patch set 6.
|Patch Set 5:

(3 comments)
|Uploaded patch set 7.
|Patch Set 6:

(3 comments)
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(25 comments)
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

(3 comments)
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2

A message from hangout successfully triggered wifi wake!
|Patch Set 1: Code-Review+2 Verified+1

See that both BT qualification and sanity tests passed for the new firmware in the test logs.
|Patch Set 1: Commit-Queue+1
|Patch Set 5: Code-Review+2 Verified+1
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)

lgtm
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Patch Set 8: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Patch Set 5:

(1 comment)
|Patch Set 6: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Patch Set 4: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Patch Set 4: -Code-Review -Commit-Queue
|Patch Set 4:

(1 comment)
|Patch Set 4: -Trybot-Ready
|Patch Set 5: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: -Code-Review -Commit-Queue
|Patch Set 2:

(1 comment)
|Patch Set 2: -Trybot-Ready
|Patch Set 3: Code-Review+2 Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Trybot-Ready+1
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 4:

Apart from oak, maybe we should also test this against all platforms running 3.18 apart from. :)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

&gt; I think we should drop this change, since the default threshold is
 &gt; already changed in https://chromium-review.googlesource.com/#/c/330095/1

Good point. Will address this.
|Abandoned

The change is addressed in https://chromium-review.googlesource.com/#/c/330095.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

&gt; Maybe merge another patch into this one?
 &gt; 
 &gt; CHROMIUM: Add lib/sdp.h include to plugins/chromium --
 &gt; https://chromium-review.googlesource.com/#/c/330093/1

Done.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

&gt; Maybe merge this patch to its original patch of introducing
 &gt; plugins/chromium?
 &gt; 
 &gt; CHROMIUM: Add the Chromium plugin -- https://chromium-review.googlesource.com/#/c/329839/

Good point. Will combine those two patches.
|Abandoned

Merge this into https://chromium-review.googlesource.com/#/c/329839.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2 Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2 Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 25.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Commit message was updated.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Uploaded patch set 19.
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 3: Patch Set 2 was rebased
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 17.
|Uploaded patch set 19: Patch Set 18 was rebased.
|Uploaded patch set 20: Patch Set 19 was rebased.
|Add &quot;default&quot; handling?
|I would suggest to move the #if/#endif loop outside
&quot;if (!frame_is_intra_only(cm))&quot;
, since for the none CONFIG_COPY_MODE scenario, there is no need to check the &quot;if&quot; condition.
|Prefer to have following format:
#if CONFIG_VP9_HIGHBITDEPTH
    if ()
    else
#endif
    build_masked_compound(); ...
|Ditto.
|Ditto.
|The above &quot;#if CONFIG_TX64X64&quot; may move up by one line to be above the closing brace &quot;}&quot;, such that following &quot;else if&quot; may stay in the same line as this closing brace.

Then combined with the following change to move &quot;#endif  // CONFIG_TX64X64&quot; up also by one line, leave the next closing brace &quot;}&quot; to be outside the &quot;#if - #endif  // CONFIG_TX64X64&quot; loop.

This way, the closing brace format issue may be gone.
|Ditto.
|Ditto.
|Ditto.
|Prefer to use the following format, to avoid duplicate code to the maximum extent:

#if CONFIG_VP9_HIGHBITDEPTH
  if (...)
    ...
  else
#endif  // CONFIG_VP9_HIGHBITDEPTH
  vp9_quantize_fp()
  ...
|Ditto.
|Ditto.
|Ditto.
|Ditto.
|Ditto.
|Ditto.
|Ditto.
|Ditto.
|It's a good code cleaning effort through the use of &quot;bs&quot;.
|Do we need to check (pbi-&gt;max_threads &gt; 1) here, and if &quot;yes&quot;, to &quot;winterface-&gt;launch(&amp;pbi-&gt;lf_worker);&quot;?
|Done.

The whole file has been moved back to vp9/common/ and renamed as vp9_filter.c.
|Done.

Both INTERP_FILTER and vpx_filter_kernels have been moved back to vp9/common/vp9_filter.h and the latter was renamed as vp9_filter_kernels.
|Done
|Done
|Done
|Done
|Done
|Done
|Done.
Indent has been fixed too.
|Done
|Done
|Done
|Done

Both of the includings have been removed. Corresponding includings have been added to the appropriate .c files.
|Done
|Done
|Done
|Done
|Done
|Done
|Yes, otherwise some files have to include vp9/common/vp9_common.h
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It's good to implement this way.

I might prefer to separate &quot;mode&quot; from &quot;scan_order&quot; though:

(1) First to obtain &quot;mode&quot; as:
mode = plane == 0? (tx_size == TX_4X4 ? ... : mbmi-&gt;mode) : mbmi-&gt;uv_mode;

(2) Then for &quot;scan_order&quot;, we may group tx_size &lt; TX_32X32 all together, as:

if (tx_size &gt;= TX_32X32) {
  scan_order = ...;
} else {
  tx_type = tx_size == TX_4X4 ? ... : ...;
  scan_order = &amp;vp9_intra_scan_orders[tx_size][tx_type];
}
|2015
|Already included in vpx_dsp/inv_txfm.h.
|Prefers to remove the duplicate code between #if - #else - #endif. Instead, may use 
#if
if {
...
} else {
#endif
...
#if
}
#endif
so that the common code is being shared.
|Done
|Done
|Thanks for the comment. Will make the corresponding change in the next CL when switching to the use of the prob tree structure.
|Done
|Done
|Maybe another macro or inline function could be defined e.g.
static INLINE int is_dst_related(tx_type) {
  return (tx_type == DST_DST &#124;&#124; ...);
}
|May we learn what is the motivation to duplicate the code in the 3 functions: vp9_fdst4, vp9_fdst8, and vp9_fdst16? Just for better performance in speed?
|idx = MIN(idx, N + 1 - idx);
|Ditto.
|Ditto.
|Same as previous comment that better to define an inline function to return a binary value to determine whether these are true or not.
|Had a fruitful discussion with Hui offline. Thanks! Will have a new patch coming up.
|Good catch! Cannot understand why the compiler did not complain it.
|Done
|Should here also be replaced by:
vp9_build_wedge_inter_predictor_from_buf()?
|Why defined &quot;i, j&quot; here that never got used?
|It does not seem &quot;k&quot; got declared. Wonder whether the highbitdepth mode has been tested.
|Within #if CONFIG_EXT_INTRA - #endif, following may be assigned to a variable:
mbmi-&gt;ext_intra_mode_info.use_ext_intra_mode[plane_type]
|Even though no difference in execution, I would suggest to add
&quot;else&quot; here
|Suggest
return (v &lt; m) ? v : ((v &lt;&lt; 1) - m + vpx_read_literal(r, 1));
|Maybe a separate function is defined to avoid duplicate code?
|Ditto - maybe a separate function be defined to avoid duplicate code?
|Comment should be:
// CONFIG_EXT_INTERP &amp;&amp; SUPPORT_NONINTERPOLATING_FILTERS
|Comment needs to add SUPPORT_NONINTERPOLATING_FILTERS
|Ditto.
|Ditto
|Ditto
|Ditto
|Ditto
|CHECK_GOLDEN_OR_LAST3 should be removed as well. Sorry that this is a flaw in the original code that should have been included within the none-LAST4 case.
|Suggest that
lfi-&gt;bilateral_used is initialized in the function of vp10_loop_bilateral_frame() where vp10_loop_bilateral_used() has been checked already.
|Suggest just simply move the open &quot;{&quot; and close &quot;}&quot; out of the #if-#endif
|Ditto.
|jzern@ has identified that Marco's submit triggered the unit test warning. But this old line of code also has its own issue.
|This function seems in pair with ref_cnt_fb(), in common/onyxc_int.h. Suggest to put it in a header file, e.g. encoder/encoder.h
|May fix the indent by one more space.
|Would suggest &quot;ref_frame - LAST_FRAME&quot; instead of the hard-coded value of &quot;1&quot;, even though the above original code also used the hard-coded value of &quot;1&quot;.
|May suggest to try to avoid #define.

If still prefer to use, please make sure all the parameters of &quot;v&quot;, &quot;r&quot;, and &quot;c&quot; are placed within parentheses, as &quot;(v)&quot;, &quot;(r)&quot;, and &quot;(c)&quot;.
|Suggest indent to be aligned with the above first line right to the left of the left parenthesis.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 9: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3:

Have put the change under NEWMVREF.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Verified+1
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 5: Code-Review+2
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Change has been successfully merged into the git repository.
|Change has been successfully merged into the git repository.
|Patch Set 1: Rebased
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Change has been successfully merged into the git repository.
|Patch Set 1: Looks good to me, approved

(3 inline comments)


|Patch Set 7: Looks good to me, approved

(10 inline comments)


|Patch Set 10: Looks good to me, approved

(4 inline comments)


|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 1:

How are the &quot;runborgs&quot; results now with all 15 experiments on?
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 4:

&gt; Please leave the configure change out of this patch so that the
 &gt; jenkins compilation goes through.

Done.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13:

(3 comments)
|Patch Set 13:

We have moved the work on mips/drsp2 to a separate CL. This CL is large partially because it is hard to avoid the dependency between convolution and filtering.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Patch Set 19:

(2 comments)
|Uploaded patch set 20.
|Patch Set 19:

(16 comments)
|Uploaded patch set 21.
|Uploaded patch set 22.
|Uploaded patch set 23.
|Uploaded patch set 24.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7:

(11 comments)
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 4:

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 8:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Abandoned

It has been squashed with another CL.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Trying hard to get it to fully work before testing on borgs. Not there yet.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16: Commit message was updated.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Uploaded patch set 22.
|Uploaded patch set 23: Commit message was updated.
|Uploaded patch set 24.
|Patch Set 23:

(5 comments)
|Uploaded patch set 25.
|Uploaded patch set 26: Commit message was updated.
|Patch Set 26: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 1.
|Patch Set 1:

(6 comments)
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned

As mentioned in the comment, it did show a slight improvement in the video that was being tested, but the runborg results shows a slight drop overall.
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Uploaded patch set 1.
|Abandoned

Committed to the wrong branch.
|Patch Set 2:

(2 comments)
|Patch Set 7:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 6:

(5 comments)
|Patch Set 10: Code-Review+2

(7 comments)

Better fix the comments.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Just submit a patch to master that cherry-picked this CL.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

Should have merged the changes to vp10/ instead of vp9/.
|Restored
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

TODO on the reference frame context design was added to Patch Set 7.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2

Better to make a comment on the background for the parameters that were chosen.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Verified+1
|Patch Set 4:

Thanks for comments from yaowu@. Another patch will be submitted shortly to address these.
|Uploaded patch set 1.
|Patch Set 4: Code-Review+2
|Uploaded patch set 1.
|Patch Set 8: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 3:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2

Done with the cleanup for vp9 as well.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 16:

(5 comments)

Suggest to put the encoder time impact in the comment.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Patch set 3 in progress - don't review just yet!
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1 Verified+1
|Removed the following votes:

* Verified+1 by Alison Chang &lt;alisonchang@google.com&gt;

|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

Deprecated
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15: Commit-Queue+1 Verified+1
|Patch Set 15: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 15: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Patch Set 16: Commit-Queue+1 Verified+1
|Patch Set 16: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 16: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: Code-Review+1
|Done
|Done
|This test required or not depend on factory. For wolf project, it depend on Crag. Crag can decide enable it or not.
|Done
|Done
|But it's not ignore case actually. It only upper scan value.
|Done
|No, this not required.
Do I need to fix it or just leave it? thanks.
|Done
|I'll use &quot;disable_dev_switch&quot; funciton to replace it in next commit. Is it OK?
|Because block_devmode seems be cleared after using this shim, so I want to enable here.
I've tried and code die here, it seems 5517 not support block_devmode?
|I can't verify. Beacuse the factory shim I built only execute when dev_boot_usb=1. This need system already in DEV mode, not in DEV request.
|I'm not sure what the purpose of creating an empty file here.
I followed KIP.

I think we should not skip SF if empty lsb-factory. It would be better to die here and OP can ask PE for help.
|I suggest to kip FACTORY_SHOPFLOOR as KIP project and Factory won't be confused.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1 Verified-1
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 2:

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3:

Hi All,

Any other concerns about this commit?  Default set to &quot;False&quot;, it doesn't affect other platforms.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: Commit message was updated
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to change: I8e3dcf723c5aadcdc29d06eb92bf19ac2e0e7e35
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 3:

Hi Bernie, Jimmy,  
please help to review because Bowgo is OOO this week. Thanks.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2:

@Jimmy, it's better, but I don't think it's meaningful. Because we know what image we have to update and using update package(factory.tgz) to do that.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1

Hi Bowgo,
So sorry for the another patch set update.
This update only update port from 8093(enguarde) to 8097(kip).
Thanks.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1:

Copy every thing from Enguarde.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R36-5841.B as commit 6e91924e441e15eb115d8f9023d2340565c3e8ff
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

So should I abandoned this CL or just wait until it can merge?
|Abandoned

Will cherry-pick from ToT once it's been verified.
|Patch Set 3: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R45-7262.B as commit cd3b6bd9353e2e71e1dc7601a8cf93e33881c4ed
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 6435bf5578d5060aa4047a8c25c52390d149b420
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 1b4cfe393c9c396c299c9a17ef9ac2ddd713686a
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch set 2: Published edit on patch set 1.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R45-7262.B as commit a8618eac522f336123046058a8b0384fd53cf14f
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch master.
|Patch set 2: Published edit on patch set 1.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R45-7262.B as commit 284f53f83fbf37d0ec49ed5ef5f78e397bc1e884
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch release-R44-7077.B.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch release-R44-7077.B.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Code-Review+1 Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

it seems the dev channel firmware on CPFE can't boot factory shim I built. So I have to build my own firmware/factory shim/test image for verify.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

Wrong Original-Change-Id
|Uploaded patch set 1.
|Abandoned

Wrong Original-Change-Id
|Uploaded patch set 1.
|Abandoned

Needs RO update, it cannot deploy to existing devices.
|Uploaded patch set 1.
|Abandoned

Needs RO update, it cannot deploy to existing devices.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1:

Copied from KIP project.
https://chromium-review.googlesource.com/#/c/245300/4
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Commit-Queue+1

Hello Hung-Te, Bowgo,
Please help to review, thanks.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|They're different flags FORCE_DEV_BOOT_LEGACY and FORCE_DEFAULT_DEV_BOOT_LEGACY, but I added a similar check for the second flag here.
|Done
|Done
|Done
|Line 450 still checks that legacy boot is allowed before it trys legacy.
|Done
|Oh. ok. yes.
|I did this ifdef in common/i2c with the others
|Done
|Done
|out is the battery function during the write message and 0 during the read, so i store it until the read message.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Should I put in a TODO about the vb2_read_gbb_header?
|coreboot_table just checks vboot_console_enabled and not console_log_level
|lib/coreboot_table needs access to console_enabled
|Done
|It is called by lib/coreboot_table. It is protected by CONFIG_CONSOLE_SERIAL. If CONFIG_CONSOLE_SERIAL is set does that mean __CONSOLE_ENABLE__ is true?
|For some reason I was unable to use rdev_readat(&amp;rdev, gbb, 0, 4) to read the header but I could use rdev_readat to read the flags.
|I added it to gbb_flag_properties in bundle_firmware
https://chromium.googlesource.com/chromiumos/platform/dev-util/+/master/host/lib/bundle_firmware.py#60
|Done
|Done
|Done
|Done
|If request_offset is 0 then get_offset returns the current data_offset so it will work.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Right now if its in RW code, it wont update RW. Because RW wasnt updated, RO wont be updated. It will reboot back to RO then update the RW and RO images.

Do we want to keep the requirement that the RO image will only be updated after updating the RW image?
|If it has been updated then
|Done
|We just didnt before, and I wasnt sure if we wanted to spend the time recalculating the hash.
|Done
|Done
|Done
|Done
|Done
|This needs to have the absolute path of the bootstub file.
|Done
|Done
|Done
|Done
|I thought we are initially supposed to set the DCP current limit to 500mA and then set it to a higher limit when ramping
|Done
|I'll move it
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Should we make this consistent with PPVAR_CLOGIC_EN?
|These should be alphabetized
|duplicate
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(5 comments)
|Patch Set 4:

(1 comment)

Should I implement the 2bit default boot logic in this CL or a follow up one
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(6 comments)
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11:

(3 comments)
|Uploaded patch set 12.
|Patch Set 12: Verified+1
|Patch Set 12: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

I was running tests with Jerry and there isn't enough space for my changes and what is currently there. If I disable console history, there is. I have cut out support for the params that are not requested as often, but there still isn't enough space. Should I do something else as well?
|Uploaded patch set 2.
|Patch Set 2:

(6 comments)
|Uploaded patch set 3.
|Patch Set 3:

(5 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 9.
|Uploaded patch set 10: Commit message was updated.
|Patch Set 10: Commit-Queue+1 Verified+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(5 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

check console_enabled in do_putchar because some boards pass do_putchar to pei_data to handle console output in romstage.
|Uploaded patch set 7: Commit message was updated.
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 8: Commit message was updated.
|Patch Set 8:

I am not sure about the 3ms. I could put in a config option to enable this check.

I moved the check for enable_console to console_tx_byte to only disable usb and uart_tx_byte.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11:

(5 comments)
|Uploaded patch set 12.
|Patch Set 12: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 13: Reverted

This patchset was reverted in change: Ie96abfc74a75c00b2cf662b54dd8e779c32c4165
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Trybot-Ready+1

(3 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: -Code-Review -Commit-Queue -Verified
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1

(1 comment)
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: Trybot-Ready+1
|Uploaded patch set 6: Commit message was updated.
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Patch Set 6: Trybot-Ready+1
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(10 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Trybot-Ready+1
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(8 comments)
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1 Trybot-Ready+1

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(1 comment)
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Restored
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: Code-Review+2
|Patch Set 2: -Code-Review

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(3 comments)

the ec binaries all have the name &quot;EC_FMAP&quot;
|Patch Set 4: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Trybot-Ready+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3:

(4 comments)
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Patch Set 4: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review+1

(2 comments)
|Patch Set 7: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|PTAL!
|Done
|Done
|Nope. I got caught on this as well. The serve address is relative to &quot;static&quot; when served by cherrypy (devserver.py:172)

The subdir inside the static dir are always followed by &quot;static&quot; relative to the devserver url when served.

Do you think there is a more attractive way to handle this?
|Oh! you're right.

That was a lot of silly.

Redefined the severity of an xBuddy exception, so it's only thrown when a path can't be translated, and we get cache hit/miss information if we want it.

PTAL!
|I thought no, since it doesn't change the behavior when -image or -payload is specified for image_to_live/devserver.

Could you elaborate on the failure, and how I could emulate a workflow that hits it...?
|Yes! Will do. :)

I keep doing them as I see them, and it's caused more than a few pointless conflicts.
|I'm not sure, but I had thought not.

First, if there's no label, we can't do much about it. The case above replaces it with payload_path (going to be merged/replaced with remote_payload), which doesn't always exist, right?

I also think it's okay for there to be no label (i.e. serve directly from the static_dir), and I still plan on using a symlink directing them to something logical. (either last referenced or latest locally built, etc), but as we discussed, this should be a less common use case that xbuddy will try its best to redirect away from. (I'm imagining that update/other rpcs will point to directories, and only if we go &quot;host:port/static/update.gz&quot; will we use the symlink)

Did I interpret your question correctly, and does this make sense to you?
|Done
|If we return '' or None, then we don't get the path information in the label, and we don't have a useful label (which we later use to look for the update.gz, or image.bin files to generate payloads from).

I didn't want to use file_name as an indicator, because it seemed less readable.
|Done
|Done
|Oops. My housekeeping instinct has significant gaps &gt;.&lt; Thank you!!
|Done
|Yup, me too. sosa asked me to do this as an rpc. I didn't ask why, but I'd assumed it was easier to develop on, and we could dance with cherrypy later.
|Done
|Done, thx!
|Done
|Done
|Didn't check until now, but nope, needed it.
|Done
|Sure.
|Done
|Done
|Done
|Done
|Done
|Done
|Roger. Redid this, so path splitting &amp; defaults are more explicit, too.
|Done. Thx!
|Done
|Yup. Tis sad. This CL was getting fat. Called halt.
|Done
|Done
|Done
|Done
|Agreed.
|Agreed that return_dir&gt;return_update_url. Swapped it out. I can't think of a pretty way to write &quot;return directory for update&quot;
|Done
|Whoops! Got it :)
|heh, that looks weird. Done.
|Done
|Done
|Oops, planning and negativity at work. Thanks for the catch, roger. :)
|I saw, thanks!
|I saw a lot of other CLs tagged with &quot;manual&quot;
Can I do the same, and list several urls and describe expected behavior?
|Sure, that confused me too.
|hurts mine, too, but didn't want it to look like the xbuddy.py import. Were you thinking 'xBuddy' as an alternative?
|Done
|Done
|To clarify, I think the renaming/moving of things should be explicitly described, instead of handled case by case by the separate classes. This stuff ends up reconstructed on the other end when autotest (and presumably other people) use devserver.
|image_label is an improvement on label, but I dont find it immediately instinctive that we cache something based on its &quot;label&quot;

If people are already used to label (and thus image_label), I'm cool with perpetuating it. :)

How about build_id or image_id?
|Done
|Done
|build_id/image_id//image_label!
|Done
|Done
|Done
|No purpose. I just figured at some point this would be mixed in with the stage call, and since stage already quietly keeps track of download threadcount, we can continue here. I guess someone was preemptively watching for performance?
|Done
|Done
|Done
|Done
|Done
|Done
|Please see comment on misunderstanding return_update_url.
|Done
|Done
|Done
|Done
|Still working on this making sense. The pieces are scattered in different places at the moment, and this seems the best I can do without forcing significant clarifying changes in build_artifact.
|whoops! this list used to include local and official. Thanks!
|Fat enough, or more? I can continue and cover more content on purpose/design, but was hesitant to start writing an essay.
|Done
|Done
|Makes sense, thx!
|Done
|Done
|Done
|Done
|Discussed this in person.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Bad naming, apologies.
|Done
|Done
|Done
|Done
|Yes!
|That bug is tagged &quot;WontFix.&quot; Do you know why this wasn't done, before?
|well.... I mentioned I'm a little blocked on this bug? I did the remote-aliases a few days ago in a different, not-yet-uploaded CL... so this is already all different. I figured my dummy Not Implemented things was distracting from this CL (i.e. the latest-official, which is more of an issue in the other CL). Deletion would make merge conflicts clearer when I came across them. :)
|Good point, but &quot;latest-official&quot; is also valid... So I suppose it's not *just* a prefix. I'll go back to calling it exactly what it is, and when I implement the latest-official stuff, I'll check for both cases explicitly to catch officialmonkeys. :)
|Oh this is cool. I'll try it the next time I start a unittest file, thanks. :)
|Awesome. Done.
|Done
|Yup, we don't need much at all.
|Done
|Whoops.
|Done
|Done
|Done
|I guess it's not fair to call it a prefix since it could stand alone.
Technically, latest-official isn't enough, we need the build suffix as well.
(latest-official effectively actually defaults to latest-official-release.)

This makes sense in the next CL!
|yup, startswith
|I gave it a shot, but I worry it's not very strong.
|Done
|Done
|Done
|This creates the file if it doesn't exist. Is there another way this should be done?
|Does this help?
|Done
|No good reason. I think meant to use ./build_image, because that makes me think of calling it, but we don't need it.
|Yes!
|Done
|Done
|Just talked with sosa about this yesterday. This &quot;suddenly getting managed&quot; is a pretty bad idea. Just swapped it in the prev patch to this CL with a more consistent listing of the builds found in build/images/

Now it reads your build/images directory and effectively takes control of it.
The first run may be destructive, as it'll just wipe all but 5 images...... Does this seems reasonable?
|Done
|readlink is what I wanted. :)
|Done
|Done
|Good point. Fixed it for every other time I used re here.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Concluded it wasn't a very informative logline anyways.
|Done.
|Trying to parse this, I think these prepositions don't make sense. period. This made more sense to me. I'll switch them because I figure more people are like you than me.
|It ends up being not quite the same.

if true:
    if false:
      etc.
|Done
|Sure. The numbers don't matter much anyways.
|I'm sorry, I didn't (and still don't really) understand the distinction. Is there some situation in which this could be no handled? http://stackoverflow.com/questions/1946426/html-5-is-it-br-br-or-br
|Moved it to devserver:xbuddy, so it's all in the same place.
|Sure!
|yup!
|That definitely would have been neater, before.

Now, I can't see a way around it, since we have to make a distinction between the chunks of the path (cherrypy splits them up as args) and the optional kwarg return_dir.
Even if we label them, cherrypy will take the first thing in the path to be return_dir, second thing to be path, etc.
|Done
|Done
|Yes! That was the wrong way to solve the cherrypy redirect problem I was having. Thanks
|Done
|Done
|I agree... the way this if/else sequence is set up, it doesn't make sense.

Bad structure comes with the similar appearance of
&quot;latest-R30-...&quot; and &quot;latest-dev&quot;

In the end, what would happen is that if it's not a version, it would attempt to treat it as a channel (the general use case of 'latest-*' e.g. latest-dev, latest-stable) and if it really were invalid, we wouldn't find it on gs, and it'd fail, and explain what it tried.

Please let me know if this doesn't seem right. :)

There are also plans to make this mapping generally clearer via an easy to override python dict.... In the works, and hopefully done before the summer ends!!
|Made it a devserver_constant, since it's a common check.
|I like it. :) Done.
|a LATEST file that points to what people are likely to want would be great. :) Also easy enough to swap this over if that is in place.

Before then, sosa suggested LooseVersion too. I think that's enough for our purposes. Does this look better?
|Good idea. I was worried about that, and forgot to fake test data that is meaningful. Done, and confirmed that LooseVersion catches it.
|Whoops, I thought they all had to be in column if any were.
Makes more sense this way, now because of the dict thing.
|Done
|Done
|Done
|=False got overridden by None, previously. The default from cherrypy fixed it now. :)
|I didn't want to drop old timestamps, since that data gets lost. (When we discover them again, they get reset) Please let me know if this still doesn't seem like the right way to handle this!
|Done
|Done
|Done
|Agreed, this looks better. Done.
|Done
|Done
|Done
|I chose to do it this more confusing way because I didn't like how it looked, with the same check multiple times. (315, 324).
Similar deal happens below.

Seemed a good setup for python's &quot;ask for forgiveness, not permission.&quot; Please let me know if you think I should change this!
|Oops, roger! I'll keep it this way for aesthetic purposes, and since as you say, it's a single error condition I'm grabbing, I think it's not too unclear. Thanks!
|Here, it's also okay if there's only one. (It's fine to fail at like 338 or at line 341.)
I can also place two identical checks here.
|I'm sorry, this was unclear.
The image url is the same either way, but the _GetLatestLocalVersion method guarantees that it exists, while a user specified path might be invalid, so this is just an extra check.

(aside: I just noticed I can hop image_url out of the if/else, sorry I missed that!)
|Oops. Done.
|Done
|Done
|Done
|the results are the same, though, then.... the only tradeoff a branch vs an or?
|Done
|Done
|sosa just removed all of this in a different CL. All the &quot;THIS METHOD IS DEPRECATED&quot; methods are actually going away :D
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Roger.
|Done
|Done
|I crawled this pretty carefully earlier. The default is '', from when it's first called, so yes, I think so.

Now checking for it explicitly to be sure.
|Done
|Done
|I didn't remember to clean up this one. Now handled in tearDown. Thanks!
|Done
|Done
|Done
|Done
|I discussed this structure with some other people a long while ago, and this seemed the most clear.

I rewrote it in plain english. This sacrifices the indexing, which had seemed clearer to me, even if inaccurate, but is at least readable and correct, now.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done. This was also an outdated description. Updated.
|Done
|Done
|It does, but I still think it belongs somewhere else. :P
|Oh fun. Thanks.
|Derp. It did once upon a time. Thank you!
|Done
|Done
|Done
|Done
|Done
|Done
|This is actually being converted into an ini file. (one of the blocked CLs, lol) I'll leave this as is. :)
|Done
|Done
|Done
|Done
|Yes, that was the original order. I flopped that earlier for what I thought was a good reason (the update files used to get copied to the image_dir, which meant we may not catch changes to the image, thinking the update was already generated for it). That reason is no longer relevant, since I stopped it from doing that (in this CL).

In general, though, 1 can fail if an image doesn't exist. i.e. wasn't built or downloaded for that image. We can get an update straight off GS.
|Done
|Done
|Done
|Roger.
|Done
|Done
|Done
|Done
|Thanks! I hadn't noticed.
|Cool. Python *is* english.
|Done, but just to check, we no longer care about what they refer to here as the &quot;old-style&quot;? (It sounds like the release number used to be part of the version number, making the version 4-chunked)
|Roger. Thanks.
|absolute vs relative is what I wanted.

Though now that you mention it, it's understood that paths are absolute paths unless otherwise specified.

Thanks!
|Done
|And less load when reading. Thanks!
|Done
|Done.
|Done
|Whoops. No.
|Done
|Done
|Done
|I'm confused, too. Apparently didn't proofread all comments, sorry!
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done.
|Whoops. Fixed this.
|My English broke. I actually rewrote it all pretty, and then realized I'm just trying to justify making a function to get rid of some clutter at the beginning of HandleUpdatePing. Settled for simplifying the refactoring.
|Thank you. That just helped a lot.
|They were there before so I left them.
This one does seem less necc than the other.
|Agreed. Moved it back.
|There was planning and confusion.
|Done
|Done
|Done
|Rewrote it. This may be more clear/ties up more loose ends.

New somewhat unclear situation:
What happens if board (from the update xml) and label (from the update call, which can include the board) don't agree?
Result: if a path rewrite was used, the given board will determine what xBuddy path is used.
If the label doesn't match any path rewrite patter, the given board never gets looked at.

Is this concerning?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Whoops, I meant remote omaha server.
|Done
|Decided to put it with the main docstring in devserver.py (where it should've already been)
|Done
|I'm sorry, would you clarify that?
|Done
|Good point.... That sounds close to being right... but I can't think of a reason to forbid making an update pkg from an image binary that wasn't necc built on this machine. (i.e. we could download a dev image, and generate a payload to it, right?)

Ended up rewriting this in the new patch.

I thought about this more, and I wanted a clearer distinction between generating an update pkg from some image binary vs. using an update pkg from some other source (i.e. could have been obtained through a remote call that got it from GS, or generated from the current/an older image)

What now happens is:
1. Check for image file first, attempt to generate a payload.
This puts the new generated update in some image_dir/cache/hash_dir, and symlinks it to image_dir/update.gz
2. If no image file was found in the previous step, then check for update file (the &quot;update.gz&quot; in that image directory) and try to serve it.

Trying to think of ways this could be messed up (really meant to serve an existing update payload, and instead end up generating it)... coming up empty so far. Ideas?
|I hit problems when None overrode the default when it's passed in. Tried a new approach in the new patch.
|Done!
I forgot that this default for the empty path is why this CL depended on the path rewrite CL.

Fixed it up to use an xbuddy path rewrite to get the latest test image for the board from the xml, and then generate an update payload from it.
|Yay! Essays! Please read my fat docstring, as it really does document changes introduced in the new patch.
|Done
|Would this be better placed in devserver_constants? This could be used in xBuddy, too.
|Suggestion: named_artifacts &amp; file_artifacts feels rather wordy, and is a little misleading, as if named_artifacts is something new. (It also sounded like artifacts would still be the most common use, and a renaming seems unnecessarily confusing)
&quot;artifacts&quot; and &quot;file_artifacts&quot; or just &quot;artifacts&quot; and &quot;files&quot;?
|This abbreviates it, so -i == --image.
|Done
|Oh shoot! It told me it couldn't pregenerate without a board, and I believed it.

I should be able to fix it up to use the default board.

Sorry! I hadn't meant to send this out for review before the other change was pushed. Just wanted to stash it in my CL list before my head exploded from things.
I hadn't meant to have you review a thing I'm not fairly sure works. :P

Thanks for looking at it though!
|That made sense to me. Currently trying to figure out how to write up a Chromium doc for xBuddy, what should go in it, and since I think it should be a subpage of the current devserver doc on CrDocs, how it's related. :)
|Shorter help string for the flag agreed. :)

I wrote a short help string for the whole script.... I don't know if it's very clear though.
Would it be bad form to squeeze in &quot;See go/xbuddy for full documentation.&quot;?
|Done
|I agree. This isn't clear. Resulted from an attempt to keep the interfaces to Get and Translate identical, since they were so similar.
|Done
|Done
|Will trybot the new patch. Sorry and thanks!
|Done
|Done
|Done
|Done
|Done
|Done
|I'm sorry, is this what you meant?
I didn't think it looked as good as them all in a column.
|Done
|Done
|Done
|Done
|Since I'm already here....
|Done
|That's true within other codebases I've seen, but not this one. I'll leave this be.
|Done
|Oops. This comment is outdated. We talked about this. I ended up keeping the same operation.
|What they appeared to do was generate a sequence of ports that could be tried, until one worked. See MakePortList.

Tbh, I didn't want to check for port availability the same way.
|Done
|Done
|Done. The answer is none. :P
|Done
|Done
|Just did this for devserver unittests. Ported it over....
|Done
|a) Oops, I thought it wasn't necc because the urlopen has a timeout, so if it's not responding it just waits for 1/20th of a second. apparently it can respond immediately with a connection refused. Added a half second sleep. b) done c) done
|No, because if a port isn't open, it catches it fairly quickly. 
there's a socket error of some sort, and the thread terminates. There *was* a bug in the code where the &quot;not devserver.poll()&quot; needed to be &quot;not devserver.poll() is None&quot; Fixed now. :)
|This seemed a little silly and unavoidable.
1) check_health is apparently a better way to check that the server is ready, compared to scanning its logs

2) on the other hand, if you already have a devserver running from that port, the check_health call will go through, even if its not the right devserver instance.
|Patch Set 1: Abandoned
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Apologies for messy uploads! Remembered that xBuddy Get has the side-effect that it tries its best to get the artifact, which we don't want for this. :)

PTAL, tyvm!
|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 5.
|Patch Set 3: (1 inline comment)


|Patch Set 5: Looks good to me, approved; Ready; Verified


|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5:

Should now address the use case of defaulting to latest local build when possible. Now also includes a bugfix in update rpc. Explained in updated commit message. PTAL, tyvm!
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7: (4 inline comments)

Thank you for the reviews, Don and Chris. :)

Chris, PTAL at inline comments, tyvm!
|Uploaded patch set 9.
|Patch Set 9: Looks good to me, approved; Ready; Verified


|Patch Set 9: Ready

Got tied up with my other commit, which had a build error. Retry.
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Whoops. Updated Makefile to include xbuddy_lookup_table.py
Inherit LGTM.
|Patch Set 1:

Micro-CL! PTAL, tyvm!
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified

Fixed a nit and rebased. Inherit LGTM.
|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

Rebase. Inherit LGTM.
|Uploaded patch set 3.
|Patch Set 3:

@BUG: Should this change be tagged with any bugs (existing or not)?

@TEST: Ran unit tests. Are there test suites for devserver I should aware of? 'sides that, I'll go look at Trybots and what they do...
|Patch Set 1: (30 inline comments)

Yay, found the tiny button to publish comments. finally.
|Patch Set 3: (9 inline comments)

Just replying to some points with questions/suggestions. Assume agreement/consent on other comments. Changes will be in next CL.
|Uploaded patch set 4.
|Patch Set 3: (13 inline comments)

You meant these? I somehow thought it would upload as a different CL when i un-drafted it, so I never posted (what I thought was rather uninformative to anyone else) list of dones.

Will do in the future.
|Uploaded patch set 5.
|Patch Set 4: (29 inline comments)

More replies, thanks for the reviews. :)
|Uploaded patch set 6.
|Patch Set 5: (4 inline comments)

I think I got them all. Thanks a lot!!

@sosa label, you mean static/archive CL? Still testing.... Dependent-ish, but I think it doesn't matter, since nobody besides me is hitting xbuddy.
|Patch Set 6: Looks good to me, approved; Verified

Inherited LGTMs
|Patch Set 6: Ready


|Patch Set 6: Ready

Previous test failure unrelated to this CL. Reattempt.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: (1 inline comment)

+ some aesthetic changes. PTAL, tyvm!
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Inherit LGTM past a rebase, because it's been a long time.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Inherited LGTM
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Hi Don,

It looks like the _ArtifactStaged and _MarkArtifactStaged were made to fix a problem of that nature.
I haven't touched those functions. (This CL may be better named as &quot;stop downloading artifacts in a staging directory and copying them over&quot;)

Since _Download blocks until the download is finished, the artifact shouldn't be tagged as &quot;staged&quot; until it really is.

Does this sound right?
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

I did unnecessary (and broken) things to downloader.py on the previous patches.
Reverted it, so this CL is functional again. Don, would you PTAL? It's basically the same, but I'd appreciate your all clear. :) tyvm
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Uploaded patch set 5.
|Patch Set 5:

PTAL, tyvm!

Would also appreciate suggestions for how to meaningfully unit test this.
|Patch Set 5: (13 inline comments)

PTAL, tyvm!
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7: (12 inline comments)

PTAL, tyvm!
|Uploaded patch set 9.
|Patch Set 8: (10 inline comments)

PTAL, tyvm!
|Uploaded patch set 10.
|Patch Set 9: (8 inline comments)

Thanks a lot, Ryan! PTAL.
|Patch Set 10: (1 inline comment)

Sorry for the confusion!
|Patch Set 10: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2:

PTAL, tyvm!
|Uploaded patch set 3.
|Patch Set 2: (4 inline comments)

PTAL, tyvm!
|Uploaded patch set 4.
|Patch Set 3: (2 inline comments)

PTAL, tyvm!
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Looks good to me, approved; Ready; Verified

Inherit LGTM.
Submitting it to CQ. xBuddy internals shouldn't affect anyone else.
|Patch Set 1: Looks good to me, approved; Ready; Verified

Inherit.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)

PTAL, tyvm!
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified

Update commit message. Inherit LGTM.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (6 inline comments)

PTAL, tyvm!
|Uploaded patch set 8.
|Patch Set 7: (1 inline comment)

Micro constant-cleanup. PTAL, tyvm, and sorry for the trouble!
|Patch Set 8: (1 inline comment)


|Uploaded patch set 9.
|Patch Set 9: Looks good to me, approved; Ready; Verified

Expanded an existing TODO + resolve merge conflicts. Inherit LGTM.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)

PTAL. tyvm, Ryan!
|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Patch Set 4: Looks good to me, approved; Ready; Verified


|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified

Fix merge conflict. Inherit LGTM.
|Uploaded patch set 2.
|Patch Set 2:

Hi Chris, just updated the commit message. PTAL, tyvm!
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)

PTAL, tyvm!
|Uploaded patch set 4.
|Patch Set 3: (7 inline comments)

PTAL, tyvm!
|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, approved; Ready; Verified


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (6 inline comments)

Sorry this grew really big. :(
Unittests aren't where I want them yet, but I figured at this size, it was reasonable to separate the tests into a separate CL. Please let me know if that is not true.
|Uploaded patch set 4.
|Patch Set 3: (59 inline comments)

Thanks a lot! :)
Updated in response to existing comments.
Unittests all passing but will want to make another sweep of manual tests. (presumably after approval before committing)

PTAL at the new patch, tyvm!
|Uploaded patch set 5.
|Patch Set 4: (39 inline comments)

PTAL, tyvm!
|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved; Ready; Verified

Thanks for all the reviews :D

Inherit LGTM.

(It published my previous patch's inline comments without my consent. Weird.)
|Patch Set 6: Ready

Probably the other CL that caused this.
|Patch Set 6: Fails

Yup, I was too confident it wasn't coming from this one. I'm very sorry.

It looked from the first run to be directly related to a completely unrelated one-line CL that I tried to push at the same time. (it was clean, but it happened to modify that file)

I already have the roughly equivalent logs from a remote trybot test I ran on this patch just after flagging it as ready last time and realizing it was premature... I will be debugging this soon. :)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Looks good to me, approved; Ready; Verified

Should be happy now.

Inherit LGTM. :)
|Patch Set 9: Ready


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, approved


|Patch Set 4: Looks good to me, approved

(1 inline comment)

Keeping the named/unknown artifacts separate sounds better to me, too.
|Patch Set 6: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Oops, realized that both --for_vm and --no_patch_kernel need to supported by image_to_live to transition vm tests out of the old flag. PTAL, tyvm!
|Uploaded patch set 5.
|Patch Set 5: Looks good to me, approved; Ready; Verified


|Patch Set 5: Ready

Retry after CL 65606 pushed.
|Patch Set 1:

Hi Don. This is what caused this: http://build.chromium.org/p/chromiumos/builders/x86%20generic%20paladin/builds/15510

PTAL, tyvm!
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Patch Set 1: Ready

I believe that wasn't me.
|Patch Set 1:

Needs verification after CL 64393 is pushed.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

Paired with CL 66157, closes the image_to_live portion of crbug.com/260491

Will test before flagging Ready, but I'm fairly sure it works, so PTAL, tyvm!
|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)

Help strings amended. PTAL, tyvm!
|Patch Set 2: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

Added a shortlink to the help string. PTAL, tyvm!
|Uploaded patch set 5.
|Patch Set 4: (2 inline comments)


|Patch Set 5: Looks good to me, approved; Ready; Verified


|Patch Set 5: Ready


|Patch Set 5: Ready

Still GS problems?
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4: (4 inline comments)

PTAL, tyvm!
|Patch Set 6: Looks good to me, approved; Ready; Verified


|Uploaded patch set 7.
|Patch Set 6: (1 inline comment)


|Uploaded patch set 8.
|Patch Set 8: Looks good to me, approved; Ready; Verified


|Patch Set 8: Ready

previous failures due to GS issues?
|Patch Set 1: Verified

Second to last one in the series.
PTAL, tyvm!
|Patch Set 1: Looks good to me, approved; Ready


|Patch Set 1: Ready

Retry.
|Patch Set 1: Ready

I was wrong. This CL was clean. Retry.
|Patch Set 1: Ready

Still pretty sure this patch is clean.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved

*pops champagne*
|Uploaded patch set 3.
|Patch Set 3:

PTAL, tyvm!
|Uploaded patch set 4.
|Patch Set 3: (23 inline comments)

Sorry for the slow response! Resulted in a lot more refactoring than planned.

Running this is about as fast as the original (&lt;10 second difference on my single run), which makes sense, since they're still running the same operations.

The new patch appears to work locally, and has just been sent off to trybot on mario-paladin.

PTAL, tyvm!
|Patch Set 3: (1 inline comment)


|Patch Set 4: (3 inline comments)

Never got to finish this on my last day :(

Handing the reins over to sosa, but publishing my more substantial comments in case they're of any help in interpreting this CL.

A tout a l'heure!
|Patch Set 3: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Rebase. Inherit.
|Patch Set 1: Verified

This is required by image_to_live, if we want to pregenerate the correct payload.

Technically could have been in the same patch as the image_to_live CL, but I had trouble testing the image_to_live part, since it runs start_devserver.

Would like to push them in sequence, and test in between.

PTAL, tyvm!
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Unittest added. Inherit LGTM.
|Patch Set 1:

PTAL, tyvm!
|Patch Set 1: Looks good to me, approved; Ready; Verified

Passed on mario-paladin.
|Patch Set 1:

Missed this one, which uses image_to_live's for_vm flag.
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified

Or I could fix the test that was testing for the broken behavior. Derp.

Fix unittest. Updated commit message. Inherit LGTM.
|Patch Set 2: Ready

GS issues.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Alright, I changed it to do that.
The only issue I came across is how can I tell not to merge when the data_bz size exceeds the individual compressed blob sizes? Since we merge the extents before we compress the new blob is seems we can't really unmerge them after that?
|Done
|Done
|Done
|This isn't reading the extents, just the data offset and length for the ops. Would it still make sense to make a vector of extents to give to ReadExtents?

I did change ReadExtents to take a const vector&lt;Extent&gt;&amp;.
|Done
|Done
|Done
|Done
|I removed the compare command in the latest patch. Do you think it would still be helpful to add the subcommand?
|Done
|Done
|Yes, that is much easier. I was overthinking it a bit.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Oops, I don't think so. I've removed it.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I'm kind of unfamiliar with kwargs. Would you mind explaining what the advantage of using a kwarg here would be?
|Done
|Done
|Done
|Done
|Done
|I thought two invocations was slightly cleaner, because otherwise I'd need a conditional to open old_part_file if old_part_file_name exists, and another to close it. Something like:

  old_part_file = open(old_part_file_name, 'r+b') if old_part_file_name else None
  self._ApplyOperations(operations, base_name, old_part_file, new_part_file,
                        new_part_info.size)
  if old_part_file:
    old_part_file.close()

I mostly did it the original way so I could use the 'with' statement. Do you have any cleaner suggestions on how to do this with just one function call?
|Done
|Done
|Done
|I added the constants to common.py.
|Done
|Done
|Done
|That makes a lot more sense, I was a little confused, I guess I just interpreted it wrong. Fixed it.
|Done
|Done
|Done
|Done
|I tried using two iterators for the block vectors here, but I thought it looked a lot cleaner and more readable this way. Is there an advantage (maybe more efficient?) to doing this loop with iterators?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think it's easier to test the sparse hole removal on its own. There's one small unit test for ClearSparseHoles that would probably be much more complicated if I combined them.
|Done
|That got changed accidentally, I think, fixed it.
|Done
|Done
|Done
|Done
|Yeah, that makes a lot of sense, fixed it.
|Done
|Done, I was trying to make it match the existing OpenKernel function. Should I change that one, too, to use std::string?
|Done
|Done
|I wasn't sure where to put these paths. Does it make sense to keep them here in InstallPlan (with the other device paths) or would it be better to have them in DeltaPerformer?
|produce
|Changed it, I think that makes a lot more sense, thanks!
|Done
|That makes sense, sorry about the confusion. Changed it everywhere else.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It seems like the other testCheck*Operation cases (like testCheckMoveOperation_FailExcessDstBlocks) used that format, so I was trying to keep it consistent. Should I still change it?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done, sorry about the confusion!
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It raises a PayloadError saying there's invalid payload magic if it's not a payload file, and an IOError if it's not an existing file. Is that okay?
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

(7 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(4 comments)
|Uploaded patch set 4.
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4.
|Patch Set 3:

(4 comments)
|Patch Set 4: Commit-Queue+1 Verified+1

I had originally planned on handling REPLACE_BZ in the same place, but since I've started working on it I decided it made more sense to put it in a separate function.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

(8 comments)
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1

I'll set the name in the next CL.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(18 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(6 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 2: -Code-Review -Commit-Queue -Verified
|Patch Set 2: -Trybot-Ready
|Uploaded patch set 3.
|Patch Set 2:

(4 comments)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(4 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(5 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(9 comments)
|Patch Set 2: Verified+1
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+2 Commit-Queue+1 Verified+1

Fixed the failing unit tests for x86 boards.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(6 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Patch set 2 accidentally included some code that wasn't ready for review yet (PerformSource*). I fixed it in patch set 3, sorry about that.
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Trybot-Ready+1
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(10 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1 Trybot-Ready+1

Yes, I used the bash script to verify it. It output SOURCE_* operations that seemed reasonable.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2 Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Patch Set 1:

(7 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Patch Set 3:

(7 comments)

I made these changes in a new CL, https://chromium-review.googlesource.com/#/c/254345/.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)

I'll make the other changes in a follow-up CL, I just made the minor changes for now.
|Uploaded patch set 3.
|Patch Set 2:

(6 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1

I ran paycheck.py on some delta/full payloads and everything looked fine.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(13 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Terminate '&lt;pmin&gt;' of '&lt;pmin&gt;,&lt;pmax&gt;'
|agreed.
|Sorry, was looking at 3.10 kernel code by mistake. In 3.18 it is in fs/kernfs/file.c, kernfs_fop_write(), line 289.
|This functions is registered through sysfs.  sysfs infrastructure already guarantees input buf is a null-terminated string so every other driver author does not have to duplicate the effort of handling the same buffer overflow issue. Check fs/sysfs/file.c.

strchr() is guaranteed to be safe on a null-terminated string.  Also the function is already in use on line 147.
|Moving to line 614 means idling the channels after suspending the fences, which seems fishy for me.
|inlined in the source code.
|When the issue happens, the last channel irq is always fired right here but does not trigger the uevent_handler.  I went through the code once and haven't figured out what is corrupted by this timing yet.

Moving the spin_lock_irq() is more like disabling the irq earlier to drastically decrease the chance this problematic timing happens.  Theoretically if the irq comes in early and went out very slow due to some reason, the issue could still occur.
|actually *pchan is initialized in either nouveau_channel_ind() or nouveau_channel_dma(). So can not move the assignment up.
|Done
|Done
|It was a conscious decision to handle loop exit condition inside loop because I would like the thread to clear all pending work before exit, with the synchronized fence wait in place we know it is guaranteed to be done in finite time.
|Same reason as above.
|If kthread_should_stop() is added here, we then will have to check the conditions again to determine which one got us out of the wait.  As I would like to get all pending work flushed before exit, list_empty() would have higher priority, thus we would need to lock the same spinlock twice in a row to do the redundant check.

Sending the signal before calling kthread_stop() is, of course, also redundancy, but is only done once per thread instead of every wait.  So I preferred to use this method to avoid locking twice.
|Was wrong about this one. Will update soon.
|Same reason.
|Done
|You are right.  Fixed.
|I am not sure which ABI you are talking about.  Nouveau driver binary gets loaded by kernel as a whole and ustate is not exposed through ioctl so changing the nvkm_clk structure has no effects ABI-wise what so ever.

The pstate node in sysfs was used to a) expose what pstate GPU is running on, b) expose writable ustate interface so user can affect how pstate is determined.  Allowing specifying a range instead of a single pstate simply extends the functionality.  I do not see why it causes any issue  while being backward compatible with the old.
|Nothing will be broken because the old protocol on pstate node still works the same old way.  When you specify 1 pstate as ustate input instead of the newly supported two, upper boundary and lower boundary coincides and dvfs will be disabled in that special case.
|No. it is not expected behavior because now we have a upper boundary and lower boundary for ustate.  DVFS needs to work in the range ustate defines.
|Do we need to acquire fctx-&gt;lock to do this?
|We can go back to that version if you prefer.
|nouveau_gem_do_pushbuf() does not really access cli.  It was nouveau abusing that mutex to prevent coherent GPFIFO access on the same channel.  It would be a big change to introduce a proper per channel spinlock/mutex to do that, thus I left it that way.  Since kthread_stop() is synchronized and there is no operation going to GPFIFO until nouveau_channel_del() calls that, it will not be any coherent GPFIFO access channel-wise.
|nouveau_channel_del() will do it.
|No.  Due to the abuse of cli-&gt;mutex, nouveau_channel_del() is possibly called with and without cli-&gt;mutex held.  It would be rather messy and probably more overhead to try to tell first there.
|Basically the solution here is if we take cli-&gt;mutex. We stop the thread outside nouveau_channel_del() with cli-&gt;mutex unlocked.  If we do not take cli-&gt;mutex, we leave it to nouveau_channel_del().
|&quot;... won the race.&quot;

I really need to get my fingers under control...
|Not sure if I said that...  But nouveau_gem_do_pushbuf() takes cli-&gt;mutex and I did not change that.  kthread_stop() is asynchronous so if there is possibly anything pending in a channel's pushbuf queue, we have to give up the mutex in order to free the channel without getting deadlocked.
|typo here.  ...kthread_stop() is synchronous...
|Sorry about my English...

By moving list_del() into protected area, ioctl_pushbuf won't be able to get a reference to the underlying channel if ioctl_channel_free() won't the race.
|Oh you are right.  In single threaded case the only one could response to the signal is the one possibly doing ioctl.
|In fs/ioctl.c, SyS_ioctl() uses fdget() which in the end goes to __fget_light().  The tricky part of __fget_light() is it does not do refcounting unless file table is shared.  So technically if we have a single-threaded process that uses gpu and somehow crashed or gets terminated in the middle of an nouveau ioctl, things could be messed up.
This would be a really really rare case though. Most processes that ever use GPU are multi-threaded.  Plus, being weirdly signaled to death is probably the only way a single-threaded process would ever crash in the middle of nouveau ioctl (without nouveau being faulty in that ioctl call).
|I am not sure.  Are we covered in the case process crashes and kernel tries to reclaim resources by closing all open file descriptors?
|nouveau_abi16_chan_fini unlocks the mutex first.  That part is the equivalant of removed part in nouveau_abi16_ioctl_channel_free().
|Not sure... I think I initially added it to expose nouveau_gem_pushbuf_queue_kthread_fn, might become duplicated during some rebase.  Removed.
|Oh, thanks.  Was looking for something similar to msecs_to_jiffies() but could not find one.  Fixed.
|Alternative workaround is just replacing this with NVIF_NOTIFY_KEEP.  That impose a performance hit though.  I still would like to fix nvif_notify for coherent robustness but I guess we have to get in a workaround for the time being.
|As workaround, I guess we can manually set the bit here with proper locking and return NVIF_NOTIFY_KEEP instead so the nvif_notify_func() does not try to set it again outside lock.
|I agree that is no other easy options then holding the lock.  In terms of the pattern lock/unlock in different functions, here is a arguably nicer way to do the exact same thing: https://chromium-review.googlesource.com/#/c/307049/
|In that case, nvif_notify_get() will get an refcnt == 1 in atomic_inc_return() and go down to call nvkm_* to re-enable the notifier.
|Hmm, then there will be a race condition in nvkm layer I guess, since that layer is not reference counted either...
|The original function here is rather messy so sort out what it originally does.  REFCNT mode mimics the exact same behavior here:

1) If ret == NVIF_NOTIFY_KEEP, it falls inside the if block and return NVIF_NOTIFY_KEEP.
2) If ret == NVIF_NOTIFY_DROP, AND this is the first time ret == NVIF_NOTIFY_DROP after last nvif_notify_get() call, it returns NVIF_NOTIFY_DROP without doing anything.  Because we make sure drop is positive, count == 0 could only happen in the exact same condition described.
3) If ret == NVIF_NOTIFY_DROP, but does not meet 2), do the same as 1) but returns NVIF_NOTIFY_DROP.  This could only happen when drop == 0 because of the refcounting nature.
|This is when NVIF_NOTIFY_REFCNT is not set so ret is not drop cnt.  But we might want to change NVIF_NOTIFY_KEEP to 0 and NVIF_NOTIFY_DROP to 1 just in case?
|Locking here hurts performance significantly.  nouveau_bo_sync() -&gt; nouveau_fence_sync() only access fifo in nv17_fence implementation which we do not use.  Also as I check nv17_fence_sync() again, it does not work if cli-&gt;mutex is already held.  So probably nv17_fence implementation is out of maintenance in the first place anyway.
|nouveau_bo_sync() calls nouveau_fence_sync() which in some implementation has fifo access.
|nouveau_fence_install does not touch fifo.  It should not WIND_RING on failure.
|The 3rd argument to nouveau_fence_sync() is a boolean stating if the wait should be interruptible.
|Because sparse bit is cleared when a page is mapped.  So we have to re-set it when unmapping.
|I do not understand your question.  Yes we set the sparse bit when unmapping.  What is the &quot;what&quot; about?
|Oh.  That is how sparse texture works.  Sparse provides you the ability to access not physically backed memory address.  If it's mapped it's mapped.  If it's mapped it's sparse.
|This code looks almost like deliberately returning the possible non-NULL value of base in any failure case.  However, at least in nvkm_ioctl_new(), error handling for 	 nvkm_object_ctor(&amp;parent-&gt;object, engine, nv_engine(engine)-&gt;cclass, data, size, &amp;engctx) did not take care of releasing possible existing allocation of engctx, nor did it passing it out anyhow, hence memory leak.  So I went ahead to add the cleaning in error handling anyway.  Just want a second eye on this to make sure I did not miss any point.

nvkm_gpuobj_create_() also has the similar problem of not cleaning its allocation in failure case, but that is beyond the purpose of this patch.
|It allocated a huge chunk of memory and used 0x1000 as PGT, 0x2000 as PDE.  Those are usually allocated separately.
|Correction, it used 0x1000 as PDB, called PGD in nouveau.  The function only initalizes the 1st PDE of PGD.  The first PDE points its small page directory to 0x2000, thus there resides small page PTEs of this PDE.
|ALIGN(1&lt;&lt;40, 1&lt;&lt;pde_bits) is 1&lt;&lt;40, pde_bits is 27 for 128K large page and 26 for 128K large page.  1 &lt;&lt; pde_bits &gt;&gt; pde_bits = 1.
|Beause PGD size is determined by large page size.

PGD_size = total_PDE_count * PDE_size;
total_PDE_count = address_space_size / single_PDE_coverage.  
single_PDE_coverage = big_page_size * 1K.

The 10 bits comes from the 1K PTE entries per PDE.  Each PDE takes 8 bytes.
|The ideal is to determine how many PDEs the PGD needs to cover PMU's memory space.

Looks like I was using ALIGN in a wrong manner.  The second parameter is supposed to be the align size instead of bits (Doesn't make sense though IMO, since the macro works correctly only with 2-ordered size).  Fixed in next version.
|Agreed. The original design was thread will finish pending push buffers even if kthread_should_stop() is true.  This patch changes this behavior here.  My suggestion is to insert if (unlikely(kthread_should_park())) above if (unlikely(!pb_data)).
|in the case nouveau_bo_vma_add() calls nouveau_defer_vm_map() instead of nvkm_vm_map(), vm-&gt;node is assigned but nvkm_vm_map() did not happen.  nouveau_bo_vma_del() will then call nvkm_vm_map().
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review-1

Seeing regression where screen on/off cycles may cause half of the screen not coming up.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7: Verified+1
|Patch Set 7:

Any plan on merging this change?
|Patch Set 7:

(1 comment)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8: Commit-Queue+1 Verified+1

Thought this was merged.

Rebased to TOT. Try merging again.
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8:

Any idea what went wrong about the change?
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8:

Anything we can do to get this landed?  There was a user-space change relying on this already landed as this was thought to be merged...
|Uploaded patch set 1.
|Patch Set 1:

Which memory writes are you referring to?
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

This does not really fix fence timeout issue, but makes some fence timeout non-fatal and easier to debug by removing the affect of aggressive PM suspend.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1

Please don't submit until I have full confidence of the exact variable in race here.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1

Now that this is fully root caused.  Patch set 1 was actually alright fix/workaround as it eliminates the possibility nouveau_fence_emit_inited() get preempted by or lose race of fctx-&gt;lock to the IRQ it triggers with fctx-&gt;emit().  But I think patch set 2 is actually better.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

This patch does not directly fix anything, but will make future fence timeout debug a lot easier because:

1. Now for each channel all pushbuf submit happens in the same thread.
2. Use synchronized fence wait instead of async wait where we can set timeout and immediately see the offender of timeout.
|Patch Set 1:

We were using one workqueue per channel, which is basically a thread per channel too. The difference is ioctl_pushbuf_2 could go directly in and try submit pushbuf also, so we could have actually more than one thread per channel doing it before this patch.  On top of that, the asynchronized input_fence wait &amp; callback makes the sequence even messier and hard to track down.

As for the coherency concern itself, yes it is fine to have multiple channels update its own GPFIFO (a.k.a PBFIFO in nouveau) coherently because each channel only writes to its own memory when submitting pushbuf.  GPU host will loop through each channel's instance block to poll for pending work.
|Patch Set 1:

Any other concerns about this one?
|Uploaded patch set 2.
|Patch Set 1:

(8 comments)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review-1
|Patch Set 1:

(1 comment)
|Uploaded patch set 3.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 1: Code-Review-1

Looking at the implementation I think we can not free struct nouveau_fence_chan directly.  What is really allocated is subclass of the struct, e.g. struct nv84_fence_chan in nv84_fence_context_new().  Also fence context is binded to channel.  So when a channel is destroyed, the fence context will go with it IIRC.
|Patch Set 1:

You are right, this is indeed leaking.

This also makes me wonder if the whole refcounting is necessary here.  Looking at nv84_fence_context_del() the context should be as good as dead as soon as the VMA un-mapping.  nouveau_fence_context_free() being a hard free instead of ref_dec would make more sense to me.  If we do it that way, all we need to make sure is no fence is still pending before releasing the context, which should already be guaranteed in nouveau_channel_del() by calling nouveau_channel_idle().
|Patch Set 2: Code-Review+1
|Patch Set 2: -Code-Review

(1 comment)
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1:

henryhsu@chromium.org
|Patch Set 1:

This is a modified version of reverted patch.  It added handling of certain race condition that happens when channel releasing and pushbuf submits are badly timed.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3:

We need that timeout because without timeout it is extremely hard to know which fence is blocking when fence timeout happens.  The timeout is not to cover any issue, but rather to ease the difficult of debugging fence timeout.

There is also other potential problem of the previous async fence wait. For example, we now know fence can out live its channel  according to https://chromium-review.googlesource.com/#/c/305330/.  If such a fence gets signaled, in async approach it will try to execute the callback on an non-existing channel.
|Patch Set 3:

I am not quite following...

Here is the original commit https://chromium-review.googlesource.com/303436.  It already have the timeout and we have a good reason to have it.

That commit was reverted because it caused camera regression.

We still need that commit because the reason it is need is still valid, so I made this modified version that does what the original one does but at the same time does not cause camera regression.

I am not sure what fix are you talking about.
|Patch Set 3:

The timeout is not for &quot;let the fence timeout and if system recovers lets call it a day&quot;.  It was for letting the error log show the correct offender of the timeout so it causes us a lot less time to root cause any fence timeout.
|Patch Set 3:

Any other concern for the -2?
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8:

(1 comment)
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: Verified-1
|Patch Set 11: Verified+1
|Patch Set 11: Commit-Queue+1
|Patch Set 11: -Verified
|Patch Set 11: -Commit-Queue
|Uploaded patch set 12.
|Patch Set 12:

(1 comment)
|Patch Set 12: Verified+1

Tested overnight.
|Patch Set 12:

(1 comment)
|Patch Set 12:

(1 comment)
|Patch Set 12:

(1 comment)
|Uploaded patch set 13.
|Patch Set 13:

It is expected behavior to have push buffers on the same channel serialized and preserve its submit ordering.  If one push buffer blocked on a fence, all sequential push buffers should also be blocked.  In this sense the way old code works is actually incorrect.
The performance downgrade actually comes from not having host(GPU) fence implementation in nouvueau and using client(CPU) fence instead.
|Patch Set 13:

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 13:

(2 comments)
|Patch Set 13:

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 15:

Sorry for the delay.  Thanks Andrew.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4: Verified+1
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Verified+1
|Patch Set 5: Commit-Queue+1
|Patch Set 1:

It is also used by channel error notifier.  However the usage and maintenance of NVIF_NOTIFY_USER bit seems rather fishy to me given there is already ref-counting inside nvif_notify.  I suggest we review nvif_notify implementation in-depth before submitting a fix for this issue.
|Patch Set 1:

There is 3 users of nvif_notify besides fence: display, connector and channel error.  All of them stick to very fundamental usage with nvif_notify_(get/put) can not possibly be called more than once.  None of their worker function would every return NVIF_NOTIFY_DROP either.  The weird NVIF_NOTIFY_USER flag bit seems to be built solely for usage for fence use.   Thus we probably should fix nvif_notify and can do it without affecting other users of the sub-module.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

Reviewing the whole control flow again, I found that fctx-&gt;notify_ref had to be corrupted before return value of callback function corrupts NVIF_NOTIFY_USER bit in nvif_notify_func().  Thus making fctx-&gt;notify_ref atomic should be enough to prevent control flow of either side set off to corrupt NVIF_NOTIFY_USER bit in nvif_notify.
|Patch Set 1:

Please see https://chromium-review.googlesource.com/#/c/306794/
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

Talked to David.  Agreed this is not enough.
|Restored
|Uploaded patch set 3.
|Patch Set 3: Code-Review-1

Still working on this.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6: Code-Review-1
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch stabilize-smaug-7547.B-chromeos-3.18 as commit e9a215af5da819a7691e47d69d06269fa1080bfb
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 2:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Patch Set 5: Verified+1

Passed gles-3.0 and gles-3.1 dEQP tests as regression check.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

Passed gles-3.0 and gles-3.1 dEQP tests as regression check on Patch Set 9.
|Patch Set 9: Verified+1
|Patch Set 9: Commit-Queue+1
|Patch Set 10: Cherry Picked

This patchset was cherry picked to branch stabilize-smaug-7547.B-chromeos-3.18 as commit ba52ae3a25b1099064e7efe4b520ddbfd8957010
|Patch Set 1: Cherry Picked from branch chromeos-3.18.
|Patch Set 1: Verified-1
|Patch Set 1: Verified+1
|Patch Set 1: Cherry Picked from branch chromeos-3.18.
|Patch Set 1: Verified+1
|Patch Set 1:

Hi Andrew,

There is also a critical regression covered by this change: https://code.google.com/p/chrome-os-partner/issues/detail?id=46910

If you have doubt about the stability of this one, please take https://chromium-review.googlesource.com/#/c/308753/ instead.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review-1

input fence is not guaranteed to be a nouveau fence.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

No bug on this.  Found the leak when examining the code for https://code.google.com/p/chrome-os-partner/issues/detail?id=47558
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

Are you testing on chromeos-3.18 tot?  The other 2 patches you mentioned are already merged:

https://chromium-review.googlesource.com/318826
https://chromium-review.googlesource.com/317426
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch set 3: Commit message was updated.
|Patch Set 3:

Tomasz:
Despite being the correct thing, this change only has effect when Time-slice sharing group(TSG) is enabled thus has no effect on A44 or any chrome device in the near future.  I did not realize this initially when doing code for a hard to repro issue.  So I guess it is up to you if you want this in chrome tree.

Alex:
I have it on my &quot;TO UPSTREAM&quot; list :)
|Uploaded patch set 1.
|Patch Set 1:

From what I read bit 15 is unspecified on gf100.
|Abandoned

Agreed this is unnecessary for A44. Will send to upstream tree instead.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 3:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

Moved error handling improvement to https://chromium-review.googlesource.com/319712.  Unified PGD details to the same function so it can be easier maintained in the future.
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 4: Code-Review-1

(1 comment)
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|I didn't put it in an else block thinking oh bufs[0] could also be invalid, but it looks like the bufs[0] != GL_NONE and GL_BACK above already checks for that. Good idea :)
|+1
|I actually had this section before the other statement, then thought it might be better to put it down here so in case we error with the default FBO, it doesnt have to always loop through the color attachments. Also, in the 3.1 specs, it says &quot;An INVALID_OPERATION error is generated if the GL is bound to the default FBO and n is not 1 or bufs is a value other than BACK or NONE&quot;. I read this as if its the default FBO, then in the random case like GL_TRANSFORM_FEEDBACK_BUFFER_BINDING, it would return INVALID_OPERATION bc its not a BACK or NONE. But my interpretation of the specs could be wrong
|Done
|Done
|Done
|Done
|Done
|Done
|If we remove the static here, the BuildSwizzleInfoMap() function will be called multiple times instead of once
|Similar problem as BuildSwizzleInfoMap()
|If this isn't static, the loadFunctionMap inside BuildD3D11LoadFunctionMap will keep adding elements to the elements since we changed it to be a static one inside the function
|Done
|dito about the static variable. Also, the end2end tests hang when the static variable is removed, which makes me think the static map inside the BuildD3D11FormatMap function is adding into the vector each time this function gets called rather than returning what's already there.
|Done
|Done
|Yea sure!
|This will be changed to a static switch soon, but for now sure (:
|Done
|Done
|Done
|Done
|If we make the map static here, and function A and B both call this BuildD3D11FormatMap function, wouldn't the map have duplicate values since the insert pushes things into the vector each time?
|Done
|Done
|Done
|Done
|According to https://chromium.googlesource.com/angle/angle/+/master/doc/ContributingCode.md, it says &quot;If you changed the gyp files other than to add or remove new files, you will also need to update BUILD.gn&quot;. It looks like the BUILD.gn file includes does an include for new files on libGLESv2 so we should be good (:
|Thanks for pointing that out! I changed it to the lambda way (:
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|It looks like the compiler in VS ignores the inline completely. There is also no performance difference between the two, so that sounds like a good idea
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|this actually doesn't need to be virtual. In order to keep 9/11 consistent, stencilSize should be calculated inside of the depthStencil function for both
|messaged
|Done
|Done
|Done
|Done
|I like this alternative and agree with the idea of containing the changes in D3D. It might even be better to keep a copy of the externalDirtyBits in StateManagerD3D instead of the RendererD3D side, so when a call is made to RendererD3D::syncState, it calls StateManagerD3D::syncDirtyBits to sync the externalDirtyBits, then StateManager::syncState uses the internal and externalDirtyBits, then clears externalDirtyBits. That way, we can contain all the state manipulation in the state manager
|Done
|That's a good idea :)! I think it may be better to have mBlendDirtyBits (and others) as a static const that's set with a lambda so as to not set it on every instance similar to:

// header
static const gl::State::DirtyBits mBlendDirtyBits;

// cpp
const gl::State::DirtyBits StateManagerD3D::mBlendDirtyBits = []()
{
    static const gl::State::DirtyBitType dirtyBits[] = {
        gl::State::DIRTY_BIT_BLEND_EQUATIONS, gl::State::DIRTY_BIT_BLEND_FUNCS,
        gl::State::DIRTY_BIT_BLEND_ENABLED,   gl::State::DIRTY_BIT_SAMPLE_ALPHA_TO_COVERAGE_ENABLED,
        gl::State::DIRTY_BIT_DITHER_ENABLED,  gl::State::DIRTY_BIT_COLOR_MASK,
        gl::State::DIRTY_BIT_BLEND_COLOR};

    gl::State::DirtyBits blendDirtyBits;
    for (auto dirtyBit : dirtyBits)
    {
        blendDirtyBits.set(dirtyBit);
    }
    return blendDirtyBits;
}();
|Done
|Done
|Done
|Done
|They diverged in my initial plan but you're right, not here :)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|remote setRasterizerState from renderer
|reset rasterizer local bits
|the dirty bits should already be set from local force bits
|Hm... at this point the only things that will be shared are the mCurXXX variables inside the state manager. On the renderer side, I'll have to see when I start creating the StateManager9. The method signatures will probably be similar (mStateManager-&gt;sync, etc) that could be called from RendererD3D::sync, but will definitely consider :)
|Done
|This has been changed back to mForceSetBlendState because mLocalDirtyBits just for setBlendState does extra work that's not necessarily at the moment. I'll move the local dirty bits back in a future patch when other things are moved in :)
|weird ._. this must be left over from the merge conflict when I was trying to rebase this onto the depth stencil state patch
|the bots would not be happy about this one
|there's already one of these in d3d9, I shall remove this one
|Done
|Done
|Done
|Done
|sort
|Remove, don't need this
|Uncomment this, memory leak uh oh :o
|Yupp, I actually tried this yesterday, but not by passing the 'this' pointer, rather just setting the deviceContext and statecache in after the two have been initialized. It might be better to just keep the device context and statecache inside of renderer and call a renderer11-&gt;getDeviceContext when needed
|Don't need these two
|Done
|Done
|Done
|We may not need the dirty bits to be a parameter until a later patch
|Done
|Done
|dirty bits not needed for now?
|Done
|Nope, this was carried over when D3D9/11 shared the same signature. Will change that :)
|Done
|done in patch 7 :)
|Yupp :) will do that for all of these cls
|Done
|I think this is clearer than forceUpdate because forceUpdate could mean from anywhere but this is specifically if it hasn't been initialized, then we force update
|I could, but it won't be consistent with other functions in this class
|Done
|Done
|Done
|Done
|nullptr :P done :)
|Done
|Done
|Done
|can probably pass in caps instead of data
|we might not need this anymore since we're not using the initialized variable
|we might be able to remove this since we don't need the initialized variable anymore
|I accidentally added the forceSetScissorState. The behavior was correct before, and all the force has now been moved into the setRenderTargetDesc for this part (see Jamie's comments on patch 3)
|Done
|Done
|Nope, nice catch!
|Done
|The viewport bit is already updated below
|:D! great
|Done
|oh I see, wouldn't we need to call mViewportBounds.valid() in applyRenderTarget instead of removing that call all together?... oh I see how Optional works. kay ignore that other comment too
|Done
|Done
|hm.. It may be confusing why a gl::Extents is used for a render target description. I'd rather use something like another struct that only has width and height or just two size_t variables
|For RenderTargetDesc? Is it because we shouldn't use it unless setRenderTargetDesc has been called to set the values?
|Done
|Done
|Done
|Done
|yupp, setRasterizer/blendstate/depthstencilstate can :)
|Done
|Done
|Done
|Done
|We should be able to merge this loop with blend state when more states are in
|Actually, nvm. It's a bit awkward because we can only include either Renderer9 or StateManager9 but not both. 

I originally had it like this: 

StateManager9.h:
class Renderer9;
class StateManager9 { ...Renderer9* mRenderer9... }

StateManager9.cpp:
#include &quot;../StateManager9.h&quot; &lt;--- (-___-)
#include &quot;../Renderer9.h&quot;

Renderer9.h
#include &quot;../StateManager9.h&quot;
class Renderer9 { ... StateManager9 mStateManager ... }

But including StateManager9.h and Renderer9.h inside of StateManager.cpp caused a problem because Renderer9.h also included StateManager9.h.
|There's a circular reference between StateManager9 and Renderer9 :( by-value won't work for this
|Yupp, must have been leftover comments from when I was reminding myself which bits is dirty to call each function
|Done
|Done
|Done
|Done
|no :(, SwapChain9::reset uses it to set some parameters
|The change made a small difference on my machine, not sure if it's big enough to call a performance regression. Done for now
|Done
|Done
|Done
|Done
|Beauty of dirty bits :). These are only called when the DIRTY_BIT_RASTER_CULL_MODE bit is dirty in D3D9. That bit is dirtied in sync state, where the check happens
|see answer from above
|Done
|Done
|Done
|I think we should keep it consistent (raster also has two) so it's easier to read / follow. Another option is to get rid of the mRasterizerStateDirtyBits too
|Done
|Done
|Done
|Done
|I don't think it's that significant since it should've been removed when we did one of the refactors
|Uploaded patch set 1.
|Patch Set 1:

Please take a look :) thanks!
|Patch Set 1: Verified+1
|Patch Set 1: Tryjob-Request+1

!tryjob
|Patch Set 1: -Verified -Tryjob-Request

@Shannon, yea sure I can do that with a separate CL. There also seems to be a bunch of places with same errors but no error messages -- I might as well add those too :)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Tryjob-Request+1

!tryjob
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Tryjob-Request+1

Please take a look, thanks! :)
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Tryjob-Request+1

I moved it to a helper function. There's a ValidProgram helper function that doesn't seem to get used everywhere. It may be a good idea to replace some of the repetitive program object code with that function too in a different CL maybe?
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Tryjob-Request+1

Updated with Mo's suggestions :)
|Uploaded patch set 4.
|Patch Set 4: Verified+1 Tryjob-Request+1

Moved the comments to the .h file :)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Please take a look, thanks! :)
|Patch Set 2: Verified+1 Tryjob-Request+1

!tryjob
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Tryjob-Request+1

(2 comments)

!tryjob
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified+1 Tryjob-Request+1

(1 comment)

I changed it back to the first patch while returning an INVALID_OPERATION. When we're ready to switch to ES3.1, we just need to update the GL_INVALID_OPERATION to be GL_INVALID_ENUM in the invalid enum check :)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4:

Oh, I was waiting for my empty tryjob to run so I can compare the errors in case I broke something, but I'll keep a watch on the build then (:
|Uploaded patch set 1.
|Patch Set 1: Tryjob-Request+1

!tryjob
|Abandoned

no longer needed
|Uploaded patch set 1.
|Patch Set 1: Tryjob-Request+1

Didn't want the cls to be large, so I'm doing it one at a time. This is just a re-org of the code so I can generate switch statements from JSON later. Please take a look, thanks!
|Uploaded patch set 2.
|Patch Set 2: Tryjob-Request+1

(12 comments)

Uploaded another patch with Mo's suggestions. Please take a look (:
|Patch Set 2:

!tryjob request
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Tryjob-Request+1

(13 comments)

Fixed up some changes that Jamie and Mo suggested, leaving the static keyword on there for now. Please take a look again :) 

!tryjob
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Tryjob-Request+1

Made some merging conflict with master changes and header changes (should probably push land this before more merge conflicts come into play)

!tryjob
|Patch Set 6: -Tryjob-Request

Please take a look again :) thanks!
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Tryjob-Request+1

!tryjob
|Patch Set 4:

Please take a look, thanks! :)
|Uploaded patch set 5.
|Patch Set 5: Verified+1

(9 comments)

Uploaded changes with Jamie's suggestions. I left out making duplicated tables for each FL in texture_format_table.cpp for now until we decide it's a good way to go. Please take a look, thanks! :)
|Uploaded patch set 6.
|Patch Set 6: Verified+1

Updated with suggestions from Geoff and Mo, please take a look again, thanks!
|Uploaded patch set 7.
|Patch Set 7: Tryjob-Request+1

(1 comment)

!tryjob

Tried to reproduce the test failure locally but no luck, kicking off another one just in case.
|Patch Set 7: -Tryjob-Request

I managed to reproduce the error locally (debug derp), taking a look now :)
|Uploaded patch set 8.
|Patch Set 8: Tryjob-Request+1

!tryjob

Uploaded a patch to try and fix failures on trybots. Going to kick 
off another one to check
|Uploaded patch set 9.
|Patch Set 9: Tryjob-Request+1

!tryjob

Fixing failures
|Uploaded patch set 10.
|Patch Set 10: Verified+1 Tryjob-Request+1

Rebased and moved changes from commit de6144f1efc79298e

!tryjob
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Verified+1

Please take a look, thanks!
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified+1

(11 comments)

Please take a look! Thanks :)

I Updated patch with Jamie's suggestions, rebased, and fixed a few merge conflicts. We decided to use D3D11 / D3D9 dirty bits for iterating through local bits instead of having GL local dirty bits. I feel like that should be in a separate cl so this one doesn't get too large. Hence, this patch still has the bit testing instead of the loop for local and dirty bits.
|Uploaded patch set 10.
|Patch Set 10: Verified+1 Tryjob-Request+1

(7 comments)

Updated with Jamie's suggestions and trying to fix test failures. Kicking off another tryjob

!tryjob
|Uploaded patch set 11.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Patch Set 12: Tryjob-Request+1

!tryjob
|Uploaded patch set 13.
|Patch Set 13: Tryjob-Request+1

!tryjob
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15: Tryjob-Request+1

(1 comment)

Made some changes based on Jamie's suggestions and rebased. 

!tryjob
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18: Patch Set 17 was rebased.
|Uploaded patch set 19.
|Patch Set 19: Tryjob-Request+1

(15 comments)

!tryjob
kicking off another try
|Patch Set 7: Tryjob-Request+1

!tryjob

Kicking off another tryjob for Hendrik
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Tryjob-Request+1

!tryjob
|Uploaded patch set 3.
|Patch Set 3: Verified+1

Please take a look, thanks! :)
|Uploaded patch set 4.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Tryjob-Request+1

(3 comments)

!tryjob
|Patch Set 2:

!tryjob {&quot;builderNames&quot;: [&quot;win_angle_dbg_ng&quot;, &quot;win_angle_x64_rel_ng&quot;, &quot;linux_angle_rel_ng&quot;, &quot;win_angle_x64_dbg_ng&quot;]}
|Patch Set 2: -Tryjob-Request

Please take a look, thanks! :)
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch set 5: Commit message was updated.
|Patch Set 5: Verified+1 Tryjob-Request+1

!tryjob
Patch 3 and 4 has the diff between what was before and after the fix. Patch 1 and 2 had the rebase difference, so it was hard to tell the fix from the change.
|Uploaded patch set 6.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)

In the previous fix, there was a performance regression that seemed to be a spread out issue rather than a specific hot spot. I decided it was probably best to split all these changes into small chunks and optimize each section. This is only optimizing D3D11 blend state. Please take a look :) Thanks!
|Patch Set 2: Tryjob-Request+1

!tryjob
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)

Just added a comment, please take a look again, thanks :)
|Uploaded patch set 4.
|Patch Set 4: Tryjob-Request+1

!tryjob {&quot;builderNames&quot;: [&quot;linux_angle_rel_ng&quot;, &quot;linux_angle_dbg_ng&quot;]}
|Uploaded patch set 5.
|Patch Set 5: Tryjob-Request+1

Rebased and added a cleanup for external dirty bits. 
!tryjob
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1

(13 comments)

Added a new version of dirty bit for blend state that's better for performance (issue and more details can be found https://docs.google.com/document/d/1TV0MAIrLyQXJQSrj8LR4kgLbSB2HKjBsUTnmN1-dMgU/edit). Please take a look :) Thanks!
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(3 comments)

Reverting merge conflict add-ons from a rebase
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12: Patch Set 11 was rebased.
|Patch Set 12: Tryjob-Request+1

(3 comments)

!tryjob
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 13: Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Tryjob-Request+1

(6 comments)

oh mighty bots be happy!
!tryjob
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 8:

!tryjob {&quot;builderNames&quot;: [&quot;win_angle_dbg_ng&quot;, &quot;win_angle_x64_dbg_ng&quot;]}
|Uploaded patch set 9.
|Patch Set 9: Verified+1

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Tryjob-Request+1

(5 comments)

Trybots be happy!
!tryjob
|Uploaded patch set 8.
|Patch Set 8:

Ignore patch 8, uploading another one to revert it. Weird merging from rebasing in scissorstate patch
|Uploaded patch set 9.
|Patch Set 9: Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Tryjob-Request+1

(2 comments)

!tryjob
|Patch Set 7: -Tryjob-Request

Please take a look, thanks! :)
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Patch Set 10:

heh yea, rebased :)
|Uploaded patch set 11.
|Patch Set 11: Tryjob-Request+1

(1 comment)

!tryjob
test bots be happy!
|Uploaded patch set 12.
|Patch Set 12: Verified+1
|Patch Set 1:

Yupp I can do that :)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Tryjob-Request+1

(4 comments)

!tryjob
|Patch Set 4:

(8 comments)

other point of order, the scissor state patch wants to go in first :P
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Tryjob-Request+1

(4 comments)

!tryjob
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(5 comments)

!tryjob
|Patch Set 3: Tryjob-Request+1

!tryjob
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: -Tryjob-Request

The rebase must have erased the edit, will fix!
|Uploaded patch set 6.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8: Commit message was updated.
|Patch Set 8: Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Tryjob-Request+1

!tryjob
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 5: Tryjob-Request+1

(1 comment)

!tryjob {&quot;builderNames&quot;: [&quot;win_angle_x64_rel_ng&quot;, &quot;win_angle_x64_dbg_ng&quot;]}
|Uploaded patch set 6.
|Patch Set 6: Tryjob-Request+1

(4 comments)

Rebased and..
!tryjob
|Patch Set 6: Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Tryjob-Request+1

!tryjob
|Uploaded patch set 2.
|Patch Set 2: Tryjob-Request+1

!tryjob

With dirty bit changes this time
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(11 comments)

Please take a look again, thanks! :)
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12: Tryjob-Request+1

(2 comments)

!tryjob
|Patch Set 12: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Tryjob-Request+1

(5 comments)

!tryjob
|Uploaded patch set 8.
|Patch Set 8: Tryjob-Request+1

!tryjob
|Uploaded patch set 9: Patch Set 8 was rebased.
|Patch Set 9:

!tryjob 
one last one with rebase!
|Uploaded patch set 10.
|Patch Set 10: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Tryjob-Request+1

!tryjob
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 3:

(1 comment)

Kay changed :) Let me know about that one comment and we should be good to go!
|Uploaded patch set 5.
|Patch Set 5: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Tryjob-Request+1

!tryjob
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Tryjob-Request+1

(4 comments)

!tryjob
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(1 comment)

Rebased, hitting the big red button time? :)
|Patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Tryjob-Request+1

!tryjob {&quot;builderNames&quot;: [&quot;win_angle_x64_rel_ng&quot;, &quot;win_angle_x64_dbg_ng&quot;]}
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 2: Published edit on patch set 1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 2: Published edit on patch set 1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R42-6812.B as commit a65eaf6a76a4b69840f3773acb48aab3f63fab7d
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R43-6946.B as commit 479dcb1c49ff01e99812a94427d13347e42ecbfb
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch firmware-gnawty-5216.239.B as commit c60c411a787972f9cf1984d808990eb3f4087cdb
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch firmware-gnawty-5216.239.B as commit 67c2bb4ea95a36faae8daa0548fc5076e17849d0
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 3: Published edit on patch set 2
|Patch Set 3: Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch firmware-gnawty-5216.239.B as commit 4700edef1726a7873aa5d89fb01dbc95cfa50c73
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 2: Published edit on patch set 1
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R42-6812.B as commit a010a4daf575888ea5ecf217f78bc6d300fa4f4e
|Patch Set 1: Verified+1
|Patch Set 2:

Hi Bernie,

Could you help add [cbuildbot_config: add banjo builders] to firmware-rambi-5216.B.
Thank you.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

It is on purpose that the fan can't run more than 5000rpm ( about duty 87%).
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1

According to our thermal team reply, when this fan spin about 3500rpm (about duty = 57%), that acoustic noise value is just 24 dB. Thus they want to set this table.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Uploaded patch set 3.
|Patch Set 4: Published edit on patch set 3
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch firmware-rambi-5216.B.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch firmware-rambi-5216.B.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Cherry Picked from branch firmware-rambi-5216.B.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Abandoned

Have the latest volume curve and upload another CL.
|Uploaded patch set 1.
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 9dac7f1574b33146edb03aa8455a7937268abe42
|Patch Set 1: Cherry Picked

This patchset was cherry picked to branch release-R45-7262.B as commit f612a6bceb2fc256c26907b2f330366ad271c063
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1
|Patch Set 2: Verified+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 291d073c4dcf51377f76a14f5031f2c0238a5a14
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch release-R45-7262.B as commit 9166935ae0be7b644072dc835f44dfbe5a628c8d
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Patch Set 2: Patch Set 1 was rebased
|Abandoned

Have the latest volume curve and upload another CL.
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Abandoned
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Abandoned
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 9be4887edd6047360a8f4fecd7fe3818605ce69f
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R45-7262.B as commit 0aa872212d857eac880a1be350272b8a37620209
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1
|Abandoned

Abandon
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1
|Abandoned

Abandon
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

@YueChen
I agree that the luma tx size is 8x8 in supertx mode, however the failing test occurs when using 4:2:2 chroma subsampling. The chroma tx size is 4x4 but as far as we understand there are 2 blocks that need to be tokenized.  Using the EndToEnd test the original code works fine in 4:2:0 or 4:4:4, but fails in 4:2:2 and 4:4:0.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 6.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 15.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Uploaded patch set 25.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Currently I am exporting the FTPClient and hence all the methods tied up to the FTPClient are being exported, some of them not intended to be public. However the methods not tied up to the FTPClient remain private. One other options that I have been considering is writing all the FTPClient methods as their own functions, not as prototypes of the FTPClient. This way we could export only the methods/functions that we want to make public. This design choice would require though to keep track of a global object that contains properties which currently are bound to the FTPClient (such as commandPort, commandId, pendingReads and so on). I am not sure if this would be a better design choice than the current one. Would appreciate your feedback.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The idea was that the TCP keep-alive functionality would keep the connection alive in idle conditions. This would then not require us the explicitly send NOOPs to the server.
|Done
|Done
|Done
|Done
|The errors have now been defined within this file. The error codes are listed here : http://src.chromium.org/svn/trunk/src/net/base/net_error_list.h
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This was reset to the IP address since a DNS name could be associated with more than one IP address and just wanted to make sure that both the command connection and data connection were connected to the same IP address. But it doesn't seem that this will posses any problem even if we keep the host as the DNS name.
|Because sometimes the server sends a response that does not contain a valid host, i.e (0,0,0,0,port, port) and since we have already stored the host name when we first initiated the command connection we can just use that address.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Currently (the CL uploaded in the next patch set) a promise is rejected if the reply that the server sends does not adhere to the FTP protocol. The promise is also rejected if the reply sent by the server indicates an error (400-500 reply code) because the action should not proceed further. I think many of the errors will require us to notify the user such as failure to login or failure to download/upload the requested files. Error handling is not yet fully implemented but currently I am thinking that the FTP library will only indicate the error that it encountered and potentially close the connection when necessary while the FTP session and the high level functions such as download, upload, listDirectory, rename, delete will handle the error.
|Done
|Done
|I am not throwing an exception here because getReplyCode is called for each line of the multiline reply to check for a matching reply code with the first line's reply code. However the lines in between the first and the last line of the multiline reply do not necessary have a valid reply code. Once I have actually gotten the full response I check it to see that it contains a valid reply code. That's when I actually throw an error if an invalid reply code is encountered.
|There are two connections established and both socketId-s are stored. hence one is saved as the commandId and the other as the dataId.
|Done
|Done
|Done
|Once the call to socketType.create(...) is made the promise is returned and it is only resolved once the onCreateComplete(...) function is called. So createSocket_().then(...) will then parallel a synchronous behavior for creating a socket.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The parsing for unix has been changed to become more robust. This implementation assumed that the entry name always occurred at the 56th character, but we have seen that it is not the case.The new parsing function will reflect that.
|Done
|since handleDownload is just an event listener for the download button, it will be called anytime the user clicks on the button, which might include cases when they haven't selected anything from the local or remote side. Maybe the name of the function is misleading and should be named handleDownloadButton()
|Done
|Done
|Done
|Done
|Done
|Done
|I ended up squashing the subsequent 2 CL into this one and abandoned them.
|I was thinking of moving this code and all the functions related to files (writing, saving to) into its own library as we reorganize the code and pull it out of the prototype. Would that be fine or would you prefer that we move this out of the FTPLibrary now?
|After measuring download time for a couple of files, 5 was the optimal value that minimized the time to download files.
|Done
|Done
|It is not needed anymore. We needed it earlier when we were debugging. It has now been removed.
|:)
|Left accidentally
|Done
|Done
|Done
|In the later version when I moved code out of the Prototype, I put it under the FTPReplyParser Class.
|Done
|Done
|Done
|Yes, this file is one of Errol's CL. I think it ended up here once we brought together the front-end and back-end. Is there something we should change?
|Done
|Done
|Done
|The format only includes hours and minutes
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The workingWriters keeps track of the writers that we have created and are currently being used. The part of the code in FTPLibrary makes sure that we never create more that max number of writers.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I did configure it to show trailing spaces. I think though it doesn't show trailing spaces for blocks of comments. I did try to remove trailing spaces for comments manually.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(45 comments)

getReply has undergone the most changes. It is updated to handle different scenarios of how the lines constituting an FTP reply could be split up. Test function for getReply and its helper functions have also been written.
SendCMD and login have also been updated. Unit testing for these two function has not been written yet.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Abandoned
|Restored
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 3:

(51 comments)
|Patch Set 8:

(5 comments)

fixed all of the issues. We'll upload the new CL with the reflected changes on Monday as well as the CL for dir-navigation which will have front-end and back-end integrated.
|Uploaded patch set 1.
|Abandoned

squashed into parent
|Restored
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Restored
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Restored
|Abandoned
|Restored
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Restored
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

This is the dir-navigation feature which brough together the front-end and the back-end. There is very little code related to download, please ignore it! This code has remained from before we branched off to create dir-navigation as a separate feature!
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(13 comments)

Issues fixed!
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(21 comments)
|Patch Set 1:

(6 comments)
|Patch Set 2:

(3 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 5:

(4 comments)
|Uploaded patch set 8.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(2 comments)
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(8 comments)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(1 comment)

Changed the lineBuffer class to parse lines and store them in an array, while also storing the data that does not form a line into a buffer.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Patch Set 4:

(3 comments)
|Uploaded patch set 9.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

(25 comments)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Make it short as the reboot_counts=3 will make it run under 5 minutes
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(5 comments)
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

Ran the test against chromeos2-row1-rack11-host11 and it passed. The test last less than 4 minutes.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1

modified the main test code and control file. add control.stress file.
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Abandoned

new cl created so need to get rid of this one.
|Uploaded patch set 1.
|Abandoned

will re-upload a different commit
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(11 comments)
|Uploaded patch set 3.
|Patch Set 3:

(7 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Abandoned

re-creating the cl
|Uploaded patch set 1.
|Abandoned

re-uploaded a new cl
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

will recheck
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

(10 comments)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(4 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(8 comments)
|Uploaded patch set 4.
|Patch Set 2:

(3 comments)
|Patch Set 2:

(5 comments)
|Uploaded patch set 5.
|Patch Set 2:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 2:

(3 comments)
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Commit message was updated.
|Since Django is searching minijack.settings when starting local server, if I don't change this name, the local server would fail to start with &quot;ImportError: Could not import settings 'minijack.settings' (Is it on sys.path?): No module named settings&quot;

Is there better name suggested?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|But since we're reexecuting SQL query everytime here, calling GetOne() multiple times would not get all result even without &quot;LIMIT 1&quot;, but always the first one.
|Done
|Done
|The return value from BigQuery is unicode, so IsValid needs to add that, but it seems that we don't need to use unicode here. Reverted to str.
|Done
|Done
|Done
|Done
|Currently I'm using pageToken to achieve this. I think the point to have a FetchOne when we already have FetchAll is that when we probably doesn't need all result, we can rely on the database without fetching all results into memory. We probably should get more than one (maybe 100) a time and cache them.
|Should we really align these? Style guide said that we shouldn't align these (http://google-styleguide.googlecode.com/svn/trunk/pyguide.html#Whitespace).
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Rebased
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Rebased
|Uploaded patch set 7.
|Patch Set 7: Rebased
|Patch Set 8: Ready; Verified


|Patch Set 1: Rebased
|Patch Set 2: Ready; Verified


|Patch Set 1: Rebased
|Uploaded patch set 3.
|Patch Set 3: Rebased
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12: Ready; Verified


|Patch Set 1: Rebased
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved; Ready; Verified

fix conflict.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

fix conflict.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, approved; Ready; Verified

fix conflict.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Rebased
|Uploaded patch set 9.
|Patch Set 9: Rebased
|Uploaded patch set 11.
|Patch Set 11: Rebased
|Patch Set 12: Ready; Verified


|Patch Set 12: Ready


|Patch Set 12: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 3: Ready


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 95c291bf941f1d558e4ea778b82d838f5848c414
|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Patch Set 1: Abandoned
|Patch Set 1: Ready; Verified


|Change has been successfully cherry-picked as 9807ef242a09541f8f8bf142ff369a3c65e83600
|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Patch Set 2: Rebased
|Uploaded patch set 4.
|Patch Set 4: Rebased
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 5: Ready


|Uploaded patch set 2.
|Patch Set 2: (17 inline comments)


|Patch Set 2: Rebased
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Rebased
|Uploaded patch set 7.
|Patch Set 7: Ready; Verified


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Looks good to me, approved; Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 6: (1 inline comment)


|Patch Set 6: (1 inline comment)


|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Commit-Queue+1 Verified+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 7.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Patch Set 7: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Done. Make sense. Change it to a static function.
|Agree.
|Remove this. See comment at line 325.
|Done
|Done
|Done
|separate this to another commit CL:287419
|Patch Set 2:

(6 comments)
|Patch Set 1:

(1 comment)
|In cros, the internal display determination rule is the name prefixed by {LVDS, eDP, DSI}
|now I can not reproduce this error, so written this.
|Done
|Done
|Done
|Done
|Done
|Once it calls cleanup(), and restore_edid() can not be called.
I will call unplug() before restore_edid() instead.
|OK
|Done
|Done
|Done
|I think I should modify this file recently. I want to fix this with some other function add. is it OK?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|indent 4 tabs.
|A space here.
|indent 4 tabs.
|i_max
|indent 4 tabs.
|indent 4 spaces.
|indent 4 spaces.
|space here.
|need align.
|need align.
|need align.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|indent 4 tabs.
|4 space here?
|space after?
|check if path is none?
|typeof?
|The actual behavior of the code should be (H-&gt;L-&gt;H-&gt;L-&gt;...-&gt;H-&gt;L), not this. However, the program was originally written, so I do not know whether it is appropriate to rewrite.
|ok~
|in next patch
|Done
|Done
|Done
|Yes, I means EL. I will modify it.
|Done
|OK!
|Done
|Done
|Done
|Done
|in next patch
|in next patch
|It will lead to a more &quot;usleep(assert_usec);&quot;.
|Done
|Done
|same above
|Done
|same above
|Done
|ok
|I will re-structure this function, since there is different meaning for low / high level between hdmi and tio version. Just use end_status for plug / unplug more clearly.
|ignore this.
|Done
|Done
|Done
|Done
|Done
|oops, It was a stupid mistake
|Here seems less a line of &quot;return message&quot;, and I want to fix this in my patch CL:210151.
|for Test: display_Tearing, I want to add a arg &quot;test_image&quot;, default: calibration image, but it can also to load a white or a black image. (svn or png)
|CL:202105 has been Code-Review+2. Is it appropriate to add an additional test the consistency between internal/external frame buffer for mirror mode?
|Sorry for I overlook this. Variables &quot;error&quot; can not be reused.
|I think use &quot;if error_list is not None:&quot; is more long but standard?
|I think under normal case will not wait up to 16 seconds, so I think it is okay? Or I can modify that to 5s if I do more experiments and confirmed it is enough.
|Done
|Done
|It seems very reasonable and useful, thanks.
|Sorry, I misunderstood it
|I mean do not worry calling apply_edid will lead backup error
|OK, I will not include this modification in the final checkin of this commit.
|Done
|Is it mean (expected_connector, connector_name)?
it is appropriate for pack them into a Tuple?
|Done
|Done
|OK, I will not include this modification in the final checkin of this commit.
|OK, I will not include this modification in the final checkin of this commit.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think the two variable resolution and resolutions is similar, Can I use resolution_list instead resolutions?
|about &quot;if not self.set_resolution(...):&quot;, It is conflict by our discuss, so can I ignore it?
|Done
|Done
|Done
|maybe we don't care the actual resolution in some testcase?
|if the test havn't call set_mirror_mode() function, It may cause some unexpected error?
|I think original message is still exists.
|meaning return immediately if there is any error?
|Done
|In CL:209835, there is no return message. so I want to confirm again it is not because there are other reasons?
|Will it lead to a down compatibility affect?
|Sorry, there is also a stupid bug. I will fix this in next patch.
|s/sleep_time/delay_time ?
|set sleep_time to 0 if don't want to delay.
|suspend_duration = sum(delay for _,delay in action_list)
|No need to return
|I want to extract this to superclass by similar way if the way is OK.
|Extract this to superclass?
|TODO: add noise during reboot / suspend_resume ?
|need updated in next patch
|need updated in next patch
|need updated in next patch
|need updated in next patch
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Not in this CL.
|I think this determine is really more related to the behavior of client, not testcase of Chameleon. Placed there seems good.
And another idea: We can return the tuple: ((originalWidth, originalHeight), (width, height)) for M38 or ((width, height), (width, height)) for M37 in display_client method for future use. (but maybe not in this CL)
|Sorry, my mistake. I think saying &quot;Issue 417113012 in Chromium Code Reviews&quot; is better.
|indent 4 spaces here.
|list here.
|list
|I think the meaning of this is a little confusion with line 29.
|multimedia_xmlrpc_server
|Is this a private method?
|@return
|Are test flows of testcase other than &quot;unplug -&gt; switch edid -&gt; plug&quot; ?
|I think it is not &quot;pulse width&quot;. Only odd-numbered values is the assert time, and which is &quot;pulse width&quot;. If my understanding is wrong, please ignore this comment.
|1. Why do you want to force the end level to LOW?
2. If you really need to do this, I recommend that described in the comment above.
|Add: at least %d parameters, but detected %d.
|argc - optind
|Should use W[0] W[1] ... to match the below descriptions.
|A miner question: Are there tabs need to close?
|If it is no needed, remove it?
|Notice that it is duplicate with Line 210.
|Here
|(?
|space here
|FYI. https://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Line_length#Line_length
|Can use tab.WaitForJavaScriptExpression(..., timeout)
|Minor: Beyond 80 characters.
(as https://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Line_length#Line_length)
|Minor: Is it typo?
|Do you want to move it outside? Or you can move it to the top before other instructions.
|What if 
preprocess_color_set = set(color_sequence + [self.COLOR_BLANK])
|I think no need to check this.
|In fact, color_set is unique.
|Same here.
|Extract it to a function?
|See https://chromium-review.googlesource.com/#/c/281141/
|What if converting checksums to tuples here?
|Oh ok!
|No space here.
|space
|space around '-'
|Maybe
logging.info(&quot;XDDDD\n&quot;
             &quot;QAQQQ&quot;)
https://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Strings#Strings
|error_list?
|8 blanks.
|INITIAL?
and should test it works well if you set it to other color?
|any ?
|8 spaces
|Is it trivial?
|Addtional () ?
|s/ is/s are/
|Should updated.
|Do you want to use:
captured_color_sequence[:1] == [self.DEFAULT_BACKGROUND_COLOR]
|after sleep?
|use try: ... finally: ?
|if not ... ?
|ditto
|ditto?
|Done
|Why do you put this here instead of Line 126?
|Why put this here?
|Need floating conversion?
|Too long~
|Sorry, Maybe:
if error is not None and error_list is not None:
    error_list.append(error)
return error
|There is a trailing space.
|Forget to change
|Forget to change
|When you will need to use the default value of color_sequence? Is there a default color sequence?
|Unused.
|Really? Seems not used it.
|No this param.
|How about omit it?
|same
|same
|same
|As the past comment in #10,
Should return error here.
(see the docstring above.)
|Perhaps this is my mistake in the past @@. Ask senior members which is better can be considered.
|You can use (
'        \n'
'        \n'
...)
|How about len(color_sequence) * a const ?
|Well, I think according to the original is better, sorry!
|Maybe it should:
...
else:
    error_list.append(error)
    if count == 0:
        return error_list
    else:
        logging.info('Retry tearing test again...')
|Although I wrote in the previous comment that there should be 8 blanks, I'm not entirely sure here. In fact, below link #1 holds 4 blanks, but CODING_STYLE (link #2) and past commit (link #3) seems to use 8 blanks.
#1: https://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Indentation#Indentation
#2: https://chromium.googlesource.com/chromiumos/third_party/autotest/+/master/CODING_STYLE
#3: https://chromium.googlesource.com/chromiumos/third_party/autotest/+/master/client/cros/chameleon/chameleon_port_finder.py
|What if ... ?
self._load_url(url)
return True
|s/REFRASH/REFRESH/ ?
|Really? I think not in _load_color_sequence_tab.
|extra space?
|like other files:
@param chameleon_port: A general ChameleonPort object.
|as above line,
captured_checksums, timestamp_list = self._display_and_capture(
        test_mirrored, chameleon_port, color_sequence)
|Do you want to add some comments here? (e.g. refer to chameleon_screen_test.unload_test_image)
|What if: (since you didn't use except statement.)
        try:
            chameleon_port.start_capturing_video()
            timestamp_list = (
                self._display_facade.load_color_sequence(color_sequence))
        finally:
            chameleon_port.stop_capturing_video()
        time.sleep(self.CHAMELEON_CAPTURE_WAIT_TIME_SEC)
        captured_checksums = (
                    chameleon_port.get_captured_checksums(0))
        captured_checksums = [tuple(x) for x in captured_checksums]
        return (captured_checksums, timestamp_list)

or you can also write a function to support this action? (Maybe too redundant):
def capturing_video(self):
    try:
        chameleon_port.start_capturing_video()
        raise
    finally:
        chameleon_port.stop_capturing_video()
here:
        with self.capturing_video():
            timestamp_list = (
                self._display_facade.load_color_sequence(color_sequence))
            ......blabla
|There are some wrong in the second half and too complex, please ignore it.
|Really need to comment here?
|add prefix _ ?
|FYI. I refer to this: https://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Naming#Naming
|OK.
|What if raise a TestFail if given_color_sequence has successive repeated colors. (since we can't detect it.)
|s/can/can't/
|We can call self._reset_background_color() here also. Then user shouldn't sets DEFAULT_BACKGROUND_COLOR to the same as first in color_sequence. (ditto, we can detect it for real)  (i.e. if Line 165 is true, raise it?)
|Too long?
|It is ok in one line.
|And 8 spaces indent?
|typo
|ok XD
|It should be ok using
self.display_facade = local_facade_factory.LocalFacadeFactory(
        cr).create_display_facade()
|and rename
|Too long?
|In fact, the external screen have the same origin as the internal one in mirroring mode, so it should no action in this case. We can also just check its mirroringSourceId in move_to_external_display() or by is_mirrored_enabled() here. Is it necessary or suitable to check it here with a addtional argument?
|display
|ditto
|ditto
|display
|ditto
|enabled
|ditto
|Need a line break?
|display?
|ditto
|display
|Why do this?
|I think &quot;False in [0]&quot; in python2 is True since implicit conversion?
|get_display_info?
|What if
display_index &gt;= len(display_info)
|ok. Alas, It is ok to use xrange(len(display_info)).
|What if finds the bounds of external display directly?
|ditto
|Extra space?
|Space here.
|Semicolon and space here.
|The term toggle implies that there are only two possible settings and that you are switching from the current setting to the other setting. Maybe it is correct to this implementation as usual.
|This feature is verified in WindowsUpdateFunction of chrome/browser/extensions/api/tabs/tabs_api.cc
Note that the method must be called on normal window state.
|The size will be checked in ash/wm/default_state.cc (SetBoundsDirect) , as it will at least (min_width, min_height) in last step, so i think sets to 0 is ok. (But may not need here)
And I noticed that (but not necessarily correct) in chrome/browser/ui/window_sizer/window_sizer.cc, it will check whether (bounds-&gt;IsEmpty()) or not (i.e. the area of window is zero). If it isn't, it will use LastActiveWindowBounds, SavedWindowBounds successively, and fail back to DefaultWindowBounds.
Alas, In chrome/browser/extensions/api/tabs/tabs_api.cc, It looks like that it will no action during not normal window state. (maybe you can recheck it and indicate this in docstring?)
|It is better to check whether the new state of the window is correct.
|What if uses extension.WaitForJavaScriptExpression instead of utils.wait_for_value in this code if you wait a JavaScript expression actually? (maybe in another change)
|Maybe similar to Yuli?
Chameleon: Use Telemetry ChromeOS Autotest Extension for display tests.
|No this method in patch set #3.
|What if uses
if not info['isInternal']:
|is.
(see https://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=True/False_evaluations#True/False_evaluations)
|I think it should be similar to
target_position = (info['bounds']['left'],
                   info['bounds']['top'])
|ditto
|ditto
|Is the magic number really needed?
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 6: Published edit on patch set 5
|Patch Set 6: Verified+1
|Patch Set 7: Verified+1
|Patch Set 5:

(1 comment)
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(10 comments)

Thanks to detailed review.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14: Patch Set 13 was rebased.
|Uploaded patch set 15.
|Uploaded patch set 16: Commit message was updated.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Patch Set 17: Verified+1
|Uploaded patch set 18.
|Patch Set 18: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15: Commit message was updated.
|Patch Set 15: Verified+1
|Uploaded patch set 16.
|Patch Set 16: Commit-Queue+1 Verified+1
|Patch Set 17:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Verified+1
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 9:

(7 comments)
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 17: Commit-Queue+1 Verified+1
|Patch Set 16:

(25 comments)

A lot of minor style fixes.
|Patch Set 19:

(4 comments)

only FYI~
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(4 comments)
|Uploaded patch set 3.
|Patch Set 3: Code-Review-1

Working temp
|Patch Set 3:

don't need to review this
|Patch Set 2:

(11 comments)
|Uploaded patch set 4.
|Patch Set 4:

(14 comments)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12: Commit-Queue+1 Verified+1
|Patch Set 12:

need to Verifiy the resolution
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Code-Review-1

(8 comments)
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Patch Set 10: Verified-1

still working for other site_tests
|Uploaded patch set 11.
|Patch Set 11: Verified-1

I think it may need more verifies.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14:

(24 comments)
|Patch Set 14:

(2 comments)
|Uploaded patch set 15.
|Patch Set 15: Verified-1

Need to split into two commit.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 18:

(1 comment)
|Uploaded patch set 19.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Patch Set 21:

(1 comment)
|Uploaded patch set 22.
|Uploaded patch set 23.
|Patch Set 23: Verified+1
|Patch Set 23: Commit-Queue+1
|Patch Set 24:

(1 comment)
|Patch Set 24:

(1 comment)
|Patch Set 18:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(4 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10: Commit message was updated.
|Patch Set 10: Commit-Queue+1 Verified+1
|Patch Set 11: Patch Set 10 was rebased
|Patch Set 11: Commit-Queue+1 Verified+1
|Patch Set 11: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: Commit-Queue+1
|Patch Set 12:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Abandoned
|Patch Set 1: Code-Review+1
|Patch Set 1:

Is it possible to change the default margin from 0 to 1 only if detects self._unlevel_func is not None?
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 8: Commit message was updated
|Uploaded patch set 9.
|Patch Set 10: Commit message was updated
|Patch Set 10: Commit-Queue+1 Verified+1
|Patch Set 11: Commit message was updated
|Patch Set 11: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Patch Set 3: Commit message was updated
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3:

Hi Tom: CL:211991 has not merged. Can I submit this CL to Commit-Queue first?
|Patch Set 4: Commit message was updated
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue
|Patch Set 4:

CL:211180 is merged.
|Patch Set 4:

Sorry, I misspelled. I means CL:211800 is merged.
|Patch Set 5: Commit message was updated
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2:

(7 comments)

OK, I will modify tomorrow.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified-1
|Uploaded patch set 2.
|Patch Set 2: Verified+1

I fixed some problems, but still can not find the root cause. So bypass it first.
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 4: Commit message was updated
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4:

Note that on non-hardware mirrored devices, It will not pass.
|Patch Set 4:

I think we can check the resolution between internal display and external display. If it is match, compare the screen.
|Patch Set 4:

If we split mirrorMode test into separate test case, will lead to a lot of extra case. I tend to modify existing superclass, if detected the same internal and external resolution and in mirrorMode, the screen between two should have both the same. Otherwise, it is in software mirror mode, we can just pass the test until we can compare whether two screen with different resolution are same. I can use the CL with a minor patch, and will not break the existing tests.
|Patch Set 4:

After the modification uploaded tomorrow, can you help me to test its behavior on TV level device?
|Uploaded patch set 5.
|Patch Set 5:

Only verified on peppy. I will verify on other devices next Monday.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Only verified on peppy. I will verify on other devices next Monday.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Verified+1

Tested OK on peppy and pit.
for Big: It will fail on some EDID, But seems not related to this CL.
|Uploaded patch set 10.
|Patch Set 10: Verified+1
|Uploaded patch set 11: Patch Set 10 was rebased.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 12:

(2 comments)
|Uploaded patch set 15.
|Patch Set 15: Commit-Queue+1 Verified+1
|Patch Set 16: Commit message was updated
|Patch Set 16: Commit-Queue+1 Verified+1
|Patch Set 16: -Commit-Queue
|Patch Set 17: Commit message was updated
|Patch Set 18: Commit-Queue+1 Verified+1
|Patch Set 18: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 18: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(2 comments)

Worked hard! I'm sorry let you change so much in our offsite.
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review-1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Abandoned

Transfer to CL:295661
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

to waihong: Is this CL make sense?
|Patch Set 1: Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review-1 -Verified

Abandoned. Goes to CL:216604
|Abandoned
|Patch Set 5: Code-Review+1
|Patch Set 5:

(3 comments)

FYI.
|Patch Set 6:

(1 comment)
|Patch Set 7:

(1 comment)
|Patch Set 8: Code-Review+1
|Patch Set 3:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Abandoned

Transfer to CL:290671
|Patch Set 3:

(15 comments)

Some minor comments FYI.
|Patch Set 3:

(4 comments)

FYI.
Alas, do you want to separate this CL into 2~3 CLs?
|Patch Set 6:

(6 comments)

Some comments FYI~
|Patch Set 6:

(2 comments)
|Patch Set 8:

(2 comments)
|Patch Set 10:

(4 comments)
|Patch Set 12:

(7 comments)
|Patch Set 12:

(2 comments)
|Patch Set 13: Code-Review+1
|Patch Set 13:

(2 comments)
|Patch Set 15: Code-Review+1
|Patch Set 17:

(2 comments)
|Patch Set 19:

(4 comments)
|Patch Set 21: Code-Review+1

(7 comments)

FYI. No need to reply.
|Patch Set 21:

(4 comments)
|Patch Set 22: Code-Review+1

(3 comments)
|Patch Set 22:

(1 comment)
|Patch Set 24:

(1 comment)
|Patch Set 24: Code-Review+1

(1 comment)
|Patch Set 24:

(12 comments)

Some trivial suggestions, FYI, need not reply.
|Patch Set 28: Code-Review+1
|Patch Set 1:

(5 comments)

FYI.
|Patch Set 3:

(6 comments)
|Patch Set 3:

(2 comments)
|Patch Set 5:

(2 comments)
|Patch Set 5:

(2 comments)
|Patch Set 5:

(1 comment)
|Patch Set 6:

(15 comments)
|Patch Set 7:

(1 comment)
|Patch Set 10:

(2 comments)
|Patch Set 10:

(3 comments)
|Patch Set 12:

(1 comment)
|Patch Set 5: Commit-Queue+1

as chinlin@
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 6: Commit-Queue+1

as chinlin@
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I deleted the ebuild, because &quot;touch interface&quot; is not used in cranky (one of the previous comments asked me to remove the touch ebuild). Now i removed this line, because ebuild does not exist. I did compile after removing all 3 lines.
|Done
|Done
|Done
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)

replacing &quot;(c) 2012&quot; to 2015 gives the following error, thatswhy i left the year as it is in EC commit. the error does not go away even after &quot;make buildall -j&quot;. Should I use &quot;repo upload . --no-verify&quot;?

----------------------------------------------------------------------
        Errors:
            * License must match:
            .* Copyright \(c\) 20[-0-9]{2,7} The Chromium OS Authors\. All rights reserved\.
            .* Use of this source code is governed by a BSD-style license that can be
            .* found in the LICENSE file\.
            
            Found a bad header in these files:
                * /mnt/host/source/src/platform/ec/board/sumo/battery.c
                * /mnt/host/source/src/platform/ec/board/sumo/board.c
                * /mnt/host/source/src/platform/ec/board/sumo/board.h
                * /mnt/host/source/src/platform/ec/board/sumo/build.mk
                * /mnt/host/source/src/platform/ec/board/sumo/led.c
                * /mnt/host/source/src/platform/ec/util/flash_ec
            * Hook script &quot;util/presubmit_check.sh 2&gt;&amp;1&quot; failed with code 1:
              Files have changed since last time unit tests passed:
                /mnt/host/source/src/platform/ec/board/sumo/build.mk
                /mnt/host/source/src/platform/ec/board/sumo/ec.tasklist
              Please run &quot;make buildall -j&quot;.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

done.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2:

(5 comments)
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

Uploaded from ToT
|Uploaded patch set 1.
|Abandoned

Uploaded from ToT
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

Changes done. Also renamed the folder from rambi to cranky
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)

Made all the changes, uploaded the source
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

now, the lines are less than 80 characters.

&quot;repo upload .&quot;, still gives error
        Errors:
            * No LICENSE found in the ebuild.
                * /mnt/host/source/src/third_party/chromiumos-overlay/sys-boot/chromeos-bootimage/chromeos-bootimage-0.0.2-r87.ebuild
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

I am not able to view 223051. Getting error &quot;page not found&quot;. Did AMI TW commit this already? Please let me know. If so, I will abandon this commit.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Overlay-parry is there in the 5216 branch already. I will abandon this.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

Yes, it is copy of rambi with string changes
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Yes, I Will abandon this. Sorry for the confusion. Did not realize AMI TW made a commit already.
|Abandoned
|Uploaded patch set 1.
|Patch Set 1:

used &quot;--no-verify&quot; to upload the patch
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1

We do not see any obvious change at this time. If we see any issue we will submit as a patch.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

&gt; This is the cros-board.eclass not chromeos-bootimage, can you make
 &gt; a CL like this on ToT which we can cherry-pick to the branch if
 &gt; there is not one already to cherry-pick?

It is already there in ToT. will abandon this commit.
|Abandoned

It is there in ToT. cherry pick to the branch.
|Can you create an issue for the CL So that we know the changes is for Olay?
|Check if you can probe dram info correctly.
|EC team suggested us to set to &quot;idle&quot; before cutoff. It works  before PVT that discharging is done by &quot;ectool chargecontrol discharge&quot;. 
 
The code should not be executed when WP is enabled.
|Shouldn't this be &quot;if !(crossystem sw_wpsw_boot?1 wpsw_boot?1); then&quot;?
|Just checked with David Huang, ectool chargecontrol discharge/idle is not available when WP is enabled. So there might be errors here if WP is enabled.
|If we set &quot;Normal&quot;, the charge state will be &quot;charging&quot;. We do not want to make it charging after discharging.
|If PVT, AC should be removed already here due to the code in line 25~29.
|Why did you remove this?
|Remove the tailing space.
|Should not have &quot;tab&quot; here.
|Should not have &quot;tab&quot; here.
|How about change the command to &quot;ectool chargecontrol idle&quot;?
|Add &quot;CHERRY-PICK: &quot; in front of Gandof.
|All upper case, Thanks!
|Uploaded patch set 1.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R40-6457.B as commit f8d34b24111c36a0dad92bc9d2b02b5e3a65f4b9
|Patch Set 1:

Should the CL be cherry-pick to release branch?
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Abandoned
|Restored
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-auron-6459.B as commit 6442d0f4fe167df498852f9bbde684b8a7c5f8cb
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch release-R44-7077.B as commit 52043e62dd2e3dafa6d7708e0ceb9327736f80e5
|Patch Set 1: Cherry Picked from branch master.
|Patch set 2: Published edit on patch set 1.
|Patch Set 1:

(4 comments)

Thank you, Ryan!
|Patch Set 5:

I think the cutoff fail might not be caused by the script. There should have some other potential reasons But if there is no delay time to process cutoff command, it will probably show &quot;cutoff fail&quot; right after cutoff command.
|Patch Set 5:

(1 comment)

Hi Ryan,
Does it always fail? Could you describe more about the fail symptom? Does DUT show battery cutoff fail screen? Does DUT shutdown successfully? Is the failure reproducible?
|Patch Set 6: Code-Review+1
|Patch Set 6: -Code-Review

(2 comments)
|Patch Set 8:

(1 comment)
|Patch Set 9:

(2 comments)
|Patch Set 14: Code-Review+1

Please double check after the CL is merged. Thanks!
|Patch Set 3:

Hi Ryan,
You are adding a new ebuild file in this CL. Could you use &quot;giv mv chromeos-bsp-gandof-0.0.1-r10.ebuild chromeos-bsp-gandof-0.0.1-r11.ebuild&quot;? I think the previous ebuild is r10. Thanks~
|Patch Set 3:

(1 comment)

Hi Ryan, 

There should have an ebuild file. Please check https://chromium.googlesource.com/chromiumos/overlays/board-overlays/+/refs/heads/release-R44-7077.B/overlay-gandof/chromeos-base/chromeos-bsp-gandof.

By the way, it should be r8 not r10. I just made a mistake in my previous comment.
|Patch Set 4: Code-Review+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Patch Set 3:

https://chromium-review.googlesource.com/#/c/330075/ should fix it
|Patch Set 1: Cherry Picked from branch master.
|Abandoned

Battery cutoff does not work on 6459 factory reset shim. Need to update script for battery cutoff. Will upload another CL instead.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Hi Ryan,
Please do a local build and verify on PVT machines. Thanks!
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 1:

Missing uprev ebuild file?
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5:

.ebuild should be r9 not r10
|Patch Set 6: Code-Review+1
|Patch Set 6:

Hi Raya,
Can you build a test image and verify before you submit commit queue?
|Patch Set 1: Code-Review-1

Please upload the patch to ToT first. And then cherry-pick from ToT to release branch. Thanks!
|Patch Set 1: Cherry Picked from branch master.
|Patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

Yes. we don't need the photo.
|Patch Set 4: Cherry Picked

This patchset was cherry picked to branch factory-strago-7458.B as commit ac47ad376add2d9771ea0736d6effb36d6e3533b
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-strago-7458.B as commit 1a8d5345e6ba397fffc7ced1a0e51c3537358f32
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch factory-strago-7458.B as commit b22427f185a6634853969060de3e692f17ad17c9
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5: Cherry Picked

This patchset was cherry picked to branch factory-glados-7657.B as commit 697446ef6df31c60bee7572dd879b73740272d87
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch factory-glados-7828.B as commit d7fd9c53ef1d1eada8c6f0f7c53c0bab50b2841e
|Patch Set 1: Cherry Picked from branch master.
|Patch set 2: Commit message was updated.
|Patch Set 1: Code-Review+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Commit-Queue+1 Verified+1
|Done
|Done
|So what we're currently doing is that the template file is going to be predefined by us, meaning we can check through and make sure it works properly. Also, with Google Chart Tools there's an arrayToDataTable function that allows us to format our data how we want and put it in array form. Ideally we would pass already formatted data into this function, hopefully giving a bit more flexibility. 

Also, we will be changing the implementation of this to accommodate different functions for the different graph types (since they are substantially different). We can add a check in the individual functions to make sure the data matches the template.
|Done
|I moved the test data somewhere else, but kept the function in case we do want to do some testing.
|The parse data function is currently being added elsewhere. Right now it's in graphlog, but we're debating whether to put it in grapher or maybe even within the class.
|We're actually going to change how we're making the data table. As mentioned in a grapher() comment, we're thinking of using an arrayToDataTable to allow for more formatting before the data is passed in. In my next CL I'll probably get rid of these files and just upload the actual templates we're thinking of using. I should probably do that in two steps right?
|Pass in a timestamp for each snapshot. I think this is already done in your local version :)
|It might be easier to get meminfo and gpu_mem data upon instantiation as well?
|If we created GPUMem, meminfo, and smaps objects to fill in the attributes upon instantiation, I don't think these functions (getSmaps, getMemInfo, getGPUMem) are really necessary. You can just create the objects directly in __init__. I suppose they could be helpful if after a procSnapshot is created we wanted to gather data again or overwrite what we previously had. However, since a timestamp is associated with each instance of procSnapshot, I'm not sure such a scenario would ever come up. Instead it would probably be best to just create a new procSnapshot instance. Just a thought...
|We already talked about this, but just so Grant and Mandeep know what our plan is: 

This function will probably be changed to something like parseGraphData() or createCSV(). Instead of actually creating the graph within a procSnapshot object, the object will analyze its own data and put it into a graph-ready form. This method will return this graph-ready data, to be used by grapher.py
|Just FYI, the arguments with keyword=value are called keyword arguments.
|Add docstrings please. Then for variable names you probably don't need &quot;_list&quot; if we know what type the argument is. Just a thought to make typing a bit easier and variable names a tad shorter...
|data_table can probably be one word. just so you don't have type the underscore ;)
|We're going to want to return so we can pass this data to grapher.
|docstrings please and thank you :D
|Done
|Thiago and I just decided to change the names to just &quot;line&quot;, &quot;pie&quot;, and &quot;bar&quot; to make it easier to type.
|Oh that might've been from earlier and I forgot to take the comment out, will do that :)
|Oh that's nifty! I'll make that change.
|need to print grapher.chooseGraph()
|print
|&quot;pie&quot; should be &quot;bar&quot;
|Well I was thinking that since James said snapshots aren't as useful we can also use bar graphs to show the shared/private distribution over a period of time. And then the total height would represent the RSS. It would have a lot of bars though and I still have to figure out if we can stack some of the bars but not all of them. I'll change it and leave this one in comment tags.
|Yeah I know. But if I don't put it in now, I'll forget :P And it's easily taken out if necessary - just get rid of the &quot;%&quot; for testing. (Note: adding a comment tag to the line won't be enough)
|Currently it's a single snapshot. We do have the option of making it over time though it might be pretty messy. We're also not sure how useful this type of graph will be but included it just in case. Any thoughts?
|Done
|Done
|I think I'm going to take the line out of each of the graph sections and just put a description placeholder at the top.
|Done
|Patch Set 1: Abandoned

See https://gerrit.chromium.org/gerrit/25336
|Patch Set 1: Verified; Ready


|Change has been successfully merged into the git repository.
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Patch Set 1: I would prefer that you didn't submit this

Can you document getSmaps() and getSmapsDict() better? A bit more detail on the return values (how the dictionaries are formatted) would be helpful. That way if I want to use these data gathering functions but not your output, I can do so more easily. Also, getSmapsDict() doesn't actually return mem_dict, but rather a tuple of pid_dict and page_addr_dict.
|Patch Set 1: Looks good to me, but someone else must approve

Docstrings changed in next CL, +1 for chrome-only functionality change.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Abandoned

Performed a git reset --soft to a previous commit where the file mem_log.py still existed in order to separate my rename commit from other changes. Therefore this change no longer applies. There might have been a better way to do this, maybe next time.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

Needed to go back in time and redo a file rename in a previous commit. This commit was dependent on it.
|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: (6 inline comments)

Hi Grant,

I'm uploading a patch with the changes you recommended. Ultimately the next CL is going to look quite different, but it would be nice to have this merged in for the time being. I'll make some comments on the next patch so you can see what we have planned.
|Patch Set 1: (1 inline comment)

Oops, forgot to comment on the test file :P
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 2: (4 inline comments)

Thiago and I talked through some of these items already, but just so everyone can be updated and see the planned changes in the code, here are some additional suggestions I thought I would just insert into this review.

Also some are merely suggestions that are definitely debatable :)
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: (5 inline comments)


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 1: (3 inline comments)


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: Looks good to me, approved


|Patch Set 1: Verified; Ready


|Patch Set 1:

Right now I'm calling drawOneChart() ten times because I have yet to find a good way to pass the replacement variable %(name)s into another function. I have a few thoughts of how to do this but it would be easier to explain in person. Any suggestions would be of great help :)
|Patch Set 1: Verified; Ready


|Patch Set 1: No score; Not Ready


|Patch Set 1: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: Looks good to me, approved


|Done
|Done
|full line will exceed 80
|full line will exceed 80
|Done
|Done
|exceed 80
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I add another method to retrieve fwid that should be called after setup
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|already exist
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Currently, sha is saved in FvSections in bios_handler. If a test failed after modifying some part of firmware (before reboot), it will use the firmware sha (before modification) to compare with original sha. So, it is better to confirm the image in bios handler is identical to the real firmware. There is still some test do some firmware modification without reboot (ex. firmware_CorruptFwBodyA in RO_notmal)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This means move this line to def run_updatefirmwareversion(machine): or firmware_UpdateFirmwareVersion.py?
|Done
|Done
|Done. But I modify to raise an error, it is more make sense!
|It will use /usr/sbin/chromeos-firmwareupdate in remote host now.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|after use factory install shim, all version will be reset to 1.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (19 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3: (7 inline comments)

I make some modify in Pactch Set 4, and Patch Set 5 have combined these modification.
|Patch Set 5: Verified; Looks good to me, approved; Ready


|Change has been successfully cherry-picked as c7e55ea952c0267c0adf93fa5a16b986aeb71b0b
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2: (13 inline comments)


|Patch Set 4: (4 inline comments)

modified
|Uploaded patch set 5.
|Patch Set 5: (8 inline comments)


|Uploaded patch set 6.
|Patch Set 6: Verified; Ready


|Change has been successfully cherry-picked as 63c30cfc5da43d562dde0f83d2f5f980333c3a26
|Uploaded patch set 2.
|Patch Set 1: (11 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Change has been successfully cherry-picked as 6b700dfb17758d3db758693ec50f094c6a35a8c8
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Patch Set 2: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Patch Set 2: No score; Not Ready


|Uploaded patch set 3.
|Patch Set 1: Verified; Ready


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (17 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (9 inline comments)


|Patch Set 1: (2 inline comments)


|Patch Set 1: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Verified; Ready


|Patch Set 3: Not Ready


|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Ready


|Patch Set 3: Verified


|Uploaded patch set 2.
|Patch Set 2: (7 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: (4 inline comments)


|Patch Set 4: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (3 inline comments)

New version will recover the naming style to original style.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Verified; Ready


|Patch Set 1:

If use other class to classify methods, it just likes we have another bios_handler, kernel_handler... (I classify methods to bios, kernel, ec... according to which kind of handler the method uses) Here Tom gave me another advise to use string conversion (in _dispatch). I can use bios.restore_body, and it will really convert to _bios_restore_body which is a method in FAFTClient.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (13 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Here are some modifications after some CL merged.
|Uploaded patch set 6.
|Patch Set 5: (1 inline comment)


|Patch Set 6: (1 inline comment)


|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

modify two places missed before
|Patch Set 8: Verified; Ready


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Patch Set 3: Verified; Ready


|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Patch set 2: Published edit on patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|DISP_REG_OVL_INTSTA design as power on zero, so we don't need to clear it
|yes, it can be removed.
|yes, we don't need this, remove it
|Done
|Done
|Done
|Done
|Done
|why using kHz? Daniel using all Hz in all gpu devfreq and IPA
|update, please check patch set #16
|update, please refer patch set #16
|update, please refer patch set #16
|after check with our thermal driver, it will provide &quot;soc_thermal&quot;, I will change it while get new patch of this.
|update this, please refer
https://chromium-review.googlesource.com/#/c/310713/1
https://chromium-review.googlesource.com/#/c/310714/1
|update please refer
https://chromium-review.googlesource.com/#/c/310713/1
|please refer
https://chromium-review.googlesource.com/#/c/310713/1
|In fact, our chip can be work fine under temperature from -40 degrees to 105 degrees. others we can't promise, maybe I can add extrapolate for wide temperate consideration (-100 ~ +200 degrees), Is that suitable?
|If we can return PVRSRV_ERROR_DEVICE_POWER_CHANGE_DENIED
with mtk_mfg_disable and don't turn off power, that will be better solution.
But now we just notify an error occur for further check if failed to power off mfg issue
|Patch Set 11:

&gt; &gt; &gt; Actually as of kernel commit 93b81f5102a7cd270a305c2741b17c8d44bb0629
 &gt; &gt; &gt; i915 has some driver-specific formats in there, so we could
 &gt; also
 &gt; &gt; &gt; add our own. Let's just we follow the same naming convention.
 &gt; &gt;
 &gt; &gt; marcheu is referring to [0], which uses the newly introduced [1]
 &gt; &gt; &quot;fourcc_mod_code()&quot; macro to define a vendor specific fourcc
 &gt; code.
 &gt; &gt;
 &gt; &gt; These two patches are currently in arlied's drm-next [2] branch
 &gt; (so
 &gt; &gt; will likely get picked up for 4.0-rc8).
 &gt; &gt;
 &gt; &gt; [0] http://cgit.freedesktop.org/~airlied/linux/commit/?h=drm-next&amp;id=93b81f5102a7cd270a305c2741b17c8d44bb0629
 &gt; &gt;
 &gt; &gt; [1] http://cgit.freedesktop.org/~airlied/linux/commit/?h=drm-next&amp;id=e3eb3250d84ef97b766312345774367b6a310db8
 &gt; &gt;
 &gt; &gt; [2] http://cgit.freedesktop.org/~airlied/linux/log/?h=drm-next
 &gt; &gt;
 &gt; &gt;
 &gt; &gt; Please redo this patch to use a similar scheme for defining the
 &gt; &gt; driver-specific formats.
 &gt; 
 &gt; Mediatek/Img - do you have any questions about the above request?

that means we don't need to define DRM_FORMAT_MT12 , and drm format will extended to 64-bit notification.  Under this configuration , how does eglCreateImageKHR work with attrib_list delievering (EGL_LINUX_DRM_FOURCC_EXT = fourcc_format:only 32-bit)
|Patch Set 12:

(1 comment)
|Patch Set 31:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Abandoned

no need
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 10: Patch Set 9 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 7:

(5 comments)
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+1 Commit-Queue+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Patch Set 1:

OK, please abandon it
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6:

The IPA integration will be re-start based on these clean up patches.
Thanks for all you have done.
|Patch Set 6:

@Daniel
Yes, you can push them now
|Uploaded patch set 16.
|Patch Set 9:

(3 comments)
|Patch Set 9:

(1 comment)
|Patch Set 17:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Patch Set 1:

related with 303848/3
callback of w/ GetStaticPower, now always get temperature=INT_MAX,
should we read temperature form thermal zone in this function?
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4:

(4 comments)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

@Daniel, can't repoduce ui-start failed with the two patches, could you give me more message (ex:boot fail log)
|Patch Set 4:

- mfg power domain including three part (mfg_async control core power, mfg_2d control 2d interface(tex, memory) , mfg control shader/3d engine)
- power on/off sequence include hw register domain reset thus
  We need to turn off mfg_async/mfg_2d/mfg to let gpu internal state machine finish power off procedure and reset all relative register/state
- indeed, the there domain is a group relationship
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

If you want to try gpu freq 600Mhz, please add opp [598000 1130000] in dts
&amp;gpu {
	operating-points = &lt;
		253500 1000000
		299000 1000000
		396500 1000000
		455000 1000000
		494000 1130000
		598000 1130000
	&gt;;
};
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

IF we can guarantee the three domain all off before set mfg power on,
thus mfg register will be all set to default, thus we don't need to clear it. Also pre-gating mfg clock will be confuse mfg power status check.
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 1: Code-Review+1
|Patch Set 2:

I have boot to ui based on Oak-tot-94 with those 10 patches
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3:

you can check the topic : scpsys-oak-tot-94
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 5:

&gt; Also you may want to add this board to flash_ec.
Here is the CL for add setzer to flash_ec support list.
https://chromium-review.googlesource.com/#/c/318101/
|Patch Set 5:

&gt; Here is the CL for add setzer to flash_ec support list.
https://chromium-review.googlesource.com/#/c/318184/
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Verified+1
|Patch Set 2: Verified+1
|Removed the following votes:

* Verified+1 by Peggy Chuang &lt;PeggyChuang@ami.com.tw&gt;

|Patch Set 2: Code-Review+1
|Patch Set 2: Verified+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Verified+1
|Patch Set 2: -Verified
|Patch Set 3: Code-Review+1
|Patch Set 2: Verified+1
|Patch Set 2: -Verified
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4: Verified+1
|H/W was already fixed.
So, we could not change about this.
If there are some issues, please refer it to our H/W team.
|When there was no battery, EC made the battery event over and over.
So EC needs additional conditions.
Checking batt_flags could make the event only once when battery was removed.
|The reason why we use 'else' is for immediately setting battery error, voltage and current when there is battery error.
|Yes, if there is the battery error by over voltage, battery should be defected.
And battery is not reverted to its common state until battery is removed and reconnected.
|It's for setting battery error state continually.
|&quot;batt-&gt;flags&quot; is always cleared battery_get_params().
So, it should be continually set error state.
Actually, this function is not called if BATT_FLAG_BAT_ANY is enable.
But, I will add more check-items for battery protection on this function.
Some items will use BATT_FLAG_WANT_CHARGE.
So, battery error state should be check separately.
|The reason why we don't use 'else' is for immediately setting battery error, voltage and current when there is battery error.
|If there is the battery error by over voltage, battery should be defected.
And battery is not reverted to its common state until battery is removed and reconnected.
|This value is cleared only once when battery is removed.
That is, we want to keep battery error state before removing battery.

Cleared value is '0', this means battery state is common.
|charger_closest_voltage() just checks configurable voltage about charger.

We want to stop to charge and enter battery error state when battery pack voltage is higher than charging voltage.
|This value is cleared only once when battery is removed.
common/charge_state.c
|@Mohammed
Temperature condition is different as battery state.
Start charging temperature is check on all state except PWR_STATE_CHARGE.
|OEM_BATTERY_STATE_STOP_CHARGE is not error.
We want just to stop charging until battery state is recovered.
|PWR_STATE_CHARGE is always set after idle or idle0.
In case of PWR_STATE_DISCHARGE -&gt; PWR_STATE_CHARGE,
actual state flow is DISCHARGE -&gt; REINITE -&gt; IDLE -&gt; CHARGE.
|PWR_STATE_CHARGE is always set after PWR_STATE_IDLE.
In case of PWR_STATE_DISCHARGE -&gt; PWR_STATE_CHARGE,
actual state flow is DISCHARGE -&gt; REINIT -&gt; IDLE -&gt; CHARGE.
|Using 'batt-&gt;full_capacity', EC could not be built.
So, I revert to the original method we aleady checked.
|Error is,
'struct batt_params' has no member named 'full_capacity'
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Verified+1
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 6: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue
|Patch Set 6:

Palatin, please review again.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 6:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue
|Uploaded patch set 6.
|Patch Set 6: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

please review again.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

We have got below message.

vapier@chromium.org: Tree is closed (sdk cannot fetch llvm git)

I executed &quot;repo sync&quot; again.
Could we merge this code after CR?
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

@Mohammed Habibulla		Aug 2 12:57 PM

charger_closest_voltage checks the same condition. How is this different?

Also please list on the issue tracker the exact steps which cause the issue that you are trying to fix.
		
@YongBeum Ha		Aug 2 1:50 PM

The parameter of charger_closest_voltage() is batt-&gt;desired_voltage and the value that is compared here is batt-&gt;volatage.

charger_closest_voltage() is to get voltage that is set to charger. This line is to check battery voltage itself. If battery voltage is higher than maximum voltage, we think that the battery has defect and don't charge the battery permanently.
	


@Mohammed Habibulla		Aug 2 12:57 PM

Once the error occurs you need to disconnect and reconnect the battery to clear the error?

@YongBeum Ha		Aug 2 1:50 PM

Yes. If battery has defect, we don't charge the battery. Disconnection and reconnection can be inserted new battery, we must clear the error.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Verified+1
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

(2 comments)
|Patch Set 8:

(1 comment)
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 12: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 12: -Commit-Queue

@Randall
Please review again.
|Patch Set 13: Code-Review+1 Verified+1
|Patch Set 13: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 2.
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Patch Set 7: Code-Review+1
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Uploaded patch set 2.
|Patch Set 3: Commit-Queue+1
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 4: Commit-Queue+1
|Patch Set 5: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Abandoned
|Restored
|Patch Set 6: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 7: Commit-Queue+1
|Patch Set 7: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Done
|removed tab.
|Done
|Done
|It is needed now, as it is no longer statically set.
|It is needed now, as it is no longer statically set.
|It is needed now, as it is no longer statically set.
|Done
|Already taken care.
|Done
|Done
|replaced R_PCH_PCR_GPIO_MISCCFG by MISCCFG_OFFSET
|Done
|Done
|Done
|Done
|Done
|Community 2 is deep sleep well group. Have added this. it is not clear whether there are any consumers for these GPIOs.
|Done. By shifting PCH_PCR_BASE_ADDRESS to iomap.h and reusing it. Including pcr.h in asl include chain causes compilation problems.
|Added 2 M's. including pcr.h for port ids causing compilation issues with ASL compiler.
|Now using the MISCCFG register to correctly pick the right interrupt (14 or 15). This is done globally for all communities since the FSP policy applies the same IRQ across all communities.
|This is an IRQ for GPIO controller itself.
|Not clear how to read MISCCFG here. can you elaborate?
|Done
|Done
|Done
|Done
|The B_23 has a soft strap attached and pull downs are not needed normally. We went with similar configuration for SMB CLK/DATA/ALERT - configuring as input and deep.
|Done
|Done. I have also made same change in kunimitsu.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Updated the comment to mention that the device becomes NULL when it is not present in devicetree or hidden.
|Done. Corrected the args.
|Done
|Done. Moved them to finalize.c. Removed the R_ &amp; B_.
|Done
|Done
|Renamed the variable to PmTimerDisabled and did associated changes. This is to indicate explicitly in devicetree that PM timer is being disabled since there is a cost involved in disabling the timer.
|chipset_in_state(CHIPSET_STATE_STANDBY &#124; CHIPSET_STATE_ON) checks for the S0ix state and was consistently getting hit during my test runs to enable/disable correctly. 
An issue will only come if enable/disable calls are called after system transitions to S0 or S0ix.
To be safe, I have added the second set of conditions  
if ((chipset_in_state(CHIPSET_STATE_STANDBY &#124; CHIPSET_STATE_ON)) &#124;&#124; chipset_in_state(CHIPSET_STATE_STANDBY)) and tested the flow again. 
Everything is working as expected.
|Done
|Done
|Removed freeze/thaw hooks. Based on chipset_in_state() == CHIPSET_STATE_STANDBY, taking actions.
|Done
|Patch Set 1:

This needs more to support the EC properly:
ec.c and ec.h files
acpi/ec.asl and acpi/superio.asl files (these should exist already as I added them earlier)
enable the EC in devicetree.cb under the LPC device
mainboard.c that calls mainboard_ec_init()

Done
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2:

(9 comments)
|Uploaded patch set 3.
|Patch Set 3:

The current version of FSP in the tree has a bug in the GpioSetIrq function which incorrectly maps the MISCCFG bit when setting. This has been notified and a fix has been pushed to the internal tree.

This should not impact the functionality of this patch since the FSP currently uses IRQ 14 for all GPIO communities. Even with the issue, it will map to zero and 14 will be assigned correctly in ASL.

Once the issue is fixed, the ASL will work correctly with 15 as well. This has been tested by overriding with 15 in FSP.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Patch Set 6:

(8 comments)

Uploaded the latest patch against the branch chromeos-2015.07. 
the new patch is https://chromium-review.googlesource.com/#/c/291230/
will abandon this.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 3:

Following commands you can use to export and change direction of GPIO
cat /sys/kernel/debug/gpio
sh -c &quot;echo 419 &gt; /sys/class/gpio/export&quot;
cat /sys/kernel/debug/gpio
sh -c &quot;echo out &gt; /sys/class/gpio/gpio419/direction&quot;
cat /sys/kernel/debug/gpio
sh -c &quot;echo 0 &gt; /sys/class/gpio/gpio419/value&quot;
cat /sys/class/gpio/gpio419/value
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

rebased patch on latest tree.
|Abandoned

Abandoning this patch, as the similar change is already merged.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Abandoned

uploaded a new version of this patch on branch chromeos-2015.07
https://chromium-review.googlesource.com/306391
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)

Uploaded a new version of this patch in the branch chromeos-2015.07
https://chromium-review.googlesource.com/#/c/306481/
|Abandoned

Uploaded a new version of this patch in branch chromeos-2015.07 
https://chromium-review.googlesource.com/#/c/306481/
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 4: Verified+1
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(4 comments)

FSP patches will come along with the 1.8.0 patchset. These are getting validated and will be open for review soon. I have updated the cros bug with details.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(2 comments)
|Uploaded patch set 6.
|Patch Set 6:

(1 comment)
|Patch Set 6: Verified+1
|Patch Set 6: Code-Review+1 Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

The kernel code is unhiding P2SB in the following way. Is there an equivalent pci_bus_write model available in Coreboot ?
https://lkml.org/lkml/2015/7/27/458
 
            /* Unhide the P2SB device */
            pci_bus_write_config_byte(pci_dev-&gt;bus, devfn, 0xe1, 0x0);
 
            pci_bus_read_config_dword(pci_dev-&gt;bus, devfn, SBREG_BAR, &amp;base_addr);
            base64_addr = base_addr &amp; 0xfffffff0;
 
            pci_bus_read_config_dword(pci_dev-&gt;bus, devfn, SBREG_BAR + 0x4, &amp;base_addr);
            base64_addr &#124;= (u64)base_addr &lt;&lt; 32;
 
            /* Hide the P2SB device */
            pci_bus_write_config_byte(pci_dev-&gt;bus, devfn, 0xe1, 0x1);
            spin_unlock(&amp;p2sb_spinlock);
|Uploaded patch set 3.
|Abandoned

Grouped all mainboard devicetree changes in the other CL.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

updated commit message with TCO timer disable.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

Shawn:

I have uploaded the direct function call patch instead of the hook based approach. 

As noted in the cros_bug update, we can have a prev_state based approach which can distinguish the S0ix/S0 sequence from S3/S0 sequence in the same hook call; I can upload that version if there is interest. But that also looks prone to error conditions such as the previous state getting overwritten.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Patch Set 6:

Have added the condition to check if it is trigerred from S3S0. Also made the change in npcx - do you need it as a seperate patch ?

I haven't used CONFIG_S0IX since the condition is enough to check in both cases. To remove the unwanted if condition in the S0IX not enabled case, something like the following can be done if needed. Thoughts ?


#ifdef CONFIG_POWER_S0IX
       if (chipset_in_state(CHIPSET_STATE_SUSPEND &#124; CHIPSET_STATE_ON)) 
#endif
       {
               /* Mask all host events until the host unmasks them itself.  */
               lpc_set_host_event_mask(LPC_HOST_EVENT_SMI, 0);
               lpc_set_host_event_mask(LPC_HOST_EVENT_SCI, 0);
               lpc_set_host_event_mask(LPC_HOST_EVENT_WAKE, 0);
       }
#endif 

This does open up a potential race due to asynchronous nature of hooks. If system transitions to S0, then the condition will not return true. It should be ok since Coreboot will anyway clear these in the S3 case.
|Uploaded patch set 7.
|Done
|Done
|Yes, that's true. CMOS is used for vboot variables. Verified that, with this Rtc Lock code present, we cannot update the crossystem fw_result value since RTC was locked and we cannot write to it.
SO, removed this part of the code and verified that by writing to crossystem data (for eg. crossystem fw_result=success).
|Added the value defines in comments.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned

Board specific RtcLock disabling not required from devicetree.cb since in SkylakeFspPkg.dsc, the default value for RtcLock is set as 0 which means disable, which will serve the purpose for all platforms.
|Uploaded patch set 1.
|Abandoned

Board specific RtcLock disabling not required from devicetree.cb since in SkylakeFspPkg.dsc, the default value for RtcLock is set as 0 which means disable, which will serve the purpose for all platforms.
|Uploaded patch set 1.
|Abandoned

fw_result=success needs to be set from OS. Nothing from CoreBoot side.
|Uploaded patch set 1.
|Abandoned

No need of success() api from Coreboot. Also setting of fw_result=failure logic will be if we only Set any SLOT or both SLOTs failed. No need of unconditionally setting Failure on vb2_fail(). The code present before was correct.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 13: Patch Set 12 was rebased.
|Patch Set 13: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 8: Commit message was updated.
|Patch Set 10: Verified+1
|Uploaded patch set 2.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 11.
|Patch Set 10:

(2 comments)
|Uploaded patch set 12.
|Patch Set 10:

(1 comment)
|Patch Set 12: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 8: Commit message was updated.
|Patch Set 1: Verified+1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Commit message was updated.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Abandoned
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4: Commit message was updated.
|Can we make it Snow instead of SMDK5250.
|I guess this was removed by mistake. will correct this.
|Will add this
|Will correct this
|We can remove PERIPH_ID_COUNT in the declaration.
|Will add offsets for the clock addresses in the above structure
so that we can have only one function for both 5420 and 5250.
|Will add this.
|will correct this
|Will add offsets for the clock addresses in the above structure so that we can have only one function for both 5420 and 5250.
|Will correct this.
|set_mmc_clock has divider as a parameter instead of rate. Since this function is generic even for exynos4 to maintain the same had set parameters as div and prediv instead of rate.
Can we have a separate function to set source or you want it to set while setting the rate ?
|Will correct this
|Had removed this as we were hard coding sdd-&gt;cur_bpw and sdd-&gt;cur_speed this below.
|OK will not remove this and use byte transfer in this case.
|Will try doing this based on (xfer-&gt;bpw == 32) instead of recomputing the the fifo size. 
Will check for transfer length is a multiple of 4 initially in s3c64xx_spi_transfer_one_message.
|Will replace the same with following condition check.
                if (xfer-&gt;len % 4) {
                        sdd-&gt;cur_bpw = 8;
                        s3c64xx_spi_config(sdd);
                } else {
                        sdd-&gt;cur_bpw = 32;
                        s3c64xx_spi_config(sdd);
                }
|By default we are setting it to word transfer mode.
|Will remove the i2s values from this dts as they are defined in cros5250-common.dtsi.
But we need to keep the codec type as the codecs are different for smdk5250 and snow boards.
|Since 5420 supports only I2S0 (needs hardware changes to support I2S1) we thought of making the same change for 5250. Will add the same in commit message.
|This was done to correct a checkpatch error. it gives a check saying the &quot;alignment should match open parentheses&quot;
|This was done to correct a checkpatch error. it gives a check saying the &quot;alignment should match open parentheses&quot;
|I guess max98090_i2c_write, max98090_i2c_read, max98090_update_bits seems to be common, would it be fine to create a separate  .c file to share these 3 functions?
|Is this change related to this patch?
|Is this change related to this patch?
|Is this change related to this patch?
|Is this change related to this patch?
|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)

With a minor change.
|Patch Set 1: Abandoned

This change was of no help in improving the performance of spi controller. It was a WIP patch, hence abandoning the same.
|Patch Set 1: (11 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Please do let me know if any review comments on the same.
|Uploaded patch set 4.
|Patch Set 4: Verified


|Patch Set 4: Ready


|Uploaded patch set 2.
|Patch Set 2: Ready; Verified


|Patch Set 1: (5 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Please do let me know if any comments on the same.
|Uploaded patch set 4.
|Patch Set 4:

Please do let me know if any comments on this, since it is pending since a long time.
|Patch Set 4: Verified

tested using following command:
flashrom -p internal:bus=spi -w &lt;patch for nv-image&gt;

U-boot is getting update and booting fine on reboot.
|Uploaded patch set 5.
|Patch Set 5: Verified

corrected the following error message in patch set 5:
/mnt/host/source/src/third_party/kernel-next/drivers/spi/spi-s3c64xx.c: In function 's3c64xx_spi_transfer_one_message':
/mnt/host/source/src/third_party/kernel-next/drivers/spi/spi-s3c64xx.c:349:11: error: 'swapcfg' may be used uninitialized in this function [-Werror=uninitialized]
/mnt/host/source/src/third_party/kernel-next/drivers/spi/spi-s3c64xx.c:339:22: note: 'swapcfg' was declared here
|Uploaded patch set 2.
|Patch Set 2:

Since 5420 supports only I2S0 (needs hardware changes to support I2S1). We thought it would be better to support I2S1 even for 5250. This patch alone doesn't give compilation error, but yes needs the clock, dts and I2S changes to make it work.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (4 inline comments)


|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1:

Hi, Bowgo,

It's not the cherry pick, attually it's roll back the change of commit 6c6c1c61ced3bf2176881041f254e47071d6a84e.
Can you have a review on it?
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

dupicate commit
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned

Dell's requirment no need to update it for battery cut off, it can be covered by factory script
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Abandoned

Abandon it, since it covered by another CL
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Commit message was updated.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Commit message was updated.
|Uploaded patch set 7: Commit message was updated.
|Patch Set 7: Verified+1
|Uploaded patch set 1.
|Abandoned

abandon due to mis-delete one file in the package
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: -Verified
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch factory-strago-7458.B as commit 632d86d8d1d3e6023b03bedc64fd3d02b2bb1929
|Patch Set 3: Cherry Picked

This patchset was cherry picked to branch factory-strago-7458.B as commit faf0ac0a37c6237d797d7d1c8c7f6a04fadcfdd9
|Apparently no one caught these glaringly &gt; 80 character lines, which were missed due to --no-verify being passed to escape the non-happy headers. Fixed in patchset 7.
|Done
|Done
|Done
|Done
|Done
|I doubt these will be upstreamed; the headers were originally pulled from the TCG's version, but they had problems.

I made this an explicit change here, since I'm not sure how else to introduce these errors/fix these problems in the spec.
|This might be useful, since otherwise they look completely meaningless and unreadable here unless one happens to know the spec.
|Whoops. Fixed.
|Done
|Done
|Done
|Done
|Assuming that it should be defined in tss_error.h ?
|Done
|Done
|Done
|Done
|Done
|Done. Bug filed is chromium:254742 .
|Apparently I don't know how makefiles work. Done.
|Will add tss/*.o to the end of that.
|Well then... that explains why make was complaining. Removed.
|more_tests is needed (even if it is empty) otherwise cros_workon_make fails. I will remove tss_more_tests though.
|tss is the subdirectory, all is the target, although all is implied.
|As noted above, tss is the subdirectory, tests is the target.
|Done
|Done
|Done
|You're right. Removed.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|This is probably poor wording on my part.

So, trousers' version of the tss headers had changed all the #include's to be &lt;tss/file.h&gt; instead of &lt;file.h&gt;. The original headers did not have this modification. For consistency's sake this modification is mirrored on these headers.
|So this CL breaks a lot of code-style rules, esp. w.r.t. carriage returns and the occasional use of tabs over spaces.

I'm not sure if we should fix this. I will have to defer this question to someone else.
|Done
|Done
|That was what I was looking for.

Done.
|Done
|Done
|Done
|Removed this comment in patchset 7.
|Removed this comment in patchset 7.
|Done
|Done
|Will change back to virtual as per discussion.
|Done
|Done
|Added to tsp_context_manager.h and tsp_context.h .
|Done
|Changed to ASSERT_TRUE(...) as per discussion.
|Yes. Whoops.
|Done
|The newline is mostly to show that this .cc file is implementing functions in tss/tspi.h .
|Done
|Done
|Noted.
|Done
|Will change this from /include/tss to /include to fix a later bug as the TSS headers try including each other (and end up referencing the wrong version).
|This was defined in tsp_context.cc, but I can move it here instead.
|So the mock was mostly to test that the C API was calling the C++ methods correctly. I haven't yet implemented the methods and the calls yet, so I can't really test it. I'll remove the virtual keyword from the other methods for now, and will add them back when there is more implementation to test.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Note: So the variable names here are the same as specified in the header files/specification document.

I have changed them to be more descriptive though.
|Done
|Done
|Removed.
|Done
|Done
|Done
|If changed to shared_ptr, I'm not sure what sorts of exceptions could be thrown (and thus need to be caught).

The two options are TSS_SUCCESS and TSS_E_INTERNAL_ERROR.
|Done
|Done
|Only reason it was necessary was for NULL, which I am not sure is defined anywhere except in cstring.
|Done
|Done
|Done
|Mostly for tests. I'm uncertain how to check hidden fields otherwise.
|The subdir Makefile pulls a lot of chrome-os specific stuff, while the top-level Makefile is mostly standalone. The subdir was/is supposed to hold my intern project (writing a replacement TSS).

dkrahn might be able to elaborate on this better than myself.
|Yes. You are right. Fixed.
|Done
|I'm not sure CHECK/DCHECK is the best thing for this. On the one hand it could be API misuse, on the other hand &#124;size&#124; may come directly from reading the TPM (i.e. not enough bytes) and thus be indicative of a different problem.

I may revisit this in a later CL.
|Done
|Done
|Done
|So in the TPM spec the way arrays are sent/received is such that the size of the array appears before the array itself. This function serves to pop the size back on again if we find that the amount of data remaining in the buffer &lt; the size we received (indicative of programmer error).
|Done
|This function is actually never called except by Send() and Recv() in tpm.cc, which uses a kTpmPacketSize buffer. There isn't too much reason for someone to be making his/her own TpmMessage to send/recv manually as a result.
|Done
|Done
|Done
|Nope. Made private.
|Done
|Done
|Done
|Made it GetDataForTest. Will have to investigate friend classes later.
|Done
|Done
|Done
|Removed.
|Done
|I tried removing some of them, but got compiler errors, so I'm somewhat certain I need them.
|These were dupes of includes up above, and were removed.
|I had a constant ready, and didn't used it for some reason. Fixed.
|Done
|Initial simple function we were trying to implement that we could test through all the layers.
|It was for va_args. No longer needed now.
|Done
|Done
|Done
|Done
|Done
|Apparently not.
|Got rid of this in patchset 5 as well.
|Done
|Turns out templates need have method definitions in the header file so that the compiler knows how to generate specific versions at compile-time.

This is done in patchset 3.
|We run into linker issues otherwise since between compiling for the library and compiling for the executable, the compiler manages to not compile the appropriate versions for some reason.

This was one workaround I discovered. There may be a better workaround that I'm not aware of.
|Renamed.
|We don't know if the resource manager is in a TspContext or a TcsContext, so thus the returns here are generic.
|Done
|It /does/ fit in one line. Huh. I assumed it wouldn't for some reason.

Fixed.
|Done
|Nope. Leftover from debugging linker issues.
|Added some comments here.
|Added some comments here.
|Done
|Typo in Makefile fixed in patchset 2.

(trunks_dbus_service.o -&gt; trunks_service.o)
|Moved code back to dbus_client.{cc,h}.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Uploaded patch set 2.
|Patch Set 2: Abandoned

Commit contains changes from other edited commit; abandoning.
|Patch Set 2: Restored

Turns out abandoning means closing, and I can't push updates to a closed change.

Apologies for Noogler mistakes.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Patch Set 6: Ready


|Patch Set 6: Ready


|Patch Set 6: Ready


|Patch Set 1: (8 inline comments)

Some additional notes: There exist macros in tss/tss_error_basics.h that replicate some of the functionality here (namely bitsetting/masking, etc.). Should I keep the duplicate functionality here for readability? or should I rely on the macros instead?
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Fixed to depend on most recent CL.
|Uploaded patch set 4.
|Patch Set 3: (3 inline comments)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4: (2 inline comments)


|Patch Set 6: Ready; Verified


|Uploaded patch set 7.
|Patch Set 7: Looks good to me, approved; Ready; Verified

Forwarding LGTM after updating from dkrahn's changes.
|Patch Set 6: (1 inline comment)


|Patch Set 1: (19 inline comments)


|Patch Set 1: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Ready; Verified


|Patch Set 3: Ready


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Patch Set 6: Ready


|Patch Set 6: Ready


|Patch Set 6: Ready


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)

Commented on the question. The nit will be fixed in the next patch after questions are resolved.

Re -I directive: Since TrouSerS already installs tss headers in tss/, what we might do is use the -I directive initially with the vanilla 1.2 headers provided in this CL's parent, then merge this particular CL once it becomes okay to swap out TrouSerS with Trunks.

Right now chaps and cryptohome both rely on TrouSerS, and rely on the headers being installed to tss/ to compile.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 5: Ready


|Patch Set 5: Ready


|Patch Set 5: Ready


|Patch Set 1: (10 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (23 inline comments)


|Uploaded patch set 3.
|Patch Set 3: (4 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: (15 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6: (2 inline comments)


|Patch Set 7: (6 inline comments)


|Uploaded patch set 8.
|Patch Set 8: Ready; Verified


|Patch Set 1: Abandoned

Duplicate of 60829.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Uploaded a different implementation (using TpmMessages that are Send()ed and Recv()ed). I tried to fix some of the issues from before, but may have missed some so I'll look through those now.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 5: (11 inline comments)


|Patch Set 4: (11 inline comments)


|Uploaded patch set 8.
|Patch Set 7: (2 inline comments)


|Patch Set 8: Ready; Verified


|Patch Set 8: Not Ready


|Patch Set 7: (7 inline comments)


|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 7: (1 inline comment)


|Patch Set 12: Looks good to me, approved; Ready; Verified

Carrying forward the LGTM.
|Patch Set 1: Ready; Verified


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Ready; Verified


|Patch Set 1:

This CL is an effort to dedup code as noted in the review of:
https://gerrit.chromium.org/gerrit/#/c/65711/ .
|Patch Set 1: (9 inline comments)


|Uploaded patch set 2.
|Patch Set 1: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 3: (2 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Ready; Verified


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Abandoned

the same commit as:
https://chromium-review.googlesource.com/#/c/268341/
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Abandoned

the same commit as:
https://chromium-review.googlesource.com/#/c/277432/
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

already committed
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Hi Frank,

did you check this patch alone on Cherrytrail(silvermont)?
on big core like haswell,ivy bridge you wont see the difference
because it has the resources to deal with 4 consecutive loads and aliasing compared to silvermont
that function also can be hot depending in the content 
right now as I checked only this patch on silvermont system
I get 16% function level gain on 64x64, 52% function level gain on 32x32, 6% on 16x16, 2.5% on 8x8 and 2.7% on 4x4
|Uploaded patch set 3.
|Patch Set 3:

Hi Yunqing,

which 2 webm files?
I checked one example and its the same with and without --enable-pic

Thanks,
Tamar
|Patch Set 6:

Hi Scott,

I didn't understand your question.

Thanks,
Tamar
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

already committed
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Hi Frank,

I got 13%-14% user level optimization with all my optimizations included so far with AVX2 disabled 32bit.
please let me know if you see that too.

Thanks,
Tamar
|Abandoned

Hello,

I want to abandon this patch because it fails to rebase.
|Restored

I abandoned the wrong commit please restore
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Abandoned

This patch failed to rebase please abandon
|Uploaded patch set 1.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Patch Set 1:

it is but Yunqing asked to resubmit all my commits
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 1.
|Patch Set 1:

Yes but Yunqing asked me to resubmit it again
|Patch Set 1:

Do I need to resubmit it again? (because its aborted)
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 1: Code-Review+1

Thank you, Yaowu! 
Cannot imagine what I was thinking...
|Patch Set 1:

Thanks for the fix. The patch makes the code much conciser. 
However, I have a feeling that this would not change what the function does since the txsize for 8x4/4x8 blocks using stx will be set as 8x8, vp9_foreach_transformed_block() will still process one 8x8 tx block rather than splitting them into 4x4s. But anyway, if it does fix the test failure, that is great. In any case if it does not completely solve the issue, post the sequence/configuration/command line of the failure case here, then let's see if we can find out other bugs.
|Patch Set 1: Code-Review+1 Verified+1

Great, that makes sense. Thanks!

 &gt; @YueChen
 &gt; I agree that the luma tx size is 8x8 in supertx mode, however the
 &gt; failing test occurs when using 4:2:2 chroma subsampling. The chroma
 &gt; tx size is 4x4 but as far as we understand there are 2 blocks that
 &gt; need to be tokenized.  Using the EndToEnd test the original code
 &gt; works fine in 4:2:0 or 4:4:4, but fails in 4:2:2 and 4:4:0.

 &gt; @YueChen
 &gt; I agree that the luma tx size is 8x8 in supertx mode, however the
 &gt; failing test occurs when using 4:2:2 chroma subsampling. The chroma
 &gt; tx size is 4x4 but as far as we understand there are 2 blocks that
 &gt; need to be tokenized.  Using the EndToEnd test the original code
 &gt; works fine in 4:2:0 or 4:4:4, but fails in 4:2:2 and 4:4:0.
|Patch Set 2: Code-Review+1 Verified+1
|Our CPU on this platform does not support LPAE.
If this is set, then we fail at  ASSERT((read_mmfr0() &amp; 0xf) &gt;= 5);
in mmu_init code since this register reads 4 for 8064
|we are just disabling the the mmu again since we do not want to make any assumption about any mmu settings changed by any binary blobs we include. We can move/ delete all the code before mmu_init to the right place once we decide on architecture.
|will take care of this
|look at src/arch/arm/armv7/mmu.c
static pmd_t *const ttb_buff = (pmd_t *)CONFIG_TTB_BUFFER;
|would you be happy with (volatile void *) cast for #defines of addresses?
|yeah, this can be removed
|what's the common file you are referring to?
|i will be converting all these unsigned references to unsigned or uint32's where applicable
|romstage size was retained from before.
The base of SRAM is actually used by TZ.
Bootblock is prepended by uber-sbl.
There is no requirement that it should go into the base of SRAM.
SBL1 goes in there initially.
|Posting for Manoj (he seems to be having issues with posting comments):
Vadim, SBL2 starts at 0x2A04_0000 addr. Technically, bootblock can use memory at 0x2A00_0000 but there is one concern. As you know, once PBL loads the combined sbl-ro+bootblock blob to imem, SBL1 running on rpm copies sbl2 and bootblock to their respective locations so if bootblock image is meant/built to be loaded at 0x2A00_0000, this will cause the issue (because SBL1 is running at 0x2A00_0000 addr). If the plan is to use 0x2A00_0000 memory at run time during boot block execution, then its fine.
In general, if boot block needs additional memory, I would suggest using 28KB from 0x2A02_0000 to 0x2A02_7000 addr till coreboot doesn't load TZBSP. By the time TZBSP is loaded, DDR is already initialized so coreboot can start using DDR for additional memory needs.
|typo..needs changing to &quot;one&quot;
|Patch Set 2:

This driver was based on an assumption that the DGT timer was being used in coreboot phase. Since we now have a GPT based implementation of the timer in coreboot, we will keep the same here.
GPT runs on the sleep clock, 32KHz and will be assumed to have been enabled in the coreboot phase.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1:

We plan to use DMA during SPI NOR operations.
We also plan on keeping the same MMU settings for depthcharge, which will use EMMC in DMA mode.

Of course, when we agree on the architecture, we can have more clarity on where to include this.
|Patch Set 1:

(1 comment)
|Patch Set 1:

mapping the memory regions should be in board as each board can have a different mapping. Also, each board can individually choose whether to enable mmu at all.

I will redo the patch to exclude everything before mmu_init.
|Patch Set 1:

Everything other than DRAM (IO mapped device and IMEM)and even a part of DRAM is mapped as uncached.
|Patch Set 1:

this is more for clearing the interrupts that the previous stage hasn't yet cleared.
This is more so that we/ kernel do not accidentally get interrupts not intended for the stage.
For instance, we have previously had L2 error interrupts which pose such problems.
We also think adding threading support to coreboot will be necessary for faster boot up speeds. Is there any opinion regarding this?
|Patch Set 1:

(2 comments)
|Patch Set 2: Verified+1

updated bug number
|Patch Set 3: Verified+1

update bug number
|Patch Set 2:

(4 comments)

P0 just needs a change of gpio's which will probably be taken care of by yogesh.
The mmc driver itself will not change.
I will upload a final version today/ tomorrow and will indicate so in comments so that you can do a detailed review.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 3:

Think this would make more sense in depthcharge as this is customization for kernel
|Patch Set 7:

There should be a TODO for all board cleanups and anyway the change should be part of depthcharge. Coreboot should provide proper hooks for such a function which can be invoked from depthcharge.
|Done
|Done
|Done
|Upon doing a bit of research, I think readline() would be even better.
|Nope, I just mistakenly thought that read() read all of it at once...
|Done
|%E turns the int into scientific notation, which is what the function generator takes.
|Done
|Done
|Done
|Done
|Done
|Sorry, this was from when the python linter was yelling at me to have two lines before each function declaration.
|Done
|I added it to the end of each noise test like you suggested as well as during the fingertip checks, before the gesture begins. I wrote a function to handle turning the noise off during the fingertip checks, but am still thinking of a way to cleanly integrate it with turning the noise off after each gesture. Perhaps after self._execute_control_command(control_cmd) in the function 'control'?
|The problem with that is that it gets called after each gesture anyways, which is what you were worried about earlier.
|Done
|Done
|Done
|It was an accident, sorry. I'll change it back
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I ended up making two new gestures in test_conf.py just for these extended tests, do you think that works better?
|Done
|I tried that, but the value in GV.EXTENDED_FREQUENCIES is the one that is used in the html writeup in the end, so what you end up getting in the report is 

(8000, 'max_amplitude', ....)

and I felt that having '8000Hz' added more value. What do you think about this?
|I have no idea what happened here and why it was changed. I'll change it back, sorry!
|Done
|I didn't add it in because we had concerns about stressing the robot tips by drawing lines with them for 4 hours.
|Done
|Do you think adding an explanatory comment would suffice? Or maybe a name like, gesture_names_equipment_required instead.
|Hm...that name doesn't make as much sense in the context of filtering for COMPLETE mode though, since there are plenty of tests that require a robot in complete mode.
|Ok, I was just thinking I would write this for now, in case the robot got fixed in the future. Is there a way to 'soft' delete this, so you don't have to rewrite it again?
|The first two noise tests are meant to be part of the ROBOT mode tests, and thus need to be in the complete list. However, I will remove the extended test.
|Done
|Done
|The line needs to be called once per packet for the state machine to work. Not sure why exactly, but that's the way it's used in the rest of the code and when I remove the line it stops working.
|Done
|Awesome, I learned something today.
|Done
|It's not written in the documentation, but line.py and tap.py do accept a delay parameter. Some instructions are given for line.py in the print statements on lines 51-52. In tap.py the delay argument is parsed on line 47 and used in line 110. I remember nearly rewriting tap.py a few weeks ago to add in the delay myself before I realized it was already there. But the delay does work, I tested it with the robot.

Should I open another CL to document the delay parameter?
|Done
|Oh, yeah. self.device is, but since self.validator is my own parameter it is not.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(8 comments)
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1
|Uploaded patch set 2.
|Patch Set 2:

(8 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

Accidentally removed some files things I should not have
|Restored

Abandoned button did not do what I expected.
|Patch Set 2: Code-Review-1
|Abandoned

Messed up git somehow. Trying again.
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2:

(15 comments)

Thanks for the feedback! I'm in the middle of making changes, but I had some questions.
|Uploaded patch set 3.
|Patch Set 3: Code-Review-1
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)

The first two noise tests are meant to be called in ROBOT mode, not in NOISE mode. That is why we had the workaround to filter the noise tests out.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 8: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 8: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(9 comments)

Some replies to your comments.
|Uploaded patch set 3.
|Abandoned

Git issues
|Restored

Trying to resolve git issues...
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1

Git issues resolved.
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned

Accidental CL due to cherrypicking mistake.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Remove the comment or print the line.
|Remove the comment or print the line.
|Space after &quot;.&quot;
|You don't need the last â€˜ï¼�â€™.  tab.Navigate('chrome://settings')
|Correct. It is a real FSI version.
|Please add checks if CHROMEOS_AUSERVER=&quot;http://ttracy.mtv.corp.google.com:15001/service/update2&quot;
and CHROMEOS_RELEASE_VERSION=&quot;0.0.0&quot; are correct.
|Should check update-engine is stopped
|Done
|Done
|Done
|I thought vendor, appid and hwid have cleaned up already. Here is the CL. https://chromium-review.googlesource.com/#/c/171161/
|Done
|Done
|Done
|Done
|Done
|Unfortunately, block = 2645920, 2645920*512/1024/1024 = 1291.95 MiB.  Also 1240 MiB failed the test ./cgpt.py write base legacy_disk_layout.json test.base.  I would consider 1322960 K more readable.  I changed K to KiB tho.
|same as line 133.
|Modified README.
Added more details.
|removed
|Yes. And indeed the result is different due to the rounded up to the MiB. According to comment in patch set 5, it is fine. Should I change it back to KiB to have better result?  Also &quot;./cgpt.py write recovery legacy_disk_layout.json test.recovery&quot; due to the same reason.
|Done
|Done
|Done - rewrote and added here.
|Done
|Done
|Done
|Done
|Done
|You are right. This supports all the tests to be passed.
|You are right. This supports all the tests to be passed.
|Added above.
|Done
|Done
|Done
|The plan is add the option for alignment, Don would add alignment later in the disk_layout.json. This is to avoid alignment maintained by hand in the future. https://code.google.com/p/chromium/issues/detail?id=333091
|I think we should make it 2. Sometimes, we rerun 2-3 times.
|TODOs should include the string TODO in all caps, followed by the username or bug id of the person or issue with the best context about the problem referenced by the TODO, in parentheses.
|Patch Set 4: Code-Review+1
|Patch Set 7:

(2 comments)
|Patch Set 4:

(2 comments)

Nit...
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, approved; Ready; Verified

+2 inherited from Gilad comment.
|Patch Set 1: Looks good to me, approved


|Patch Set 1: Looks good to me, approved


|Patch Set 2: Looks good to me, approved


|Patch Set 2: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2:

@ sosa: When I didn't have these board in the file, I get unknown board error. So I added and test it today. All test on all boards ran successfully.

@ Mike: I agree that we should be a centralized place for this. I am not sure why we aren't creating/using a centralized place. We have a release going on, so I had to add this in for now and ran the test for today's release.
|Patch Set 2: Ready; Verified


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Ready; Verified


|Patch Set 1: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 9640226d850b41aa2453e1d359dd18c3ed1232bc
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(3 comments)
|Patch Set 3: Commit-Queue+1 Verified+1
|Change has been successfully cherry-picked as 26c74f0118a664a0ee67edd6095f0b0387e64c7a
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(6 comments)
|Uploaded patch set 3.
|Patch Set 3:

(6 comments)
|Uploaded patch set 4.
|Patch Set 4:

(7 comments)
|Uploaded patch set 5.
|Patch Set 5:

I got this number &quot;2645920&quot; from a newly repo sync'd code.
|Patch Set 5:

I tested it with rounded up to MiB, the test failed. (the outcome is not exactly the same.) If you want to see where exactly it failed, you can run the following tests.  If we are okay with the difference in test results, I can change it to MiB instead of KiB.

./cgpt.py write base legacy_disk_layout.json test.base
./cgpt.py write recovery legacy_disk_layout.json test.recovery
../../../scripts/build_library/cgpt.py write base disk_layout.json
test.base
../../../scripts/build_library/cgpt.py write recovery disk_layout.json
test.recovery
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Patch Set 7:

(3 comments)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1 Verified+1
|Uploaded patch set 10.
|Patch Set 10: Commit-Queue+1 Verified+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Patch Set 10: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 10: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Abandoned
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)

lgtm.
With nit
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|We can't just keep _duts.
In _duts, there may be duts that are disconnected(we keep they for factory_restart which won't raise DPCHEvent).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6: Commit message was updated.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 8: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1

(25 comments)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 7: Patch Set 6 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(5 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(4 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7:

(1 comment)
|Uploaded patch set 9.
|Patch Set 9: Commit-Queue+1 Verified+1

(2 comments)
|Patch Set 9: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 4: Commit-Queue+1 Verified+1
|Patch Set 4: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 4: Commit-Queue+1
|Patch Set 4: -Commit-Queue
|Patch Set 4: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 2:

(8 comments)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6: Commit-Queue+1 Verified+1
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|No, I didn't. But I'm also not sure where to find the up-to-date guidelines for these comments.
|setup() is run when the autotests are built (on the host). See https://www.chromium.org/chromium-os/testing/autotest-developer-faq#TOC-Adding-binaries-for-your-tests-to-call-as-part-of-the-test. So I would imagine that if make fails the autotest build would fail which would make sense.
|This basically just looks like the platform_Perf autotest (https://chromium.googlesource.com/chromiumos/third_party/autotest/+/a2937ffcd4db00706f4891ff66d88f882e2cb9ec/client/site_tests/platform_Perf/platform_Perf.py)
|So if I wait for the output with .wait() the test hangs when running. We can talk about this in person.
|Done
|Done but PTAL
|Done
|This should have been removed before I uploaded. My bad.
|Yes. That plus the attribute lines in the test program.
|Done. Good point.
|So I haven't really had any issues catching the callstack (mostly because of the loops in main).
|Done
|Done
|Done
|Done
|Done
|No, if the source fails to build then the autotest will fail to build (as it should). Please see Autotest FAQ (https://www.chromium.org/chromium-os/testing/autotest-developer-faq#TOC-How-do-I-create-a-test-that-requires-compiling-code-) or any other autotest that builds sources.
|Done
|Nit: I think removing this makes sense but I just want to double check that you meant to remove this.
|just need to add the EXPECT here :)
|I would propose 60-20-20 split for these since callgraphs will be used before branches given CWP's current priorities.
|I would suggest 65-20-5-5-5 here as well.
|And move this to the default file (remove the core file since we have no reason to discriminate core devices).
|core here should be removed
|These test cases should be organized within the same function &quot;TestGetOddsFilenameForCPU&quot;. Further the go testing format would probably be more useful here. That is, define a struct with fields for each input and expected output (cpu, model_name, wanted_filename), then create a list of structs with each element being a test case, then call the function in a loop over the struct array. Let me know if you have questions.
|We want each x86_64 board (not just core and celeron2955) to send back cycles and callgraph so we can't just copy the 'unknown-cpu' version. This is true for each known cpu type.
|This (and the files themselves and everything that goes with it) should be named a x86 (not the specific version i686). E.g. kx86CPUOddsFiles
|formatting here
|In what cases would they not match or only partially match. Is the data definitely not valid if they don't match?
|in the autotest?
|// Returns the number of entries.
|kDelimiter if that's what you are using it for.
|The generic is not needed if we aren't specifying anything anymore.
|Nit: I'm not sure this is the most efficient way to do this but my python is pretty rusty.
|This should probably be outside the loop so we know which succeeded and which failed (unless one failing means that the others shouldn't be tried)
|Why should this fail the test?
|Do we use i(d)TLB-misses for anything? I would say leave these out until we need them.
|Is this line formatted correctly?
|Can this comment be removed as well?
|Why is this a pointer in the first place? (Everything else is const&amp;)
|Are we keep cross endian support?
|Why is this NOLINT?
|Done
|Are there any guidelines for changing these enums? This seems like it could be problematic
|What is the reason behind moving this in this patch?
|These comments are a bit confusing, can you elaborate?
|Are there different rules for the ':' for explicit vs not constructors?
|This doesn't seem to exist (I'm looking at https://console.developers.google.com/storage/chromeos-localmirror/distfiles/?prefix=platform)
|I think you need another space here.
|Is GZFileToBuffer used in many places?
|Did you mean to leave this as a comment?
|are
|Nit: if these are left as comments can you check if they need a space as well (after the #)
|Needs ,1.
|Similar to objdump below cmd should be nm if possible.
|Since this is a filename and not the actual data it should be named  *_path or *_filename.
|? line length here looks off
|This function is clunky and doing too many things (at least more than it says). Please look over this again.
|Please add better comments here and throughout.
|I think you might want a line before this comment? Please double check.
|This should have a comment above it too.
|closing quotation mark
|Should there be an empty line here?
|PerfDataProto has a grouping message StringAndMd5 (or something like that). Can you either use that here or factor it out of both files into a quipper_common.proto?
|Please comment on when it is used
|If you'd like to try then remove the md5_prefix strings here.
|needs to be updated
|Is the arg after perf guaranteed to be the subcommand?
|if this is a stat command we must also add -v
|I think we want to do that here because we want to say that quipper only parses 'stat -v' output so we hardcode -v in quipper.
|Done
|Done
|Done
|Done
|Done
|Done
|Added &lt;cstdlib&gt; (like utils.cc).
|Done
|Done
|Done
|Done
|Done
|I've added support for the overall time given by the -v flag. -I support would take more work and I don't think we plan to implement it until someone needs it so it's more of a Feature Request than a TODO from what I see.
|Done
|The _test file needs the full declaration. I'm not sure how else to make that work.
|Done
|Done
|Done
|Done
|No, if ScopedTempFile fails then _path is empty (according to the class comments) and we don't want to continue the test in that case.
|Done
|Done
|Done
|Moved to a new function. Thoughts on the function name and where to put it appreciated. I think the current name of the function name decently describes what precision to expect.
|Done
|Whoops, take 2.
|Done PTAL
|Done
|Done
|Ack. This is just a test string.
|Ack. This is a copy of the exact output including the extra spaces after r02c4. I have added an extra empty line to the small input above instead.
|Done
|Done. Made all names consistent.
|Done
|+1. Done.
|Shoot. Done.
|I think either both should be &lt;unit&gt;As&lt;type&gt; or both should be &lt;unit&gt;&lt;type&gt;. Similarly either Sec and Ms or full names.
|Done
|Done
|Done
|TODO: This part will need to be implemented within PerfRecorder
|and -v will be added as well
|Are we sure these don't fail/crash on all arm machines? I think there is an autotest for this?
|In that case I would say move this to a different cl with tests/autotests for arm.
|Can you add the perf stat command as well
|We should use braces for all if statements (at least we do in other places in this file.)
|Is this still explicit?
|As a side note if we want to have a condition on the value of this we should explicitly declare each value.
|I mean that in the enum you should specify values, e.g. 
  FATAL =0,
  ERROR =1,
  INFO=2,
  WARNING=3,
or whatever is appropriate in order to ensure the FATAL is the smallest, especially if you want to exit on that condition.
|Use begin/end since that's what you are using (mostly) when calling this.
|Is this true? The site you pointed at earlier doesn't seem to agree: http://man7.org/linux/man-pages/man1/perf-mem.1.html
|Does this take a long time?
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

&gt; (1 comment)

Done
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1

I can't imagine the unit test error has to do with this change so let's retry.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 1:

(15 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(4 comments)
|Patch Set 1:

PTAL
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1

I can't imagine the unit test error has to do with this change so let's retry.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Are there any users of Quipper that may want/need FINISHED_ROUND events? If they or us need these events what would need to change?
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Verified+1 Trybot-Ready+1
|Uploaded patch set 4: Commit message was updated.
|Patch Set 4: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4: Commit message was updated.
|Patch Set 1:

(2 comments)

I think what we want is: toplevel-cpu_architecture (x86, x86_64, armv7l, unknown) and under that a default.txt (not unknown.txt) which sends back the default for each architecture (cycles and callgraphs for each) as well as a file for each specific chip (in this case only celeron-2955 is the only specific one). So:

commands/armv7l/default.txt
commands/x86/default.txt
commands/x86_64/default.txt
commands/x86)64/celeron-2955u.txt
|Patch Set 1:

sorry, and:

commands/unknown.txt (which only has cycles)
|Patch Set 2:

(4 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4:

Cool. You should also test one of each type of x86_64 and x86_32. So using the dashboard: quawks, link, parrot, x86-alex
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)

perf_tool.cc should probably have tests but if there is something else that covers it then fine
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

I think this is alright for the most part. I'm just not sure it's the best way to fix one unsafe call (unless there is more background that is missing?)
|Patch Set 1: Code-Review+1

Please ask Bhaskar or Tipp to take a quick look to make sure we didn't miss anything weird.
|Patch Set 1: Code-Review+2
|Patch Set 1:

(1 comment)

Have you tested just this change by itself? What happens if this change goes in but the follow up doesn't?
|Patch Set 1:

Ah, the depends tree and my emails came in different orders. Please just check for each set of patches in order that they are still green.
|Patch Set 1:

Please make sure to test all dependent code.
|Patch Set 1: Code-Review+2
|Patch Set 1:

What happens when you CHECK inside perf_serializer? Also you'll want to add another reviewer that knows more about device memory management.
|Patch Set 2: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 5: Code-Review+2
|Patch Set 7: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)

One formatting question but it looks fine
|Patch Set 1:

(1 comment)
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2

Nevermind, my eyes were playing tricks on me.
|Patch Set 4: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1:

(2 comments)

Please add Tipp to review as well.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2

(1 comment)

How long does this take to run?
|Patch Set 4: Code-Review+2

(1 comment)

LGTM after small fix.
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review+2

Changes look good. Thanks.
|Patch Set 1: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2

(1 comment)

Please verify all tests before committing.
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 7: Patch Set 6 was rebased
|Patch Set 2:

(4 comments)
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 6: Code-Review+2
|Patch Set 6: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(14 comments)
|Uploaded patch set 3: Patch Set 2 was rebased.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Patch Set 1:

(12 comments)
|Uploaded patch set 7.
|Patch Set 7:

(6 comments)
|Uploaded patch set 8.
|Patch Set 8:

(3 comments)
|Uploaded patch set 9.
|Patch Set 9:

(2 comments)
|Uploaded patch set 10.
|Patch Set 10:

(1 comment)
|Patch Set 10: Verified+1
|Patch Set 10: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

(1 comment)
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Updated for Counter autotest as well. PTAL
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: -Code-Review

Need to undo this for SandyBridge
|Patch Set 3: Code-Review+2
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1

The errors seem to be from different tests. Let's try again.
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1:

My only concern is that this will show as passing when it isn't on some architectures. Is there some guidance on when/where to use TEST_NA or other return values?
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 1:

Awesome, thanks for getting started on this so quickly.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 4: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

Why is this happening? And how did you determine each value in test_files.h?
|Patch Set 1: Code-Review+2

Sorry, just read the bug. Okay, jso still just wondering how did you determine the values?
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|added a counter for 10.  I didn't add the extra logging since we probably already have 10 errors in the log.
|Good catch!
|This is a failsafe.  We don't need this counter at all for it to work.

David was worried about a particular failure case that session manager becomes ready but the DBus call &quot;EnableChromeTesting&quot; keeps failing for whatever reason.  Then we limit our max tries to give up eventually.
|Done
|Done
|It is used as a decrementing counter.  10 is the initial value.  I can declare another constant for 10 if you want.
|Done
|Done
|Done
|Updated it to execute after the current dbus iteration is complete. 

I thought about the new thread/process approach, but with that we are losing control of the exact timing.  So if the deadlock is caused by timing (the comment is not clear on why),  then new thread will not help.
|so how it is not :) repo upload would complain if otherwise.
|unique_ptr will complain.  I added a new namespace for it.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Yes, this constant is shared by a couple files.  This is the only shared constant introduced by this new remote debugging feature.  I have not looked but there might be others for existing code. 

We can have another cl that refactors existing code if needed.
|Done
|Done
|Done
|Done
|Updated.

I was confused too.  The Chromium codebase seems to do exactly what you said.  But then I looked at service_constants.h and it was the opposite.  And service_constants.h probably is the largest const file :)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|updated to a vlog.
|Done
|Done
|Done
|is there any tool to check this?  I noticed sometimes repo upload will show errors about explicit include, but not for this.
|It feels a bit unsafe not to run destructor.  Is it common practice in C++ code?
|I can do that.  Do we want to update the other pointers to scoped ptr?
|Who owns the object and runs the destructor?
|I agree it works now.  But it sort of breaks the boundaries between the container and the classes inside.  The container now must know it is safe to not run destructor and the contained classes use nothing requires explicit release.

Added TODO.
|Done
|Done
|Done
|Done
|Done
|Done
|moved this to a separate file since it grows big.  I have it in debugd namespace though.  Let me know if you still want to move it to &quot;internal&quot; namespace.
|Done
|Done
|Done
|Done
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1 Trybot-Ready+1
|Uploaded patch set 3.
|Patch Set 2:

(9 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 3:

(10 comments)
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)
|Uploaded patch set 7.
|Patch Set 6:

(1 comment)
|Patch Set 7:

(4 comments)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Code-Review+2 Verified+1 Trybot-Ready+1

fixed a previous rebase-update merge mistake I made which caused the build to break.

Also added another two conditions before decrementing the counter and hopefully it is clearer.

restore previous +2
|Patch Set 9:

Yes. it was a bad merge when I was uploading the last patch.
|Patch Set 9: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1 Trybot-Ready+1
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(13 comments)

PTAL
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 2:

(3 comments)

I have to make some changes to the logic.  Now in addition to enable remote debugging during debugd init.  I have to also listen to session state change and re-enable it each time when session stopped.  It seems the session is recreated each time after user log out.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 4:

(2 comments)

PTAL.

Updated the code to handle the potential timing problem you mentioned.  Now it would try to enable remote debugging during Init.  If that fails, the LoginPrompt signal should give it a second chance.
|Uploaded patch set 7.
|Patch Set 6:

(8 comments)

I have seen it enables on LoginPrompt.  It shows the the desktop background image and quickly flashes once.  Noticable but not bad.
|Uploaded patch set 8.
|Patch Set 7:

(14 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 8:

friendly ping...
|Uploaded patch set 9.
|Patch Set 6:

(1 comment)

Should we wait for Ben?
|Uploaded patch set 10.
|Patch Set 9:

(1 comment)
|Uploaded patch set 11.
|Patch Set 10:

I pinged him,  no reply yet.  I will wait a little bit.
|Patch Set 11: Code-Review+2 Verified+1 Trybot-Ready+1

restore previous +2.

Talked to Ben but he is in meetings.  He is OK as long as Jorge +2.
|Patch Set 11: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 11: Trybot-Ready+1
|Patch Set 11: Commit-Queue+1
|Patch Set 11: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 11: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 11: Commit-Queue+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Trybot-Ready+1

If the call to session manager fails,  debugd will ignore the error and still enable the other debug features.  It only affects the chrome remote debugging which will not be turned on.
|Patch Set 6: Commit-Queue+1
|Patch Set 6: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

Dan, we need your help :)

I read through chrome_setup.cc there seems to be a few ways to setup command line flags:
  1. Check the existence of a file
  2. /etc/chrome_dev.conf
  3. Run a bash script and check the output
  4. /etc/ui_use_flags.txt

2 and 4 seem not a good fit.  Is 1 or 3 the preferred way?
|Uploaded patch set 3: Commit message was updated.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2:

Updated the commit message.  Thanks for the heads up.
|Patch Set 2: Commit-Queue+1 Verified+1 Trybot-Ready+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+2 Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Verified; Looks good to me, approved; Ready


|Patch Set 1: Looks good to me, approved

Not reviewing code, just acknowledging this should be merged.
|Patch Set 1:

Not reviewing code, just acknowledging this should be merged.
|Patch Set 1: Looks good to me, approved

Not reviewing code, just acknowledging this should be merged.
|Patch Set 1: Looks good to me, approved

Not verifying code, just approving that this needs to be merged.
|Patch Set 1: Looks good to me, approved

Not reviewing code, but approving for merge (code was already approved for previous merge to trunk).
|Patch Set 1: Looks good to me, approved


|Patch Set 2: Verified; Looks good to me, approved; Ready

Reviewed on waterfall page - lgtm
|Patch Set 1: Verified; Looks good to me, approved

Approving for merge to the branch; code was previously reviewed to merge to master.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 9680328535d595b50afc06f0bfdf12f8ef31fdd5
|Patch Set 1: Verified; Looks good to me, approved


|Change has been successfully cherry-picked as 9bdad5b3a8bf0b9b2db79acc51186ce3fdaec7aa
|Patch Set 1: Looks good to me, approved

Reviewing for merge approval to branch only.
|Patch Set 1: Looks good to me, approved

Reviewing for merge approval to branch only.
|Patch Set 1: Looks good to me, approved

Reviewing for merge approval to branch only.
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as d7215b938c14ad522cd2ffa31b2a7fa76b578f42
|Patch Set 2: Reverted

This patchset was reverted in change: Ib2da794c31841dfe316226a3d577b5b7c764a43e
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 2c45067484ed3b4476b27ff68babea451e435ddd
|Patch Set 1: Looks good to me, approved; Ready; Verified

Merge approved, submitting.
|Change has been successfully cherry-picked as 3c6e5813bc50228e13940b691413561a369fe44b
|Patch Set 1: Looks good to me, approved; Ready; Verified

Chumping this into the mini-branch per approval from RTC in order to generate a build tonight with this CL.
|Change has been successfully cherry-picked as 7c3548c603dd0da0e00bb37679e5a51a4e84710c
|Patch Set 1: Looks good to me, approved; Ready; Verified

Chumping this into the mini-branch per approval from RTC in order to generate a build tonight with this CL.
|Change has been successfully cherry-picked as 808856df7537d7aa9bed95123139db9995e91546
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 65685a0e4c3cbf00189448109f09cef329da982d
|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as d09613c55667ed35a613b403599172a5a51b4006
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as 3e58c7e8a2e3aa8e898444e4559f7a68a80c879c
|Patch Set 3: Reverted

This patchset was reverted in change: Ia41255e476a7ee198ac9fb49fed45bbbb1de2ba6
|ok if it's unique
|OK. Thanks!
|Done
|Done
|Done
|Done
|Done
|Now there isn't. 
By default I want to skip only when resources contains none file, but finally didn't do it. Should I remove it?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Patch Set 5: Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Patch Set 6: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 6: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

all fixed.
|Patch Set 1:

(2 comments)
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 1:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|These aren't in chromium anymore either. Might as well remove them and close this bug.
|These aren't in the Chrome codebase anymore. We can remove them.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|yea let's just get the basic stuff in.

Removed for now.
|Done
|Done
|Done
|This logic doesn't map from the old logic, you need to negate the dev-&gt;le_state.svc_resolved too
|I think the previous method of determining the list and then only having one foreach loop is cleaner than the duplicated code 3 times here.
|I know this isn't your code, but a goto for 2 lines of code?
|These three copypasta except for the attributes/comments.  Maybe refactor?
|nit - trailing whitespace
|The spec says you run this in three different sizes, but you completely replace the request here, this is just doing the same thing three times. 

Either: make the encoding invalid in a smarter way or maybe we only need to do this once.

The test spec isn't specific on how it is invalidly encoded.
|See below on consistency.
|Prepend here too for consistency, and maybe above too (where it's just True/False). (sorry I didn't see this one before)
|Call this SERVICE_CLASS_ID_LIST_ATTR_ID to follow the Spec, or SERVICE_CLASS_ID_LIST to follow the GROUP_ID constant from below.
|It's simpler (and likely faster) to do:
sorted(set(all_services))
|indeed. I have a fix for this.
|This will need to change too. I could change os_requirments to be a tuple of paths for keys, one of which must exist.

Alternately it could be a non-hard-failure to be missing these, and the log would include the suggested package.
|nit: spelling
|This can be shortened to if supports_add_device == bool(flags &amp; bluetooth_socket.HCI_PSCAN)
|Only using current_settings from this tuple, maybe pull it out using self.device.read_info()[4] like with get_dev_info() later.  Similarly later.
|This file is unexpected wrt the commit message.
What does this do that bluetooth_Sanity_Discovery doesn't do?
|These weren't copied over right.
|Does this need to be done twice?  It should already be done by the dance done above, yes?
|The idea is yes. if match-&gt;owner is null then we are not matching on owner.  Similarly for match-&gt;path.  So you can match just path or just owner (or &quot;any ad&quot; but that isn't very useful)
|This is reasonably generic - you can just say service UUIDs to reconnect and add the AG UUIDs.  Maybe term change to services_to_reconnect,  retry_devices, retry_data, etc.
|missing break here
|There isn't a good reason to have this separate from ag_cb.  Just put this code at the top of ag_cb.
|I'd swap the order of these.
|Patch Set 1: Code-Review+2

(2 comments)

just nits if you want to deal with that bug
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2

lgtm
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Uploaded patch set 2.
|Patch Set 1:

(4 comments)

Just waiting on Miao-chen to check the Media Transport component of this.
|Patch Set 3: Published edit on patch set 2
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 1:

(2 comments)
|Patch Set 5: Published edit on patch set 4
|Patch Set 4:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 4:

(3 comments)
|Patch Set 6:

(1 comment)
|Patch Set 7: Trybot-Ready+1
|Patch Set 7: Verified+1
|Patch Set 7: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Trybot-Ready+1

ping.  Does gerrit not mail people when Verified+1?
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Uploaded patch set 3.
|Patch Set 2:

(3 comments)
|Patch Set 3: Verified+1
|Uploaded patch set 4.
|Patch Set 3:

(2 comments)
|Patch Set 4: Verified+1
|Patch Set 4: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review-1

You also need to remove the experimental guard around the initialization of the advertising manager in the src/adapter.c
|Patch Set 2: Code-Review+2
|Patch Set 5: Code-Review+1

LGTM.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2:

(3 comments)
|Patch Set 3: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1 Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Code-Review+1

(2 comments)
|Patch Set 2: Code-Review+1

LGTM. Can't +2 yet. :/
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 3: Code-Review+1

Fair enough justification on my P3 comments.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

(3 comments)
|Patch Set 1:

Note that I cannot +2 in gerrit yet.
|Patch Set 2: Code-Review+1

lgtm
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+2
|Patch Set 1:

(2 comments)
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 2: Verified+1
|Patch Set 2: Trybot-Ready+1
|Patch Set 2: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 3: Published edit on patch set 2
|Patch Set 3: Verified+1
|Patch Set 3: Trybot-Ready+1
|Patch Set 3: -Trybot-Ready

Trybot-Ready label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Trybot-Ready+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

(4 comments)
|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Patch Set 3:

What does &quot;commit ready&quot; mean?
What is necessary for &quot;commit ready&quot;?
|Patch Set 3: Abandoned

Submitted in a different change.
|Patch Set 1: Verified


|Patch Set 1:

[This is Erik, on Midori's behalf.]

I would love to see IPv6 enabled on a global basis.  However, that sounds like an extraordinarily large task: to fully test the entire system for IPv6 readiness.

I agree with the approach of &quot;try it and see&quot;, it's really the only way to truly test everything.  But I'm concerned that the scope of testing is too large for the time we have for this particular project (Midori's internship).

Among other things, (to pick a few other packages out of this file that we'd probably need to test) I have concerns about:

  * Is the IPv6 &amp; 802.11x interaction bug fixed?

  * I don't have access to an IPv6 VPN solution, so I'm not sure how to test that.

  * I don't have access to an IPv6 LDAP environment to test that either.

I think the test plan for all these things and more will span several months, no?  But I don't know what the test setup is or what it would require.

I'd err on the side of step-by-step progress at this stage.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Uploaded patch set 3.
|Patch Set 3: Verified


|Change has been successfully cherry-picked as afdd61f3967fa15c793d68676850bc53e69a53ba.
|Patch Set 1: Verified


|Patch Set 1: No score

I'm really sorry.
This is my mistake.
This project is not completed.
|Patch Set 1: Abandoned

Replaced with different change.
|Patch Set 1: Verified

This change is the same as Change I6ae69c5b.
As the error message comes out when I submit patch set, I submit a patch about module change again.
|Change has been successfully cherry-picked as a2e0098077651679a3cd0ab570d8b97b5223bfd4.
|Patch Set 1: Abandoned

Separated into other changes.
|Patch Set 1: Verified

Just package import.
|Uploaded patch set 2.
|Patch Set 2: Verified

I have fixed option support.
Thank you for your advice.
|Uploaded patch set 3.
|Patch Set 3: Verified

Had to rebase.
|Change has been successfully cherry-picked as 211f66b2a847cfb101b0b7d90dbc63628b9ded33.
|Patch Set 1: Abandoned

My mistake.
|Patch Set 1: Verified


|Change has been successfully cherry-picked as bdc4e32f78435177c8b61e6fe989a686933ec734.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 7.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Uploaded patch set 22.
|Uploaded patch set 23.
|Uploaded patch set 24.
|Uploaded patch set 25.
|Uploaded patch set 26.
|Uploaded patch set 27.
|Uploaded patch set 28.
|Uploaded patch set 29.
|Uploaded patch set 30.
|Uploaded patch set 31.
|Uploaded patch set 32.
|Uploaded patch set 33.
|Uploaded patch set 34.
|Uploaded patch set 35.
|Uploaded patch set 36.
|Uploaded patch set 37.
|Uploaded patch set 38.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Abandoned

Redid in another patch to fix build issues
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15: Commit message was updated.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Uploaded patch set 17.
|Uploaded patch set 18: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8: Patch Set 7 was rebased.
|Change has been successfully merged by Sarah Parker
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

&gt; (2 comments)
 &gt; 
 &gt; Thanks for the quick fix. Looks good, though see minor comments
 &gt; about whitespace.

Fixed, thanks for pointing out the bug :)
|Change has been successfully merged by Sarah Parker
|Uploaded patch set 1.
|Change has been successfully merged by Sarah Parker
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|DONE
TRACKPAD will be disabled during S3 -&gt; S5 and enabled during S5 -&gt; S3. 
TRACKPAD is a wakesource from S3 and hence cannot be done in S3-&gt;S0 case.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 3: Commit message was updated.
|Patch Set 3: Verified+1
|Patch Set 3: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(5 comments)
|Patch Set 3: Verified+1
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4: Verified+1
|Uploaded patch set 5.
|Patch Set 4:

(1 comment)
|Patch Set 5: Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Verified+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 3: Verified+1
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Verified+1
|Patch Set 1: Verified+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Verified+1
|Done
|Done
|Done
|Done
|Done
|Oh, OK. It's just because they were there even before I modified the code. I can remove them.
|Done
|Done
|This is just an example and suggestion. Since we are not sure in future what we will do based on different versions of glsl and there are so many versions of them. I suggest we just create some parameters for future use. 

If you guys think it will work, I'll modify other places accordingly.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Um, Ken gave some opinions about glsl 1.3 which is not core. So I'm not sure how I can change here.
|Done
|Done
|Done
|Done
|Done
|I added a note about the confusion of current version.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Why it's unnecessary?
|Done
|Done
|Done
|Done
|There is no &quot;Tf uintBitsToFloat(Tu value)&quot; in OpenGL 4.1, or OpenGL 4.2, this function appears in OpenGL 4.3 first. In OpenGL 4.1 and 4.2, there is only function &quot;Tf intBitsToFloat(Tiu value) &quot;. Guess we need to stick to the version 4.1, otherwise, it's even meaningless to emulate those 4 functions. Because those 4 pack_unpack functions are missing from 4.1, but in 4.2 already. (Gee, I wish the users have better graphics cards!)
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|exponent could be negative later. But I set the other two to uint.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I copied and pasted this one from MipmapTest.cpp. Deleted already.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I think it's a bit too verbose too. I wrote the test based on observing the test &quot;DebugShaderPrecision_test.cpp&quot;. Would you please find me an example in the project to do as you said? Or I can just remove most of the lines, but leave a few definition related lines?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|To be able to emulate the pack_unpack functions, I used 2 functions existing in GLSL 4.1: 
genIType floatBitsToInt(	genType x);
genType uintBitsToFloat(	genUType x);

These two functions appeared from GLSL 3.30
https://www.opengl.org/sdk/docs/man/html/floatBitsToInt.xhtml
https://www.opengl.org/sdk/docs/man/html/intBitsToFloat.xhtml

So I guess for the earlier versions we need to emulate even those 2 functions. 

But, because this task assumes that users' gpu support at least glsl 4.1. So I emulated the functions based on the existing functions in glsl 4.1
|Done
|Done
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 3: Published edit on patch set 2
|Patch Set 3:

Related patch https://chromium-review.googlesource.com/#/c/260232/
|Uploaded patch set 4.
|Patch Set 5: Published edit on patch set 4
|Uploaded patch set 6.
|Patch Set 7: Published edit on patch set 6
|Patch Set 5:

(3 comments)
|Patch Set 5:

(2 comments)
|Patch Set 8: Published edit on patch set 7
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Patch Set 10: Published edit on patch set 9
|Patch Set 8:

(12 comments)
|Patch Set 8:

(1 comment)
|Uploaded patch set 11.
|Patch Set 12: Published edit on patch set 11
|Patch Set 10:

(5 comments)
|Patch Set 13: Published edit on patch set 12
|Patch Set 14: Published edit on patch set 13
|Patch Set 12:

(3 comments)
|Patch Set 14:

(1 comment)
|Patch Set 15: Published edit on patch set 14
|Uploaded patch set 16.
|Patch Set 16:

Patch 16 is exactly the same as patch 14. I cherry-picked patch 14 and it can compile pass angle_unittests but cannot pass angle_end2end_tests. However, I ran the angle_end2end_tests for the latest synced build of project angle, it failed at the same place.

&quot;Program: ...IDIA.COM\angle\src\tests\Debug_Win32\libGLESv2.dll
File: libANGLE\renderer\d3d\d3d11\Image11.cpp
Line:593

Expression: result==((HRESULT)0x8007000EL)&quot;
|Patch Set 8:

The test can pass on my other PC. But it still failed on my major host machine today. 

OS: Windows 7. 
GPU: nvidia GeForce GT430
CPU: Intel i7 970 @ 3.2GHz

Failed Test: TextureTest/2.MipmapsTwice
|Patch Set 16:

I filed an angle issue:
https://code.google.com/p/angleproject/issues/detail?id=984

Correct, this issue has nothing to do with this patch. To reproduce this issue, I didn't even cherry-pick this patch. 

But this patch can pass the tests on other host machines (with different GPUs).
|Patch Set 17: Patch Set 16 was rebased
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 3: Published edit on patch set 2
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 4: Published edit on patch set 3
|Patch Set 4:

Jamie, I saw CONTRIBUTORS and AUTHORS:
https://code.google.com/p/angleproject/source/browse/CONTRIBUTORS
https://code.google.com/p/angleproject/source/browse/AUTHORS

There is no NVIDIA section. Should I create a patch and upload it?
|Uploaded patch set 1.
|Removed the following votes:

* Code-Review+2 by Shannon Woods &lt;shannonwoods@chromium.org&gt;

|Uploaded patch set 1.
|Abandoned

First try
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1
|Patch Set 3: Published edit on patch set 2
|Patch Set 1:

(6 comments)
|Uploaded patch set 4.
|Patch Set 3:

(6 comments)
|Uploaded patch set 5.
|Patch Set 6: Published edit on patch set 5
|Patch Set 4:

(10 comments)
|Patch Set 4:

(2 comments)
|Patch Set 7: Published edit on patch set 6
|Patch Set 7:

I read the slides &quot;ANGLE: From OpenGL to Direct3D and back again&quot;. On the slide 34, it mentioned something related to workaround of GL Driver bugs. There is one line: We'll have to port Chrome's workarounds into ANGLE. And another line: Available GL versions and extensions will vary much more than in D3D. I understand that Project ANGLE was first designed to run on Windows. However, it is reachitected to run on different platforms. My suggestions is due to the complexity of GL versions, maybe we should separate the GL related enum options from other shader related enum options. And set another parameter to notify the translator to translate input into hsls, essl or opengl. Because in a long run,  we might add more GL versions.
|Uploaded patch set 8.
|Patch Set 9: Published edit on patch set 8
|Patch Set 9:

I added the parameter SH_GLSL_410_CORE_OUTPUT and SH_GLSL_420_CORE_OUTPUT, then modified the code based on the behavior of SH_GLSL_150_CORE_OUTPUT.
|Uploaded patch set 10.
|Patch Set 11: Published edit on patch set 10
|Patch Set 12: Published edit on patch set 11
|Patch Set 13: Published edit on patch set 12
|Patch Set 14: Published edit on patch set 13
|Patch Set 15: Published edit on patch set 14
|Patch Set 15:

New patch is here:
https://chromium-review.googlesource.com/#/c/264840

I'm still modifying the code. I'll add reviewers later.
|Uploaded patch set 16: Patch Set 15 was rebased.
|Patch Set 9:

(9 comments)
|Patch Set 14:

(3 comments)
|Patch Set 16:

(1 comment)
|Patch Set 16:

I tested the shading language in this patch by Nsight. I first created another opengl project and used the functions I emulated in a shader. Then I wrote some test cases, basically different floating numbers including corner cases, such as pos/neg zero, pos/neg infinity, pos/neg overflow, pos/neg subnormal, NaN etc. To be able to see the output value, I used Nsight to debug the shaders and it let me see all the results in &quot;watch&quot; of Visual Studio. I uploaded the testcase shaders and the test result in the bug: https://code.google.com/p/angleproject/issues/detail?id=947

I didn't know a way to test the glsl emulation as we test hlsl emulation. To get the accurate result (floating numbers instead of just output color), this is the only way I can think of. 

Nsight can debug shaders very well.
|Uploaded patch set 17: Patch Set 16 was rebased.
|Patch Set 18: Published edit on patch set 17
|Patch Set 18:

Ken, I have a question, I read the code in src/tests/compiler_tests/. I only saw the examples of verifying these code paths are taken when expected. But I didn't see examples of verifying the output values of the shaders. There is only file which kinda verify the variables value: ConstantFolding_test. It checked the value by setting the value to a constant value. Should I use the same approach to check the output value? Thanks!
|Uploaded patch set 19: Patch Set 18 was rebased.
|Patch Set 20: Published edit on patch set 19
|Patch Set 20:

src/tests/compiler_tests/Pack_Unpack_test.cpp I uploaded is not the final version. I have some questions about it.
I will add more ASSERT in there. 

I saw some errors when I debug the angle_unittest project. The error is :

compiler_tests\Pack_Unpack_test.cpp(44): error: Failed
Shader compilation into GLSL 4.1 failed ERROR: 0:3: 'uint' : undeclared identifier 
ERROR: 0:3: 'u' : syntax error 

However, I checked the file src/compiler/translator/Types.cpp 

and found

case EbtUInt:                return &quot;uint&quot;;                 break;


I'm not sure why I get this kind of error. Thanks!
In addition, I'm writing a end2end_test. The plan is render to a texture and get the pixel color. I guess outputting color cannot cover all the test cases such as NaN or INF. But those corner cases are covered by the tests I ran using Nsight as I mentioned in the angle issue itself
|Patch Set 21: Published edit on patch set 20
|Patch Set 21:

Guess I didn't upload the project file, so the new file is not the solution explorer.
|Uploaded patch set 22.
|Uploaded patch set 23.
|Patch Set 24: Published edit on patch set 23
|Patch Set 25: Published edit on patch set 24
|Patch Set 25:

Thank all of you for the tips! Now the unittest can pass. I am still working on the end2end test. 

However, I still don't know how to correctly modify and upload the &quot;angle_unittests.vcxproj&quot; and &quot;angle_unittests.vcxproj.filter&quot; . 

I &quot;git add -f&quot; those two files and uploaded them in patch 23 and 24 as you can see. But when I tried to cherry-pick the package as experiment, I got the following error:

From https://chromium.googlesource.com/angle/angle
 * branch            refs/changes/32/260232/23 -&gt; FETCH_HEAD
error: The following untracked working tree files would be overwritten by merge:

        src/tests/angle_unittests.vcxproj
        src/tests/angle_unittests.vcxproj.filters
Please move or remove them before you can merge.
Aborting


Would you please help me?

Thanks!
|Patch Set 26: Published edit on patch set 25
|Patch Set 26:

Thank you guys!
So I  modified 
src/tests/angle_unittests.gypi
src/tests/compiler_tests/compiler_tests.gypi

I created a new repository and cherry-pick the patch, but I still cannot see the Pack_Unpack_test.cpp file appear in the Solution Explorer in VS. 

Do I need to extra things to make it work?

Thanks!
|Patch Set 27: Published edit on patch set 26
|Uploaded patch set 28.
|Patch Set 29: Published edit on patch set 28
|Patch Set 29:

Thanks! I cherry-picked the patch and ran gclient runhooks, and then I can see the file appears in the solution explorer. 
But after uploading the patch again after I ran gclient runhooks,  I cherry-pick the new patch, I still cannot see the file. 
Does that mean that you need to run gclient runhooks too?
Thanks!
|Patch Set 29:

Ken, I understand that I need to rerun. 

But how can I make you guys NOT need to rerun the command after you cherry-pick my patch?
|Patch Set 29:

Ah, I see. Thanks!
|Patch Set 30: Patch Set 29 was rebased
|Patch Set 31: Published edit on patch set 30
|Patch Set 31:

Hello, when I am writing the end2end test, I met another problem. I used the header &quot;#version 300 es&quot; in gl_tests/PackUnpackTest.cpp as I did in compiler_tests/Pack_Unpack_test.cpp, however, I got some shader compliation error: 'webgl_packSnorm2x16_emu' : no matching overloaded function found. 

I'm confused, which header should I include in which file in the end2end tests ?

Thanks!
|Uploaded patch set 32.
|Patch Set 33: Published edit on patch set 32
|Patch Set 33:

Thank you! Olli. 
I modified the code and I think I did the similar thing as in MipmapTest.cpp. But I still get some errors:

shader compilation failed: 
0(2): error C5060: out can't be used with non-varying fragColor
0(4): warning C7532: global type uint requires &quot;#version 130&quot; or later
0(4): warning C0000: ... or #extension GL_EXT_gpu_shader4: enable
0(4): warning C7532: global function packSnorm2x16 requires &quot;#version 420&quot; or later
0(4): warning C0000: ... or #extension GL_ARB_shading_language_packing: enable
0(5): warning C7532: global function unpackSnorm2x16  requires &quot;#version 420&quot; or later
0(5): warning C0000: ... or #extension GL_ARB_shading_language_packing: enable
0(2): error C5060: out can't be used with non-varying fragColor



I'm just confused. Would you please help me?
Thanks!
|Patch Set 33:

Hi, Jamie, after modified the line in ComplilerGL.cpp, I got more erorrs when debugging end2end test. 

For example, in MipmapTest.GenerateMipmapFromRenderImage tests, the errors are like:

MSVC++ Runtime Library errors:

File: compiler\translator\PoolAlloc.cpp
Line:45
Expression:PooloIndex!=TLS_INVALID_INDEX


File:common\tls.cpp
Line:101
Expression:index!=TLS_INVALID_INDEX &amp;&amp; &quot;SetTLSValue():Invalid TLS Index&quot;


In terminal:
unknown file: error: SEH exception with code 0xc0000005 thrown in SetUp().
unknown file: error: SEH exception with code 0xc0000005 thrown in TearDown(). 
[FAILED]MipmapTest.GenerateMipmapFromRendereImage, where GetParam()=ES3_OPENGL


Of course, for PackUnpackTest, the same error appears.
|Uploaded patch set 34.
|Patch Set 35: Published edit on patch set 34
|Patch Set 35:

Hi, Jamie, I tried it on Nvidia Geforce 750M, GT430 and NVS 4200M. I saw the same erorrs. At least Geforce 750M supports the latest version of OpenGL. Maybe I missed something.
|Patch Set 36: Published edit on patch set 35
|Patch Set 36:

Need to cherry-pick this patch first:
https://chromium-review.googlesource.com/#/c/272738/2

Thanks! Olli.
|Patch Set 35:

(7 comments)
|Patch Set 37: Published edit on patch set 36
|Patch Set 38: Published edit on patch set 37
|Patch Set 39: Patch Set 38 was rebased
|Patch Set 39:

Patch 39 was produced by rebasing 38 , and I modified the parent change number to Olli's change. Somehow there is some conflict. I'll solve it later.
|Patch Set 37:

(6 comments)
|Patch Set 40: Published edit on patch set 39
|Uploaded patch set 41.
|Patch Set 41:

I think this patch is ready.
|Uploaded patch set 42.
|Uploaded patch set 43.
|Patch Set 41:

(2 comments)
|Uploaded patch set 44.
|Patch Set 43:

(11 comments)
|Uploaded patch set 45.
|Patch Set 43:

(1 comment)
|Patch Set 45:

I think this patch is ready. Thanks!
|Patch set 46: Published edit on patch set 45.
|Patch Set 47: Patch Set 46 was rebased
|Patch Set 45:

(4 comments)
|Uploaded patch set 48.
|Patch set 49: Published edit on patch set 48.
|Patch Set 47:

(4 comments)
|Patch Set 51: Patch Set 50 was rebased
|Done
|no and it does not take \n either
|I avoided them in the previous version, where I used python XML parser. After leaving the parsing step to the closure library, I found that there is no need to avoid.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|The situation is:
For multiline result I send it to DeviceNodeSplit first, get a XML-formatted string, then send it to here. So the '&lt;'&amp;'&gt;'s should not be escaped.
But for single-line result it may go wrong.

Maybe I should call DeviceNodeSplit first even if the result is only a single line?
|Can't figure out how I could call &quot;&#124; grep&quot; without shell=True. :(
|To check if EC is available since check_output does not allow the execution to fail.
|Maybe I will convert the input hardware_name from string to a list of possible readable names(like ['Touchpad', 'Trackpad'] in the touchpad case) and search among all of them. Is that fine?
|I chose to search by strstr because the 'Name' in file ‘/proc/bus/input/devices’ contains not only the hardware name(like Touchpad). For example the touchpad is named &quot;N: Name=&quot;Elan Touchpad&quot;&quot; on my device.
How should I deal with it then?
|It's for handling the first case since tag_name is initialized ''.
My strategy is to save the previous tag_name read(which starts with '  ') in tag_name, read and store the content in tag_content until the next tag_name is reached.
|The HTML file generated shows it doesn't.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(14 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(3 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|&quot;unrestricted servers&quot; here may be a little confused.
|Done
|The latter is done.

What &quot;I think we can have more than one of these at a time.&quot; refers to?
|Done
|chameleon_host.py has its own func 'disconnect_tunneling' and tunneling_process is set as None originally. In its 'disconnect_tunneling', it detects whether the tunnel is None or not. I'm not sure if there exist such a case, that a host like current chameleon, has its own tunnel_process, and the tunnel remains None for some reasons, and want to use the shared function 'disconnect_ssh_tunnel' here to disconnect itself. So I add a judgement here, maybe such case won't happen and this part can be removed.
|Done
|Done
|Done
|close_fds=True is added

using shell=True will lead to 2 tunnel processes being created when this part of code is tested in moblab, 1 for goobuntu. It seems that different operation systems have different mechanisms for shell.
|Done
|after re-image of moblab, the requirement of sudo is gone.
|moblab should use this &quot;sudo&quot; scripts, should I add a moblab detection here or just ignore this case?
|Is it redundant to detect whether a tunnel is None or not before every call of &#124;disconnect_ssh_tunnel&#124;?

chameleon_host.py is planed to use rpc_server_tracker to create ssh tunnel, like other hosts (eg. servo), and the current codes of ssh tunneling will be removed.
|chameleon_host.py has its own func 'disconnect_tunneling' and tunneling_process is set as None originally. In its 'disconnect_tunneling', it detects whether the tunnel is None or not. I'm not sure if there exist such a case, that a host like current chameleon, has its own tunnel_process, and the tunnel remains None for some reasons, and want to use the shared function 'disconnect_ssh_tunnel' here to disconnect itself. So I add a judgement here, maybe such case won't happen and this part can be removed.
|Done
|Yeah I notice that, I reply an answer at change set 5 &amp; 10.
|chameleon_host.py has its own func 'disconnect_tunneling' and tunneling_process is set as None originally. In its 'disconnect_tunneling', it detects whether the tunnel is None or not. I'm not sure if there exist such a case, that a host like current chameleon, has its own tunnel_process, and the tunnel remains None for some reasons, and want to use the shared function 'disconnect_ssh_tunnel' here to disconnect itself. So I add a judgement here, maybe such case won't happen and this part can be removed.
|There may be an issue about cmd errors in repair process. I'm not sure.


When a job try to reset a DUT, it fails, and report error as:


base_utils:0268&#124; [stderr] bash: python: command not found
repair:0187&#124; Failed: Miscellaneous CrOS host verification checks
AutoservRunError: command execution error
* Command: 
    /usr/bin/ssh -a -x    -o ControlPath=/tmp/_autotmp_tke7QEssh-
    master/socket -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null
    -o BatchMode=yes -o ConnectTimeout=30 -o ServerAliveInterval=900 -o
    ServerAliveCountMax=3 -o ConnectionAttempts=4 -o Protocol=2 -l root -p 22
    100.96.51.212 &quot;export LIBC_FATAL_STDERR_=1; python -c \&quot;import cPickle\&quot;&quot;



and the following repair fails with the following error:



AutoservRunError: command execution error
* Command: 
    /usr/bin/ssh -a -x    -o ControlPath=/tmp/_autotmp_RQqIfSssh-
    master/socket -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null
    -o BatchMode=yes -o ConnectTimeout=30 -o ServerAliveInterval=900 -o
    ServerAliveCountMax=3 -o ConnectionAttempts=4 -o Protocol=2 -l root -p 22
    100.96.51.212 &quot;export LIBC_FATAL_STDERR_=1; status system-services &#124; grep
    start/running&quot;


Then I checkout the previous version to repair the DUT, it succeeds.


I checkout back, and repeat repairing the DUT. The repair fails.


But I re-verify the DUT, the verification succeeds.
|Task RepairStrategy.repair() is supposed to fix all verifiers in verifier_data, even if some of them has nothing to do with the repair_data? When veryfier_data and repair_data are generated in real cases, is there any requirements for the relationship between them?
|the final repair of DUT will be conducted here or in verifier.try_repair?
|In the above unittest about test_verify_fail, the log of fake_host use content '('FAIL', None, child_verifier.message)', not property 'description'. What's the rules of using 'description' and 'message' in different cases?
|A small question,
Error for AutotestHostVerifyError, and Failure for AutotestRepairFailure, what's the difference?
|oh, I mainly want to ask why one is ***Error, and another is ****Failure, I see the the docstrings are almost the same.
|Do we need to test whether the `verify()` method of every verifier is called once, if these verifiers are in a verify_data which has dependencies?
|understand
|exchange the order?
|I wrote a separate unittest file for testing. I will combine the unittest funcs to dev_server_unittest.py, and then submit the unittest changes.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Nowhere... without further considerations. I set it as a default value if timeout for run_ssh_call is None. 

Now it's changed to 1.
|Done
|Done
|Done.

Since some functions like &#124;get_control_file&#124; or &#124;stage_artifact&#124; which run &#124;run_call&#124; are decorated by function &#124;remote_devserver_call&#124; to handle retrying, these exceptions are captured by &#124;remote_devserver_call&#124;. 

The error.CmdError generated by ssh_call currently doesn't invoke a retry, just be raised as a DevServerException.
|Done
|Done
|Done
|Done
|Done
|Currently, the logic of using tunnel here is:
1. Create a tunnel, not to confirm whether the tunnel is ready to communicate.
2. Create a RetryingAFE, the afe will retry any command until the tunnel is ready to talk, which means we assume that tunnel will work eventually.


Just the same as the logic of using tunnel for servo, except for that servo retries the tunnel when it's created. AFE retries it afterwards.


If we want the RetryingAFE to handle &quot;re-create tunnel if the tunnel is down&quot;, we need to implement
1. confirming the tunnel for moblab is ready when it is created, don't use RetryingAFE to do this task.
2. Add a check in RetryingAFE, which says that if tunnel is used but not works, re-create it and confirm it works, then do retrying.


After discussion this offline with Fang, since only a small number of moblab-tests exist, the best way seems to be at this moment, just keep the original logic with moblab, and see whether tunnel is frequently broken in real test lab, and decide later if it's worth to entirely change the retrying mechanism for MoblabHost.
|Done
|Done
|Originally, an independent afe is created with a long timeout to check whether moblab is alive again after reboot.

New MoblabHost need to generate its own afe (self.afe) after reboot, in order to re-create tunnel. So the new self.afe has a longer timeout (default 5) than normal (default 1). 

Here we set it back to normal afe's timeout after verifying that moblab is alive.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I add it to RetryingAFE. 

Reboot only re-create self.afe using longer timeout_min, so in func _initialize_frontend_rpcs(), tko's timeout_min is set as the default value: self.timeout_min.
|unfortunately it can't... goes to 83 chars a line.
|Done
|Done
|done, add '\n\n\n' at line 1133.
|Done
|Done
|Done
|Done
|Done
|Done
|oh, it's a debugging message, not tend to change it to `cautotest`.

done.
|Done
|Done
|Done
|Add func `_add_idles()` to add idle DUT based on `_IDLE_MESSAGE_TEMPLATE`.

Done.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done for most cases.

some exceptions: use to_return to shorten a very long line.
|Done
|In def testDevserverHealthy, I test different calls for 'run_call' from different types of dev_server to make sure different types of dev_server call different run_call():

dev_server.CrashServer.devserver_healthy() --- use 'run_call' in DevServer

dev_server.ImageServer (AndroidBuildServer).devserver_healthy() --- use 'run_call' in ImageServerBase
|I don't understand it well. What I get now is that `SshConnectionTest` is not that precise for this class since it's basically for testing of `run_call`, so the class name should be changed to `RunCallTest`?
|Done
|Done, it's currently `CmdError`.
|Done
|Done
|Done
|Done
|Done
|Done
|Other errors like KeyError in the ACPowerVerifier are logged in `logging.info()`, why we use `logging.error()` here?
|Done.

But in the discussions, the developers want to see how to repair it when they see the verification errors?
|Done
|Done
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Verified+1
|Patch Set 2: Commit-Queue+1
|Patch Set 1: Code-Review+2

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

&gt; Uploaded patch set 4.

Changes in this revision:

1. Simplify the process of safe ssh connection with tunnel. Now it contains
two steps (in AbstractSSH):
a. call &#124;create_ssh_tunnel&#124; to create a ssh tunnel between local port and 
remote server.
b. call &#124;wait_for_connection_established&#124; to obtain a well-connected proxy,
the func will wait for the ssh tunnel's successfully establishment.

ServoHost, ChameleonHost, and rpc_server_tracker follow the same logic to
create safe ssh connection.

2. In AbstractSSH, remove &#124;rpc_port_forward&#124; since it does the same thing
as &#124;create_ssh_tunnel&#124;.

3. In AstractSSH, Change &#124;rpc_port_disconnect&#124; to &#124;disconnect_ssh_tunnel&#124; for:
a. the input arg 'port' is useless
b. the whole function is about to disconnect the existing ssh tunnel created
by &#124;create_ssh_tunnel&#124;.

4. Add a &#124;enable_ssh_tunnel_for_servo&#124; flag to enable/disable ssh tunnel for
servo.
|Patch Set 4:

(1 comment)

Changes in this revision:


1. Simplify the process of safe ssh connection with tunnel. Now it contains two steps (in AbstractSSH):

a. call &#124;create_ssh_tunnel&#124; to create a ssh tunnel between local port and remote server.

b. call &#124;wait_for_connection_established&#124; to obtain a well-connected proxy, the func will wait for the ssh tunnel's successfully establishment.

ServoHost, ChameleonHost, and rpc_server_tracker follow the same logic to create safe ssh connection.


2. In AbstractSSH, remove &#124;rpc_port_forward&#124; since it does the same thing as &#124;create_ssh_tunnel&#124;.


3. In AstractSSH, Change &#124;rpc_port_disconnect&#124; to &#124;disconnect_ssh_tunnel&#124; for:

a. the input arg 'port' is useless

b. the whole function is about to disconnect the existing ssh tunnel created by &#124;create_ssh_tunnel&#124;.


4. Add a &#124;enable_ssh_tunnel_for_servo&#124; flag to enable/disable ssh tunnel for servo.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(8 comments)

&gt; Uploaded patch set 9.

Despite the previous changes, &#124;_create_ssh_tunnel&#124; in Chameleon Host is changed to &#124;create_ssh_tunnel&#124; to make this CL fit for chameleon host. 

The whole change for chameleon host will be in a separate CL.
|Uploaded patch set 10.
|Patch Set 10:

(1 comment)

Too many redundant changes will be made for a seperate CL for ChameleonHost. So after trying, I decide to combine the CL of chameleomhost and servohost together.

For ChameleonHost, all the codes of the previous SSH tunnel construction codes are kept. They can be deleted after a complete test of the new codes in rpc_server_tracker.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

(1 comment)

New updates:

For Chameleon Host, we just add a enable_ssh_for_chameleon tag in this CL. 

The refactoring of SSH tunneling code for ChameleonHost will be in a seperate CL related to BUG=chromium:588806.
|Uploaded patch set 13.
|Patch Set 12:

(3 comments)
|Patch Set 13:

(1 comment)
|Uploaded patch set 14.
|Patch Set 14: Code-Review+2 Commit-Queue+1 Verified+1
|Patch Set 14: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 14: Commit-Queue+1
|Patch Set 2:

(3 comments)
|Patch Set 2:

(1 comment)
|Patch Set 11:

(3 comments)
|Patch Set 11:

(2 comments)
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(21 comments)

Updates for Set 5:

1. Separate 'timeout' for socket and ssh-connection.
DevServer.run_call() takes timeout for socket.
ImageServerBase.run_call() takes timeout from global variable DEVSERVER_TIMEOUT_MINS.

2. Regarding on the ssh error logging issue, the ssh errors will be shown in debugging mode in ImageServerBase.run_ssh_call(). After being logged and raised, error.CmdError will be wrapped 
to DevServerException, as other error types.

3. Troubleshooting ssh_call:
In the utils.run(call,....) of ImageServerBase.run_ssh_call, there is a logging info there like:
base_utils:Ã—Ã—Ã—Ã—&#124; Running 'ssh 100.96.51.25 'curl &quot;http://100.96.51.25:8080...&quot;''
We can see the running ssh-based rpc call there, so we don't log it when constructing it.
|Uploaded patch set 6.
|Patch Set 5:

(9 comments)

Updates for Set 5:

1. add back timeout feature for run_ssh_call.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(13 comments)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Patch Set 6:

(3 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Patch Set 2:

The returned message for email is like:

Notice to Infrastructure deputies:  All hosts shown below are
in `UNUSED` or `UNKNOWN` status.
Please pay attention to these idle DUTs.

Idle Host List:
Hostname                                      Board       Pool
(No Idle Duts)

---------------------------------------------------------------
(or has idle duts)

Idle Host List:
Hostname                                      Board       Pool
chromeos4-row12-rack4-host7                   celes     suites
chromeos4-row12-rack4-host21                  celes     suites
chromeos4-row12-rack4-host19                  celes     suites
chromeos4-row12-rack4-host8                   celes     suites
|Patch Set 2:

The column is aligned in reality.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(13 comments)
|Uploaded patch set 5.
|Patch Set 5:

(4 comments)
|Uploaded patch set 6.
|Uploaded patch set 7: Commit message was updated.
|Patch Set 6:

(3 comments)

http://go/cros-manage-duts is updated. 

PSA will be sent then.
|Patch Set 7: Code-Review+2 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1:

(4 comments)
|Uploaded patch set 5.
|Patch Set 5:

(5 comments)
|Uploaded patch set 6.
|Patch Set 6: Code-Review+2 Commit-Queue+1 Verified+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

Patch set 1:

The updated status.log is like:

START   ----    verify  timestamp=1458255128    localtime=Mar 17 15:52:08       
        GOOD    ----    verify.ssh      timestamp=1458255128    localtime=Mar 17 15:52:08       
        GOOD    ----    verify.power    timestamp=1458255128    localtime=Mar 17 15:52:08       
        FAIL    ----    verify.tpm      timestamp=1458255128    localtime=Mar 17 15:52:08       The host TPM is in a bad state with last_error=12305
        GOOD    ----    verify.cros     timestamp=1458255129    localtime=Mar 17 15:52:09       
END FAIL        ----    verify  timestamp=1458255129    localtime=Mar 17 15:52:09
|Uploaded patch set 2.
|Patch Set 2:

add 3 kinds of diagnosis.
|Uploaded patch set 3.
|Patch Set 3:

(7 comments)

Run 'Log into the DUT, and execute &quot;stop tcsd&quot;. Then verify the DUT.'

status.log is like:

START   ----    verify  timestamp=1458331763    localtime=Mar 18 13:09:23       
        GOOD    ----    verify.ssh      timestamp=1458331763    localtime=Mar 18 13:09:23       
        GOOD    ----    verify.power    timestamp=1458331763    localtime=Mar 18 13:09:23       
        FAIL    ----    verify.tpm      timestamp=1458331764    localtime=Mar 18 13:09:24       TPM connect failed -- last_error=12305.
        GOOD    ----    verify.cros     timestamp=1458331765    localtime=Mar 18 13:09:25       
END FAIL        ----    verify  timestamp=1458331765    localtime=Mar 18 13:09:25
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 5: Code-Review+2

I tried searching all deleted functions and variables too, seems no left.
|Done
|Done
|Done
|Done
|Does this also apply to the python functions that I export?
|Done
|yes, DWORD is something defined by the XIMEA API.
|Done
|Done
|Done
|Because I'm using the safe buffer policy, I doubt they delete the pointer. However, is it possible that C++ automatically deletes the pointer when it falls out of scope?
|actually, no. these should be the same. I've remove the frames variable.
|Done
|Not sure what 35.5 stands for, maybe extract out as a variable?
|Do you mean to skip the test here? With this line the 3 lines below are not executed.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Do these .java files need the open-source copyright header?
|I think some of these new public classes need javadocs.
|I think this constant should be in lower camel case, as well as background_color below.
|javadoc?
|javadoc?
|javadoc?
|javadoc?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Commit-Queue+1 Verified+1

(13 comments)
|Patch Set 6: Code-Review+2
|Uploaded patch set 1.
|Abandoned
|Patch Set 3:

(2 comments)

Hi Dennis,

I only have two small things, otherwise the code looks great!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Ready for review.
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)

Done.
|Uploaded patch set 7.
|Patch Set 7:

(3 comments)

Done.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

actually done.
|Uploaded patch set 11.
|Patch Set 8:

fixed issue that was breaking nose2 tests.
|Uploaded patch set 12.
|Patch Set 12:

(2 comments)

Done
|Patch Set 12: Verified+1
|Patch Set 12: -Verified
|Patch Set 12: Commit-Queue+1 Verified+1
|Patch Set 2:

(7 comments)

Hi Dennis,

I have reviewed the .java files, and have a few comments below.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 1.
|Abandoned
|Uploaded patch set 2: Patch Set 1 was rebased.
|Done
|Would you prefer that the usage statement is also surrounded by &lt;&gt;?
|Done
|If time == -1, then it hasn't seen the packet transmitted line, so it does error out in that case.

It no longer checks that min/avg/max/mdev gets returned because /bin/ping doesn't always return those (e.g. in error case).
|Patch Set 1: Verified; Ready


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 2: (2 inline comments)

PTAL
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Ready; Verified


|Patch Set 5: Ready


|Patch Set 1: Ready; Verified


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: Ready; Verified


|Patch Set 7: Ready


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready; Verified


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Ready


|Patch Set 1: Looks good to me, approved; Ready; Verified


|Change has been successfully cherry-picked as b34a73f7d53492530e38fdd1dee14cee0eaee867
|Patch Set 1: Commit-Queue+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Please refer to HDMI 1.4b Table 8.14, HDMI_VIC = 4 indicates 4096x2160p24
|tegra fb driver allows double buffering.  
see &lt;kernel&gt;drivers/video/tegra/fb.c
|Right. It means double buffering. How do we make sure HDMI display can flip current frame correctly while disB is writing next frame to the same framebuffer.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Verified+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Verified+1

In HDMI 1.4b, 8.2.3 and 8.3.2 both define 4K VIC. In order to support 4K HDMI EDID, below four changes are all required.

https://chromium-review.googlesource.com/195333 (8.2.3)
https://chromium-review.googlesource.com/195334 (fix for CL 195333)
https://chromium-review.googlesource.com/195335 (8.3.2)
https://chromium-review.googlesource.com/195336 (fix for CL 195335)
|Patch Set 4:

Dylan,

I'm not able to push this change to upstream (git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git). Since it is depending on below two commits which are not in upstreaming either. 

Can you help to request Erik Gilling and Eric Laurent to push their change to upstream first?

commit a20ce0579367ffb7208b433a8e06fe95cdeab6f4
Author: Erik Gilling &lt;konkers@android.com&gt;
Date:   Sun Feb 6 19:32:17 2011 -0800

    video: fbmon: add HDMI dectetion to fbmod edid parsing
    
    Looks for ieee registration number 0x000c03 as per HDMI spec.
    CEA-861-E section D.6.8.

commit a20ce0579367ffb7208b433a8e06fe95cdeab6f4
Author: Erik Gilling &lt;konkers@android.com&gt;
Date:   Sun Feb 6 19:32:17 2011 -0800

    video: fbmon: add HDMI dectetion to fbmod edid parsing
    
    Looks for ieee registration number 0x000c03 as per HDMI spec.
    CEA-861-E section D.6.8.
|Patch Set 4:

upstream has been moving towards using Tegra's drm driver and not the legacy tegrafb/tegradc driver. 

HDMI VSDB parsing is already implemented. Please see do_hdmi_vsdb_modes() @&lt;kernel.git&gt;drivers/gpu/drm/drm_edid.c
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Verified+1
|Patch Set 4:

upstream already have hdmi vsdb parsing.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Verified+1
|Uploaded patch set 4.
|Patch Set 4: Code-Review+1 Verified+1

Updated commit message.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: Verified+1
|Uploaded patch set 7.
|Patch Set 7: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue
|Uploaded patch set 3.
|Patch Set 3: Code-Review+1 Verified+1
|Abandoned

squashed this with the previous patch and added Pankaj's  signoff there.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Abandoned

Mark is working on the right fix.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1 Verified+1

verified on blaze.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 1: Commit-Queue+1
|Patch Set 1: Code-Review+1 Verified+1

Verified on Norrin with Sony 4K TV
|Patch Set 4: Verified+1

verified on Norrin with sony 4k hdmi tv
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 1: Fails; Do not submit


|Patch Set 1: Abandoned
|Patch Set 1: Fails; Do not submit


|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Looks good to me, but someone else must approve; Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve; Ready; Verified


|Patch Set 1: Looks good to me, but someone else must approve; Ready; Verified


|Done
|yes, for now, while we figure out how we will implement the per site byte usage tracking.
|Done
|Done
|Yes.  I'll let Michael fill it in with whatever structure he is using to store the bytes per day (so he might also change the argument here)
|You're right in this case though, I think I will remove the comment, since this function could be useful for something else as well.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13: (1 inline comment)


|Uploaded patch set 14.
|Patch Set 13: (1 inline comment)


|Uploaded patch set 15.
|Patch Set 15:

Switched the orders of the methods so that they all match.
|Uploaded patch set 16.
|Patch Set 15: (1 inline comment)


|Patch Set 16: Verified


|Change has been successfully cherry-picked as f235ef7e57cbfe000c7141cb203ae716bde8d359.
|Change has been successfully cherry-picked as 8886ddcc7ee96eb081b123d0e1ccc4bc539cead3.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 7.
|Uploaded patch set 2.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Verified; Looks good to me, but someone else must approve


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, approved


|Patch Set 6: Verified


|Change has been successfully cherry-picked as a19d1e2ae9301fdc5d0610475b4693e28f46f5d2.
|Uploaded patch set 2.
|Patch Set 2: Verified


|Change has been successfully cherry-picked as 9cdfcaf47a1663368bf11f5b28fd25081a5b7c9a.
|Patch Set 1: Looks good to me, approved


|Uploaded patch set 2.
|Patch Set 2: Verified; Looks good to me, approved


|Change has been successfully merged into the git repository.
|Uploaded patch set 1.
|Abandoned

move to project overlay
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 4.
|Patch Set 4: Verified+1
|Removed Verified+1 by ariel fang &lt;ariel_fang@wistron.com&gt;

|Abandoned
|Uploaded patch set 1.
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R48-7647.B as commit 6aeda3546f89ab79ed9e0e09a13eb645d29b2b39
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Verified+1
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 1: -Code-Review
|Patch Set 1: Code-Review+1
|Patch Set 2: Cherry Picked

This patchset was cherry picked to branch release-R48-7647.B as commit 6a3853b09c822a21f71b544922c532193ed1e918
|Patch Set 1: Cherry Picked from branch master.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Done
|Yep! Adapted from https://www.opengl.org/archives/resources/features/OGLextensions/
|Yeah, it's a pretty bad driver bug to advertise an extension and return NULL for its entry point. I think we will never hit this path in practice, so I went with a bit more coarse error handling here.
|Yep, good idea. Done.
|It's a bit awkward that we have these two levels of asynchronous handling in case of implicit dma-buf fences, first in gem_unmap_wq and then using nouveau_fence_work.. But I can't really suggest anything better so I'm fine with this.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 3: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3:

Added BUG and TEST keywords to the commit message..
|Patch Set 3: Commit-Queue+1 Verified+1
|Patch Set 3: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2: Code-Review+1 Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1 Commit-Queue+1 Verified+1
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1

I'm fine with this approach.
|Does &quot;hda_codec_beep_nid&quot; need to match &quot;hda-codec-beep-nid&quot; in config.txt?
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Verified; Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Verified

I have verified this on stout as well.
|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Verified


|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve


|Done
|I either misread the datasheet or got rid of the wrong line by mistake when doing this. Changed it back now.
|The way I had it originally definitely wasn't right, since it would just keep copying the same error header and failing over and over. Assuming you're right about possible valid packets after the failed one, I changed it to move to the next packet.
|I tried doing this and got a strict aliasing error.
|Done
|Done
|Done
|Done
|Done
|Done
|The most recent version still has promiscuous mode turned off, and I've checked that it receives broadcasts. There's a different bit to disable broadcast which is off by default.
|Done
|Done
|Done, by removing this one since it was already the default.
|Done
|I left this one as is--it seems strange to me for the driver to decide to halt rather than letting the caller deal with it.
|Done
|Done
|The way it is here looks correct from reading the datasheet, and in fact it didn't work when I tried the other way. Not sure why the U-Boot code seems like it's doing something different.
|I wasn't sure if this is the best way to do the config stuff, so I didn't bother adding it to boards other than panther for now. I'll add it to everything else once someone has looked at this.
|That makes sense to me, but I'd rather not bundle it in with this.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done in another CL.
|I don't actually understand what these are for. Is it a problem to have it in here?
|Done
|Done
|Done
|Done
|Done
|Done
|Got rid of the phy_id argument
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

More details about the current status:

It gets to sending a DHCP request (line 156 in netboot/main.c). I've verified using tcpdump that the request gets sent correctly and the DHCP server is sending a response. I've tracked down the error to a timeout while waiting for the bulk transfer.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

The length issue wasn't causing the problem I've been seeing. It never gets to that point in the function at all, it always prints &quot;Bulk read error&quot;, with an error code that apparently means a timeout, and returns up at line 476. I've looked at the USB code in libpayload and put in a bunch of printfs to trace what's happening, no luck figuring out anything useful from that so far.
|Patch Set 2:

Updates:

I got it to boot successfully if I turned MacCrPrms on instead of turning it off, with no other changes from what's here except one in error handling that it wasn't hitting anyway. &quot;Fixing&quot; the length calculation actually broke it and I had to change it back. I know we don't actually want it running in promiscuous mode, but now I know that it's otherwise working.

Also, I finally managed to find a datasheet that has the relevant information on it, so I'm going to go look through this and see if I can find anything useful. http://ww1.microchip.com/downloads/en/softwarelibrary/man-lan95xx-dat/lan9514_lan9514i%20databook%20rev.%201.2%20(03-01-12).pdf
|Patch Set 2:

I figured out the problem! I needed to be writing the MAC address to a register after reading it from the EEPROM. (I also wasn't setting the bit to receive broadcasts, but that was a different issue.) I'll upload the changes tomorrow after I have a chance to do a little cleanup, and then probably do more cleanup over the move days.

This code is primarily based on the other driver we already have, and secondarily based on smsc95xx.c from third_party/u-boot, although I'm not sure that much similarity with u-boot will be left once I have a chance to do more cleanup. If that still needs attribution, can you point me to an example of a good way to do that?
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1:

(15 comments)
|Patch Set 3:

(4 comments)
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Patch Set 2: Commit-Queue+1 Verified+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Patch Set 2: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 2: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(7 comments)
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 5: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Uploaded patch set 1.
|Patch Set 1: Commit-Queue+1 Verified+1
|Patch Set 1: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 1: Commit-Queue+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 4: Patch Set 3 was rebased
|Abandoned

Causes test to exit prematurely.
|Uploaded patch set 1.
|Abandoned

Meant to be a draft.
|Restored

Still being verified.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Commit-Queue+1 Verified+1
|Patch Set 5: -Commit-Queue

Commit-Queue label set to 0 programmatically by chromite.
|Patch Set 5: Commit-Queue+1
|Uploaded patch set 4.
|Patch Set 4: Commit-Queue+1 Verified+1
|Uploaded patch set 3.
|Patch Set 3: Commit-Queue+1 Verified+1
