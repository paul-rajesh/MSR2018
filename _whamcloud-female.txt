===Database gerrit_whamcloud

== Dumping data for table JOINED_TABLE

|why not just set exist = true when rc == 0? then later only check exist is enough.
|a comment for this line? I don't get it.
|does this equal to:
        if (old != 0)
?
|does this equal to:
        if (new != 0)
?
|since there is no further patch for this, XXX can be removed.
|typo: layout -&gt; update, and this is also seen in several other places.
|wrong indentation.
|though only 2 MDS are used currently, is it better to iterate $MDSCOUNT and do this?
|dt_write_lock() is not taken here, is it on purpose?
|is it possible that this function did nothing because of race, and ldata doesn't point to next entry?
|s/missed/missing/
|s/missed/missing/
|s/does/is/
|s/does/is/
|is it possible to move this check into lfsck_namespace_insert_orphan(), which will make code easier to read. and the same for several other places below.
|is la-&gt;la_nlink set?
|isn't it set already?
|can't we always declare this in advance?
|these 3 tests doesn't test DNE?
|yes, and since they will be called in OUT too, they should register as callback like tgt_lfsck_in_notify too.
|it's strange to place a pointer in a on-wire struct.

IMHO LE_SKIP_NLINK_DECLARE and LE_SKIP_NLINK don't need to be handled as other events, but to be wrapped into lfsck_skip_nlink_declare() and lfsck_skip_nlink() functions, and also two function pointers for OUT.
|since there is no compatibility issues, is padding needed?
|s/corrent/correct/
s/assumeed/assumed/
|s/corrent/correct/
|s/found/find/
|s/contains/contain/
|s/missed/missing/
|how come is this three? and is it fixable if called more than 3 times?
|if there is no further processing for this case, please remove XXX.
|ditto, remove XXX if no further processing. BTW how can administrator know it's such case and handle it correctly?
|Hmm, but if it should be called more than 3 times to fix it, does it mean this can't be fixed by LFSCK?
|because wake_up() needs to access sai, if do it outside, sai needs to be refcounted here, IMO it's simpler to do it this way.
|There is a tiny race here:

1. when sa_make_ready() reaches here, scanner is not waiting on this entry, so wakeup is false.

2. at this end of this function, after entry is set to ready, it won't wake up scanner, which may stall scanner process, and timeout in the end.



Putting this after __sa_make_ready() will solve this race.
|When reaching here, normally this means current process opened this dir, so others should not statahead on the same dir anyway.
|Yes, but this is rare case because the above situation only happens when dir was both opened by parent process, and then forked a child process, then they shared the opened file handles. And parent closed dir, and then stat files under this directory, while child closed dir at this moment.

Since this is rare, IMHO we don't need to optimise it.
|I tend to disable statahead for current dir upon any failure in starting statahead thread, because situation may get complicated, and statahead may actually hurt performance. And IMO less code is always better.
|this is why this is flag is introduced, thus setting opendir pid/key, enable/disable statahead, and start/stop statahead thread is separated.
So the running statahead will be stopped at the time of dir close.
|it's true that this statahead thread will hang there util dir is closed, but it's not a big waste because the thread is just suspending there and won't take much resources. And I want the logic to be simple: statahead will quit when dir is closed, or its hit ratio is too low, as for other exceptions it doesn't need to quit immediately.
|s/depricated/deprecated/
|In racer test this often failed with -ENOENT, which is normal. IMHO failure of this function is not necessary to print error message.
|s/stroes/stores/
|I am curious why it's not implemented like below mechanism: track batchid to wait for current batch to finish. And it looks strange to wait inside semaphore.
|I'm wondering why not move below code after if (!export) and  do new connect. Then we won't mix up connect and reconnect here.
|1.8 code takes export refcount inside mds/filter_connect(), so by default after obd_connect() a refcount of export should be put, just like below. And for reconnect, IMHO it's a bug to take an extra refcount in 2.x code, because it's just an existed export, obd_reconnect() just does some initialization work.
|For new connect, one refcount is taken in class_conn2export(), while for existed export, it's taken in the beginning. So either case it's fine to put refcount below.
|I still think you should separate handling of new connect and reconnect.
|I mean move line 977 - 981 after obd_connect(), IMO this is necessary for new connect only.

I'll do some test later to verify how export refcount is.
|code like this is hard to maintain, I'd suggest you do some test to make clear how the export refcount is, and fix this in a clean way. IMHO for new connect, export refcount should be 2 here (it's initialized to be 2); while for reconnect, no refcount should be taken, so for both cases export refcount should be put here.
|lprocfs_exp_setup() will be called during connect/reconnect, if it's waiting there, I'm afraid umount should fail. Could you wait for it finish and then try umount?

If it still fails, could you `lctl set_param debug=-1` on the failed node, and collect debuglog and upload to the jira ticket? It's better to enable this debug before system is up.
|what test did you run? it seems to work in my local environment. And even autotest passed with this patch.
|This is a target only field, please put it in struct obd_device_target.
|There is still a small race without a lock: eg. a connect comes has arrived, but hasn't increased obd_conn_inprogress yet.

I'd suggest you check target-&gt;obd_stopping in target_handle_connect() with obd_dev_lock held, and also increase obd_conn_inprogress inside the lock. while class_cleanup() still checks obd_conn_inprogress here, but with obd_dev_lock held. Now that this field is protected by obd_dev_lock, the data type can be 'int' instead of atomic_t.

Also it'll be better to move this check to the beginning of class_cleanup() (to the place obd_stopping is checked), because this check should not be especially for obd_nid_hash, but to serialize connect and obd cleanup.
|This is a bit strange, why not print &quot;no target&quot; directly.
|it's calculated just now, is it necessary to do it again? btw I don't see any static value either.
|was the old message removed? I don't see it in the left column.
|on second thought, we shouldn't put such failed page in page cache, the reason it's there is because read_cache_page() always add page into page cache, I'll update this patch soon.
|I agree with you, but I can't think of a case that this assert can be triggered.
|I'm curious why it's not just set to 'imp_state'?
|s/ /tab/
|it's better not make this a loop, because in some weird situation client may stuck in a deadlock, instead we can just call md_intent_lock() one more time here.
|add full comments for new functions.
|XXX means this piece of code should be improved later, which doesn't make sense here.
|shouldn't this comment be removed?
|is this comment still true? because ll_update_lsm_md() doesn't revalidate any longer.
|this check and return is unnecessary, because it will return below anyway.
|I'd prefer the way Andreas suggested:

lwi = LWI_TIMEOUT(cfs_time_seconds(cfs_fail_val), NULL, NULL);
if (lwi.lwi_timeout &gt; 0) {
        l_wait_event
        ...
}
|function name is a bit misleading, maybe lfsck_namespace_record_ds()?
|why not use rwsem any longer? and if you choose to use as normal semaphore, it's more efficient to use mutex.
|after this you should have child dentry, and you should lock i_mutex like above. So why not just call ll_lookup_it() instead of ll_get_fid_by_name() and goto line 3074 in this case?
|why not set inode flags and state in ldiskfs_create_inode()? this looks more natural to me.
|is it possible to move this block to lmv_create()? so that llite code should not be aware of DNE.
|this check is not necessary, because ptlrpc_req_finished() will check it internally.
|why remove this check?
|Um, 'index' can be used here, though the reason index is saved above is that after entry state is set, it can be freed by scanner process any time, so it's not safe to access entry after that.

So this is not a major problem, I will change this if another patch update is needed.
|As said by Oleg, this may be the same issue as LU-5116, I've spent some time trying to verify they are, but not finished yet, once it's confirmed, I'll abandon this patch.
|this will still cause open handle leak if iget failed, so it's better to cleanup open outside this function, and a new function other than ll_close_inode_handle() which doesn't fill close request from inode should be implemented.
|should it be called here? why not call it in lookup and intent_open directly? because md_get_lustre_md()/ll_update_inode() failure will cause open handle leak too.
|is there a better way to find a non-conflict name? this doesn't look efficient.
|a lot of duplicate of code in lfsck, is it possible to make them a library and shared by mdt and lfsck?
|s/indoe/inode/
|s/conut/count/
|still consider performance for old kernel?
|okay, patch updated.
|okay.
|obd_statfs() will sleep, so this function can't hold spinlock, and I don't want to make this too complicated.

obd_statfs() and obd umount will be done serially, so the race window should be quite small (the verification test shows it's safe for 10mins), and actually the original requirement only want to access 'stats' safely. so for other proc entries like this, if it's too complicated (it may involve many places like obd initialization and cleanup), it may not worthwhile. Any suggestion?

BTW, the patch for b1_8 is abandoned, please review patch for 2.x in http://review.whamcloud.com/#change,326
|I don't see where this macro is used.
|unused?
|I'd like to see return value type specified here, i.e
#define KERN_SHRINKER(name) int name(...)
|Should lmv_set_mdc_active() do the same?
|Should lmv_notify() do the same?
|I find the function 'start'/'stop' is not used by sanity.sh, instead `do_facet ost$devnum mount/umount ...` is used. is it more consistent to use the same functions?
|why this block is removed? User space application may forget to cancel locks.
|if page lock can be used, no need to introduce a new lock here.
|It's better to name uuid explicitly like this:
$LCTL add_uuid NID_$(ost_nid)_UUID $ost_nid &gt; /dev/null 2&gt;&amp;1
|should it be echo __$(echo $1 &#124; tr '-' '_' &#124; tr '.' '_')?
I saw it's like this in last version.
|sure.
|okay.
|okay.
|lprocfs_obd_cleanup() will remove it, however obd-&gt;obd_proc_exports_entry may be set to an error no, which may cause problem, I will update the code and resubmit.
|ok.
|ok.
|In theory max_pages_per_rpc is a per-export value, it's not per super block.

export this value to procfs can help testing.
|okay.
|Yes.
|Could you explain in more details? In my understanding the logic of ll_get_dir_page() is like this:
1. call ll_dir_page_locate() to find a page containing given hash, if page hash start &lt; end, and end == hash, this page is not treated as a valid one (but actually it may just be the one we want, but this needs to be handled by hash collision code which doesn't exist yet).
2. if page is not found, call read_cache_page(aops-&gt;readpage) to get a page starting with given hash.

I don't see more loops wasted here.
|Ehh, the problem is more complicated than expected:

when aops-&gt;readpage is called, the requested page has been inserted into page cache with given index (also hash) before readpage RPC, so in the pages returned from MDS, the hash start value of the first page is set to the given hash value. Therefore each time aops-&gt;readpage (except the first one) is called, we will observe hash collision for the dir page just read and the first new page returned, but actually there may not exist real hash collision at all.

And it's not easy to eliminate this hash collision, because when we try to locate a page with a hash value, we want the page cover this hash, currently this is not guaranteed in subsequent pages read from MDS.

In brief, current dir page locate code requires hash is consecutive between two pages, and this will always lead to hash collision.
|Yes, I agree. AFAICR wangdi has moved directory page cache management into MDC layer in his CMD branch.
|ok
|ok
|add_to_page_cache_lru() is not exported in old kernels.
|Is bigger page size supported now? I didn't change any logic here, the original code returned bytes transferred is only guaranteed server page aligned, and previously it's also checked here.
|the for loop will check &quot;rc == 0&quot;, it's not break here because cfs_kunmap(pg) is called below.
|Ehh, I didn't change any logic here, &quot;rc&quot; is bytes read from readdir now.
|I forgot to update first-&gt;ldp_flags (LDF_COLLIDE should be set if the last dp has this flag set).

I will update the patch after this round of review.
|ptlrpc and LNET layer will ASSERT ptlrpc_bulk_desc-&gt;bd_iov_count &lt;= PTLRPC_MAX_BRW_PAGES), so even with small page size, the count is calculated with CFS_PAGE_SIZE.

In this implementation, I only fill one lu_dirpage in each *page(this is a waste for big page size on server), I will fill serverl lu_dirpages in one *page in next patch.
|yes, the code is just this.
|'flags' stores ldp_flags of last lu_dirpage, and the above three lines will only be executed once after all lu_dirpages are merged.
|it's not necessary to check result, even upon failure, the adjustment below is okay.
|ahh, yes, I should use $(page_size)
|sanity.sh uses tab width 4, it looks good in my vim, anyway I will make it shorter.
|Have you ever seen this before?

for normal client, obd_disconnect() will be called explicitly in client_common_put_super(), therefore at the time of osc device cleanup, the import has been cleared already. While echo client is different, obd_disconnect() is called by zombie thread, which is executed asynchronously.
|Please add comment here, otherwise no one can understand in the future ;)

BTW, `fake' is not a good name, `tmp' or `existed` may be better.
|good.
|yes.
|mds_intent_policy() looks to be the only entry for IT_OPEN, so child_lockh is not NULL, I will add an ASSERT(child_lockh != NULL) here to ensure open lock is revoked as planned.
|Yes, I agree. I will commit another patch soon.
|This is for negative child but MDS_OPEN_CREATE case. If child exists, 'need_open_lock' will be cleared, so it will be not called twice.
|Could you point out the place where child lock is decrefed?
|can op_namelen be NULL? should LASSERT here.
|why continue if tgt == NULL?
|Okay, I see. I didn't know the stack is so tight for mds_open.
|It's safe to reuse child_lockh, originally I thought the code is cleaner to not reuse. I'll fix this.
|better to use !!l(e32_to_cpu(dp-&gt;ldp_flags) &amp; LDF_COLLIDE)
|see above.
|I forgot why if (1) here, could you explain it?
|Should d_mountpoint(de) and (de == de-&gt;d_sb-&gt;s_root) cases return rc directly like this instead of goto out_sa?
|better name it SA_LEFT_BEHIND_MAX.
|better to name it ll_sa_entry.
|better name to is_entry_left_behind()?
|better name it ll_sai_entry_alloc()?
|Looks like do_sa_lookup/revalidate() can be consolidated into one function do_statahead_one() now.
|should LASSERT(inode != NULL);
|should never go here, LASSERT(!d_mountpoit(dentry));
|should never go here, LASSERT(dentry != dentry-&gt;d_sb-&gt;s_root);
|can igrab() fail?
|can you leave some comments here?
|Ahh yes, I'll fix it. BTW, ASSERT lu_object refcount equals zero is checked in lu_object_purge().
|ok
|Hmm, I agree. And actually I may add OBD ACITVE check for lprocfs_nid_stats_clear_write() mistakenly, most of the proc entry write function may sleep, and I didn't mean to make them safe in this patch, that said, this patch only guarantees proc entry read function safe access in system initialization and shutdown.

I'll remove OBD ACTIVE check for this function.
|I see. The above case is possible. I'll move line 899-901 into lov_cleanup().
|Normally after class_cleanup(), the only operation can be done to the obd is class_detach(), which won't access tgts any longer.

And Maloo test result looks okay.
|This can be fixed as you suggested.
|This block of code is put here because of below comment:
	                /* clear pools parent proc entry only after all pools is killed
	                 */
I don't understand why it's necessary, otherwise only the pools cleanup code can be untouched.
|this can be fixed.
|ok.
|ok
|I prefer function called agl_first_inode(), see comment below.
|this function name is a bit wordy, I suggest ll_agl_add_inode(). Besides, it's a bit misleading to ll_sa_entry. Since there is not a struct ll_agl_entry, it's better to call it inode directly.
|igrab() can be done later, thus no need to release and take lli_agl_lock here.
|It's more natural to put cfs_waitq_signal() in ll_agl_entry_to_prep().
|Could you explain why this agl thread is needed? Since it only triggers agl, this task can be done by statahead thread, therefore we can avoid one thread for each `ls`.
|It looks strange to loop again here, l_wait_event won't cause overhead if condition is met.
|What's the policy to agl? Only when sa_sent_full?
Could you comment here?
|Yes, I'll fix it.
|Yes, you're correct, I'll fix it.
|Okay, I'll return -EPERM here like obf code.
|As mdt_thread_in_init() suggests, fields is better to initialize before using, because it's expensive to zero out all fields, and mti_tmp_fid1 is only used in several requests.
|obf_lookup() will try to convert lname to child_fid, but it may fail, however it continues using child_fid for subsequent operation, but this variable may be old value from last request.

I'll move it to mdt_thread_info_init.
|It should be okay, I copied this line from another test.
|There is a policy for mutex: only the owner can unlock the mutex, but this doesn't meet this requirement.
|The difference is documented in Documentation/mutex-design.txt as follows:

- only one task can hold the mutex at a time
- only the owner can unlock the mutex
- multiple unlocks are not permitted
- recursive locking is not permitted
- a mutex object must be initialized via the API
- a mutex object must not be initialized via memset or copying
- task may not exit with mutex held
- memory areas where held locks reside must not be freed
- held mutexes must not be reinitialized
- mutexes may not be used in hardware or software interrupt contexts such as tasklets and timers
|Not noticed at commit time, will remove these whitespaces in next round.
|IMHO it's better not to mix different semantics in one function; and currently even when node is not a router, we can get peer status via /proc/sys/lnet/peers, if the code is changed in your way, the output will be different and may confuse users.
|As you said tfm == NULL should be checked as well, so it's better to check it in ll_crypto_alloc_blkcipher():

static inline struct ll_crypto_cipher *ll_crypto_alloc_blkcipher(...)
{
    struct ll_crypto_cipher *tfm = crypto_alloc_blkipher(...);

    if (tfm == NULL)
        tfm = ERR_PTR(-ENOMEM);
    return tfm;
}

And the same for other places.
|Shouldn't it RETURN(PTR_ERR(tfm))?
|Yes, you're right, to solve this, a seqlock may work, but it's not worthwhile to make code so complicated. I'll update the patch, and just let ldlm resouce dump a certain amount of granted locks.
|If it's printed in reverse order, it may confuse people in debugging. Let me think whether there is a simple way to print the last N locks in order.
|Ahh, I did changed it locally, but I might pushed it in a hurry and not committed before push. I'll update it soon, sorry for the inconvenience.
|Replay-dual test_0a() failures are in two categories, one is config file missing or corrupt as you said, and the other is disk inconsistency (eg. ldiskfs_check_descriptors: Checksum for group 128 failed (8626!=19185)). And the two kinds of failures are half to half.

LU-1362 also reported replay-dual failure on physical environment, and the log shows there are unwritten data after target device set to rdonly,  see log 
replay-dual.test_14b.dmesg.service360.1336082515.log:
 Lustre: DEBUG MARKER: == replay-dual test 14b: delete ost orphans if gap occured in objids due to VBR == 14:56:51 (1336082211)
 LustreError: 27624:0:(osd_handler.c:938:osd_ro()) *** setting device osd-ldiskfs read-only ***
 Turning device sdb (0x800011) read-only
 Lustre: DEBUG MARKER: mds1 REPLAY BARRIER on lustre-MDT0000
 Lustre: Failing over lustre-MDT0000
 Lustre: Skipped 4 previous similar messages
 Write to readonly device sdb (0x800011) bi_flags: f000000000000001, bi_vcnt:
1, bi_idx: 0, bi-&gt;size: 4096, bi_cnt: 2, bi_private: ffff8804005b98e8
 Write to readonly device sdb (0x800011) bi_flags: f000000000000001, bi_vcnt:
1, bi_idx: 0, bi-&gt;size: 4096, bi_cnt: 2, bi_private: ffff8804005b9950
 Write to readonly device sdb (0x800011) bi_flags: f000000000000001, bi_vcnt:
1, bi_idx: 0, bi-&gt;size: 4096, bi_cnt: 2, bi_private: ffff8804005b9338
 ...

Anyway the 'mcreate' should not be done after 'sync', though I'm not clear whether it may cause disk data lost or corrupt.
|why match table is called cpu-partition data?
|active resource list?
|Is it reasonable to just print error message here? In what situation could this happen?
|Is it possible there are huge number of unused peers in pt_deathrow? It looks fine so far.
|coding style: it looks strange to put default: in the beginning.
|doesn't the above two lines equal to:
cfs_list_splice_init(&amp;ptl-&gt;ptl_msgq, &amp;zombies);

IMHO it's easier to understand, but remember to declare zombies with CFS_LIST_HEAD(zombies).
|this is more like a vfs scalability changes.
|It's better to list all kernel changes which will affect lustre, eg:
* dcache per-inode inode alias locking
* dcache remove dcache_lock
...
|d_count is protected by d_lock now, but in lustre code, most of them are debug messages, and the rest look to be safe.
|the semantic of kernel function d_rehash_cond() is different, I suggest rename it to d_rehash_locked() and remove the 'lock' argument because lustre always calls it with lock = 0.

and its another declaration in lustre_compat25.h should be removed now:

#if !defined(HAVE_D_REHASH_COND) &amp;&amp; defined(HAVE___D_REHASH)

#define d_rehash_cond(dentry, lock) __d_rehash(dentry, lock)

extern void __d_rehash(struct dentry *dentry, int lock);

#endif
|this macro can be removed, which is not referenced anywhere.
|UNLOCK?
|LOCK?
|i_lock here.
|d_unhashed() should be protected with d_lock.
|i_dentry should be protected by inode-&gt;i_lock now.
|d_alias is protected by i_lock, make sure i_lock is held upon entry, and correctly put below.
|UNLOCK?
|d_lock for d_unhashed.
|i_lock here, see above.
|i_lock here.
|good, this can prevent filling hash with invalid dentries.
|because d_lustre_invalid and d_lustre_revalidate is not in d_lock, this check doesn't make much sense, and no matter dentry is invalid or not, it's safe to call d_lustre_revalidate().
|Firstly I think it's better not to reuse unhashed alias, but actually this dentry is unhashed by d_invalidate() (this is the only place a referenced dentry get dropped), and it's no different from INVALID dentry, we should try to reuse it.

I'll update the patch later.
|It's done inside d_lustre_invalidate.
|Yes, it looks a bit strange, but I want it look the same as d_splice_alias.
|Good catch! IMO it's fine to remove this ASSERT since ll_splice_alise() just wants to make sure only one dentry exists for one file. There is no need to serialize .lookup and d_lustre_revalidate.
|Since this is an existed dentry, its validity is not updated here, but in ll_lookup_it_finish() later. And only for new dentry the invalid flag should be set explicitly to prevent it found by others.
|This macro is not necessary, and this lock is never changed.
|these variables are used only when HAVE_SERVER_SUPPORT is defined below, if don't include them, gcc on FC15 will complain.
|Hmm, as you pointed out, __d_lookup() has compared hash before calling d_compare().
|Calculating hash may be less efficient here.
|okay.
|Several revalidate may be called at the same time, and if one clears lustre_invalid flag, others don't need to continue.
|This is wrong if HAVE_D_COMPARE_7ARGS, and actually this dentry is in arg list, no need to get it out of d_name.

I'll update the patch later.
|Yes, I'll fix it.
|It's better to check it separately in configure, but this patch is in gerrit for too long time, I'll fix this in another patch after this.
|ldlm_revoke_lock_cb() looks to have the same issue, and needs fix too.
|gcc on FC15 will give a warning because rc is never used.
|Yes, it's relative to the bug I mentioned. Herein lmv_early_cancel() should send request to the MDT where fid2 resides to async cancel fid4 lookup lock, but it sends to where fid4 resides, and as a side effect, MF_REMOTE_FID4 is set.

I think if this is really a bug, it should be fixed in a separate ticket, and at that time this line can be removed.
|why introduce this change? I don't see the relationship with the problem to solve.
|Currently Catalog takes loghandle-&gt;lgh_lock during record write, so writing is serialized, there is no need to merge records, but pass them down, and these records will be written in a loop (this loop is inside loghandle-&gt;lgh_lock).
|Yes, only Changelog (based on catalog) may write multiple records at one time, but in original design both catalog and llog uses the same llog_operations interface, so if I want to let catalog supports writing multiple records at one time, I have to change llog_operations.lop_add interface, and this function is an implementation of this interface.
|mdd_rename() uses this.
|this is also an implementation of llog_operations.lop_add.
|Yes.
|There is still llog_add() which is a wrapper of this function, it's done so just to make adding one record simpler.
|Yes.
|this is a duplicate, they are in wirecheck.c.
|okay
|okay.
|okay.
|okay.
|Please describe the change in more details.
|Please add comment here:
 /* old client requires reply size in it's PAGE_SIZE, which is rdpg-&gt;rp_count */
|This description isn't accurate: previously the dir data is filled in LU_PAGE_SIZE(I don't think it can be called partially filled), but if 1.8.x client PAGE_SIZE is bigger than LU_PAGE_SIZE, this error is triggered.
|Why not define this below MDS_OPEN_NEWSTRIPE? IMO that's the place for open flags, and the code can be simpler.
|I don't think capa should be bypassed by default, filter_auth_capa() should check whether this client doesn't support capa.
|Same.
|Since this function can be called internally, this capa should be set to BYPASS_CAPA outside for this case, while NULL if from client.
|typo!
|This looks to be a subtle issue, because MDT has updated i_flags successfully, so the issue is that is it acceptable that MDS has OST has different i_flags?
|This check doesn't look to be necessary, and i_flag update can be put right after ccc_inode_lsm_put(...).
|It looks fine so far, Oleg, what's your opinion?
|I see. But it really doesn't look to be a good idea to use a lock just to synchronize creation, and IMHO if we call lvbo_init before adding this resource into hash we can get rid of this lock entirely.
|This looks reasonable, but I can't understand how it could barely work before! Because mostly lvbo_init is NULL, and such resource would be created with mutex held, but this is wrong. Could you explain this?
|It's better to remove DCACHE_LUSTRE_INVALID definition to avoid confusion, therefore we can just introduce a bit flag here:

unsigned      lld_invalid:1;
|You can set dentry-&gt;d_fsdata = NULL before synchronize_rcu, then you don't need check d_unhashed either. Besides, you can add a struct rcu_head in struct ll_dentry_data, then you can use call_rcu to release it asynchronously.
|Ahh, you're right! But IMO it's not safe yet, because there is no lock, .d_release can be called any time.

The last resort is to store the 'invalid' flag in the last bit of dentry.d_fsdata, and use a mask to access this flag or ll_dentry_data.
|Access to dentry-&gt;fs_data is atomic, and I can't think of a race relative to RCU-walk, could you give an example?
|Why check d_unhashed? Can't !ll_d2d() cover the case you mentioned? I don't want different semantics mix together.
|In the case you mentioned, ll_splice_alias() should have been called.
|I don't find the place it's called in blocking ast, could you point it out?
|Can it LASSERT here other than a check?
|better to use OBD_FREE_PTR(lld).
|No, it's for patched client. But it's not needed any more.
|I think it's a good chance to remove vfs_races-*.patches under lustre/kernel_patches/patches.
|a better name lld_rcu_head.
|a better name lld_invalid.
|coding style: lld == NULL &#124;&#124; lld-&gt;ll_invalid
|coding style: if (lld != NULL)
|coding style: LASSERT(lld_d2d(dentry) != NULL)
|IMHO this looks too cumbersome. Why not just take a refcount of obd-&gt;obd_nid_hash here, and drop it after use?
|Ahh, it doesn't help to fix in lprocfs_obd_setup, the real issue here is that the accessed obd might be gone during proc entry access, I can't think of a perfect solution here, maybe the original fix I suggested is the simplest way.
|Hmm, it looks like this refcount should be taken by this proc entry (in lprocfs_register()), however in current implementation it's missing. So taking a refcount here is necessary because this obd might be gone any time, but if you'd like, you can try to fix it in lprocfs_obd_setup(): take a refcount of obd before register proc entry, and remember to release this refcount somewhere.

It looks quite possible to me that these problem can happen in 2.x, it's better to do some test, and it would be best if it can be made into a sanity test.
|A simpler fix is to move class_decref() before LPROCFS_ENTRY(). (it looks better to move class_incref() below LPROCFS_EXIT() too).
|It still makes sense because if QUOTA is disabled, this piece of code will not be compiled at all.
|I didn't touch this line, should it get fixed here?
|It's a surprise that 'noacl' option doesn't effect for lustre at all. IMO this should be fixed in another ticket, and those tests should be added there.
|Okay, I'll do that. And the newly added acl test should fail in his DNE test.
|Ahh, I made this patch in chaos branch, and then patched to master to commit. I'll fix it.
|See above lli_opendir_pid is checked, so if process A starts statahead, only process A can access, and stop statahead data.
|Hi Jammes, could you explain why set ost1 here only?
|According to below comment, you ll_lookup() should act similar to ll_lookup_nd() for (CREATE &amp;&amp; !OPEN) dentry. Because such dentry will be handled in .create, thus no need to be lookup here.
|Why this is optimized away? Without this did you see anything went wrong? And IMHO if this should be optimized, (CREATE &amp;&amp; !OPEN) should do the same.
|Yes, you're correct. For (CREATE &amp;&amp; !OPEN), ll_lookup_it_finish() should not revalidate this dentry based on parent UPDATE lock.

And there is no need to revalidate the dentry here, we can just leave it as is.
|Hmm, this should be why original ll_lookup_nd() just returns NULL after creating a negative dentry for (O_CREATE &amp;&amp; !O_OPEN), so such dentry will not be really looked up from server.
|lookup(O_CREATE) should not return a negative dentry unless O_EXCL.
|ll_lookup_it_finish() only revalidate child dentry according to parent UPDATE lock because it's a negative dentry. And I think the changes you made there is not necessary either.
|Same as Fan's comment, I do't see the sense to revlidate dentry here, could you explain the cause? And without it will anything go wrong?
|For .create a dentry is created and added to dcache, but because LOOKUP lock is not fetched, it's not revalidated and exposed. So at this time if others lookup this dentry, it won't be found and needs lookup from server again.
|Since create doesn't fetch LOOKUP lock, I don't see the reason to do the revalidation here. Could you explain the reason?
|Debug message is &quot;hashed %d&quot;, but it's value is d_unhashed.
|Fanyong, why negative dentry needs to continue with statahead window update?
|Yes, storing all parameter as a single property should be simpler and more transparent.

Firstly I'm afraid this will set a length limit for parameter string, however the max length of ldd_params is 4096, while property value length is 8192, this is not a problem.
|I'm okay with this, though it's better to use a defined variable REC_SIZE_MAX=${REC_SIZE_MAX: -1024} in the beginning of the script. Thus in the future once Lustre supports bigger IO record size, the script doesn't need to be altered as well.
|I don't see anything concerning ELC here, could you explain in more details? Did the test fail with ELC enabled?
|mcreate creates file with mknod, so it doesn't enqueue any lock in client side. But it doesn't anything with ELC.
|Since this struct contains exact hsm_progress, it's fine to use hsm_progress as the first argument, then ioctl copy from/to user space is more straightforward.
|why cast type here?
|is O_LARGEFILE needed here for 32bit platform?
|what's the purpose to create files here?
|for sanity test, there is no need to create a lot of files, write to one file, and check content later is enough IMO.
|why `sleep 1` here? if it's necessary, is 1 second always enough?
|Would there be so many imports? IMHO it's hundreds at most for now.
|The implementation looks a bit too complicated, why not make use of &quot;imp_pingable&quot;? then import doesn't need to be removed from and added to pinger list frequently, and less code needs to be touched.
|This can be bit flag imp_has_uncommitted:1 to save space.
|imp_force_verify can be reused IMHO, the subtle difference from previous is that the next ping may not be immediate, but scheduled, however this depends on whether pinger is woken up.
|this variable is not needed, imp-&gt;imp_has_uncommitted can be used.
|can you explain why this check is added?
|can we introduce a OBD_CONNECT_SUPPRESS_PINGS flag, and let server decide the status of suppress_pings?
|Hmm, such dentry is left in memory because parent d_lock should be held when navigating dir-&gt;i_dentry, and yes these dentries may consume lots of memory if load is not high, however dcache should be able to shrink these dentries upon memory pressure.

I'm wondering to improve this by calling shrink_dcache_parent() after invalidating is done for all, but I'm not planning to do it soon until we see memory issue due to this.
|I don't like the idea of setting a possibly wrong mode here, and then adjust it in __mdd_acl_init(), we can just set a correct one at one place.
|extra whitespace.
|I agree, and this block plus below ACL set is ACL initialization for new entry, just the same as ldiskfs_init_acl(), so that we can combine them into mdd_init_acl().
|LA_MODE is cleared before setting attr in this function by change in LU-974, shouldn't we undo that to make sure correct mode is set?
|LA_TYPE is not cleared by LU-974, I'm afraid it can't be removed, could you check commit history?
|Even this check belongs to ACL initialization, it's better to put it into mdd_acl_init() too.
|As I've said in last comment, LA_TYPE is not cleared by LU-974, and I don't know why it's cleared here. Could you double check this?
|If you take a closer look at those subtest 27?, many will leave file after test, however most of them don't have stripes (0 size), but 27p/r have data.

The real issue is that all the subtests share the same $tdir, as looks to be designed so. So IMHO for a subtest, if it requires an empty test dir, it's best to clean it up itself.
|Can this patch fix LU-2862?
|This wrapper doesn't make much sense, ostid_fid_unpack can be called directly if this patch needs an update.
|Good catch, this is another place that may cause the crash of LU-2388. I'll fix it in next update.
|atomic_inc_return returns count after increase, as doesn't apply here.
|do_statahead_enter() calls ll_sa_entry_get_byname() to lookup sa_entry by name hash, if enhash and linking to sai_entries are not atomic, then unlinking this entry in ll_sa_entry_fini() may crash.
|It will be good to replace all checks for this with OCD_HAS_FLAGS.
|good catch, I'll update the patch later.
|It's not to set an empty layout, but xattr_set(XATTR_CREATE) with the layout of snd_o.

If we use REPLACE flag, xattr_set later will return error. See `man setxattr`.
|You're right. It looks like that I have to introduce a new flag LU_XATTR_SWAP for layout swap on a stripeless file.
|The knowledge of what operation to be done on these objects resides in MDD, IMHO LOD shouldn't know this. BTW it will be strange a xattr_set(LU_XATTR_SWAP) becomes xattr_del.
|I will update it soon.
|AFAIU this situation won't happen, because layout_gen is not swapped in `lfs swap_layouts`. Imagine file1 layout_gen 42, file2 doesn't have layout, after swap_layouts, file1 doesn't have layout, and file2 layout_gen is 1. It means after layout swap, if a file lost layout, its generation is lost too.

I'm not sure this is reasonable, but it's what the code does.
|such return value is strange, maybe -EAGAIN?
|It would be good to leave comments for this patch in the beginning.
|I agree with Bobi, and the commit message is too simple, please detail the changes in your next update.
|This can be simplified to:
$GETSTRIPE -q $1 &#124; sed -e 1,2d &#124; while read obdidx oid hex seq; do
    local ost=$((obdidx + 1))
    ...
|I don't quite get it. IMHO rc == -ENOENT is the result we expect for normal situation, and instead of remove rc != -ENOENT, line 964 should be:
if (rc == 0 &#124;&#124; rc != -ENOENT)
because rc == 0 means target object exists, and mdo_link should not be done for both normal and replay case.

Do you think I should change this way?
|It looks like there is a bug in the original code: inode-&gt;i_dquot[cnt] may be NULL, but dquot_resv_space() below will access it without check.
|MDS_OPEN_BY_FID is set recently to do open by fid for intent open, so actually we shouldn't provide name here, thus name should be NULL always.
|Yes, when we have the inode, we should have got the fid, so in this case we should open with the known fid (instead of name in case this file has been renamed)
|So the old code is wrong, will it cause any issue? Can we make a test for it?
|Actually mnt root dentry never calls lookup/revalidate/.. and etc dentry operations, so that its dentry operations can be NULL. So that it may be NULL before access, and currently lustre lookup/permission will revalidate it before access, but other operations don't need.
|IMO root dentry can be revalidated the same as normal ones, can't it?
|In this patch ll_d_init() is only called if the dentry is really looked up (in ll_splice_alias()), Herein we only need to return a dentry to NFSD, if it's DISCONNECTED, it's not in dcache yet, else if it exists in dcache, ll_d_init() should have been called for it (bottom filesystem adds it to dcache in lookup).
|Hmm, I see your point, thanks!
|In LU-3544 name and len may be invalid for nfsd export, and since MDS_OPEN_BY_FID is set, name is not packed into request.

But this will cause interop failure with 2.1 server, see LU-3765.
|sure, I'll fix it.
|Though fid is allocated on client, but only when server created file with this fid, and replied to client, and then client will update this fid to ll_inode_info.lli_fid.

So any time client requests open_by_fid, the file with this fid should have been created on MDS, and upon open_by_fid failure, MDS should not try to open with name because at this moment name may be invalid, and even if it's valid, the name may not be accurate (eg. rename happened, and this file is rename target). So upon open_by_fid failure, MDS should return error to client directly, and this means the file with the specified fid is gone or similar thing happened.
|By default hops is set to &quot;-1&quot; before entry, since its type is unsigned long, how is it handled?
|Why this check is introduced? Will anything go wrong without this?
|mutex after spinlock, do I miss anything?
|mutex after spinlock.
|mutex after spinlock.
|padding whitespace in the end, I will update this patch.
|The comment is outdated.
|osc_lru_waiters looks to be redundant, if no one is waiting, no one will be woken up.
|imp_replay_cursor looks better.
|isn't this md_clear_open_replay_data()? BTW, mdc_setattr() should be updated to use md_set_open_replay_data() too.
|(open_req-&gt;rq_commit_cb != NULL) should not be checked here, but below before calling it, since this request should be finished anyway.
|close_req != NULL
|ptlrpcd_alloc_work looks to be a hack, why not use kernel work_queue mechanism? Is it to avoid allocating env only?
|It's really weird that a fake request is made just to call a function , and this function is set as request interpret callback! If ptlrpcd is just a work queue thread, it'll be reasonable.

Anyway I can live with it.
|Hmm, it's the same, just looks strange.
|ll_invalidate_page() is different from ll_invalidatepage(), which is a helper for error injection only.
|There is a helper function called ll_invalidate_page(), which does the same as this function, the name of that function is misleading, how about get rid of that function and calls cl_page_discard() directly?
|you're right, I'll change it and do a full test.
|This is because we want lookup and open to be atomic, if we return 1 here, later open/create needs to create a new file on MDS, which means this negative dentry is actually invalid.

For positive dentry, file will be open-by-fid by default, and no new file will be created, so we can skip IT_OPEN for it.

To sum up, the difference of positive and negative dentry is that the former has fid, and later operations will be done on the fid, but the latter one is only a hint, if there is an intent (especially open/create), we should not trust it.
|LOOKUP_CREATE and LOOKUP_PARENT won't be both set, so here is the revalidate of the last component in open(O_CREAT).

And we only return 0 for open(O_CREAT) but not create() is because we don't want to fetch any lookup/update lock for create(), so for create only it will return 1 here, and let .create to really create the file on server (without fetching any lock back).
|The point is that server doesn't know how to handle the race for case 3:
1. at time of .revalidate, client had open handle.
2. but at time of .open, client had lost its handle, and since O_CREAT is set, it asked server to open(O_CREAT).
3. MDS found that the file with the specified fid doesn't exist, it couldn't create file any more, because it couldn't reuse the old fid, or create with a new fid.

According to POSIX, this won't happen on a local filesystem because parent i_mutex serialise unlink and lookup, so for a network filesystem, the client has to obtain open handle at the time of lookup, and then at the time of .open it can just use the open handle.

Current revalidate code does the same, and it should be the same cause.
|This is because for positive dentry, we may already have open handle at the time of .revalidate, but at the time of .open this file may have been unlinked by others, if O_CREAT is set,  we can't handle it in .open, because we can't create a new file with different fid then. So to avoid this subtle case, we always do a real open for open(O_CREAT), in which MDS also updates its mfd, therefore at the time of .open, even others tried to unlink this file, it still exists in MDS and client will not need to create in .open.
|IMO only the bit fields need protection from rq_lock, and int fields like rq_replen, rq_nob_received don't need.
|see above.
|ditto
|ditto
|I agree, it's better to get rid of read/write_proc_t and use seq_file in all places to keep code clean.
|yes, I understand your concern, and I've done this in this patch. currently only top mdd functions references env variables directly, and fills it there, and passes down to other mdd functions as argument (with const identifier to prevent change). Did I miss anything? Could you write sample code for this place?
|I don't get you yet, could you explain more, or give an example?

Do you mean the first argument &quot;env&quot; of mdd_may_create()? It will be needed by function mdd_read_lock() inside mdd_may_create().
|'create' is not used below.
|Why these two lines are added? Is it a bug in current code?
|is it possible that result is CLP_GANG_ABORT here?
|Ahh, I looked into open_by_handle_at(), now that name_to_handle_at() syscall does call exportfs_encode_fh() to encode fh too. But this should apply to NFSD reexport too.
|I'm fine with the fix, but IMHO this has no relationship with open by handle syscall, but because new exportfs_encode_fh() doesn't pack parent info into nfs fh for directory file anymore. I don't understand why this is done, maybe because with subtree check set, DISCONNECTED directory will reconnect_path() anyway.
|Could you explain in more details? Current code does d_add() for unhashed dentry into dcache.
|I see, please add some comment here.
|why !it_disposition(it, DISP_OPEN_CREATE) is checked here?
|I agree.
|The code looks correct, but could you write a test for this?
|could you leave some comment to explain why it's commented out?
|Which subtest in santy 103 test failed? And I don't understand the issue you said yet. Could you reproduce it in a simple test?
|Do you mean we don't revalidate dentry? And this issue doesn't look to be a new issue, could you explain more of this? And can you write a test for this?
|kernel without atomic_open() doesn't revalidate dentry either now, is this the root cause?
|Yes, I'm sure, you can check LU-3544.
|style: use tabs.
|coding style: LASSERT(rule-&gt;tr_nids_str != NULL)
|Server code shouldn't LBUG upon error.
|return -ENOENT, then rc is useless.
|it's more straightforward to: return -EPERM
|ditto.
|return -EINVAL.
|I don't see the reason to take spinlock in all nrs_policy_ctl() handling, could you look into that?
|return -ENOMEM.
|return -ENOMEM
|return -ENOMEM?
|IMO you can add an argument conf to dt_locat_at() to avoid introducing a duplicate function.
|this state is not stored in disk, and it looks to be a duplicate info of i_nlink, I don't know how it can work.
|Hmm, this looks working, but is it layer violation? Lustre object specific state is stored in ldiskfs inode structure, and these state is volatile which won't be stored into disk if last iput() is called. LDISKFS_STATE_LUSTRE_DEAD can work because after last iput() it will be gone, but I suspect the other added state flag for scrub can also work as expected.

We may store these state in object, which looks more natural, but it will introduce overhead.
|why lfsck can't use lod_tgt_desc directly, but allocate its own descriptor?
|some status look to have similar semantic, could you draw a state transition table?
|lc_file_ram and lc_file_disk should be some unioned struct.
|unioned struct.
|when will ss == NULL?
|why this FAIL_CHECK depends on lfsck thread running?
|ofd_lastid_rebuilding is protected by ofd_lastid_rwsem, but the above are by ofd_flags_lock, this doesn't look to be safe, and IMO ofd_lastid_rwsem is not needed for this flag.
|SET/GET_INFO is like ioctl, lack of sanity check for arguments. IMHO it's better to introduce new RPCs LFSCK_CTL for communications between lfsck master and slaves.
|for lfsck why it doesn't check whether there is async attr_get request queued, and sync those requests instead of issuing a new request?
|it's a bit strange that below functions are put in target dir, and built into ptlrpc module, IMHO they are used by OSP/LWP only, and it's fine to put in osp dir as before.
|Hmm, I see, but the reason why it's called in OFD is that LWP is not well wrapped as a device, so below functions will be called directly by OFD.
|style: change above whitespaces to tabs is another update is needed.
|ditto.
|too much code to alloc buf, could we allocate it in thread_info in advance and use it directly here?
|when will this function return 0?
|Does it make more sense to store current MDT-object fid in name? so administrator knows how to deal with it?
|use lower case letters for local variables.
|This looks like a hack, why not create a directory like lost-found, and add links to such objects there, and remove them after all lfsck is finished?
|I don't object to re-create lost object, but I just don't like the way to mark it for later use. I'd rather create a new type of EA XATTR_NAME_LFSCK and store information there.

BTW, I saw you've added XATTR_NAME_LFSCK_NAMESPACE before, and I have a question why you did not store lfsck data as plain data, but as EA?
|Ehh, stats for LLI_NONE could be omitted or just reserved, so nothing needs to be hacked.
|these statistics data could be grouped into an array, and adjusted cleanly like lo-&gt;ll_objs_lfsck_stats[type]++.
|I don't see the rate control, will it consume too much memory?
|since to_fix is set to true only once, you can just do below at the place at line 2348 and then goto 'again' to make logic more straightforward.
|I'd prefer create lost-found/MDTxxxx dir in the way client does, that is MDT0 alloc fid from MDTxxxx and create this dir like a normal mkdir. Though a sequence may be used only for this fid only, but this mechanism can be used in the future for similar case that MDT0 wants to create remote directory.
|Two -&gt; More than one?
some -&gt; same?
|it looks the mdt object was correctly fixed, why still put ii under lost-found? or do I misunderstand it?
|local variables use lower case letters, and the same for below variables.
|I agree with John, and this piece of code should be used to support old kernels before.
|IMHO you don't even create a specific workqueue, but schedule_work() to keventd to finish this task.
|shouldn't below lookup and check be done asynchronously by workqueue?

BTW if ofo_pfid_inconsistent is set, it should mean that there is a inflight check, and should skip current check.
|Hmm, I see your point, but what really takes time is to verify pfid, and it doesn't make much sense to create a work just to update local object attribute, instead you can just update it synchronously.
|is o_create_async in use?
|is o_setattr_async in use?
|o_pin and o_unpin don't look to be in use, why not remove them?
|o_quotacheck should be obsolete now.
|thread_is_stopped() should be more appropriate here, I will update this in next round.
|entry should never be NULL because statahead thread kept all un-stated entries, I'll change it to LASSERT.
|see dentry_was_stated() in llite_internal.h
|This doesn't work, because kernel has crashed in lustre_kill_super-&gt;kill_anon_super-&gt;generic_shutdown_super-&gt;shrink_dcache_for_umount which is before this function is called. I'll move waiting statahead threads to ll_umount_begin.
|Hmm, this is done because after amount_begin shrink_dcache is called, and it will BUG() if it can't free all dentries. On second thought, we can dput(parent) in statahead thread earlier, so that we don't need to wait for statahead threads to quit here. I'll verify it locally and update the patch later.
|on second thought, I decide to add ll_sa_running back, and wait all statahead threads quit in client_common_put_super(). By this kernel won't complain and lead to strange errors.
|yes, I forgot removing that assert when the implementation changed.
|We don't pick sa_entry off the list, and sai last put will cleanup all entries, so there is a race the cleanup might be done twice. So we let sai put to clean all up.
|Hmm, it's a small optimization here:

statahead thread will quit when it reaches the end of directory, but badly it won't wait for inflight statahead RPCs to finish, and we want more async statahead RPC reply get handled, so we stop interpreting statahead reply as late as we can.

As for the issue you mentioned, the dangling sa_entry in sa_entries_received list will be put in last ll_sai_put().
|I removed S_ISDIR() check because file type may be updated to other types, which I observed in racer test, and if this happens, statahead won't be stopped, and sai not put, finally cause umount hung.

I'll see how to handle this correctly.
|More sanity check is better.
|This is to ensure sai won't be referenced after last put, currently this is realized by statahead thread waiting for inflight RPCs to finish and checking lli_opendir_key == NULL in do_statahead_enter(), which is a bit subtle.
|Hmm, it's fine to quit after some timeout, though waiting indefinitely here won't cause any trouble. I'll update this if another rebase is needed.
|you're correct, I'll fix this.
|This piece of code was introduced by Wang Di, and it may be related with DNE, and since he is still working on it, it may be fixed in the future.
|You're right, originally I thought statahead thread will spawn and terminate agl thread so it's not necessary, but agl thread may still access sai content after setting its status to STOPPED.
|Actually sai_agl_valid is not needed to be protected by lli_agl_lock, but you're right about the race: even statahead waits for agl thread to stop, agl thread will call wake_up() after stopping which will access sai too.
|Yes, sai is used by refcounting. But statahead thread should tell agl thread to quit, so the code here is needed.
|hmm, it's 21: (4096 - 256)/196 = 20
256 is header size, 196 is ea size for each stripe.
|ahh, typo.
|Hmm, actually the original code for lock mode can be reserved, but for open(FMODE_READ), it only fetches a open lock back, without LOOKUP&#124;UPDATE bits.
|Yes, LCK_CW and LCK_PR will conflict with each other. So open lock is different now: a open(FMODE_READ) will conflict with open(FMODE_WRITE).

The reason is that mdc_revalidate_lock() matches LCK_CR&#124;LCK_CW&#124;LCK_PR&#124;LCK_PW mode locks, but setattr use LCK_PW, a lock with mode LCK_CR only conflicts with LCK_EX, therefore a client LOOKUP&#124;UPDATE lock will not be canceled as designed and will cause error.
|Okay, I'll add comment in the code.
|For chmod/chown/setfacl LOOKUP lock will be canceled, thus even the client still holds the OPEN lock, the dentry won't be used by subsequent open, and it will be opened again, so there is no security issue.
|I'll finish the remaining cleanup work in the patch for LU-3270.
|Can we LASSERT(exp-&gt;exp_nid_stats == old_stat) if exp_nid_stats is not NULL here? And if it's true, we can just putrefy(old_stat) below.
|this looks to be a bug, shouldn't struct mdt_rec_create the same for 1.8 and 2.x? if so, it should be fixed rather than just a comment here. But I don't want it be fixed here.
|good, after moving umask process to MDS, new client can act the same as old client, then the result is acceptable, and additional process is not necessary.
|actually 'ur_umask' is zero for old client, zero umask is just the old value used by MDS.
|I did run 'make newwiretest', but I forgot to update wirecheck.c. Thanks.
|Thank you, I'll take care of it next time.
|It's in another patch http://review.whamcloud.com/#patch,sidebyside,1972,4,lustre/include/lustre/lustre_idl.h.
|the type of task_struct-&gt;fs_struct-&gt;umask is int, and kernel other places also uses type 'int' to reference it.
|I'm afraid this change will confused existed scripts (or tools).
|this looks redundant, because root is also namespace visible.
|I'd prefer change test_1 into a common function which accept test directory, and new test_1 and test_1a call the function directly.
|shouldn't an 'else' be here to kunmap() and release 'page'?
|since GOTO is used, better change RETURN to EXIT or GOTO.
|s/will/with/?
|style: name != NULL
|lli_lsm_md is NULL for slave inode, so this check doesn't work as expected.  And on second thought NFS can work without lli_pfid, I'll update the patch later.
|lcc_page doesn't look to used any longer, is it reserved for future use?
|good catch.
|yes, I'll fix.
|Hmm, I've thought about this, but decided not to create in open. This is because we never want to change inode fid, see ll_update_inode(), this looks reasonable, because open is done on a known inode which has fid already.

From user space it will see open(O_CREAT) failed with -ENOENT, this may not comply with POSIX, but IMHO it's acceptable.

And if we want to handle this corner case, we may have to reuse the fid in client to recreate the file, and we need create it exclusively. This is also odd compared to the handling in this patch.
|Because statahead is getattr-by-fid, the fetched fid should be the same. It should be safe to assert on client side.
|This is a small race: between statahead readdir and statahead revalidate, the fid,name pair may be changed, because the dentry is found by name, but we do statahead by fid.
|Both new and old clients should have created file with this fid in lookup/revalidate already, so upon failure in open by fid, we don't need to handle MDS_OPEN_CREAT specially here, but return error to client.
|This can be done in a separate patch if necessary.
|Hmm, but I don't know a way to differentiate open after revalidate and open by NFSD. And herein a normal open may not come here, because the the file will be opened in .lookup. so for open after .revalidate, file should have been accessed before, it may be worthwhile to fetch open lock.
|http://review.whamcloud.com/#/c/7475/10 was landed, which simplified dentry revalidation, so that in most cases .revalidate just returns true, and let file open later.
|now 2.4 has this flag set, and AFAIK we only need to interop with 2.4 so far.
|If parent != child, then op_fid1 has been set with correct parent fid.
|Actually now lli_pfid is used by dne code to store master object fid, and on second thought NFS export can work without this, because if parent is unknown, it will set to the same as child, and MDT can handle this correctly. I've checked this on all branches, and I'll commit a patch to remove the use of it for NFS.
|These is a sanity test to expect to see error returned if internal open flags is set, and it looks reasonable as well.
|Please see mdt_open_by_fid_lock(), op_fid1 is used there, if we can't provide the correct parent fid, we can set it the same as child fid, and if MDT detect this, it will find fid from linkea.

As the above comment explains, for striped directory, we can't know parent stripe fid without name.
|op_fid3 was used by M_CHECK_STALE.
|If O_CREAT is set, client will not use valid cached dentry, but call .lookup to ensure file is created if necessary, please see ll_revalidate_dentry(), so MDS_OPEN_BY_FID should never be set with MDS_OPEN_CREAT simultaneously. I added an assert for this before, but it looks scary, and I removed it later, should I add some code to print error if it really happens?
|yes. Per John's comment, this is more friendly to user space applications.
|Then should I use 0x80000000000000ULL for OBD_CONNECT_UNLINK_CLOSE instead of current value you suggested? because obd_connect_names[] doesn't have index.
|This is complicated, how do you think if we define cfs_timer_disarm() to del_timer_sync() which is a safe version to delete timer in SMP.
|We don't want to introduce new wrapper functions, so I think it's fine to use del_timer_sync() directly here. And currently linux is the only platform lustre supports, if in the future other platforms are considered it will be fixed at that time.
|above loop looks scary, is it possible that dt_lookup() always returns -ENOENT?
|I agree with Bobi.
|ll_dir_chain_fini() can be moved to line 1274, and then upon ll_prep_md_op_data() failure, it can jump to line after ll_dir_chain_fini().
|It's not quite the same, in close it has file open mode, so knows the file handle. but for unlink, it just chooses one file handle cached and closes it in the sequence of WRITE, EXEC and READ.
|Yes, mdc_free_open() shouldn't free this unlink request early, I'll add check for it.
|unlink only closes unused file handle, it should not conflict with release. I'll add Jinshan to review this.
|it looks like lfsck should take LCK_EX mode lock always, why need to specify it in each call?
|It's because we used seq_file simply, the unused parameter is used as iterator to read/write multiple items, but we only do for single one. This is straightforward, should I document it down?
|Alex, could you give some suggestion on description of this proc entry?
|enclosing in parenthesis here will cause compile failure, and these will be fixed in another cleanup patch.
|ll_sai_put() will not need to hold spin lock if refcount &gt; 1.
|Ehh, I added this timeout per your request, in my original implementation I just wait for file_release() to notify to quit.

Because statahead thread will wait for all inflight RPCs to finish below, this won't cause any real issues.
|I just noticed that this was fixed in the last patch in this series, do you think it's okay to fix it there?
|good catch!
|what's &quot;tt_magic&quot; for?
|it's not in use for now.
|this assert always follows thandle_to_dt_update_request(), which can be put in to latter.
|shouldn't this be an assert?
|return NULL is wrong, because caller check return value with IS_ERR.
|it looks like you've changed to access this thandle via llog object and opd_storage; this comment needs update.
|use lfsck_obj2dev(child) instead?
|why only change this function, should all lfsck_layout_repair_xxx() follow the same semantic?
|ENTRY doesn't have corresponding RETURN.
|typo: s/interpterer/interpreter/
|RETURN doesn't have peer, and it's not necessary to trace entry/exit for such helper function.
|if transaction is not remote, this won't be called, so this comment needs update.
|Previously open cache can be used by normal applications, but with this change it's unused and each LOOKUP_OPEN will talk to MDS, and open cache will be NFS-reexport only.
|this looks scary.
|lfsck_ltd2tgt() may return NULL, can this assert always apply?
|ditto.
|since update_records.ur_params is commented out, you can use
struct object_update_param ur_params[0] directly in struct update_records.
|this struct doesn't look necessary, any place use this can use &quot;struct object_update_param&quot; directly.
|same.
|yes, I understand, but this checkout can be done outside of this function.
|it's strange to set &quot;record_update&quot; in this function since the name is just get_thandle, I don't see why it can't be checked in update_record_pack(), i.e, check fid_is_sane() and tt_update_records is not NULL.
|all lod_sub_object_declare_op() functions look similar, why not make it a macro?
|even this, you can make a macro which creates a template of this function, and then define each function with this template.
|lod_sub_object_op() can be made into a macro too.
|it's strange to pass in &quot;rc&quot; as argument, IMHO this macro should be in ({...}) format with return value.
|is it possible opc_str[opc] be NULL in the future?
|all functions in this file are called by OSP only, what's the benefit to put it in out_lib.c? IMHO this will increase ptlrpc module size, and make it unable to use OSP specific thread_info.
|s/OUT_XATTR_DEL/OUT_WRITE/?
|tur_update_records and tur_update_params were allocated in top_trans_start(), but freed here, which looks weird to me. At least you should allocate the default value in update_key_init(), and allow it be extended in use.
|all functions in this file are called by LOD only, and the same I don't see the benefit to put them in ptlrpc, btw, if these functions are in LOD module, then update_thread_info is not needed, but put into lod_thread_info instead.
|this looks like layer violation, is it better to check this in tgt_txn_start_cb()?
|same.
|the meaning of this flag doesn't look explicit to me, could you add comment?
|why not set lrd_ltd to dt when ld_child == dt?
|comment of this function needs update now that more is done.
|lb_len is allocated buffer length, which is often bigger than actually written, is this what you want?
|th_top is needed by sub_thandle only, why not put it there?
|I don't see why this is moved out of top_thandle, there are too many structure named xxx_thandle already.
|can th_top be NULL here? as is said, top_thandle should not need this field.
|IMHO sub_thandle can be embedded into osp/osd_thandle, so that it doesn't need to be allocated separately, and can simplify the code.
|this can be adjusted to LASSERT(ibits == MDS_INODELOCK_UPDATE &#124;&#124; ibits == MDS_INODELOCK_LOOKUP)
|it's more common to use param-&gt;oup_buf directly, and this is seen in other places in your patches too.
|s/executation/execution/
|update_transno was defined above already.
|can update_transno &lt; next_transno? should it be no different from req_transno?
|why not introduce a lock for OSP? which looks less layer violation to me.
|style: convert above and below whitespaces into tabs.
|is it better to name it osp_updates to differentiate from osp_update_request.
|return value is not in bool type.
|ditto.
|no lock for oaua_update, is it safe?
|it looks like only osp_md_write() calls this, could you explain why such version mechanism is for write only?
|as said above, could you explain what requests whose version unset?
|typo: s/his/this/
|typo: s/_arg/arg/
|lock is not necessary, since it will only be set at cleanup time, and currently it's not locked at that time.
|better to use -EINTR than -EIO?
|is it better to use th_result instead of -EIO?
|why version needs update here?
|this will cause LU-6330, please check it there.
|it should be (rc == 0 &#124;&#124; rc != -EREMOTE)
|style: parent != NULL
|if rc == 0, do we need to check OBD_MD_MDS yet?
|ours may be NULL, or you need to check return value of osp_object_update_request_create() in osp_update_request_create() to ensure ours is not NULL.

This is also seen in some other places where this is called.
|as you said our_rc can be positive value, but some interpreters treats all non-zero value as error, should positive converted into 0?
|trailing whitespace.
|ocd_inodespace is a log2 value, shouldn't it be converted anyway?
|there are sanity checks for o_dirty against grant, if per-extent tax is not added, those checks will fail.
|okay.
|it can save 1 RPC in this way.
1. if the transaction is remote only, commit can be done in tgt_blocking_ast(), just like extent lock cancel.
2. since all MDTs in DNE are symmetric, it's no different to sync which one.
|ok, I'll add a flag to achieve this.
|because the involved MDTs of previous conflicting operation is not known here except the one where OSP resides, and the MDT where the conflicting lock comes from may not belong to the involved MDTs mentioned above, so this patch just commit on opd_storage.

for example, previous operation involves obj0 on MDT0, obj1 MDT1, here comes an operation on MDT2, and involves obj0 on MDT0 and obj2 on MDT2, so it needs to commit previous operation, current patch will revoke cross-MDT lock on obj0, and cause MDT0 to commit.

do you have options for this?
|if cbpending is set, then the MDT where resource resides knows this, and it will sync there in tgt_blocking_ast() for CANCEL.
|it will be saved in ptlrpc_reply_state, and be released upon commit like local COS lock, or if it's revoked, it will be stolen from ptlrpc_reply_state, and cancel it immediately, finally the MDT where the resource resides will commit.
|I don't follow. Strict cos is to eliminate dependency between 'mkdir a/b' and any previous operation on parent 'a'. So the previous operation can have either local or remote lock on 'a', while tgt_blocking_ast is target BAST for remote lock.
|since this will cause sync on blocking cross-MDT lock cancel only, it should not hurt performance much.
|ahh, you're right, I'll fix it.
|soc is not enabled by default, so this is a good chance to enable it.
|1. no, before cross-MDT lock release, the transaction this lock belong to should commit to disk.
|Besides, I found one benefit to not set cbpending: this cross-MDT lock may be used by following operations too, so it avoids RPC if lock found in cache.
|because in this implementation write count is released immediately, if CBPENDING is set, it will be canceled. however we want to keep it until local transaction commit and then cancel it. So no matter you set CBPENDING or not, there needs a mechanism to save this lock until transaction commit.

As you can see from above if lock is not to be saved, mdt_fid_unlock_cancel() will cancel it immediately.
|it's clean to do it here, check in save_lock() is in case MDT is added dynamically.
|it's to let tgt_blocking_ast() to know this is a blocking lock, so that cross-MDT lock can do blocking-sync-on-cancel.
|this is cross-MDT lock, which is not set CBPENDING by defulat, so in cases it's not not saved, it should be unlocked and canceled immediately. see mdt_save_remote_lock() which is the only user.
|cross-MDT lock doesn't locate obj, because tgt_sync() will check obj version, while for DNE obj version may not be updated if it's remote (see tgt_txn_stop_cb()), so obj is not set here, and tgt_sync() below will do fs_sync.
|yes, these are cross-MDT locks, and in DNE these will be sync-on-cancel locks.
|yes, you can call it &quot;holding until commit&quot; lock, it's held to let resource owner know it's being used, so the resource owner can do sync-on-cancel on conflict.
|yes, and that's exactly what's done here and nothing more did here, though it's called relock, it doesn't take extra lock, but relock parent (which we can't know in the beginning).
|yes, we can know it from ea_data, however that should not be analysed in MDT layer, and also default stripe may lead to striped directory too?

for slaves, only when enqueueing we can know it's striped, isn't it? I don't think MDT should do too much to get these information, but wait for LOD to return to us.
|I'm not sure, or in the future -EAGAIN may come from other failures.
|do you mean mc is remote? it will return -EREMOTE to client.
|yes, if mp is remote, it will set modify_remote in the beginning, so all locks will check against COS locks.
|it's the same as COS is enabled but all requests from the same client. so there will be a lot of locks, and these locks will be released if the transaction they are in are committed.
|yes, previously mkdir didn't take child lock, this patch 'mkdir' will take child and stripe locks, and also relock parent if child is striped. So both striped mkdir and non-striped mkdir will take child lock, and the former will also take stripe locks.

so most of this patch is for the special case of 'mkdir d1' and 'mkdir d1/d2' when 'd2' is striped, and the other part is to relock parent with COS checked, which is for the case of any change on 'd1' and 'd2' is striped, e.g. 'chmod 777 d1' and 'lfs mkdir -c 2 d1/d2'.
|also in lmv_create():

        if (exp_connect_flags(exp) &amp; OBD_CONNECT_DIR_STRIPE) {

                /* Send the create request to the MDT where the object
                 * will be located */

                tgt = lmv_find_target(lmv, &amp;op_data-&gt;op_fid2);

And I just verified, the create will be processed where d2 resides.
|`lfs mkdir -i 1 d1/d2` will be done on the MDT where d2 resides, if d1 is remote, it will enqueue remote lock on d1, which will conflict with COS lock of d1. if d1 is on the same MDT as d2, this is a local operation, so won't conflict with COS locks of d1.
|yes, it's a special case, because DNE can create striped dir, which requires previous change on its parent permanent. eg. chmod 777 d1; lfs mkdir -c 2 d1/d2
|IMHO LDLM_FL_LOCAL is a flag to release lock after last decref, so currently only MDT local lock is set with this flag. If it's not set for distributed operations, these locks will be cached after use, even when the transaction they belong to is committed.
|no, when distributed operation enqueues local lock, it needs to specify this flag too to check against COS locks.
|I don't get you, could you explain in more details?

this flag is set in two cases:
1. distributed operation enqueues local lock.
2. distributed operation enqueues remote lock, this flag will be set in ldlm_handle_enqueue0
|I don't get it. How are those unused locks got rid of?
|yes, but there is default LMV, so it's inconvenient for MDT to know it's a striped directory creation.
|the case in dlm_lockd.c is for cross-MDT lock, for local lock only the caller know whether it should check against COS locks, so herein it's a striped dir, COS lock check is needed.
|yes, child fid is known. But is there a cheap way to know whether the fid is remote and striped?
|mti_locked: where current operation enqueued any lock.
mti_modify_remote_pre: 0 means current operation has not enqueued PW/EX remote lock.
mti_modify_remote_post: 1 means current operation has enqueued PW/EX remote lock, it will be set after each remote lock. so comparing this state with _pre, we can know whether a lock to take is a remote lock, this is done in mdt_modify_remote_check() after each lock.

I'll update comments in next update.
|yes it's feasible, but to check stripes, the object should be initialised first (to getxattr from it). If you do like this way, I will change to it in next update.
|no, eg. 'unlink a/b', 'a' is local, 'b' is remote, when MDT tries to lock 'b', it knows it's remote, or it's striped, then it should relock 'a' with flag set (check COS locks).

or do you mean we always check whether all involved objects are remote or striped in the beginning, so from locking the first object, we set this flag? yes, it's doable, but it's a too much of code, and also redundant with existed code. If distributed operation is rare (is it true?) on DNE, then relock will be rare too.
|I agree, but I don't want to change too much code, this can be improved in the future.
|yes, a modify_remote_state data structure as argument for lock can work, but it touches more code. But this data structure may need to be allocated in env too, but pass as argument to each place object is locked.
|explained in commit message comment.
|err, isn't this suggested by you?

because b can be recovered from other MDT, if a is not recoverable, recovery for b will fail, this is not acceptable for DNE recovery.
|tgt_blocking_ast() will sync for such lock cancel.
|Done
|Mostly it is. Because in the past mkdir didn't take lock on child, but now it's needed for DNE COS.

Except one small change which may belong to the previous patch (Commit-on-Sharing for DNE): relock parent with COS checked if child is striped for mkdir. (that's why I wrote in the comment &quot;eliminate dependency between 'mkdir a/b' and any 
operation on 'a'&quot;)
|for distributed transaction, it needs to set this flag when enqueueing local lock also, and this can't be detected by export and lock mode.
|on local node, if the second one is a distributed op, it needs to ensure the first one is committed, so this flag is needed.
|yes, I'm adding them.
|I'll see to that, but since migrate do try_lock anyway, and there is other case it may fail with -EBUSY, and according to the code -EBUSY is not a fatal error, and user should just retry.

Di, what's your suggestion?
|I'll see to that, but since migrate do try_lock anyway, and there is other case it may fail with -EBUSY, and according to the code -EBUSY is not a fatal error, and user should just retry.

Di, what's your suggestion?
|'lock_slaves' is not trustworthy because lock is not taken and slaves may be unlinked after that, so it can only be used as a hint for cos_incompat, now it needs to be initialised again. This is that cause of autotest sanityn cleanup error.

The same for other places it's used.
|it's moved into inodebits_lockmode_compat() above.
|by default COS is disabled, but on DNE system EX/RW locks are converted to COS locks and saved, and they are ignored by local operations(which involves single MDT), and checked by distributed operations (which is normally reint, and modify objects on several MDTs).
|as described above, this happens when current operation is distributed.
|in the beginning I added a LDLM callback -&gt;compat to do this outside of LDLM code, which separates LDLM and other modules. But inodebits lock is the only user of this callback, and it brought in more code changes and was not welcomed, so I got rid of it and moved it here. If no one objects I can bring that piece of code back.
|yes, MDT local EX/PW locks are always converted into COS locks and saved, but they are ignored by local operations, but checked by distributed operations (which set LDLM_FL_COS_INCOMPAT).

what do you think ruin ldlm? is it tgt-&gt;lut_commit_on_sharing check?

I'll add a design document later.
|Done
|there may be COS and RW/EX(concurrent enqueue by other service thread) locks for one object, so even upper layer knows it doesn't check COS locks, it needs to enqueue this lock, which will go here, or do I miss anything?
|indeed, previously LDLM_FL_COS_INCOMPAT is passed to inodebits_lockmode_compat(), but later I found replay may miss this flag, so I set this flag on @req directly. I'll remove it if an update is needed.
|yes, we can check l_blocking_lock, but why not just check cbpending? besides original Sync-on-Cancel in tgt_blocking_ast() already check this flag, so I set it here.
|tgt_blocking_ast() doesn't set this flag, that's why I set it here. It's okay to set it inside tgt_blocking_ast(LDLM_CB_BLOCKING).
|sync-on-cancel has &quot;blocking&quot; and &quot;always&quot; modes, while cross-MDT lock uses &quot;blocking&quot; mode, i.e, only when this cross-MDT lock is canceled, it triggers sync upon cancel. Because OSP won't cancel cross-MDT lock until local transaction is committed, which also guarantees distributed transaction update logs are committed, so it doesn't need to always trigger sync upon cancel.
|it's for cross-MDT lock Sync-on-Cancel, so that upon cross-MDT lock cancel, it knows there is a blocking lock, and will do sync there, see tgt_blocking_ast().
|yes, we can, if another update is needed I'll change this.
|there are limited in-wire ldlm flags, so this flag can only be set before use.
|because cross-MDT lock is in OSP layer, and can't access local storage, so upon cancel, it needs to trigger transaction commit on remote MDT where the resource resides, and it uses the existed Sync-on-Cancel mechanism on servers.
|okay, I'll change it to slc (Sync-Lock-Cancel) if another update is needed.
|soc (Sync-on-Cancel) is to trigger transaction commit for cross-MDT lock cancel. DNE Commit-on-Sharing triggers transaction commit for distributed operations, and to achieve this it uses both Sync-on-Cancel and Commit-on-Sharing.
|no, this is a readonly proc entry, all possible values are listed here to conform to ofd_sync_lock_cancel_seq_show().
|could you explain in more details?

how can two COS locks from different client exist on single-MDT system? the second lock will trigger Commit-on-Sharing which cancels the first one. Do I miss anything?

As for your second question, all locks in one bunch of the skiplist have the same mode/ibits, so check bunch head is enough, and no need to iterate each one.
|On second thought, this may not happen in real world. Because there can't exist two COS locks with the same bits from different clients currently. If we assume this is always true, check skiplist bunch head is enough.
|Indeed, I'll update the patch later.
|Done
|AFAICR CLIENT2 is always set when running auster, maybe recently there are some changes in starting auster, I'll check it in the beginning of this test like other places.
|I agree with John, check on server is enough, code here is redundant.
|ditto.
|IMHO LCF_BL_AST is used in client only, you can just set 0 here.
|do you mean LCF_BL_AST? AFAICS it's for ELC, which is used on client only, and this function is for OSP.
|doesn't $mds_indexs equal to $(comma_list $(mdts_nodes))?
|it's strange that line loghandle is set is not inside lgh_lock, and it doesn't look safe to me.
|ditto.
|this line should be inside lock_res_and_lock().
|this strict COS is to eliminate dependencies even from same client (it's not only for creation, but all modify operations on 'a').

so the general DNE COS is implemented in http://review.whamcloud.com/#/c/12530/.
|see previous comment.
|okay.
|both 'unlink /a' and 'mkdir /a' will enqueue PW lock on '/', so this will trigger COS, or do I miss anything?
|yes.
|yes, you're right. I'll change to lock child strict instead of parent.
|Oh, I made mistake in last comment. the COS lock is per-hash lock, so the conflict chance is rare between mkdir.
|mdt_count is counted based on config, so even only MDT0 is started, the count will be correct, I've verified it locally. or do I miss anything?
|Done
|this function doesn't look to be necessary, mdt_remote_permission_check() can be placed where it needs.
|s/fix/fixed/?
|s/mini/min/
|it's better to save policy before setting it, and restore it here.
|why get ref? can't it be deleted directly?
|you should haven meant insert_update_records_to_replay_list() instead of dtrq_insert().
|shouldn't batchid be cleared at the beginning of each loop? instead of here upon d_t_c_b_u() success.
|comment needs update since this function does lookup now.
|comment needs update.
|since variables are __u64 type, it's not necessary to spinlock here, and the same for all places lut_last_transno is used (except where it's updated).
|'nthreads' is meaningless here, should be set to 0. anyway it's not related with this patch.
|extra '\'.
|IMHO this doesn't fully solve the race, but only prevent request with MSG_REPLAY flag to resend, but actually this request may have been resent before this flag is set.

The race is actually between ptlrpc_resend() and ptlrpc_check_set(), ptlrpc_resend() will resend any request on the sending list which doesn't get reply. But reply may come after it resent the request.
|Hmm, this doesn't look possible to happen yet, but it looks strange that ptlrpc_check_set() checks rq_resend after after_reply(), maybe it should be an assert.
|1. a request lnet timeout, which leads to ptlrpc_resend().
2. in ptlrpc_resend() a replayable request doesn't get reply, and was resent, but only ptl_send_rpc() is called, the request doesn't reach MDS yet.
3. the above replayable request gets reply, and ptlrpc_check_set() calls ptlrpc_retain_replayable_request(), which marks request with MSG_REPLAY.
4. now this replayable request reaches MDS, since MDS is not in recover state, which cause eviction.

Is this possible?
|what if after_reply() is called for this replayable request, and then ptlrpc_resend() set rq_resend on this request?
|bash supports loop in background, so creating a temporary script is not necessary.
|style: hint != NULL
|this checkpatch warning may be false, because it's 2 whitespace after a tab, which is for indentation.
|this error message will be printed if above check is removed, should it be converted to DEBUG?
|though this is debug message, it's more clear to use la_copy all along.
|Done
|llapi_fid2path-&gt;root_ioctl() doesn't check relative pathname is because this command support fs name also, and it's hard to differentiate fs name and relative pathname. so if pathname doesn't start with '/', it's treated as fs name.

I'll fix other issues mentioned.
|When I wrote this code, I looked upon 'fileset' as opaque string, and MDS replied a FID corresponding to 'fileset' with this name, in this way we can support variable types of file set in the future. But current MDS only treats 'fileset' as subdir off ROOT.
|'level' and 'msg_flags' is unused here. Since this RPC packs a mdt_body in the request, any flag can be added in the future.

old server will ignore the field of fileset, if a new client mounts old server subdir, it will fall back to mount ROOT. This looks natural somehow, that's why I'm reluctant to introduce a new feature flag. Do you think this is necessary?
|I guess the main cause of this extra MDS_GETATTR is to fetch ACL, so that later permission check can be done correctly.

And what attributes do you think it should fetch and verify?  'fileset' is not necessary to be directory, but could be any type of container. maybe we don't need to check in client side, but let subsequent operation to be checked on server side.
|Done
|Done
|Done
|Done
|Done
|should it schedule() here?
|this can't be done outside of lli_sa_lock because sai may have been freed at this moment, and it's safe to wake_up inside spinlock.
|can you make sure which change really fix your issue?
|maybe such defensive code is not good, because it may hide real issue. IMHO an error message is enough.
|if above defensive code is removed, this doesn't look necessary.
|why set it 0?
|yes, it's a flaw, and I noticed it before, but since it's not the direct cause, so I didn't point it out, anyway it can be fixed here.
|IMHO memory barrier should be enough here, will you take a try?
|if it's not waken up because check sa_ready() and set sai_index_wait is not atomic, shouldn't sa_entry be ready now? so that l_wait_event below shouldn't wait.
|AFAICS this is the only point lwp_register_item is freed, so I don't see why it needs to be refcounted.
|but it needs root object, and when it's called this object is got by MDT already.
|it needs to revalidate anyway, because once it may have been revoked, and this revalidation needs to be done before real operation starts to avoid mixing this lock with locks in the operation.
|I found it's not natural to originate an ldlm lock in LOD, because AFAICR ldlm stuff should be handled in MDT layer.
|hmm, in the beginning I thought there should be fs default LMV stripe, do you know why there isn't?
|hmm, why originally not lock it here? wouldn't it cause stale cache somewhere?
|yes, it won't cause sanity issue, but for existed target, we've taken lock, and it's not necessary to invalidate. If another update is needed, I can update this to make code simpler.
|hmm, it's not easy to set ei_cbdata outside of this function, but it can be set to lock-&gt;l_ast_data after lock, while I thought in the future there may be more cases to cache remote lock, so it's packed here.
|umount will cancel all locks, while invalidate is called in lock cancel.
|because invalidate is done on existed objects in cache only, if object not found in cache, it will allocate a new one and initialise it, which will cause deadlock upon umount.
|but IMHO .invalidate() should be called on existed object in cache only, even checking umount in mdt_remote_blocking_ast() can avoid deadlock, it's still a waste to initialise a new object and then .invalidate its attributes.
|if object was released, mdt_object_find() will allocate and initialise object again, but this may lead to deadlock in umount.

To solve this, I'll replace mdt_object_find() with mdt_object_find_in_cache(), which will find object in cache only.
|yes, we can, but if target exists, we have locked it explicitly in MDT layer, so that its attributes are valid, and can be used safely as long as the lock is there.
|patch set 5 failed on sanity 230f, the cause is stale linkea, so from patch set 6 I disabled OSP attribute cache by default.

master can pass this test is because it always ignores cached xattr.
|yes, invalidate on LDLM lock revoke can help, but don't you think it's a big performance impact? Because we don't cache remote lock, so I don't think it makes sense to enable OSP attribute cache by default.

IMO there are two cases we enable OSP attribute cache:
1. we know we hold the LDLM lock, so the cache does help, this is the case for fs root.
2. update log, because the caller is the single user, it's safe here.

If you don't like LOC_F flag here, do you think it makes sense to call dt_declare_xattr_get() to enable OSP attribute cache for update log? it will look a bit weird this way, or I can add dt_declare_attr_get() interface to enable OSP attribute cache.
|current master code will enable OSP attribute cache by default in osp_md_declare_object_create(), and during test of this patch I found it will cause stale attribute used, so I disabled OSP attribute cache by default, but I found replay-single.sh 116a and some other tests failed, it's because update log needs to know log size (which is stored in attribute), so that it can write log in correct offset (see osp_md_write()).
|ahh, I answered it in last update, but forgot to commit the comment.

Previously I was asked not to cache default striping in LOD, and there existed an attribute cache mechanism in OSP, so I enabled the cache for remote MDT object. Yes it's better to add the similar mechanism for OSD, but is it beyond the scope of this ticket, I can create a ticket and handle next.
|default layout is stored in lod_default_striping now, which is not parsed here, but in lod_ah_init() when creating new files.
|Actually IMHO lmm doesn't need to store pool, because it's not used anywhere. Only the default pool in parent is used to create new files.
|yes, I implemented the latter.
|yes, line 3226 child will inherit all parent defaults first.
|this will invalidate cached attributes in OSP, and LOD doesn't cache default striping any more.
|this flag is protected by LDLM lock, so it's safe.
|okay.
|because without caching this PR lock, xattr cache is invalid, to avoid regrab such lock each time (there is not a separate thread to help regrab this lock), we will match from cache first, if not found then do real lock.
|yes, but according to the code some entries might be referenced and cannot be dropped.
|this code is prone to cause error, you can initialise inode to -ENOENT to avoid checking NULL pointer everywhere.
|parent needs to be locked before lookup child, but later if we find child is striped, i.e., this is a distributed operation, it needs to eliminate dependencies of any change to parent and child, if parent was not locked with cos_incompat set, it needs to relock parent.
|Yes, you're right, I though the output format should better be the same. Okay, I'll update the patch later.
|this function is a bit misleading, perhaps qmt_prep_lock_array() is better.
|s/unless/unused/?
|because list_replace_rcu() can ensure this replace is atomic, so the reader can always find old or new, other then empty.

from kernel code, I don't see mark used anywhere.
|I shouldn't say 'wait', but 'ensure'.
|umm, IMHO to support RCU list_head can only be walked forward, that's why there doesn't exist list_for_each_entry_reverse_rcu(). So if reader won't walk list reversely, it won't cause any issue.
|can you explain in details? IMHO the caller just remote this entry from list, call_rcu() below will wait for the reader to exit critical section.
|Alex didn't favour adding this flag before, so you'd better add him to review.
|see mdt_save_remote_lock(), which will be a good place to clear this flag.
|as I said in last comment, we'd better add a new lock flag which indicates whether attributes cached with this lock, so to avoid looking up object for all lock cancel.
|it's better to add a flag (which indicates attributes cached with this lock) so that we don't need to lookup mdt object for each lock cancel.
|I'd suggest not reference mdt_object at all, but lookup from cache, if found, invalidate, otherwise do nothing because object may be deleted from cache already: mdt_device can be got from ldlm_namespace-&gt;ns_obd-&gt;obd_lu_dev, and fid from res_id.
|Actually this once existed, but was removed, because if two distributed operations lock the same object (with the same mode), they should detect conflict.
|PR lock is not cached, so it seldom matches, besides lock match is not trivial operation. If a PR lock really helps, we can cache it explicitly (like ROOT xattr lock).
|ehh, the above ldlm namespace is MDT's, while the remote ROOT lock belongs to OSP's, which is freed in mdt_stack_pre_fini() above, but I don't think we can be sure no new request come after that.
|why make this so complicated? if we can assert refcount &gt; 1, and this put just drop one refcount, and safe to do inside spinlock.
|comment here is too simple to understand the real cause, and It's better to add error injection to reproduce this.
|no, I don't find in local test.
|Done
|it's tested above already.
|fine.
|ahh, it's for debug, thanks.
|what's the purpose of this?
|this looks too long, is there a better way?
|this function has three type of return values, which is not normal, it's better to check exp_need_sync outside of this function, or comment needed.
|yes.
|how come it races with ldlm_lock_decref? since the same rs is handled by the same thread.
|replace should be rare, remove old and add new is straightforward, why make it so complex?
|above is optimisation for -ENOENT or -ENODATA, which is to avoid to talking to remote MDT to know EA doesn't exist.
|replace is rare, IMO this is too complicated.
|because ops attr cache is valid with ldlm lock, and will be cleared upon lock revoke, 'replace' should be rare, but add new.
|Is this valid? I don't see 0 length value be converted to -ENODATA in local filesystem code.
|why 0 should be converted to -ENODATA?
|It happens when MDT (slave MDTs) can't fetch sptlrpc from MGS.
|no idea.
|As I said in the commit message, I think sptlrpc can be handled the same as other configs. This code is to serialise sptlrpc access, which is not needed any more.
|why not return -ETIMEDOUT? which looks more natural.
|If status is changed before percpu_counter_inc(), what will go wrong?
|yes, I read that patch, that's why I left this comment. IMHO no lock is needed, since access to barrier-&gt;bi_status is atomic (in case read bi_status result changes, you can read it to a temporary variable, and compare using this variable).
|will there be multiple writer? if not, I don't see why lock is needed here.
|Your code only guarantees barrier status check is atomic, and after checking, its status can change by others anyway. So for your requirement, no lock is needed.
|Okay, I see. Originally I thought this lock is for data, but it turns out to serialize barrier_freeze() and barrier_entry().
|IMHO check this inside mdt_reint() is more clean. And MDS_CLOSE can be checked in the beginning of mdt_close(), and let client retry later, which is simpler.
|Yes, since delay close don't cause any trouble, and the code is much simpler. Anyway it's your decision.
|Only one entry in mdt_reint().

The benefit to do it in mdt_reint() is that for reint operation MDT doesn't need to go deep into mdd_trans_start() to know that current operation should be delayed. So that the load can decrease, which may help freeze.
|Can this timeout be obtained from obd_timeout? So that user doesn't need to provide this.
|Yes I know they are independent. But it's also hard for user to know the value to set, what I said is that obd_timeout can be a hint, or wild guess as default, and it's better if this timeout value can be adapted by system, other than user.
|mgs_barrier_rwsem doesn't look be to necessary, I don't see place it's held long time, why not just just mgs_mutex?
|It's better not to LBUG() on network data.
|'newname' can be 'snapname'.
|fork_config/erase_config is easier to understand for users.
|Since this is used by fork_lcfg only, it's acceptable.
|This is a general function, we shouldn't add upper layer logic here, instead we should check exception outside this function.
|is there requirement to modify snapshot name?
|this is outside of ou_lock, can it guarantee all stale our fail with -EIO?
|won't this cause incompatibility with old data?
|better to name this llc?
|the above two can be inside a union.
|this is not true.
|In struct lov_mds_md they are not in a union.
|this should rarely happen, it's better to add fault injection to cover below code.
|better to name the above two comp_md_entry and comp_md, or just lcme, lcm.
|eh, this flag ldo_comp_cached is not necessary, you can just check whether ldo_comp_entries != NULL.
|when will do_comp_entries != NULL but ldo_comp_cached not set? my question is now that the layout is always cached for object (until object is removed from object cache), this flag doesn't look necessary.
|master doesn't check this at all.
|we can live without this flag, can't we?
|why not call it lod_verify_lum?
|why remove this line? lds is thread data, and may be used multiple times.
|why remove this line?
|this line shouldn't be removed.
|why this is removed, if so, the comment should be updated too.
|could you comment what this means? shouldn't this be treated as EINVAL? I don't understand why id is mixed with flags.
|what does this mean?
|when will left &gt; 0?
|I don't get it, if the component was inherited from parent already (and it's valid), it shouldn't set to fs global default values.
|this may mislead, because 'root' is 'fs default', while the last one is fix up to sanity values.
|see comment in line 3712.
|why?
|why? can you comment on the logic of layout inheritance?
|why it's different from master?
|lp shouldn't be NULL here.
|is the logic changed? this should be done when parent doesn't provide default values for all fields.
|we can't return here, because layout may not be sane, which will cause assertion in create, so at least we need to fix up at the end of this function.
|ditto, so you need to verify whether this failure will cause assertion later.
|why remove the above code?
|ahh, never mind, I see it added in next patch.
|is it better to add a new LLT? otherwise comment for LLT_EMPTY needs update.
|it's ambiguous to just comment it 'index', maybe 'layout index + stripe index', or 'subio_index', 'comp_index'?
|when lump == NULL, it's used to delete default stripe info, previously it sets all to default value, but in your code it does nothing, which is wrong.
|it's good to remove extra code, but even ll_layout_refresh is redundant IMO, which can slow down setstripe.
|The use of llot_cur_comp doesn't look natural to me, is the API decided in design document already? I'd prefer to expose lap_layout_comp to user, and specify it explicitly in all API.
|Shouldn't we return -EROFS here other than filter out CREATE flag?
|lookup(LOOKUP_CREATE) is from open(O_CREAT), IMHO it's correct to reject such open in an rdonly filesystem.
|I mean lookup can reject it right here, and no place says lookup(LOOKUP_CREAT) can't return -EROFS. Actually your code is not wrong, but I think it makes code complicated, what failure my suggestion may cause?
|ahh, I made a mistake, when I checked mknod yesterday, I missed i_mutex lock in lookup_create(), so create and lookup will be serialized in any case. Bruno is right, this can only happen between create and access by fid.
|IMO this can happen with concurrent create and lookup, create may have finished creation on server, but ll_create_it() not called yet, now another lookup can initialize this inode, thus this race happens.
|lookup will initialize this inode, and allocate a dentry for it, that's why inode-&gt;i_dentry is not empty upon create in LU_8907.
|so a single write will never trigger more than 1 layout component initialisation?
|why li_end is not set to offset+count?
|without memory barrier here we can't make sure these are executed in this order, a smp_mb() is needed here.
|s/found stable/find stale/
|yes, I'll fix this in next update.
|Because the subsequent updates in the same request may access this object either, we can't BANSHEE it here, otherwise the subsequent update handling will dead wait.
|In sanity 17n, dir was opened, then it was migrated (accessed in OUT), and then files under it were migrated, in the last step, it issued getattr dir, which cause deadlock.
|yes, I also think so, but current code BANSHEE object for create only, I thought there might be some unknown reason. I'll update the patch.
|Maybe I misunderstood something: objects allocated in OUT also have all layers initialized, because out_handle() -&gt; dt_locate_at() uses site-&gt;ls_top_dev to allocate object, it's the same as objects allocated in MDT. Previously I thought you mean some operation done by OUT doesn't update all layers, so such object can't be reused.
|1. MDT opened object, and store pointer in mdt_file_data.mfd_object
2. this object is accessed in OUT, flag INCOMPLETE is set.
3. MDT getattr lookup this object, found it's INCOMPLETE, wait for it release, deadlock occurs.
|I tested this, and found deadlocks, the root cause is open will get a refcount of obj, and release it on close, so in this period if this object is accessed in OUT, and then from MDT, it deadlocks. What's your suggestion?
|Then why BANSHEE object allocated by OUT_CREATE? And in the first comment, you said &quot;why do you care about OUT_CREATE only? any OUT_* can populate an object in  LU ?&quot;
|the opened object won't be released until close, but during this period it may be accessed from OUT and MDT again, so in the last step when it's accessed from MDT, lookup will wait for it to release.
|Normally this unhashed object will be put below and get freed, so in this short period if another object with the same fid is created, will it bother?

If you mean this object was referenced already before it's unhashed, um, that looks to be a rare case since this is newly created, if you think this should be handled, we can alloc this object and never put it cache for create, do you think it's okay?
|I'll double check this, you can see LU_OBJECT_HEARD_BANSHEE is still set in osp_object_release() because this function can't be called there which will cause deadlock.
|Yes, I'll add that.
|It's here to be identical with lod_read(), which doesn't have declare function, and this is an assertion, there is not much difference to put it in both places.
|because it will be used to decref locks from newrep rs also, this looks more general.
|Indeed, it may triggers async commit for COS lock, which won't sleep, but reprocess waiting list may sleep, I'll update the patch.
|yes, but I don't find why ldlm_lock_decref() can't be called inside rs_lock.
|There may be issues with current code: ptlrpc_save_lock() is called inside exp_lock and scp_rep_lock, so ldlm_lock_decref() may be called rarely. Anyway I'll try to understand why it's necessary to do it here.
|do you mean convert to COS mode inside rs_lock? because ldlm_lock_downgrade() will sleep.
|I'm afraid not, they should be per-thread data, not on-stack data, but hr thread doesn't have this yet.
|Yes, but this is frequently used, and it's too big to allocate in stack.
|Previous LASSERT in line 2229 was triggered because lock was released by transaction commit. To avoid this, get lock inside rs_lock.
|Actually this lock mode is used to drop r/w count, it's even okay to not change its mode because the saved lock is always write lock. And if transaction was committed already, this lock will be released below soon, it doesn't matter to set its mode to COS, the biggest impact is it may cause extra sync, but because the window is so small this will hardly happen.
|Patch Set 15:

(5 comments)
|Patch Set 24: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 20: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 23:

(3 comments)
|Patch Set 24: Code-Review+1
|Patch Set 27: Code-Review+1
|Patch Set 24: Code-Review+1
|Patch Set 26: Code-Review+1
|Patch Set 28: Code-Review+1
|Patch Set 24:

(1 comment)
|Patch Set 25:

(1 comment)
|Patch Set 28: Code-Review+1
|Patch Set 24: Code-Review+1

(4 comments)
|Patch Set 27: Code-Review+1
|Patch Set 28: Code-Review+1
|Patch Set 21: Code-Review+1

(1 comment)
|Patch Set 22: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 21:

(4 comments)
|Patch Set 24:

(1 comment)
|Patch Set 24:

(1 comment)
|Patch Set 28: Code-Review+1
|Patch Set 8: Code-Review+1

(1 comment)
|Patch Set 12: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 12: Code-Review+1
|Patch Set 11: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 12: Code-Review+1
|Patch Set 17: Code-Review+1
|Patch Set 12:

(8 comments)
|Patch Set 13:

(1 comment)
|Patch Set 14: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 7: Code-Review-1

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)

Fan, sorry for the late reply, I just saw it.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 12: Code-Review+1
|Uploaded patch set 2.
|Abandoned

not needed any more, fixed by other patch.
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 11.
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 9: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Abandoned

not needed any more, and it's subtle to fetch too many locks.
|Patch Set 2: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Patch Set 3: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

Hi Hiroya, I did some test to make clear how export refcounted in connect, it should work now. Could you help review and verify it works in your test environment (for normal and recovery cases)?
|Patch Set 4: (1 inline comment)


|Patch Set 4: (1 inline comment)


|Patch Set 5: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 6: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 7:

Hiroya, could you check the  build failure? I found other 1.8 patch build successfully.
|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 8:

The patch for master has been landed: http://review.whamcloud.com/#change,3244
|Patch Set 9: Looks good to me, but someone else must approve


|Patch Set 10: Looks good to me, but someone else must approve


|Patch Set 10: -Code-Review

Johann, could you help abandon this patch?
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 18:

why it's removed from /lost+found in a hurry? but not leave it there and let LFSCK handle it, and put link count after processing?
|Patch Set 24: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3:

(2 comments)
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

both maloo failures are not caused by this patch: sanity 39k failure first appeared on Nov 14: https://testing.hpdd.intel.com/sub_tests/query?utf8=?&amp;test_set%5Btest_set_script_id%5D=f9516376-32bc-11e0-aaee-52540025f9ae&amp;sub_test%5Bsub_test_script_id%5D=08407d3a-32be-11e0-b685-52540025f9ae&amp;sub_test%5Bstatus%5D=FAIL&amp;sub_test%5Bquery_bugs%5D=&amp;test_session%5Btest_host%5D=&amp;test_session%5Btest_group%5D=&amp;test_session%5Buser_id%5D=&amp;test_session%5Bquery_date%5D=&amp;test_session%5Bquery_recent_period%5D=&amp;test_node%5Bos_type_id%5D=&amp;test_node%5Bdistribution_type_id%5D=&amp;test_node%5Barchitecture_type_id%5D=&amp;test_node%5Bfile_system_type_id%5D=&amp;test_node%5Blustre_branch_id%5D=&amp;test_node_network%5Bnetwork_type_id%5D=&amp;commit=Update+results
while cont-sanity failure has a ticket LU-5924.
|Uploaded patch set 5.
|Patch Set 5:

lustre-rsync-test 2b failed for LU-4256
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Abandoned

This is a wrong fix.
|Patch Set 11: Code-Review-1

This will introduce a security hole: a malicious client can fake a request with PERMITTED flag set, so that it can access any content under a directory. IMHO you should always allow lookup '..' on MDT, but for others it should be done as before. This should be a MDS size only change.
|Patch Set 11:

s/MDS size/MDS side/
|Patch Set 12: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Fanyong, the dt_lookup() LBUG on parent, which is the 2nd fix in this patch.
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 6:

(2 comments)
|Patch Set 7: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 12: Code-Review+1
|Patch Set 16: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 7: Code-Review+1

(2 comments)
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4:

(2 comments)
|Patch Set 4: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 8: Code-Review+1
|Uploaded patch set 1.
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 9:

(1 comment)
|Patch Set 11: Code-Review+1
|Patch Set 12: Code-Review+1
|Patch Set 17: Code-Review+1
|Patch Set 1: Code-Review-1

To invalidate lustre dentry, setting an INVALID flag is all that's been done. So I don't see the reason to lock inode during migration, could you point out a failure that's caused by this?
|Patch Set 1:

i_mutex has nothing to do with dentry management, if it's needed here, it should be of other reason. BTW you should add a test to reproduce the failure.
|Patch Set 4:

(1 comment)
|Patch Set 5:

The patch looks fine, but I still don't understand how it can fix LU-4712, which panic'd on an invalid dentry (possibly a freed one), which this patch just serialise migrate with lookup/rename/.... BTW according to John's test, this issue also happens when migrate is disabled.
|Patch Set 5: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 9:

(3 comments)
|Patch Set 9: Code-Review+1
|Uploaded patch set 4.
|Patch Set 6: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 11: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Chris, I don't follow you, lai.siyao@intel.com is my official email address.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Abandoned

wrong fix
|Patch Set 7: Code-Review+1
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 11: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1

this looks like a hack, but I can't think of a better way.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1

basically I'm fine with this cleanup; is there any plan to re-implement SOM?
|Patch Set 5: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1

(2 comments)
|Patch Set 2: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: (1 inline comment)


|Patch Set 2: (2 inline comments)


|Patch Set 2: Abandoned

fix for 1.8 not required.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 3: (3 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: (2 inline comments)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned

This is a duplicate of TT-59, and Sarah is working on that.
|Patch Set 2: Looks good to me, but someone else must approve

I am just wondering whether customer uses NUMA arch, and is this tested and working?
|Patch Set 3: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

Since Andreas is not available recently, add Johann to review.
|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

review for b1_8 is on http://review.whamcloud.com/#change,526
|Patch Set 1:

If the invalid message is shorter than sizeof(struct ptldebug_hdr), and it's at the end of the log file, it's not counted into bad line.

This test is as follows:
1. dump a log file, modify some lines to bad format, and count bad lines.
2. `cat log_good log_bad log_good &gt; log_corrupt`, and then count bad lines.
3. in step two, the short message is not at the end of log file, therefore it's not counted into bad lines.

Oleg, if you still think this is a bug for `lctl`, I will modify lctl code and re-submit a patch.
|Patch Set 2: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3:

Hi Sarah, could you check http://review.whamcloud.com/#change,460?

node_var_name() is a better name than client_var_name() IMO.
|Patch Set 4: (1 inline comment)


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: (3 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3:

It's not a issue IMO: all the proc entries are for obd which is initialized already, while filter_common_setup() mostly setup disk filesystem.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1:

Hi Oleg,

This failure is not triggered by autotest in this round, could you merge this debug patch, so that it may be triggered in other autotest, and help find the cause. After that I will remove this debug patch.

Thanks,
- Lai
|Patch Set 1: (6 inline comments)


|Patch Set 1: (4 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (4 inline comments)


|Patch Set 2:

Oleg, I see we need to support large pages, but current 2.x seems lack of this.

In mdt_readpage(), start and end hash is stored in each directory page, if client page is bigger than server page, the hash value read by client should not be able to cover the range the client page really holds. eg, if client page is 8k, twice the size of server page, and this dir happens has 8k bytes of data, so on server side, it's two pages, and each page stores the start and end hash, but client treat them as one page, and will assume the hash range of the first server page as its, finally this should lead to problem.

To fix it, server should know the page size of client, and package directory entries into reply buffers according to client page size.

Please correct me if I misunderstood.
|Uploaded patch set 3.
|Patch Set 3:

This is tested with LU_PAGE_SIZE 512, 1K, 2K and 4K Byte, so I think the large page size on client size should work too.
|Patch Set 3:

Oleg, the reply dir entries are packed with page size LU_PAGE_SIZE, so the only requirement here is both server and client CFS_PAGE_SIZE bigger than LU_PAGE_SIZE (this should always be true):
* on server size, only LU_PAGE_SIZE will be used to store lu_dirpage inside a *page, and this lu_dirpage will be packed into reply buffer.
* on client, if necessary several lu_dirpage in reply buffer will be combined into one dir page.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: (3 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

The only test failure is caused by http://jira.whamcloud.com/browse/LU-478.
|Uploaded patch set 8.
|Patch Set 8:

A test case added for large readdir in sanity 24v.
|Uploaded patch set 9.
|Patch Set 9: (2 inline comments)


|Uploaded patch set 10.
|Patch Set 1: (1 inline comment)


|Patch Set 1:

So for MGC, I checked the code, it's similar to normal OSC. lustre_common_put_super() will call obd_disconnect() for it explicitely, if the situation you mentioned happens, it should be another race condition, it's better to fix in another ticket.
|Patch Set 1:

OST logs are missing in maloo test result, and client reports mount OST failed with -ENOTCONN.
|Patch Set 1: Abandoned

this is a temporary patch.
|Patch Set 1:

Autotest should have failed on http://jira.whamcloud.com/browse/LU-426, will wait for LU-426 patch landed and retrigger test.
|Patch Set 1: Abandoned

this is a temporary patch.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: Looks good to me, but someone else must approve

(1 inline comment)

Though this looks work in theory, I suggest full test is done before committing.
|Patch Set 1: (2 inline comments)

rc = seq_client_alloc_seq(seq, &amp;seqnr);

if (rc) {
   CERROR(&quot;%s: Can't allocate new sequence, &quot;
          &quot;rc %d\n&quot;, seq-&gt;lcs_name, rc);

   cfs_up(&amp;seq-&gt;lcs_sem);

   RETURN(rc);
}

I've added seq_fid_alloc_fini() before cfs_up(), so it's safe here.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Abandoned

git push to wrong branch.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 1:

Oleg, do you think it's okay to land?
|Patch Set 5: (2 inline comments)


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 2:

Hi Oleg, this patch is ready to merge.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1:

Merged from master and retrigger autotest.
|Uploaded patch set 2.
|Patch Set 2:

No change against last patch, but rebase to master.
|Uploaded patch set 3.
|Patch Set 3:

update from master, no new changes.
|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 10: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Patch Set 3: Abandoned

This fix introduced new bug, a new fix has been submitted. This can be abandoned now.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 6: (3 inline comments)


|Patch Set 9: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 8: (11 inline comments)


|Patch Set 17: Looks good to me, but someone else must approve


|Patch Set 10: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 10: Looks good to me, but someone else must approve


|Patch Set 1:

Hi Oleg,

Could you check my comment on LU-482, if you don't object, this patch should be an acceptable solution.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

merge again to retrigger autotest.
|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

Retrigger autotest because last time failed on provisioning.
|Uploaded patch set 7.
|Patch Set 7:

Two failures in last autotest are known issues, retrigger autotest.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

Though the original request is for 1.8 only, I port it to 2.x.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

Grrr, this is required to be fixed in 2.x only.
|Patch Set 2: Restored

abandon in wrong place
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: (1 inline comment)


|Patch Set 7: (1 inline comment)


|Uploaded patch set 8.
|Patch Set 8: (5 inline comments)


|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11:

Update to master branch, nothing changed.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13:

Previous Maloo conf-sanity.sh test failed because in mdt_init0() mdt_procfs_init() is called after mdt_start_ptlrpc_service(), while the latter one needs register several proc entries under mdt proc entry.
|Patch Set 13:

I've run three rounds of auster test, and all could pass. I think the failure reported by maloo may be a mistake, and I will retrigger it.
|Uploaded patch set 14.
|Patch Set 14:

This time Maloo only reported conf-sanity failure, but I can't reproduce it. The log shows MGC request timeout and cause client mount failure, I don't see anything special occurred, maybe it's caused by network failure.

I will retrigger a maloo test.
|Uploaded patch set 15.
|Patch Set 15:

The test log shows the MDT OSC connect request failed with -ETIMEDOUT, and this request held one refcount which was not put because request_out_callback() was not called.

And finally cause this OSC import was never put.

I am not quite clear how this patch affects this, will need a little more time to review the code.
|Patch Set 15:

The failure looks not related with this patch , but it doesn't happen in tests for other patches. I will split this patch into several parts, and see which one will cause the failure.
|Patch Set 15:

I triggered maloo once, and it passed without failure: http://review.whamcloud.com/#change,938. I will merge from master and trigger maloo again to confirm.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 17:

Hi Bobi, Johann and Mike, this patch has passed autotest finally, could you review one more time? Many thanks!
|Uploaded patch set 18.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(7 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

Johann, could you land this?
|Patch Set 1:

Oleg, could you land this? It's blocking autotest.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

This doesn't really fix.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

The failure looks to be ORI-467, I'll retrigger the test later.
|Patch Set 3:

Don't find anything special in testlog, and it could pass in my test environment, retrigger autotest.
|Uploaded patch set 4.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

Autotest failed on a known issue, I'll retrigger the test.
|Patch Set 4:

Failed on a known issue, retrigger autotest.
|Patch Set 2: I would prefer that you didn't submit this

Mutex is not the same as semaphore, and it has some special rules compared to semaphore:
* - only one task can hold the mutex at a time
* - only the owner can unlock the mutex
* - multiple unlocks are not permitted
* - recursive locking is not permitted
* - a mutex object must be initialized via the API
* - a mutex object must not be initialized via memset or copying
* - task may not exit with mutex held
* - memory areas where held locks reside must not be freed
* - held mutexes must not be reinitialized
* - mutexes may not be used in hardware or software interrupt contexts such as tasklets and timers

I've made a patch before, and found the following semaphore cannot be replaced with mutex:
* lustre_lock.l_sem
* quotacheck_thread_args.qta_sem
* obd_device_target.obt_quotachecking
* client_obd.cl_mgc_sem

I'll attach my patch here, will you update it?
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 5: (2 inline comments)


|Patch Set 6:

Some new change for relative code:

/var/lib/jenkins/workspace/lustre-reviews/arch/i686/build_type/server/distro/el5/ib_stack/inkernel/BUILD/BUILD/lustre-2.1.56/lustre/mdt/mdt_open.c: In function 'mdt_empty_transno':
/var/lib/jenkins/workspace/lustre-reviews/arch/i686/build_type/server/distro/el5/ib_stack/inkernel/BUILD/BUILD/lustre-2.1.56/lustre/mdt/mdt_open.c:588: error: implicit declaration of function 'cfs_mutex_down'
/var/lib/jenkins/workspace/lustre-reviews/arch/i686/build_type/server/distro/el5/ib_stack/inkernel/BUILD/BUILD/lustre-2.1.56/lustre/mdt/mdt_open.c:611: error: implicit declaration of function 'cfs_mutex_up'
|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: No score

The only failure is caused by LU-614.
|Patch Set 3: Looks good to me, but someone else must approve


|Uploaded patch set 4.
|Patch Set 4: Looks good to me, but someone else must approve


|Uploaded patch set 6.
|Patch Set 6: Looks good to me, but someone else must approve

merge again to retrigger autotest.
|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 13: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: No score

Oleg, you're mistakenly added to inspector by me, you can ignore this inspection.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

Failed on known issue, rebase and retrigger test.
|Uploaded patch set 3.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1:

Chris, yes if there are 1 million locks, they will be dumped, but in this period no lock is held, and it will be done on one specific CPU core, so other ldlm threads won't be blocked, and system won't be unresponsive.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 1:

Once a panic is reported:

2012-04-04T02:28:34.647562-05:00 c0-0c1s6n1 BUG: unable to handle kernel paging request at fffffffffffffffe 
2012-04-04T02:28:34.647631-05:00 c0-0c1s6n1 IP: [&lt;ffffffff8111ca49&gt;] nameidata_to_filp+0x39/0x80 
2012-04-04T02:28:34.647644-05:00 c0-0c1s6n1 PGD 1529067 PUD 152a067 PMD 0 
2012-04-04T02:28:34.647656-05:00 c0-0c1s6n1 Oops: 0000 [#1] SMP 
2012-04-04T02:28:34.647666-05:00 c0-0c1s6n1 CPU 0 
2012-04-04T02:28:34.677634-05:00 c0-0c1s6n1 Modules linked in: xpmem dvspn(P) dvsof(P) dvsutil(P) dvsipc(P) dvsipc_lnet(P) dvsproc(P) nic_compat lmv mgc lustre lquota lov osc mdc fid fld kgnilnd ptlrpc obdclass lnet lvfs libcfs ib_core ipip tunnel4 krsip kdreg gpcd_gem ipogif_gem kgni_gem hwerr(P) rca hss_os(P) heartbeat simplex(P) ghal_gem cgm craytrace 
2012-04-04T02:28:34.677675-05:00 c0-0c1s6n1 Pid: 3742, comm: creat07 Tainted: P W 3.0.13-0.27.1_1.0000.6537-cray_gem_c #1 
2012-04-04T02:28:34.708155-05:00 c0-0c1s6n1 RIP: 0010:[&lt;ffffffff8111ca49&gt;] [&lt;ffffffff8111ca49&gt;] nameidata_to_filp+0x39/0x80 
2012-04-04T02:28:34.708180-05:00 c0-0c1s6n1 RSP: 0018:ffff880204df3d08 EFLAGS: 00010282 
2012-04-04T02:28:34.708203-05:00 c0-0c1s6n1 RAX: ffff88020e17a100 RBX: ffffffffffffffe6 RCX: ffffffffa072f360 2012-04-04T02:28:34.708215-05:00 c0-0c1s6n1 RDX: 0000000000000000 RSI: 0000000000000022 RDI: ffff880204df3e28 2012-04-04T02:28:34.708233-05:00 c0-0c1s6n1 RBP: ffff880204df3d28 R08: 0000000000000022 R09: 0000000000000000 2012-04-04T02:28:34.708244-05:00 c0-0c1s6n1 R10: 0000000000000300 R11: 0000000000000000 R12: ffff880204df3e28 2012-04-04T02:28:34.737729-05:00 c0-0c1s6n1 R13: ffff88020e08a540 R14: 0000000000000200 R15: ffff880204df3dc8 2012-04-04T02:28:34.737769-05:00 c0-0c1s6n1 FS: 00000000006f7860(0063) GS:ffff88021fc00000(0000) knlGS:0000000000000000 2012-04-04T02:28:34.737783-05:00 c0-0c1s6n1 CS: 0010 DS: 0000 ES: 0000 CR0: 000000008005003b 2012-04-04T02:28:34.737802-05:00 c0-0c1s6n1 CR2: fffffffffffffffe CR3: 000000020ce51000 CR4: 00000000000006f0 2012-04-04T02:28:34.737813-05:00 c0-0c1s6n1 DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 2012-04-04T02:28:34.768314-05:00 c0-0c1s6n1 DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 2012-04-04T02:28:34.768355-05:00 c0-0c1s6n1 Process creat07 (pid: 3742, threadinfo ffff880204df2000, task ffff88020e17a100) 
2012-04-04T02:28:34.768367-05:00 c0-0c1s6n1 Stack: 
2012-04-04T02:28:34.768378-05:00 c0-0c1s6n1 ffff880204df3e28 ffff880204391c38 ffff880204df3e28 0000000000000000 
2012-04-04T02:28:34.768396-05:00 c0-0c1s6n1 ffff880204df3d88 ffffffff8112ad8a ffff88020d470000 0000000100008241 
2012-04-04T02:28:34.768407-05:00 c0-0c1s6n1 ffff880200000022 ffff88020e08a540 ffff880204df3d88 0000000000000051 
2012-04-04T02:28:34.797410-05:00 c0-0c1s6n1 Call Trace: 2012-04-04T02:28:34.797435-05:00 c0-0c1s6n1 [&lt;ffffffff8112ad8a&gt;] do_last+0x1da/0x790 
2012-04-04T02:28:34.797447-05:00 c0-0c1s6n1 [&lt;ffffffff8112c003&gt;] path_openat+0xc3/0x3c0 
2012-04-04T02:28:34.797472-05:00 c0-0c1s6n1 [&lt;ffffffff8112c413&gt;] do_filp_open+0x43/0xa0 
2012-04-04T02:28:34.797483-05:00 c0-0c1s6n1 [&lt;ffffffff8111da12&gt;] do_sys_open+0x152/0x1e0 
2012-04-04T02:28:34.797493-05:00 c0-0c1s6n1 [&lt;ffffffff8111dacb&gt;] sys_open+0x1b/0x20 
2012-04-04T02:28:34.823257-05:00 c0-0c1s6n1 [&lt;ffffffff8111dae0&gt;] sys_creat+0x10/0x20 
2012-04-04T02:28:34.823295-05:00 c0-0c1s6n1 [&lt;ffffffff812e60fb&gt;] system_call_fastpath+0x16/0x1b 
2012-04-04T02:28:34.849374-05:00 c0-0c1s6n1 [&lt;0000000000440270&gt;] 0x44026f 
2012-04-04T02:28:34.849453-05:00 c0-0c1s6n1 Code: 83 ec 20 4c 89 65 f0 48 89 5d e8 49 89 fc 4c 89 6d f8 48 8b 9f 98 00 00 00 4c 8b a8 40 03 00 00 48 c7 87 98 00 00 00 00 00 00 00 
2012-04-04T02:28:34.849469-05:00 c0-0c1s6n1 83 7b 18 00 74 18 48 89 d8 4c 8b 65 f0 48 8b 5d e8 4c 8b 6d 
2012-04-04T02:28:34.849490-05:00 c0-0c1s6n1 RIP [&lt;ffffffff8111ca49&gt;] nameidata_to_filp+0x39/0x80 
2012-04-04T02:28:34.849501-05:00 c0-0c1s6n1 RSP &lt;ffff880204df3d08&gt; 
2012-04-04T02:28:34.849512-05:00 c0-0c1s6n1 CR2: fffffffffffffffe 
2012-04-04T02:28:34.875343-05:00 c0-0c1s6n1 ---[ end trace c52f1715fb11f9f9 ]--- 
2012-04-04T02:28:34.875371-05:00 c0-0c1s6n1 Kernel panic - not syncing: Fatal exception 
2012-04-04T02:28:34.875420-05:00 c0-0c1s6n1 Pid: 3742, comm: creat07 Tainted: P D W 3.0.13-0.27.1_1.0000.6537-cray_gem_c #1 
2012-04-04T02:28:34.875438-05:00 c0-0c1s6n1 Call Trace: 
2012-04-04T02:28:34.875450-05:00 c0-0c1s6n1 [&lt;ffffffff81006141&gt;] try_stack_unwind+0x151/0x190 
2012-04-04T02:28:34.900836-05:00 c0-0c1s6n1 [&lt;ffffffff81004b04&gt;] dump_trace+0x84/0x440 
2012-04-04T02:28:34.900863-05:00 c0-0c1s6n1 [&lt;ffffffff81005cf7&gt;] show_trace_log_lvl+0x57/0x70 
2012-04-04T02:28:34.900913-05:00 c0-0c1s6n1 [&lt;ffffffff81005d20&gt;] show_trace+0x10/0x20 
2012-04-04T02:28:34.900926-05:00 c0-0c1s6n1 [&lt;ffffffff812e2bfd&gt;] dump_stack+0x74/0x7f 
2012-04-04T02:28:34.900937-05:00 c0-0c1s6n1 [&lt;ffffffff812e2c97&gt;] panic+0x8f/0x1cb 
2012-04-04T02:28:34.900955-05:00 c0-0c1s6n1 [&lt;ffffffff81005b13&gt;] oops_end+0xa3/0xe0 
2012-04-04T02:28:34.900966-05:00 c0-0c1s6n1 [&lt;ffffffff81023a41&gt;] no_context+0xf1/0x260 
2012-04-04T02:28:34.926653-05:00 c0-0c1s6n1 [&lt;ffffffff81023cf5&gt;] __bad_area_nosemaphore+0x145/0x1f0 
2012-04-04T02:28:34.926680-05:00 c0-0c1s6n1 [&lt;ffffffff81023dae&gt;] bad_area_nosemaphore+0xe/0x10 
2012-04-04T02:28:34.926756-05:00 c0-0c1s6n1 [&lt;ffffffff81024326&gt;] do_page_fault+0x2d6/0x400 
2012-04-04T02:28:34.926770-05:00 c0-0c1s6n1 [&lt;ffffffff812e5cdf&gt;] page_fault+0x1f/0x30 
2012-04-04T02:28:34.926788-05:00 c0-0c1s6n1 [&lt;ffffffff8111ca49&gt;] nameidata_to_filp+0x39/0x80 
2012-04-04T02:28:34.952710-05:00 c0-0c1s6n1 [&lt;ffffffff8112ad8a&gt;] do_last+0x1da/0x790 
2012-04-04T02:28:34.952739-05:00 c0-0c1s6n1 [&lt;ffffffff8112c003&gt;] path_openat+0xc3/0x3c0 
2012-04-04T02:28:34.952787-05:00 c0-0c1s6n1 [&lt;ffffffff8112c413&gt;] do_filp_open+0x43/0xa0 
2012-04-04T02:28:34.952800-05:00 c0-0c1s6n1 [&lt;ffffffff8111da12&gt;] do_sys_open+0x152/0x1e0 
2012-04-04T02:28:34.952810-05:00 c0-0c1s6n1 [&lt;ffffffff8111dacb&gt;] sys_open+0x1b/0x20 
2012-04-04T02:28:34.952854-05:00 c0-0c1s6n1 [&lt;ffffffff8111dae0&gt;] sys_creat+0x10/0x20 
2012-04-04T02:28:34.952867-05:00 c0-0c1s6n1 [&lt;ffffffff812e60fb&gt;] system_call_fastpath+0x16/0x1b 
2012-04-04T02:28:34.952878-05:00 c0-0c1s6n1 [&lt;0000000000440270&gt;] 0x44026f
(gdb) list *(nameidata_to_filp+0x39) 0xffffffff8111ca49 is in nameidata_to_filp (fs/open.c:818). 
813	 /* Pick up the filp from the open intent */ 
814	 filp = nd-&gt;intent.open.file; 
815	 nd-&gt;intent.open.file = NULL; 
816	 
817	 /* Has the filesystem initialised the file for us? */ 
818	 if (filp-&gt;f_path.dentry == NULL) { 
819 path_get(&amp;nd-&gt;path); 
820	 filp = __dentry_open(nd-&gt;path.dentry, nd-&gt;path.mnt, filp, 
821	 NULL, cred); 
822	 }

The backtrace shows filp is -ENOENT, and I think it's fine to always lookup_instantiate_filp() return value, and latest kernel does this in all places.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 13: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

This doesn't work on master, no need to backport.
|Patch Set 1: I would prefer that you didn't submit this

This patch doesn't work on master.
|Patch Set 1: I would prefer that you didn't submit this

This patch doesn't really work on master, and no need to backport.
|Patch Set 1:

Hmm, RHEL5 kernel still takes BKL in mount, I'll check the kernel version from which BKL is removed in mount path, and make this macro work only before that version.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4:

Hi Oleg, this patch has defects, and it's fixed in http://review.whamcloud.com/#change,2928
|Patch Set 1:

Xuezhao, you're right, I missed the code in libcfs. You may create a patch under LU-506 and cleanup the remaining code.
It looks fine to me to remove lock_kernel() from cfs_daemonize().
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9: Abandoned

Only one patch is left for fc15 support, this combo patch is needless any longer.
|Patch Set 1: Abandoned

debug patch, not in use any longer.
|Uploaded patch set 2.
|Patch Set 2:

Oleg, this is a debug patch, it won't be committed. Thanks for your suggestion, I'll reflect it in the real patch when it's ready.
|Patch Set 2: Abandoned

debug patch, not in use any longer.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Abandoned

This patch doesn't work in verification test.
|Patch Set 9: (3 inline comments)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (2 inline comments)


|Patch Set 2: I would prefer that you didn't submit this

(15 inline comments)


|Uploaded patch set 3.
|Patch Set 3:

After more thoughts and tests, I think the whole lustre dcache mechanism and code could be simplified a lot:

Current implementation has a super hack d_rehash_cond(), because kernel doesn't export it, in our hack dcache_lock is dropped and d_rehash() is called, and this leaves a small interval which makes hash/unhash racy. To solve this, a new lock ll_lookup_lock is introduced to guard all hash/unhash operations. But why lustre needs call d_rehash_cond()? the answer is that when dentry is set LUSTRE_DCACHE_INVALID, it's often dropped from hash. But this is not necessary! An LUSTRE_DCACHE_INVALID dentry won't be found in hash (except by lookup operation, this is similar to DISCONNECTED dentry), so it doesn't matter whether it's dropped or not.

I've made a new patch based on this, and run sanity and racer.sh test successfully, I'll commit it later.
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 6:

Maloo failed on a  known bug, I'll retrigger the test.
|Uploaded patch set 7.
|Patch Set 7: (2 inline comments)


|Patch Set 7: (1 inline comment)


|Uploaded patch set 8.
|Patch Set 8: (1 inline comment)


|Patch Set 8:

Kernel &gt;= 2.6.38 uses d_set_d_op() to set dentry operations, and .d_delete is called before refcount decrease now. I'll update the patch later.
|Uploaded patch set 9.
|Patch Set 9:

The backtrace shows nd-&gt;intent.open.file is -2 (-ENOENT), a possible cause might be that ll_lookup_nd -&gt; lookup_instantiate_filp, but the return value is not checked, therefore 'file' can be set with an error code.

I'll try to fix it this, and do some test, if all look okay, I'll update the patch later.
|Patch Set 9:

the mentioned crash should have been fixed, and I found another bug of statahead in test, now that the patch is too big, I'll split it into three serial patches.
|Uploaded patch set 10.
|Patch Set 10:

The other two patches are at:
http://review.whamcloud.com/#change,2491
http://review.whamcloud.com/#change,2492
|Patch Set 10:

Hi Wally, there is an integrated patch including all remaining patches for 2.6.38 patchless client, you can refer to that: http://review.whamcloud.com/#change,2170.

Hmm, change 2492 is a general issue for statahead code, and it doesn't need to depend on this patch. But both change the same file, so when you merge them, you will get code conflict, but it's not hard to solve. When one of them get landed, I'll update the patch of another one.
|Uploaded patch set 11.
|Patch Set 11:

Customer reported crashes with previous patch http://jira.whamcloud.com/browse/LU-1297. The cause of ll_ddelete() ASSERT is that dget_dlock() is not under dentry-&gt;d_lock in ll_find_alias(). This is fine for kernels &lt; 2.6.38 because dput() will take dcache_lock, but new kernel removes dcache_lock, d_lock is now a must to update dentry-&gt;d_count.
|Uploaded patch set 12.
|Patch Set 12:

Failed on a known issue, rebased and retriggered test.
|Uploaded patch set 13.
|Patch Set 13:

merged from master, no new changes.
|Uploaded patch set 14.
|Patch Set 14:

Grrr, I pushed this to wrong Change-Id, the real BKL patch is at http://review.whamcloud.com/#change,2169. I'll update this patch soon.
|Uploaded patch set 15.
|Patch Set 15: (1 inline comment)


|Patch Set 15: (4 inline comments)

Invalid dentry will be released at the last dput().
|Patch Set 15: (1 inline comment)


|Uploaded patch set 16.
|Patch Set 16:

Sarah, you need apply http://review.whamcloud.com/#change,2169 to be able to compile on 2.6.38.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Patch Set 19:

rebased to resolve conflict.
|Uploaded patch set 20.
|Patch Set 20:

rebase to resolve another conflict.
|Patch Set 20: (1 inline comment)


|Uploaded patch set 21.
|Patch Set 21:

Sarah, could you run racer and simul again on 2.6.38.6-26 kernel for this new patch?
|Patch Set 21: (2 inline comments)


|Uploaded patch set 22.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

The code is fine, and it's really best to add sanity test for such operations, under sanity.sh test_154().
|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 9: Looks good to me, but someone else must approve


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Hmm, unlink and rename may miss sync lock cancel in MDC, I will update the patch.

As for the flag name, I think current one is more straightforward, it just tells whether MDC should cancel locks synchronously in it's rpc to MDT.
|Uploaded patch set 4.
|Patch Set 4:

Hi Niu,

After second thought, I think your idea is good, ELC logic will be moved into LMV and MDC. The code will be easier to understand.

But I'm afraid there is a bug in lmv_rename(): it tries to cancel fid4 lookup lock, but it sends request to the MDT where fid4 resides, instead of the MDT where fid4's parent resides.
|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 6:

No change against last patch, but the fix of the bug mentioned  in http://review.whamcloud.com/#change,1502 depends on this.
|Patch Set 6:

Oleg, what's your opinion on this? I think both way are okay, and DNE has chosen to create missing config in upgrade, if 1.8 -&gt; 2.1 should follow this policy, I will make another patch.
|Patch Set 6: Abandoned

Regenerating config can fix this issue.
|Patch Set 1:

Oleg, yes, this is a fix for DNE. I'll add Wangdi to review.
|Patch Set 1: Abandoned

regenerating config can fix this issue.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: (7 inline comments)

The background is that Catalog has used loghandl-&gt;lgh_lock to serialize write operation, if it can write multiple records, then these records can be consecutive. But Catalog and llog use the same set of interface struct llog_operations, if I want to allow Catalog write multiple records, all implementations of llog_operations have to change their interface though they only write one record each time.

If we don't take advantage of Catalog serialization mechanism, we can add another lock to serialize all changelog write, but currently there is not a set of interfaces for changelog, but uses llog APIs all around, then all the places changelog write should be lock protected. Firstly this lock is redundant, besides, it may hurt parallel performance.

I don't find an easy way to solve this in user space utility, because several rename records can be written without orders, then there is no way to find matched RNMTO for RNMFRM record.

Mike, I don't object to other ways to fix this, since you're  expert on this, please give some advice.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Previous patch doesn't handle rename correctly, and CLF_RENAME_EXISTS is redundant because if target fid is valid, it means target exists.
|Uploaded patch set 5.
|Patch Set 5:

There was a small bug in lr_create(), and it's fixed in Patch set 6.
|Patch Set 5:

Errr, typo, I mean Patch Set 5.
|Patch Set 5: (5 inline comments)


|Uploaded patch set 6.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve

Sheng, you can verify it yourself by setting LU_PAGE_SIZE to a smaller value, eg. 1k.
|Patch Set 1:

Hi Gatekeeper, customer thinks this patch is ready to land.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

Hi Oleg, IMO MDT should continue with that case too. Do you think it's better to return -EINVAL for that one?
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: Abandoned

wrong commit message.
|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 2: (3 inline comments)


|Patch Set 2: (2 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 3: I would prefer that you didn't submit this

(7 inline comments)


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned

Abandoned because of code dependencies, new patches made.
|Patch Set 1: Abandoned

Abandoned because of code dependencies, and new patch is made.
|Patch Set 1: Abandoned

Abandoned because of code denpendencies, new patch is made.
|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

Hi Oleg, customer thinks this is ready to land.
|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 6: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 14: Looks good to me, but someone else must approve


|Patch Set 15: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

The log shows OFD LBUG in some place, and my local test doesn't fail on this test. I'm afraid this is a OFD bug, will take a further look.
|Uploaded patch set 4.
|Patch Set 1: (1 inline comment)


|Patch Set 1:

There is already a test conf-sanity 21d for this, however our autotest system is not configured to a standalone mgs, so this test is always skipped. Chris need get involved to make it work.

The nids for OST is set at target mount time by checking all network interfaces, and then send to MGS to register target. So each time target is restarted, it will register with all current nids.

There is a command `lctl add_uuid ...`, but it's only for test, and in my understand this command can be run on client only.

the config MDT steals is OSC config to OST, so the nids are for OST, MDT can't know it by checking interfaces of its own.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(4 inline comments)


|Patch Set 1: (2 inline comments)


|Patch Set 1: (2 inline comments)


|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve

What's the result of racer and simul test?
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3:

There is a similar issue LU-1908, so racer umount fail should not be a problem here.
|Patch Set 4: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3:

Hi Gatekeeper, this patch is ready to land.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

Hi Prakash, did the test you listed trigger this panic? it's a bit strange because it passed in my setup.
|Patch Set 1:

It's my fault, I tested on a wrong place. I will update patch soon.
|Uploaded patch set 2.
|Patch Set 9: (3 inline comments)


|Patch Set 10:

Grrr, you committed a new patch before I published comments for patch 9, but the comments should apply too.
|Patch Set 10: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 2: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 4: (1 inline comment)


|Patch Set 5: I would prefer that you didn't submit this

(5 inline comments)


|Patch Set 7: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

when I updated to latest b2_1, this failure disappears. I retriggered maloo test.
|Patch Set 3:

Test failed on LU-747, I'll retrigger the test.
|Patch Set 3:

Autotest failed on LU-482, retriggered.
|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Patch Set 4:

Hi Oleg, this patch is ready to land.
|Uploaded patch set 5.
|Patch Set 3: Looks good to me, but someone else must approve

Any difference from last patch?
|Uploaded patch set 2.
|Patch Set 2:

Autotest failed because dbench not found; I'll retrigger autotest later.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 6: I would prefer that you didn't submit this

Please check my comment in Jira ticket.
|Patch Set 11: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 12:

IMHO the old code is not in good shape: attribute is set in several places, it deserves to define clear interfaces and logic for mdd and osd layers for attribute setting. However this may be out of scope of this patch, if others agree, I don't object to this patch.
|Patch Set 13: I would prefer that you didn't submit this

http://review.whamcloud.com/#change,5421 has addressed this issue, so that this patch is not in need any more.
|Uploaded patch set 2.
|Patch Set 4: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: (2 inline comments)


|Patch Set 3: (2 inline comments)


|Patch Set 4: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 3: (2 inline comments)


|Patch Set 3: I would prefer that you didn't submit this

Please update ticket number.
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 2.
|Patch Set 2:

kernel build failed because kernel ABI check fails. The cause might be that dqptr_sem is removed from struct dquot, I'll keep it there but unused in next commit to see the result.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

It's not easy to replace the global dqptr_sem with a per-inode semaphore because in functions like remove_dquot_ref() inode_lock needs to be taken before access inode, however inode_lock is a spinlock.

I'll update the patch, but still with i_lock.
|Patch Set 5:

Could you take a look at drop_dquot_ref()? The lock order is dqptr_sem -&gt; inode_lock, if dqptr_sem is replaced with a per-inode semaphore, it will be taken inside inode_lock, that's not viable. What's your suggestion?
|Uploaded patch set 6.
|Patch Set 6:

I'm measuring performance improvement with https://github.com/dmonakhov/lmbench, will update the test result later.
|Patch Set 6:

Mdtest performance test result updated on https://jira.hpdd.intel.com/browse/LU-2442?focusedCommentId=54643&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-54643
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 10: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 25: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

All the failures are known issues.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 1: (1 inline comment)


|Patch Set 1:

Andreas, I don't know the way to mknod a regular file, and if mknod a special file, swap layout will return error.
|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

maloo failed on known issues.
|Uploaded patch set 5.
|Patch Set 5:

rebase from master.
|Patch Set 5: (2 inline comments)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 22: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 5: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 9: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2:

Separating statahead thread (exit) from statahead RPCs makes code complicated. I'd prefer statahead thread wait for all inflight statahead RPCs finish, and clean them up and then exit. By this way statahead is not guaranteed to quit when ll_file_release() is called, but this should not be an issue. I'll implement this and if all goes well, I'll commit a patch separately.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve

(1 inline comment)

Now that it can pass, but I don't understand the cause of the original failure yet.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned

wrong commit message
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

This should be a separate patch since it has no relationship with dqptr_sem changes.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 16: I would prefer that you didn't submit this

LU-3286 is a duplicate of this bug, and it can't pass with this fix.

You may also verify in a simpler way:
1. set system up
2. umount mgs
3. umount ostx
4. mount ostx, and it should succeed with local copy llog.

Ldiskfs can pass this test, but zfs not yet.
|Patch Set 16:

The culprit might be in mgc_process_cfg_log() mgc_request.c Line 1696:

        if (lctxt &amp;&amp; lsi &amp;&amp; IS_SERVER(lsi) &amp;&amp; !IS_MGS(lsi) &amp;&amp;
            cli-&gt;cl_mgc_configs_dir != NULL &amp;&amp;
            lu2dt_dev(cli-&gt;cl_mgc_configs_dir-&gt;do_lu.lo_dev) ==
            lsi-&gt;lsi_dt_dev) {
|Patch Set 16: Looks good to me, but someone else must approve

I'm okay with it, and I'll check why ZFS still fails later.
|Patch Set 17: Looks good to me, but someone else must approve


|Patch Set 18: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3:

Sometimes master is not stable due to other commits, I've retriggered autotest, if it still fails, it may need a merge from latest master.
|Patch Set 1:

This looks tricky, though I don't know the proper way.

What will happen if lustre code calls list_move_tail() after including SPL list.h?
|Patch Set 2: (1 inline comment)


|Patch Set 3:

shouldn't ll_atomic_open() set IT_CREATE by 'open_flags &amp; O_CREAT' instead of mode? because according to `man 2 open` if O_CREATE is not set mode is ignored.
|Patch Set 4: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: No score

(1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: I would prefer that you didn't submit this

Autotest sanityn test_7 failed is because though mnt root dentry is never revalidated, d_op-&gt;d_compare will be called for its children, so that root d_op should be set.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

rebased.
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)

It's fixed in 2.4 because it's more handy to upgrade client, besides 2.3 server may need fix too. Since we don't need to consider 2.5 client &lt;-&gt; 2.1 server interop (AFAIU from Peter), we can keep 2.5 the old as is, and only pack name for 2.4 client. Do you think this is okay?
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 1: Abandoned

replaced by http://review.whamcloud.com/#/c/7476/
|Patch Set 3: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5: Abandoned

This fix is included in http://review.whamcloud.com/#/c/6392/.
|Patch Set 6: (1 inline comment)


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 5: (1 inline comment)


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(3 inline comments)


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 1: Abandoned

This is replaced by http://review.whamcloud.com/#/c/7476/.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: I would prefer that you didn't submit this

IMHO MGS failover nid should not be set by --mgsnode, but by --failnode. Because all nid by --mgsnode should be a primary nid.
|Patch Set 4:

Hmm, you're correct, Please add a conf-sanity test for this.
|Patch Set 4: No score


|Patch Set 5:

Please add a conf-sanity test.
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

rebased from master.
|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 3.
|Patch Set 3:

rebased.
|Patch Set 1: Abandoned

Duplicate.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1:

It's a 2.1 server bug anyway, because intent was executed, but flag not set. 2.1 client won't fail because 2.1 client packs name into open request, and MDS will retry with open by name, and this flag will be set at that time.

If we don't want to change 2.1 server code, the compatibility code will look strange on 2.5:
1. setstripe requests OPEN lock
2. upon open replies negative, DISP_IT_EXECD is not set.

IMO it's easy to backport this small change to old 2.1 code.
|Patch Set 2:

open by fid won't cross mdt because client will talk to the mdt where the fid exists directly, in current code if the file with the specified name is on another mdt, mdt will notify client with -EREMOTE, and client will open again on that mdt(this is done in lmv). And after the change of lu-3765 on master code, since open request won't pack name any more, client will only talk to the mdt where the fid exists.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: Abandoned

With http://review.whamcloud.com/#/c/8093/ we can achieve the same goal without touch 2.1 code.
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 5: (2 inline comments)


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1:

This looks awkward IMHO, I'd prefer implement as described in simplified-interop. We may just re-open all opened O_RDONLY files (or maybe non-create open? this can be a callback registered into import) after recovery is finished and before delayed requests sent, . In this way any time such file is closed, the open request can be released without server interference.

This doesn't look to be a lot of change, but we have to keep  fake transaction for old client.
|Patch Set 1:

The above is the same as the long term fix described by Andreas: decouple non-create open with ptlrpc replay, instead do it like ldlm lock replay.
|Patch Set 4: (2 inline comments)


|Patch Set 7: (2 inline comments)


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 4: (1 inline comment)


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 6: (1 inline comment)


|Patch Set 6: (1 inline comment)


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 9: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1:

Like you have said, LOOKUP lock can't be held long time by client, there is always race that this dentry may become invalid after revalidate. IMHO revalidate is mainly for network filesystem like NFS which doesn't have DLM like mechanism to maintain dcache consistency.

Besides, if revalidate returns false, this dentry will be lookup.

I'll do more racer test and see if there is real blocker for this.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

rebased from master.
|Patch Set 5: (1 inline comment)


|Patch Set 5: (1 inline comment)


|Patch Set 5:

I've tested for several days, but can't reproduce the crash Oleg met. I'll update the patch and test it in a larger scale.

Oleg, do you know what test will trigger this crash? And if you have the dump, could you upload it somewhere to let me analyze?
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 10: (1 inline comment)


|Patch Set 10: (1 inline comment)


|Patch Set 10: (1 inline comment)


|Patch Set 2: (4 inline comments)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

Now that maloo failed and patch needs refresh, it's better update the code as described in the comments.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

rebased from master.
|Patch Set 11: (2 inline comments)


|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 15: Looks good to me, but someone else must approve


|Patch Set 18: Looks good to me, but someone else must approve


|Patch Set 8: (1 inline comment)

Will this cause performance degradation in certain situations?
|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 15: Looks good to me, but someone else must approve


|Patch Set 2: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 2: (1 inline comment)


|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1:

1. mkdir -p &lt;nfs_mountpoint&gt;/d1
2. echo adf &gt; &lt;nfs_mountpoint&gt;/d1/f1
3. cd &lt;nfs_mountpoint&gt;d1/f1
3. `echo 2 &gt; /proc/sys/vm/drop_caches` on NFS server (where lustre client mounted) can invalidate all dentries.
4. on NFS client `cat f1` will cause f1 dentry subtree checking, which will call get_parent finally.
|Patch Set 1:

Backtrace shows it LBUG on exp_rootfh(), could you make sure this is not encode for root fh only?
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 9: (1 inline comment)


|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 16: Looks good to me, but someone else must approve


|Patch Set 10: Looks good to me, but someone else must approve


|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 4: Code-Review-1

(2 comments)
|Patch Set 4:

(1 comment)
|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 3: (2 inline comments)

This looks to be mixture of TBF and deadline policy, could you explain why it's implemented this way? And this may lead to server idle on throttling.
|Patch Set 3:

BTW could you answer the question raised by Nathan on Jira ticket?
|Patch Set 3:

Basically I'm fine with the code, but IMHO TBF policy is not tightly coupled with deadline policy, so if we can implement them separately, and also implement fallback mechanism mentioned by Andreas, the architecture will be more flexible, eg. we can couple different policies like TBF and ORR together.
|Patch Set 9: (8 inline comments)

A lot of unnecessary GOTO is used, which will record a debug message if trace is enabled.
|Patch Set 15: Looks good to me, but someone else must approve


|Patch Set 18: Code-Review+1
|Patch Set 3: (1 inline comment)


|Patch Set 4: (1 inline comment)


|Patch Set 4: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 2: (1 inline comment)


|Patch Set 21: (6 inline comments)


|Patch Set 9:

why not implement a LWD (Light Weight Device) like LOD to manage all the LWPs?
|Patch Set 4: Code-Review+1
|Patch Set 17: (1 inline comment)


|Patch Set 12:

According to https://wiki.hpdd.intel.com/display/opensfs/LFSCK+2+MDT+-+OST+Consistency+Solution+Architecture chapter 4.8, there is an alternative to implement OST_CONSISTENCY_VERIFY, which looks more efficient, and why it's not implemented?
|Patch Set 21:

(2 comments)
|Patch Set 21:

(1 comment)
|Patch Set 6: Code-Review+1
|Patch Set 9: Code-Review+1

(2 comments)
|Patch Set 13: Code-Review-1

(2 comments)
|Patch Set 13: Code-Review+1
|Patch Set 12:

(2 comments)
|Patch Set 3: Code-Review+1
|Patch Set 14:

(2 comments)
|Patch Set 14:

(2 comments)
|Patch Set 16:

(2 comments)
|Patch Set 13: Code-Review+1
|Patch Set 11:

(1 comment)
|Patch Set 12:

(3 comments)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 14:

There are already too much lustre kernel threads, I'd like to use kernel workqueue keventd to do self repair: you can put inconsistency item into a list, and queue a work to keventd, which will pick the first item from the list and repair it, and if list is not empty, queue another work to keventd.
|Patch Set 15:

(2 comments)
|Patch Set 15:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4:

(4 comments)
|Patch Set 4: Code-Review+1
|Patch Set 1: (1 inline comment)


|Patch Set 1:

sai has taken one refcount of dir inode, therefore lli_inode_info is safe to use in such case. Or did I miss anything?
|Patch Set 1:

These locks are not introduced for this patch, but to fix original race issue in statahead implementation: other process may stop statahead any time, so it's not safe to access sai without lock. I'll move sai_generation to lli structure to avoid one lock.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: I would prefer that you didn't submit this

(1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5: I would prefer that you didn't submit this

client_common_put_super() should wait for all running statahead threads to quit, otherwise umount may fail because inode refcount still taken.
|Uploaded patch set 6.
|Patch Set 6: I would prefer that you didn't submit this

(1 inline comment)


|Uploaded patch set 7.
|Patch Set 7: (1 inline comment)


|Uploaded patch set 8.
|Patch Set 8:

Yes, statahead still holds refcount of inode, but in this case it's like a normal process which is operating on this inode, and umount just complains and wait for it to quit, and no crash occurs.
|Patch Set 8: (1 inline comment)


|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 11: I would prefer that you didn't submit this

Hmm, it turns out to be that when client does umount, ptlrpcd still holds statahead RPCs, and there is no chance to finish it, and it's worse that ptlrpcd will destroy these RPCs after umount is done. And finally it causes deadlock.

I'll revise the patch and commit later.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13: (2 inline comments)


|Uploaded patch set 14.
|Patch Set 14: (1 inline comment)


|Patch Set 14:

I found two more statahead bugs which may cause umount hung, and they should be the cause of umount hung in previous implementation in which  statahead thread wait for RPCs to finish. So I will revert to that implementation and add these two fixes. I've run racer repeatedly for 2 hours, and it always passes.
|Uploaded patch set 15.
|Patch Set 15: (3 inline comments)

No, close dir doesn't wait for statahead RPCs to finish, but just stops statahead (ll_stop_statahead), which will signal statahead thread to stop, and the statahead thread to wait for RPCs to finish.
|Uploaded patch set 16.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Patch Set 19:

The only possibility I can imagine is that ll_stop_statahead() is called more than once, and this may only happen when another process open this dir also, which will set lli_opendir_key. The root cause is ll_stop_statahead() doesn't only check lli_opendir_key is not NULL, but not whether it's the original key. I'll try to find a way to fix this.
|Patch Set 19:

Patrick, could you post the backtraces of related processes to help me understand this?
|Uploaded patch set 20.
|Patch Set 21: Patch Set 20 was rebased
|Uploaded patch set 22.
|Patch Set 22:

(3 comments)
|Uploaded patch set 23.
|Patch Set 23:

(3 comments)
|Uploaded patch set 24.
|Patch Set 24:

auto test failed on LU-4422, will retrigger after it's fixed.
|Uploaded patch set 25.
|Uploaded patch set 26.
|Patch Set 26:

Chris, originally this patch only addressed one issue, but in verification test more issues are found, and they are added into this patch. I'll split this patch into small ones and base on your patch.
|Abandoned

this is broken into several small patches:
http://review.whamcloud.com/#/c/9663/
http://review.whamcloud.com/#/c/9664/
http://review.whamcloud.com/#/c/9665/
http://review.whamcloud.com/#/c/9666/
http://review.whamcloud.com/#/c/9667/
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

(1 comment)

Autotest failed is because mdt checks client eadatasize in xattr packing, I'll update the patch to remove this check.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3: (2 inline comments)


|Uploaded patch set 4.
|Patch Set 4:

Oleg, I replied on Jira page, please check there.
|Abandoned

This is a wrong approach, and this should be fixed in another way if this issue emerges again.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3:

liblustre should fail to work now, does it make sense to clean its source code? IMHO cleanup common lustre kernel module and user space header files is enough.
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

this patch was reverted because of conflict with dne migrate code.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 2: (4 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4: (2 inline comments)


|Patch Set 4: (1 inline comment)


|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1

This looks working, but IMHO it's still too subtle and complicated in the refcounting.
|Patch Set 2:

I see your point, but I like the common usage of refcounting: the last put will free item, and no need to check any state.
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 11: Looks good to me, but someone else must approve


|Patch Set 12: Looks good to me, but someone else must approve


|Patch Set 16: Looks good to me, but someone else must approve


|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review-1
|Patch Set 4:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1:

Jinshan, I'm curious why ll_write_end() doesn't unlock page? Basically this doesn't conform to kernel locking policy, so if we call kernel function in IO path this may cause deadlock in other corner cases like this.
|Patch Set 1:

But why CPS_OWNED state needs taking page lock? And we still call lock/unlock_page() in many places directly, if we can call them in all places, is there a chance we separate page lock state with CPS_OWNED state?

BTW to avoiding deadlock in the long run, we need to track kernel changes in IO functions, which doesn't look to be decent.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 15:

(2 comments)
|Patch Set 23: Code-Review+1
|Uploaded patch set 1.
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Uploaded patch set 7.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review-1

(1 comment)
|Abandoned

This fix is wrong, and replaced by http://review.whamcloud.com/#/c/10692/
|Patch Set 10: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: (2 inline comments)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: (3 inline comments)


|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5:

John, good catch!

With this patch, client may still open with IT_CREATE set, but MDS will ignore this flag upon open, because client has created if necessary in lookup/revalidate. Previously I cleared this flag in client code before calling ll_intent_file_open(), but in this one I removed that piece of code, and I forgot to remove this assert.

I'll update the patch soon, thanks!
|Uploaded patch set 6.
|Uploaded patch set 11.
|Patch Set 11: (2 inline comments)


|Patch Set 11: (1 inline comment)


|Patch Set 11: Rebased
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14:

updated to latest master.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 18:

Those tests failed but no logs attached, is it normal? I'll run it manually to see the result.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Patch Set 20:

(6 comments)

I'll check the racer failure and update the patch later.
|Patch Set 20:

(1 comment)
|Uploaded patch set 21.
|Uploaded patch set 22.
|Patch Set 22:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

parallel-scale-nfs failed on iorssf, I'll look into that.
|Patch Set 1: Code-Review+1
|Patch Set 1:

I'm not clear of flag LDLM_FL_WAIT_REPROC, but it looks like when it's set, nothing is done in -&gt;l_completion_ast(), if so, why should ldlm_lock_match() call it?
|Patch Set 1:

but l_completion_ast is called in ldlm_lock_match() only when ((flags &amp; LDLM_FL_LVB_READY) &amp;&amp; !ldlm_is_lvb_ready(lock)), so this should be for extent lock, then if l_completion_ast does nothing because LDLM_FL_WAIT_NOREPROC is set, why should it be called?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 6.
|Patch Set 7: Patch Set 6 was rebased
|Uploaded patch set 8.
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 1.
|Abandoned

This is a test patch.
|Patch Set 3: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Uploaded patch set 1.
|Abandoned

committed to wrong branch.
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 14: Code-Review+1
|Patch Set 4:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 5: Code-Review-1

(1 comment)

John, you're right. And in http://review.whamcloud.com/#/c/9663 lli_opendir_key is only set by .open and .release, which isolated opendir key setting and sai refcounting, and make statahead logic more straightforward.
|Patch Set 7: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

yes, it has interop issue with old server, I'll add a connect flag.
|Uploaded patch set 2.
|Patch Set 2: Code-Review-1

Autotest failed because a fake transno is set for close in unlink, which will cause gap in replay and recovery failure. I'll update the patch soon.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Patch Set 5:

IMO this is different from the release-on-close case, because this is already in unlink context, it's strange to pack a close request but with unlink format, and why we not just do unlink with file handle packed?

BTW RQF_MDS_RELEASE_CLOSE is a simple extension of RQF_MDS_CLOSE, but RQF_MDS_REINT_UNLINK not, I can't think of a way to extend in a simple and straightforward way.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Andreas, I don't quite get you. For close, it needs to store transno separately because it uses a different portal; but for close in unlink, it's part of unlink operation, so it doesn't have its own transno. Could you explains more about how it affects uncommitted open?
|Abandoned

This was replaced by http://review.whamcloud.com/#/c/11062
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

The code looks okay, but it looks to be heuristic, and what if it doesn't wait?
|Patch Set 3: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 13: Code-Review+1
|Patch Set 12: Code-Review+1
|Patch Set 15: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 4: Code-Review+1

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 10: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 19:

Oleg, will you consider landing this recently?
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 11: Code-Review+1
|Patch Set 11:

Oleg, this is also ready to land.
|Patch Set 11:

the dependency patch failure was vet to be known issues, and auto test retriggered and passed, now they are ready to land.
|Patch Set 15: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 42: Code-Review-1

(5 comments)
|Patch Set 43: Code-Review+1
|Patch Set 44:

(1 comment)
|Patch Set 48:

(3 comments)
|Patch Set 53: Code-Review+1
|Patch Set 54: Code-Review+1
|Patch Set 32: Code-Review-1

(3 comments)
|Patch Set 44: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

this is not for landing.
|Abandoned

not needed.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 21: Code-Review+1
|Patch Set 23: Code-Review+1
|Patch Set 25: Code-Review+1
|Patch Set 29: Code-Review+1
|Patch Set 2: Code-Review+1

it's better to add some tests for this.
|Patch Set 3: Code-Review+1

a test for this is preferred.
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 5:

(2 comments)
|Patch Set 5: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 38:

(10 comments)
|Patch Set 38:

(1 comment)
|Patch Set 38:

(3 comments)
|Patch Set 44: Code-Review+1
|Patch Set 51: Code-Review+1
|Patch Set 52: Code-Review+1
|Patch Set 54: Code-Review+1
|Patch Set 57: Code-Review+1
|Patch Set 28:

(2 comments)
|Patch Set 33: Code-Review+1
|Patch Set 41: Code-Review+1
|Patch Set 46: Code-Review+1
|Patch Set 35:

(3 comments)
|Patch Set 36:

(1 comment)
|Patch Set 47: Code-Review+1
|Patch Set 52: Code-Review+1
|Patch Set 33:

(4 comments)
|Patch Set 37: Code-Review+1
|Patch Set 46: Code-Review+1
|Patch Set 51: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 9: Code-Review+1

(1 comment)
|Patch Set 30: Code-Review-1

(4 comments)
|Patch Set 31: Code-Review-1

please check comments for previous patch.
|Patch Set 49: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Abandoned

no plan to land on 2.5.
|Patch Set 6: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 20:

(14 comments)
|Patch Set 35: Code-Review+1
|Patch Set 36: Code-Review+1
|Patch Set 21: Code-Review-1

(1 comment)
|Patch Set 33: Code-Review-1

(2 comments)
|Patch Set 34:

(1 comment)
|Patch Set 46: Code-Review+1
|Patch Set 47: Code-Review+1
|Patch Set 12:

In my understanding this patch is not aimed to land, right?
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 44: Code-Review+1
|Patch Set 45: Code-Review+1
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 11: Code-Review-1

(2 comments)
|Patch Set 12: Code-Review-1

please check comments for previous update.
|Patch Set 26: Code-Review+1
|Patch Set 27: Code-Review+1
|Patch Set 29: Code-Review+1
|Patch Set 31: Code-Review+1

(1 comment)
|Patch Set 7: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

a malicious client can still access it, shouldn't this be checked on server side?
|Patch Set 1: Code-Review+1

Hm, set_info needs tidy up some day.
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Abandoned

b2_7_fe contains this already.
|Uploaded patch set 1.
|Abandoned

There exists a backport already: http://review.whamcloud.com/#/c/18828/
|Patch Set 1: Code-Review+1
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Patch Set 2:

Hmm, I'll do it later.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)

I haven't conducted inter-op test yet, and neither on zfs, could you give some advice on which kind of test to do?
|Patch Set 26: Code-Review+1
|Patch Set 30: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1

this looks fine, however it's like an optimisation, other than a fix, is it?
|Patch Set 3: Code-Review+1
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

hi Alex, I tested this patch against Di's DNE code, with 2 MDS's and 2 clients:
1. `mkdir /mnt/lustre/d_1` on client1.
2. `lfs setstripe -c 2 -i 1 /mnt/lustre/d_1/d_2` on client2.
3. `touch /mnt/lustre/d_1/d_2/f_1` on client1.

what's going on is like this:
1. command 1 saved ROOT update lock as COS lock.
2. command 2 issued getattr on ROOT, which caused transaction of command 1 to sync. and it then saved remote lock of d1 as COS lock and continued creating d_2.
3. command 3 issued getattr on d_1, which revoked remote lock of d1 on mds2, and it slept waiting for it to become available, the remote lock was canceled after transaction of command 2 was committed, and then getattr on d_1 succeeded, and f_1 creation continued.

From the logs, the sync happened twice, and eliminated transaction dependency successfully.
|Patch Set 2:

I don't see sync with one client, but why it bother? for single MDS there is no sync either, and this won't cause dependency issues among clients.
|Patch Set 2: Code-Review-1

And I found an issue of this patch is that remote lock won't be canceled immediately, but postponed to be done after transaction commit (initiated by kernel periodically), so it will cause slow lock cancel, thus lead to poor performance. I'll see how to fix this.
|Patch Set 2:

but 2nd mkdir is from the same client, and no other client accessed it, will it cause any trouble?
|Patch Set 2:

`mkdir d_1` doesn't enqueue any lock on d_1, while COS is built around ldlm lock, can such dependency be eliminated by COS? and is it possible to discard the info of d_2 on mirrored MDS instead of recover it?
|Patch Set 2:

do you want to lock child and piggy back this lock to client for 'mkdir'? if it's just a server local lock, the 2nd mkdir won't revoke COS with same client(local for server local lock). can you describe it in more details? and how can this avoid sync?
|Patch Set 2:

it can be modified to this, but it will cause performance issues. eg. for single MDS, it's not necessary to revoke.
|Patch Set 2:

MDT-originated lock? do you mean both local lock and remote lock?
|Uploaded patch set 3.
|Patch Set 3:

hi Alex, the dependency elimination between two mkdir is implemented by http://review.whamcloud.com/#/c/13139/
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5:

Alex, could you explain a bit about previous comment? Do you mean this cross-MDT COS and original COS should be able to be enabled separately?
|Patch Set 5:

yes, the semantic is the same as before when COS is enabled.
|Patch Set 5:

1. mkdir enqueued PW lock on '/', which is converted to COS lock after creation.
2. 'unlink' will lookup '/' first, which enqueued PR lock on '/', if this is from a different client, it will conflict with above COS lock, which will cause transaction commit.
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 7: Patch Set 6 was rebased
|Uploaded patch set 8.
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Patch Set 8:

(1 comment)
|Uploaded patch set 10.
|Patch Set 10:

(3 comments)
|Uploaded patch set 11.
|Patch Set 11:

(1 comment)
|Patch Set 11:

since the next patch will cache COS lock for DNE by default, it's not better to use COS to save cross-MDT lock instead of reinventing wheels.
|Uploaded patch set 12.
|Patch Set 13: Patch Set 12 was rebased
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 15:

(3 comments)
|Patch Set 15:

(2 comments)
|Uploaded patch set 16.
|Patch Set 15:

(1 comment)
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Patch Set 19:

(3 comments)

I'll make it a single patch later.
|Patch Set 19:

(2 comments)

if cross-MDT lock got BAST while it's still being used, ldlm_handle_bl_callback() will set CBPENDING, and nothing more because it's R/W count is not zero.

When this lock is not used and unlocked, mdt_save_remote_lock() will not save it, but cancel it immediately.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Uploaded patch set 22.
|Patch Set 22:

(3 comments)

I've run racer several times, and not related issues found. But it was not run for hours, just for minutes.

In racer test many migration failed because it tries to lock all linkea objects' parent, but since previous mkdir was not committed yet, it often failed.
|Uploaded patch set 23.
|Patch Set 22:

(2 comments)
|Patch Set 23:

two failures were seen in last autotest, sanityn 77c is from LU-7084, while recovery-small 23, which was retested for hours in my system, and couldn't reproduce.

I'll retest this patch.
|Patch Set 23:

Alex, no, I'll ask Di for help on this.
|Patch Set 23:

(9 comments)
|Patch Set 23:

(5 comments)
|Patch Set 23:

(3 comments)
|Patch Set 23:

(3 comments)
|Uploaded patch set 24.
|Patch Set 24:

(1 comment)
|Uploaded patch set 25.
|Patch Set 24:

(1 comment)
|Patch Set 25:

in last round autotest failed on sanityn.sh 55b, the cause is that rename should lock source and target dir, and then lookup source, otherwise a deadlock may happen, which is detected by 55b. I'll fix it and update the patch soon.
|Uploaded patch set 26.
|Uploaded patch set 27.
|Patch Set 27:

cont-sanity failed on LU-7449.
replay-single failed on LU-7298.
|Patch Set 27:

(5 comments)
|Uploaded patch set 29.
|Patch Set 29:

in latest update, sanityn 33c 33d were added for sanity test, and migrate will retry once upon -EBUSY, this is done in user space lib.
|Uploaded patch set 31.
|Uploaded patch set 32.
|Uploaded patch set 34.
|Uploaded patch set 36.
|Uploaded patch set 37.
|Patch Set 37:

maloo reports sanityn failed, but the log shows all tests passed, I'll check with Jian.
|Patch Set 37: Code-Review-1

(1 comment)
|Uploaded patch set 38.
|Patch Set 38:

replay-single 70b failed on LU-6844, recover-small 130b failure is also seen in https://testing.hpdd.intel.com/sub_tests/abab770e-9dc1-11e5-91b0-5254006e85c2, which looks to be a bug in master.
|Uploaded patch set 39.
|Patch Set 39:

(10 comments)
|Patch Set 39:

(4 comments)
|Patch Set 39:

(2 comments)
|Patch Set 39:

(2 comments)
|Uploaded patch set 40.
|Patch Set 40:

(1 comment)
|Patch Set 40:

(1 comment)
|Patch Set 40:

(1 comment)
|Uploaded patch set 41.
|Uploaded patch set 42.
|Patch Set 42:

(2 comments)
|Uploaded patch set 43.
|Uploaded patch set 45.
|Uploaded patch set 46.
|Patch Set 2: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 15:

could you add a test for this? BTW what should user do in this situation to bring all MDS back?
|Patch Set 20: Code-Review+1
|Patch Set 22: Code-Review+1
|Patch Set 32: Code-Review+1
|Patch Set 34: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3:

(2 comments)
|Patch Set 4: Code-Review+1
|Patch Set 4: Code-Review-1

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 6: Code-Review+1
|Patch Set 2: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Abandoned

this is used for test, not needed any more.
|Patch Set 2: Code-Review-1

(2 comments)
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 3: Code-Review-1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 13: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

yes, indeed, I'll think about it.
|Uploaded patch set 2.
|Patch Set 2:

in this update, strict COS lock will conflict with both PDO and subtree lock, so that any change on 'a' will conflict with 'mkdir a/b'.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

hi Alex, in my understanding once COS is enabled, REP-ACK won't take effect, so for unlink after reply is acknowledged the local COS lock still stays there, until transaction is committed.
|Patch Set 3:

(3 comments)
|Uploaded patch set 4.
|Patch Set 4:

Alex, sorry for the late reply, I just get back from vacation.

The only way to enable CoS on DNE environment that I once thought of is to add an ioctl in mdo_iocontrol to check OSP device count in LOD layer, and cache the result in MDT layer. Any suggestion for this?
|Patch Set 4:

ok, I'll do it soon.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(2 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Abandoned

merged into http://review.whamcloud.com/#/c/12530/
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Andreas, the way you proposed is similar to this, because an operation doesn't know whether it will modify remote object until it tries to enqueue PW/EX remote lock, so after that it can know whether it should compare with COS lock when enqueueing local lock, and the same it needs to relock from start.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Abandoned

merged into http://review.whamcloud.com/#/c/12530/
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 7.
|Abandoned

http://review.whamcloud.com/#/c/12530/12 replaces this patch, so for DNE COS locks will be ignored by local operations, but be checked against cross-MDT lock or specified explicitly with LDLM_FL_COS_INCOMPAT.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 15: Code-Review+1
|Patch Set 19: Code-Review+1
|Patch Set 30: Code-Review+1
|Patch Set 37: Code-Review+1
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5:

it looks like it may take more time for MDS's to interconnect, I'll try to let wait client recovery finish first.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 4: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 1:

this was fixed by http://review.whamcloud.com/8061, so it can be abandoned.
|Uploaded patch set 1.
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 4: Patch Set 3 was rebased
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 7: Patch Set 6 was rebased
|Uploaded patch set 8.
|Patch Set 10: Patch Set 9 was rebased
|Patch Set 11: Patch Set 10 was rebased
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1

(2 comments)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 7: Code-Review+1

(1 comment)
|Patch Set 3: Code-Review+1
|Uploaded patch set 4.
|Patch Set 4:

updated to latest master, and a small style fix.
|Uploaded patch set 5.
|Uploaded patch set 7.
|Patch Set 7:

updated from latest master to get auto test pass.
|Uploaded patch set 8.
|Patch Set 8:

rebased.
|Patch Set 8: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 11: Code-Review+1
|Patch Set 13: Code-Review+1
|Patch Set 7:

what if the dtrq was canceled and destroyed before replay request with the same transno reaches?
|Patch Set 7: Code-Review+1
|Patch Set 10:

(1 comment)
|Patch Set 12: Code-Review+1
|Patch Set 6:

(2 comments)
|Patch Set 8: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 15: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review-1

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 2:

I mean it's possible that REPLAY request was resent by ptlrpc_resend() (and ptl_send_rpc() was called) before ptlrpc_retain_replayable_request() is called, and it's useless to clear rq_resend flag here, and MSG_REPLAY flag will be set on the request, if the request hasn't reached server yet, the race may still exist.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 8:

(1 comment)
|Patch Set 10: Code-Review+1
|Patch Set 11: Code-Review+1
|Patch Set 16: Code-Review+1
|Patch Set 6: Code-Review+1

(1 comment)
|Uploaded patch set 9.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

auto test failed on LU-4203
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 9: Patch Set 8 was rebased
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 12: Patch Set 11 was rebased
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 7: Code-Review+1
|Patch Set 6: Code-Review+1

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 3.
|Patch Set 5:

okay, I'll update it.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(10 comments)
|Patch Set 9:

yujian, I've got all needed informations, but don't have enough time on this big change, will turn to this later.
|Patch Set 1: I would prefer that you didn't submit this

This doesn't look to be a right fix, because d_lustre_invalidate() may only __d_drop()  when dentry refcount is zero, that's only possible in ll_md_blocking_ast() for unused dentries.
|Patch Set 1:

No, when d_lustre_invalidate() finds dentry has zero refcount, and calls __d_drop(), dcache_lock should have taken. In the place you pointed out dentry  refcount should not be zero. It will be good to LASSERT(spin_is_locked(&amp;dcache_lock) before __d_drop() is called.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 6.
|Patch Set 7: Code-Review+1
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Code-Review+1
|Uploaded patch set 7.
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

it's not regression, 65k is rewritten in this patch, maybe it's because the sleep it not long enough, I'll see how to make it more stable.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

The auto test failure shows 65k may fail because orphans may not be destroyed after OST deactivated and activated, so check for orphans may not always be true. I'll remove check for it.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 8:

ok, I'll do it later.
|Uploaded patch set 9.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 1:

I can't access MRP-2739, so can you describe what corruption will it cause for non-directory? Previously it's done for non-directory file is because we want to reuse obsolete dentry (lld_invalid is set) to avoid allocating new dentry, and such obsolete dentry exists because lustre client doesn't shrink them proactively, but let dcache to do it.

So I don't object to change this, but it's better to add code to reclaim obsolete dentries to avoid consuming too much memory.
|Patch Set 2: Code-Review+1

could you retest to pass autotest?
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1:

(3 comments)
|Patch Set 1:

(4 comments)
|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 17: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4:

(1 comment)
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Patch Set 1:

(1 comment)

I need check autotest failures, will update patches later.
|Uploaded patch set 2.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Patch Set 4:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 10.
|Patch Set 10:

(1 comment)
|Patch Set 10:

yes, default stripe is cached in OSP in this patch. Actually all xattrs are cached in OSP if explicitly enabled (by calling osp_declare_xattr_get()), and upon XATTR lock revoke, these xattrs will be released.
|Patch Set 10:

for local OSD, it will read from disk each time.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

(1 comment)
|Patch Set 12:

(1 comment)
|Patch Set 12:

(1 comment)
|Patch Set 12:

hmm, one more question, master only enables OSP attribute cache for newly created file (in osp_md_declare_object_create()). So do you want to enable this cache for all objects?
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14:

(1 comment)
|Patch Set 15: Patch Set 14 was rebased
|Patch Set 15: Code-Review-1

(1 comment)
|Uploaded patch set 16.
|Patch Set 16:

Kernel error detected: [11560.801713] VFS: Busy inodes after unmount of dm-1. Self-destruct in 5 seconds.  Have a nice day...
 insanity test_1: @@@@@@ FAIL: Error in dmesg detected

This error message in `dmesg` causes lot of test failures, which can pass in my local test environment. I'll do more test to verify.
|Uploaded patch set 17.
|Patch Set 18:

autotest failed on LU-7117
|Uploaded patch set 19.
|Patch Set 19:

sanity test_29 failed due to LU-7418, which has been merged in master. I'll rebase and verify soon.
|Patch Set 20: Patch Set 19 was rebased
|Uploaded patch set 21.
|Patch Set 21:

(1 comment)
|Patch Set 21:

(1 comment)
|Patch Set 21:

(1 comment)
|Patch Set 21:

yes, that was handled by a new flag in mdt object, but later we enabled attribute cache for all objects by default, so to make sure the attributes not stale, we have to always invalidate them upon lock cancel.
|Patch Set 21:

yes, we can invalidate in mdt_object_unlock(), but locks are often saved and canceled later, do you think it's not necessary to keep attribute longer?

as for your question, I will do some simple test and update later.
|Patch Set 21:

to achieve DNE CoS, the remote locks are saved until transaction is committed.
|Uploaded patch set 22.
|Patch Set 22:

(2 comments)
|Patch Set 6: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1

since this patch won't pass for current code, do you want to land it? if so you may need to base this on the following patch.
|Patch Set 2:

yes, I see, but maloo failure will cause this unable to land, that's why I suggest you base this on 19164, or merge this into that one.
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 12: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Suppose a case the cached xattr is not added by setxattr, but by getxattr, because there may be concurrent getxattr, to avoid reading partial content, get cached xattr has to be serialised with add xattr into cache.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4:

reint operations used to take parent lock before lookup, while if this reint operation is a distributed, it needs to trigger commit of local transactions. But to know whether reint is distributed, we need to know whether child is striped, in current code this is checked before locking parent.

This can be improved by relocking from beginning when we found child is striped, so that the lookup under lock semantic is kept. I'll file a new ticket and fix there.
|Patch Set 14: Code-Review+1
|Uploaded patch set 1.
|Abandoned

improper commit message.
|Uploaded patch set 1.
|Patch Set 1:

I checked other reint operations, and didn't find such issue there.
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

autotest found more issues, and patch updated.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 11: Code-Review+1
|Patch Set 13: Code-Review+1
|Patch Set 15:

It looks that disk metadata on MDT, e.g. LOVEA is not trustable during LFSCK, why not checksum metadata? If so, we may avoid some wrong fixing, and the error handling can be simpler.
|Patch Set 15: Code-Review+1
|Patch Set 16: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Abandoned

replaced by http://review.whamcloud.com/#/c/21612/ because it needs an LU reference.
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Patch Set 6:

(1 comment)
|Patch Set 6: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

shouldn't wiretest be updated along?
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Patch Set 4: Code-Review+1

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

namelen is passed in to avoid calling strlen(name) again for osd_oxc_add().

a deleted is not necessary because obsolete data can be tolerated in this case.
|Patch Set 1:

To let reader notice stale entry, the flag should be checked/set with spinlock, and the reader needs retry to read in new data.

I don't quite get your example, but IMO one thread set/delete EA, while another thread read EA, it's acceptable that the second thread read in stale EA.
|Patch Set 1:

after list_del_rcu(), should the same thread be able to find the deleted entry in the list?

umm, it looks like I should use list_replace_rcu() in osd_oxc_add() in case entry replace is not atomic therefore the newly added entry can't be seen in list traversal.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

fanyong, yes, because the backtrace shows both panic in osd_oxc_lookup().
|Patch Set 5:

fanyong, yes, because the backtrace shows both panic in osd_oxc_lookup().
|Patch Set 5:

fanyong, yes, because the backtrace shows both panic in osd_oxc_lookup().
|Patch Set 5:

fanyong, yes, since the backtrace shows both panic on osd_oxc_lookup().
|Patch Set 5:

(2 comments)
|Patch Set 5:

(1 comment)
|Patch Set 5:

Generally use of RCU means it doesn't matter a stale entry is used, if in a system stale entry is not permitted, a flag can be added (protected by a lock).

IMO xattr cache is in the former category.
|Patch Set 5:

I don't think the same thread can find a deleted entry.

e.g.,
1. reader iterated list to lookup entry, and it just scanned the first one.
2. writer added new entry into list head.
3. reader won't have chance to find the new one, but the old one, if the stale one is not allowed to use, then it has to lookup from head again.

This is why replace is needed.
|Patch Set 5:

yes, subsequent lookup will find the new one, but concurrent lookup may not be able to find either new or old one.
|Patch Set 5:

(1 comment)
|Patch Set 1: Code-Review-1

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 3:

(1 comment)
|Patch Set 4:

I think we need to verify this can fix LU-8592 first, because currently only MDTx caches MDT0 ROOT xattr lock, we need to confirm it's this lock that caused object leak.
|Patch Set 4:

I think we need to verify this can fix LU-8592 first, because currently only MDTx caches MDT0 ROOT xattr lock, we need to confirm it's this lock that caused object leak.
|Patch Set 4:

I think we need to verify this can fix LU-8592 first, because currently only MDTx caches MDT0 ROOT xattr lock, we need to confirm it's this lock that caused object leak.
|Patch Set 4:

I think we need to verify this can fix LU-8592 first, because currently only MDTx caches MDT0 ROOT xattr lock, we need to confirm it's this lock that caused object leak.
|Patch Set 4:

I think we need to verify this can fix LU-8592 first, because currently only MDTx caches MDT0 ROOT xattr lock, we need to confirm it's this lock that caused object leak.
|Patch Set 6:

Is it confirmed that the leaked object is remote ROOT?

BTW originally the remote object cache with lock is designed to be general, though it's used to cache remote ROOT xattr currently, so if we can't make certain of the cause, I don't prefer change it this way.
|Patch Set 6:

Currently mdt-&gt;mdt_md_root is put in mdt_fini(), maybe it's put too early, and in the mean time mdt still handles requests. If so, we can just delay this a bit later.
|Patch Set 7:

(1 comment)
|Patch Set 9:

(1 comment)
|Patch Set 9: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1

could you add a test for this?
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(5 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2:

(1 comment)
|Patch Set 3:

(2 comments)
|Patch Set 6: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Abandoned

sorry, wong ticket number.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 15: Code-Review+1
|Uploaded patch set 2.
|Patch Set 35: Code-Review+1
|Patch Set 36: Code-Review+1
|Patch Set 27: Code-Review+1
|Patch Set 28: Code-Review+1
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 3:

ping.
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 5: Code-Review-1

(1 comment)

IMHO we need to cache MDT-object's EA, because filesystem default stripe is based on this. Furthermore, this cache is not for LFSCK only, which can be used by normal operations.
|Patch Set 8:

(2 comments)
|Patch Set 8:

(2 comments)
|Patch Set 9: Code-Review+1
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Patch Set 2:

Why do you think this is is an issue, did you see any thing go wrong?

When statahead is not enabled, revalidate won't be blocked, so it can support rcu-walk. It's a small optimisation.
|Patch Set 17: Code-Review+1
|Patch Set 14: Code-Review+1
|Patch Set 14: -Code-Review

(2 comments)
|Patch Set 14:

(1 comment)
|Patch Set 14:

(1 comment)
|Patch Set 14:

(1 comment)
|Patch Set 14: Code-Review+1

(1 comment)
|Patch Set 13:

(1 comment)
|Patch Set 13:

(2 comments)
|Patch Set 13: Code-Review+1
|Patch Set 14: Code-Review+1
|Patch Set 16:

(2 comments)
|Patch Set 16:

(1 comment)
|Patch Set 16:

(1 comment)
|Patch Set 16: Code-Review+1
|Patch Set 18: Code-Review+1
|Patch Set 13:

(3 comments)
|Patch Set 13:

(1 comment)
|Patch Set 14: Code-Review+1
|Patch Set 13: Code-Review+1
|Patch Set 14: Code-Review+1
|Patch Set 13:

This looks working, but IMHO it's not better than wrapping up a shell to mount each target as local filesystem and modify config files directly.
|Patch Set 13:

I mean we can rename filesystem fsname in mountdata, and also set 'writeconf' option, so that MGS treats this as a new system.
|Patch Set 13: Code-Review+1
|Patch Set 14: Code-Review+1
|Patch Set 13:

Pardon, I don't see where 'rename filesystem fsname' is used in this patch, what's that for?
|Patch Set 13: Code-Review+1

(1 comment)
|Patch Set 15: Code-Review+1
|Patch Set 18: Code-Review+1
|Patch Set 3:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 6:

(8 comments)
|Patch Set 6:

(21 comments)
|Patch Set 6:

(1 comment)
|Patch Set 11: Code-Review+2
|Patch Set 9:

(1 comment)
|Patch Set 9:

(1 comment)
|Patch Set 11:

(1 comment)
|Patch Set 14: Code-Review+1
|Patch Set 10: Code-Review-1

(2 comments)
|Patch Set 14: Code-Review+1
|Patch Set 11:

(1 comment)
|Patch Set 13: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Patch Set 7: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 4: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 24: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Abandoned

replaced by https://review.whamcloud.com/#/c/26001/
|Patch Set 1: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 1: Code-Review-1

(1 comment)
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Ehh, this is also used by OUT, object allocated by it is not fully initialized in all layers, so such object may not be used by others (call trace from MDT), and should be discarded right after use.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 3: Code-Review-1

I'll update this later, which will wait for partially initialized object.
|Uploaded patch set 4.
|Abandoned

replaced by https://review.whamcloud.com/#/c/26965/, I used the same change-id, don't know why it's not at the same place.
|Restored

oh, I mistakenly abandoned it.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

Di, could you comment on this?
|Patch Set 4:

Di, do you think the latest fix is correct?
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5:

(1 comment)

The original cause of deadlock in LU-9049 is that lookup object will wait if object is marked dying, because there is no strict ordering for ldlm lock and object lookup, one process can hold lock then lookup object, another one may take object refcount, mark it dying, then request ldlm lock, so system may deadlock.

Because current code can handle dying object already, there is no need to wait for such object. But as Di said, object created in OUT is not complete in all layers, and shouldn't be used in MDT context, so we'll mark such object dying after creation, and others wait for its last put.
|Patch Set 5:

(1 comment)
|Patch Set 5:

I think Di means lod_object is not initialized in OUT creation, e.g. lod stripe info and sub objects.
|Patch Set 5:

Alex, out create uses dt_locate() to allocate obj, and it's initialized in all layers, but it calls dt_create() to create this object which bypasses LOD layer so stripe is not set. Do you mean out_tx_create_exec() should calls md_create()? But in my understanding OUT should be right above OSD?
|Uploaded patch set 6.
|Patch Set 6:

ok, I'll tweak the code like this and test.
|Patch Set 6:

Yes, in theory there can be case which leads to deadlock, I'm tweaking the code to see whether incomplete obj can be handled correctly by subsequent operations other than removing it from cache.
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Patch Set 8: Patch Set 7 was rebased
|Patch Set 8:

rebased to see whether soak test can pass.
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review-1

LU-9563 shows REP-ACK hr may also race with mdt_steal_ack_locks() because the latter doesn't steal locks with rs_lock, this patch needs update.
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 8:

transaction commit may miss decref saved locks in rs in following case:
1. REP-ACK hr reset lock handles in rs, and prepared to downgrade locks.
2. transaction commit hr found there is no lock saved, and then released rs.
3. REP-ACK downgraded locks.

In the end, locks are not decref'ed, and will cause deadlock.
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|&quot;out&quot; not &quot;out_cache&quot; should be enough.
|Please see my last comment.
|ditto
|ditto
|I check the patch again, here it should be ok to use one &quot;out_cache&quot;.
|out_cache includes too many things here. To make it clear, we'd better split it into several goto labels, e.g. out_dataslab, out_perm, out_hash and out_cache.
|I mean for example,
if (ll_inode_cachep != NULL) {
       cfs_mem_cache_destroy(ll_inode_cachep);
       ll_inode_cachep = NULL;
}

if (ll_inode_cachep == NULL), we don't need to set ll_inode_cachep = NULL; again.
|BTW, do we need to move these &quot;xxx = NULL;&quot; into if() {} ?
|This line will conflict with the similar change in http://review.whamcloud.com/#/c/13235/3/lustre/tests/sanity-sec.sh. I still suggest to merge these two patches together.
|Why? Then how about the assert in ll_free_sbi() ?
|Done
|Done
|This line caused both recovery-small.test_23 and replay-single.test_14 failure.

recovery-small.test_23.console.client-19vm3.log showed
12:24:02:LustreError: 9196:0:(mdt_open.c:1831:mdt_close()) ASSERTION( mfd != ((void *)0) ) failed: 
12:24:02:LustreError: 9196:0:(mdt_open.c:1831:mdt_close()) LBUG

replay-single.test_14.console.client-19vm3.log showed
08:48:27:LustreError: 4455:0:(mdt_open.c:1831:mdt_close()) ASSERTION( mfd != ((void *)0) ) failed: 
08:48:27:LustreError: 4455:0:(mdt_open.c:1831:mdt_close()) LBUG
|I ever tried to make the parameters into one line, but it can't pass commit-msg 70 columns check. Any idea?
|The following changes about &quot;not less then 10Mb, and limited by 512Mb in libcfs&quot; were deleted in LU-1249. I'm not sure if that patch should also be ported to b1_8.
|{get,set}_obdfilter_param
|Here, the value should be 1.
|Sorry, I really changed that in patch#3. Probably I misused patch#2 when I updated. I will correct it soon.
|Sorry for my misunderstanding, you are right :)
|The logic makes me a little confused. I'd like to return 1 if dir or fs is empty, just as is_mounted() does.
|(style): don't need &quot;$&quot; in front of the second RMCNT
|According to the code in lfsck.c :       
        log_close(0);
        if (fix_failed) {
                fprintf(stderr, &quot;%s: exit with %u unfixed errors\n&quot;,
                        progname, fix_failed);
                return 2;
        } else {
                printf(&quot;%s: fixed %u errors\n&quot;, progname, fixed);
                return !!fixed;
        }
return 1 means errors found and fixed, so I think the second run is to do a double check.
|Why do we need to run lfsck twice? Can we remove the second run?
|Hmm, I still think doing check in this function is better, but the return value is really a little confused.
|Here, we can't use &quot;return $?&quot; because if lfsck is not found on remote node, $? will be 1, which will mislead &quot;the filesystem has errors fixed by lfsck&quot;.
|Sorry, C coding style
|Why don't replace other RETURN()s in &quot;case OBD_IOC_REPLACE_NIDS&quot;?
|Here is an obd-&gt;obd_name.
|(style): could you please align these variables as same as what you did in lprocfs_wr_identity_upcall()? Thanks.
|(style):ditto
|(style):ditto
|(style): ditto
|style: alignment
|It's same to remove_mdt_files(), which is only used for lfsck.sh too. I have to put it here since it is called by do_rpc_nodes().
|(style): OLDDEBUG=$(lctl get_param -n debug 2&gt; /dev/null)
|(sugestion): better use $tfile.1
|(defect): forget to replace R1, so it should be

mv $DIR/$tdir/$tfile.1 $DIR/$tdir/$tfile.2
|(defect): forget to replace R1 and g,  so it should be

$CHECKSTAT -t file $DIR/$tdir/$tfile.2 &#124;&#124; error &quot;$tdir/$tfile.2 not a file&quot;
|(suggestion): better use d$testnum.1
|(defect): forget to replace f, so it should be
 
mv $DIR/$tdir/d$testnum.1 $DIR/$tdir/d$testnum.2
|d$testnum.1 ?
|I find there are still many empty error()s and many places needed to be replaced with $tdir/$tfile in test_$(seq 24 39). Don't we change them in this patch?
|(style): while [ $(ls -sd $DIR/$tdir &#124; awk '{ print $1 }') -eq 4 ]; do
|(style): exceeds 80 columns
|ditto
|(style): bs=$(page_size)
|(style): exceeds 80 columns
|(style): [ -z &quot;$(lctl get_param -n mdc.*-mdc-*.connect_flags &#124; grep xattr)&quot; ] &amp;&amp;
|(style): if [ -n &quot;$(mount &#124; grep \&quot;$MOUNT.*flock\&quot; &#124; grep -v noflock)&quot; ]; then
|ditto: $()
|ditto
|Thanks! I will fix it.
|Style: * alignment
|To be pleasing to the eye, we can use &quot;struct ptlrpc_request *req;&quot; 
Just a little suggestion.
|If you accept my above suggestion, here we need &quot;req = mdt_info_req(info);&quot;
|ditto
|Style: According to the new &quot;coding guidelines&quot;, variable should be declared one per line, type and name, even if there are multiple variables of the same type. For maximum readability, the names should be aligned on the same column. Thanks!
|{} can be removed.
|Done
|Done
|See the reply in http://review.whamcloud.com/#patch,sidebyside,5981,2,lustre/tests/test-framework.sh
|Done
|(style): if the patch is refreshed, please add a space after &quot;,&quot;.
|I agree.
|After looking into the code, I think using &quot;option&quot; will be easier because we should pass it to the following mkdirs.
|Done
|Done
|If we use basename and dirname above as read suggested, do we still need this further check?
|Yes, especially when we pass multiple directories. But now I have no better idea about how to fix it.
|(suggestion): can we move and rename this test case to test_154c and rename the following test_154c to test_154d? because the names of 154A and 154a are a little confusing.
|I think either one does work.
|Not sure.
|I will simplify them into one &quot;for&quot; loop.
|(suggestion): we can merge the above two lines into one.
|Defect:This time I know why you move this &quot;if&quot; condition into if (policy != NULL) {}, because here is policy-&gt;l_extent. But please don't put LDLM_DEBUG there.
|Suggestion: we can use -EINVAL instead of -1.
|(style): data != NULL
|(style): fid != NULL
|(style): req != NULL
|(style):if () {}, If one part of a compound if block has braces, all should.
|(style): else {}, If one part of a compound if block has braces, all should.
|Done
|Done
|Done
|Done
|Done
|Done
|If realpath() returns non-NULL, the resolved path will be stored into mop.mo_device. Thanks for your reminder that dm device should be considered. I will update this path later.
|The kernel code shows that lo_file_name is defined as __u8 array, as follows
struct loop_info64 {
        __u64              lo_device;                   /* ioctl r/o */
        __u64              lo_inode;                    /* ioctl r/o */
        __u64              lo_rdevice;                  /* ioctl r/o */
        __u64              lo_offset;
        __u64              lo_sizelimit;/* bytes, 0 == max available */
        __u32              lo_number;                   /* ioctl r/o */
        __u32              lo_encrypt_type;
        __u32              lo_encrypt_key_size;         /* ioctl w/o */
        __u32              lo_flags;                    /* ioctl r/o */
        __u8               lo_file_name[LO_NAME_SIZE];
        __u8               lo_crypt_name[LO_NAME_SIZE];
        __u8               lo_encrypt_key[LO_KEY_SIZE]; /* ioctl w/o */
        __u64              lo_init[2];
};

And if I don't use (char *) cast, it reports error &quot;mount_utils.c:188: note: expected â€˜const char *â€™ but argument is of type â€˜__u8 *â€™&quot;.
|orro-&gt;oo_ref might be 0
|The two params are lod.*.qos_prio_free and lov.*.qos_prio_free. And lov/lustre-MDT0000-mdtlov is a symlink of lod/lustre-MDT0000-mdtlov. So, two values are same,  you can choose either of them for the test.
|Done
|Done
|Done
|(typo):error &quot;stripe count...&quot;
|I agree to use fops only. Then this patch would be very large and hard to split into some small ones. Probably client side patch and server side instead?
|During my working on this port, I find we also need LPROC_SEQ_FOPS_WO(name) for server side code.
|(suggestion): Could we rename this to LPROC_SEQ_FOPS_WO_TYPE? it will be clearer.
|Could we keep these ost error messages and at the same time we add a new message like &quot;the parameter will be passed down the stack&quot;? because these error messages are still helpful for debugging.

BTW, I agree to add PARAM_OSD, although we have no osd parameters now,  it will make sense in the future.
|Done
|(style): Please remove this blank line.
|(style): extra blank line
|(defect): There is a typo &quot;]&quot; in the original patch. We can use ${#fid_list[@]} instead of $fid_nr.
|&quot;lfs fid2path&quot; shows these open files come from test_11/60/71.
|Yes, the test previously failed due to these open files. In my local test I find that some of the open files come from test_11 and test_71. I will check other cases one by one and fix them properly.
|If some open files left by the previous test cases are found, remove them. Otherwise, we will get a wrong open file number in this test.
|(style): please remove the trailing spaces if you get a chance to refresh the patch.
|(defect): This function is part of seq_file support introduced by LU-3319, which was not landed to b2_5, so we don't need to port it in this patch.
|(defect): ditto, remove #ifndef macro, just keep lprocfs_osd_module_vars.
|Done
|Done
|Done
|Thanks for pointing this out! Besides, this will trigger a endless check_and_cleanup_lustre loop if LFSCK_ALWAYS=yes. I am working on the fix.
|I think yujian means &quot;get_param&quot;. No matter what, if there is a chance to update the patch, please replace these &quot;cat proc entries&quot; in test_73/74 per yujian's suggestion.
|We are already in condition of &quot;if (fl &amp; LU_XATTR_REPLACE)&quot;, so here, &quot;if (fl &amp; LU_XATTR_CREATE)&quot; should be enough.
|After discussion with hongchao, I know this should be still mount3. Please ignore my previous comment.
|(defect): Here should be &quot;goto failed_mount4;&quot;, right?
|After checking the code, I find that besides (append_size == 1), write_max and append_max in above two lines are both probably equal to 1 by setting option &quot;-a 1 -w 1&quot;.
Could you please fix them as well? Thanks.

BTW, please rebase the code before updating the patch. Thanks.
|Please update the commit message to including the situations of write_max == 1 and append_max == 1.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|(abbr.): what does ssp_ stand for? &quot;service summary period&quot;? sp_* should be enough.
|(typo):It's really summer now. &quot;Summary&quot; ?
|Sorry, I don't quite understand the meaning of depth, length, statistic, carry and carry_times. Could you please explain in more details?
I guess you define a sampling interval and the total sampling number, right?
|(abbr.): since you define struct ptlrpc_service_summary, the prefix ss_ should be easier to understand than sh_.
|(style): please use tabs for code indent where possible.
|(style): can be in one line.
|(defect): snprintf(page + rc, count - rc,
|(style): please use tabs for code indent where possible.
|ditto
|(style): period-&gt;sap_carry_times ++;
|These macro definitions are only used here for value assignment. If we need to change them in the future, we'd better find a way to make them tunable.
|Now I understand &quot;length&quot; a little.
|(style): please use tabs for code indent where possible.
|(style): please use tabs for code indent where possible.
|ditto
|ditto
|Thanks, done.
|Done
|Sounds *_interruptible() is more suitable to terminate the user process.
|The error message should be &quot;'mkdir bar' failed after recreating cwd&quot;.
|Same, here should be &quot;mkdir .bar&quot;.
|Yes, this is not a complete fix per your comment on LU-5297.
|Actually before I pushed this patch, I had a talk with Niu and he mentioned the comment in LU-5297. But at that time I have no a good fix for the LBUG caused by this test case.
|Yes, I know. I will discuss with you to complete the fix.
|(defect): Here we can't use ldd_fsname to tell if it's a new fsname because ldd_fsname is used to store old fsname when calling osd_read_ldd() before we parse any new options.
So, I suggest to use &quot;fsname_option&quot;, something like index_option you are using.
|(suggestion): If you get a chance to update this patch, please use bool type for these two variables.
|(style): if (suffix != NULL)
|(style): if (paramname != NULL)
|ditto
|ditto
|ditto
|ditto
|ditto
|Great, thanks Ryan!
|We should have directories and symlinks counted as well, and if so, we have to exclude those existent head directories finally, e.g. /proc/fs/lustre. So, that's why I did in the last patch.
|Yes, we use do_div() in the kernel space for division operation, but here it's used in the user space, so &quot;/&quot; is OK.
|(defect):I just found and reported the bug LU-7437. We shouldn't call lprocfs_param_pattern() inside {list/get}param_display(), otherwise it will add the prefix &quot;/proc/{fs,sys}/{lnet,lustre}&quot; each time so that the parameters can be listed recursively.
|(defect): I guess the &quot;valuename&quot; misled this change. This change made sanity.sh test_401 fail because it skipped all the directory names when we use &quot;-R&quot; option.
Maybe we should rename &quot;valuename&quot; to &quot;paramname&quot; to something else to avoid the confusion.
|Done
|Thanks Andreas! I will keep an eye on 17082 patch.
|(defect): forget to return -EFAULT
|I didn't use -EINVAL because the invalid record is different from common errors, it should be handled as an error in osp_sync_process_record() first, and then return 0 to let sync thread continue processin other records. If I use -EINVAL, I'm afraid it will be mixed with other real -EINVAL errors.

If we can assure that won't happen, I'd like to use it instead.
|I made this change because we do have three types of return values to be handled differently in osp_sync_process_record(), one for success, one for error, and one for invalid record, addressed in this patch. 

Since the invalid record is different from common errors, so I changed the value to EINVAL. I think that's why wangdi changed the return value as well in http://review.whamcloud.com/#/c/10828/4.
But with that patch the code becomes not so readable because in that patch 0 on invalid record while 1 on success is returned by osp_sync_new_xxx_job(), and then has to be converted to 0 on success by osp_sync_procee_record().

BTW, I just had a look at b2_5 and b2_4. b2_5 is same to master, and b2_4 has no LU-5188 patch, still keeps 0 on success. So we can only back port this patch to b2_5 to keep the code compatibility.
|Let me check.
|OK.
|Just like what I said in the previous version patch, we do have three types of return values to be handled differently in osp_sync_process_record():
- for success, return 0
- for error, return -EXXX, and
- for invalid record, return EINVAL, which is addressed in this patch.

I didn't use -EINVAL because the invalid record is different from common errors, it should be handled as an error in osp_sync_process_record() first, and then return 0 to let sync thread continue processin other records.
If I use -EINVAL, I'm afraid it will be mixed with other real -EINVAL errors.
|Alex, if this positive EINVAL makes the patch weird, can we use &quot;1&quot; instead, like the original code?
|Even if we do check invalid record here before proceed with osp_sync_new_setattr_job(), we still need to cleanup the state, I mean decreasing _changes and deleting this invalid record, right?
|Done
|Done
|Done
|Done
|Done
|Done
|Yes, this is a defect. The lowest N=7 bits by default in the sequence ID are used as the OI table index key.
|(defect): $TMP/$tfile is stored locally, not on mgs.
|Thanks, you are right. It can be improved by
rec_list=($(awk '/9_sub.*record/ { print $((NF-3)) }' /$TMP/$tfile &#124; tail -n 4))
|Olaf, oops, I forgot &quot;do_facet mgs&quot; here. Thanks for your correction.
|(style): line over 80 characters
|(style): line over 80 characters
|(defect): forgot &quot;\&quot; at the end of this line
|(defect): Please remove this line because there is no /proc/fs/lustre/ost directory on MDS. This causes &quot;error: set_param: ost/OSS/*/nrs_policies: Found no match&quot; (see LU-6688).
|(style): usually we use [ $rc -eq 0 -o $rc -eq 11 ] instead.
|I think &quot;TBF&quot; is a typo here, should be ORR policy, right?
|Please ignore my previous question. I see now. Thanks.
|I saw the following osd code:
        /* LOD might calculate the max stripe count based on max_ea_size,
         * so we need take account in the overhead as well,
         * xattr_header + magic + xattr_entry_head */
        ea_overhead = sizeof(struct ldiskfs_xattr_header) + sizeof(__u32) + LDISKFS_XATTR_LEN(XATTR_NAME_MAX_LEN);

So I know the 32-byte ext4_xattr_entry you mentioned above should be the entry head. But, why LMA has such an entry?
|BTW, what link do you mean for MDT? struct link_ea_header?

According to my previous calculation in LU-6544, ldisk_inode size is 156 bytes, lma size is 24 bytes. If we consider 24(link) or 16(fid) as well, as long as N &lt; 10, it will fit into a 512-byte inode.

That is, N=8 will leave about 52 free bytes in a 512-byte inode; N=30 will leave about 36 bytes in a 1024-byte inode.
|Not odd, some extra bytes are needed for 4-byte alignment I didn't mention them here explicitly, but I used the &quot;margin for alignment&quot; in the following lines instead.
|Yes, you're right, only &quot;link&quot; is stored.

I just printed xattr entry name and value in ldiskfs_xattr_set_entry(), shown in the following:

i_name is lma, name_len is 3, value_len is 24

i_name is link, name_len is 4, value_len is 47 (filename is abcde)

i_name is lov, name_len is 3, value_len is 80 (OSTCOUNT=2)


I will recalculate the size.
|(typo): s/trough/through
|(typo):s/trough/through
|(defect): This test can't be supported by ZFS, so please skip it for ZFS.
|(defect): There is an issue in the original script. If we set &quot;REFORMAT=no&quot;, it will still format all. So, we should set REFORMAT as yes/no or true/false.
|I still think it's better to add the following code here instead, just like my comment for patch set #2.
if (rc &gt; 0)
        rc = 0;
|(defect): it should be &quot;if (rc &gt; 0)&quot;, because next() could return 1, and we will output error message if (rc &lt; 0) in the following code.
|Yes, you are right, this only happens when the value contains &quot;=&quot;.
|Since we decide to give a warning if value contains '=', we need do this check &quot;strchr()&quot; before calling param_display(), otherwise when running &quot;lctl set_param jobid_var=a=b&quot;, it won't give a warning.
|Please move &quot;strchr(value, '=')&quot; check here, before calling param_display(), so that no matter what formats we use, we will always give a warning if value contains '='.
|Thanks for the mention!
|(style): Please remove these spaces at the beginning of each line.
|(suggest): please move &quot;if (h == NULL)&quot; here instead of two above.
|Thanks for pointing this out. I will improve it if I get a chance to refresh the patch.
|Anyway, version check can avoid the LBUG during the test. Let me add it.
|(minor style): we don't need &quot;_&quot; between set and checksum. &quot;Set checksum failed&quot; is OK.
|ditto
|(defect): here should use &quot;get_param -n&quot;, otherwise $old_debug will have a beginning with &quot;debug=&quot;.
|(defect): should add double quote around $old_debug.
|Yes, it's a little old and there are many such kind of obsolete version checks(&lt;2.6) in our scripts. Can we file a new ticket to remove all of them instead?
|(defect): I notice that test_77e/f/g have already been included by Lixi's patch in LU-6668, landed. Please have a check if they are duplicate.
|(Typo): &quot;The limit numbers like 100, 200 mean the number ...&quot;
|I agree to do it in a separate patch.
|Since you said it's a little bigger than the limited value in real testing, can you provide a range(no bigger than some value) to prove it? I mean we need to see the tbf rule does work as we defined/expected.
|(Typo): &quot;The limit numbers like 100, 200 mean&quot; not &quot;are mean&quot;.
|Right, if &quot;-E&quot; follows &quot;-e&quot;, zfs will do some useless effort; but if &quot;-p&quot; follows &quot;-e&quot;, the params will be added to ldd_params finally, but zfs will still waste some time.
I will improve that.
|Done
|Done
|Done
|Done
|You are right, when len==0, we don't need to print anything.
|&quot;-E&quot; means &quot;--erase-param&quot;, while &quot;-e&quot; means &quot;--erase-params&quot;
|Oops, I will change it. True means in the form of &quot;key=&lt;value&gt;&quot;.
|Done
|Done
|OK, I will improve that.
|I agree,  I didn't see any chance to update mgs logs if add_param() fails. But, this is from Seagate's patch, I'm not sure if there is some situation they have caught.
Nikitas, could you explain more why we need to set UPDATE here?
|Done
|Done
|For ldiskfs, it already works in this way; for zfs, I think we need to add a flag for each property in ldd_params to remember its final status.
|&quot;--erase-params&quot; causes ldd-&gt;ldd_params[0]='\0', to remove all the parameters. In such case, we don't need to check &quot;--mgs&quot; or &quot;--mgsnode&quot; anymore, because there is no any parameters.
But, as long as &quot;ldd-&gt;ldd_params[0] != '\0'&quot;, that means there are some parameters, we must check.
|Yes, we can, but after that we need to specify --mgsnode next time.
|I did spend some time on looking up such functions, finally with Liwei's help, we found only zfs_prop_inherit() and zfs_prop_set_list() can do this, but zfs_prop_set_list() needs the newer zfs version than what lustre is using. So I use zfs_prop_inherit() here.
|Actually I tried nvlist_remove_nvpair(), but I found it only changed the nvlist in memory, not on-disk. I need a function to call zfs_ioctl() to write them back.
|Those parameters that have been removed by osd_erase_ldd() won't appear in ldd_params here, because we call erase_param() to remove them from ldd_params before we call osd_erase_ldd().
|OK, now the main problem is that ldd_params doesn't remember which parameter is removed. For ldiskfs, it can be deleted from ldd_params directly, but for zfs we need to remember that until these parameters are updated on-disk finally.
I have two ideas. The first, keep ldd_params as a string, add a flag to each parameter to remember its status; the second, change ldd_params to store a structure.
|zfs is different from ldiskfs. It stores all the parameters in the nvlist, no matter ldd_params or not, so I have to write them back again.
|Sorry, the previous reply is for --erase-params.
I think these lines of code can be removed.
|(defect): here should be &quot;&#124;&#124;&quot;. BTW, I also found both &quot;--erase-param&quot; and &quot;--erase-params&quot; can't work correctly for zfs. I'm looking into zfs_{read/write}_ldd() code and will update the patch later.
|(defect): please add version_code check in case of any interop test failure.
|(defect): tunefs has no &quot;--print&quot; option, and your patch didn't add new &quot;--print&quot; option also.
|ditto
|ditto
|Why we don't erase each parameter that specified with &quot;--param&quot;? Why we need to check the first?
|hmm, for ZFS we don't need to erase before add, because zfs  will over write the value automatically; for ldiskfs, it's different. If the same parameter name is specified for many times in one command line, e.g. &quot;--param abc=123 --param abc=345&quot;, both &quot;123&quot; and &quot;345&quot; will be remembered by add_param(), even you erase &quot;abc&quot; at the first time.

So, IMO, either we don't erase anything, just run add_param() as before; Or, we do erase_param() every time, no matter whether it's the first time or not. 
However, if the parameter is specified for many times, the first choice probably will cause the parameter size larger than 4096, and the second choice will cost more erase operations. 

I prefer the second one.
|I see now. I will improve the comments a little to make it clearer.
|Done
|Yes, we add new parameter no matter whether this parameter has existed or not.
BTW, there is no (rc&lt;0) case returned by erase_param().
|I think the caller does need to handle &quot;EINVAL&quot; error. Actually, there is no special handling if (rc &gt; 1), it will &quot;goto out&quot;.
|Done
|I guess you mean the last few lines.
|OK, I will split it into two patches.
|Done
|yes, you are right.
|Done
|(defect):I just recognized that the version check here is old, now it should be &quot;2.9.5x&quot;.
|Hmm, we can keep this check for those  (2.8.55 &lt;= version &lt; the current)..
|(defect): it should be &quot;-ge $(version_code 2.8.56)&quot; for now.
|Since this patch introduces &quot;generic&quot; type, the command &quot;lctl set_param ost.OSS.ost_io.nrs_policies=&quot;tbf reg&quot;&quot; should be OK. So please update sanityn.sh test_77h to support the new command format.
|I suggest to use &quot;combined_mgs_mds &#124;&#124; stop_mgs &#124;&#124; return 204&quot;.
|Please modify this message according to the change.
|Please modify this message because we don't need to set FSNAME.
|(defect): we don't need to set FSNAME anymore.
|I still suggest to use &quot;load_modules&quot; instead of modprobe on the different nodes.
|I know the issue you are worried about is that mds1 is reformatted with the same index, but mgs isn't and it will report that index already in use.
I compared test_55 and test_56. I think instead of keeping the old fsname, we just need to reformat each time.
|stopall before the test
|remove this &quot;add mds1&quot;
|replace stopall with reformat
|remove this reformat
|Can you explain here why we need start_mgs in the end of t32_test_cleanup() ?
|libcfs is rmmoded by &quot;cleanup&quot;, in the beginning of test_41c. Anyway, thanks for pointing this out.
|(typo): MGS and MDS are seperated.
|3) and 10) are same, please remove one.
|Can you explain the conflicts?
|(suggestion): For better understanding the commit message, I suggest to list these items by test case numbers in sequence, for example:
conf-sanity.sh
 1) test_32:
 2) test_41:
...
sanity-hsm.sh
 1) ...
sanityn.sh
...
|Could you please expain it more? If the later test cases need mgs, they should check the env themselves before the test.
|(style): &quot;Need combined ...&quot;
|(defect): I suggest to add &quot;load_modules&quot; following &quot;cleanup&quot; in the beginning of this test, instead of modprobing here.
|Can you explain the conflicts here if we don't use a new fsname?
|I think we can't owe test_68's failure to test_66. Instead, the right way is to check the env in the beginning each case and clear the env in the end.
|As I said, we should reformat in the end of test_75 and check the env in the beginning of test_76a.
|(style): please add &quot;{}&quot; to this if condition, if there is a chance to update the patch.
|I agree.
BTW, bobi, how many kinds of resend issues were found? Do we need to add a test case for each of them?
|-p option will be removed from test_mkdir() by the patch https://review.whamcloud.com/#/c/26212/. So, could you please remove it if you get a chance to update the patch next time? Thanks.
|Ditto
|(Style): it's better to move these local variable declarations to the beginning of this test case.
|ditto
|ditto
|ditto
|(suggestion): Can we add the correct answer to each error message or any comment? For example, in the last one we can say: 
error &quot;start-1M, end+5M, !count+2, flag=init, $found != 1 (f3)&quot;
or
[ $found -eq 1 ] &#124;&#124; #f3
|Why removed &quot;test -e .../warning_dir_size&quot; here?
|In my local test, if I run this tests more than once, this &quot;has reached&quot; message will be skipped by the message &quot;Lustre: 12308:0:(osd_handler.c:472:osd_ldiskfs_add_entry()) Skipped 1 previous similar message&quot; and cause failure.
|Done
|Done
|Done
|Done
|Will do.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Andreas, I haven't started to improve it yet. As I discussed with Eric, I need to convert the doc to be xml format as part of lustre manual by the end of this week. Then I will improve it and finish the whole manual be the end of May.
|Done
|Done
|Done
|Done
|Done
|It should be &quot;touch /mnt/lustre/pfldir/commonfile&quot;
|It should be &quot;pfldir&quot;, done.
|Done
|Done
|I have reported this to Niu and he will fix it.
|Please see LU-9462
|Done
|I will use [STRIPE_OPTIONS] instead.
|Found this --yaml option in patch https://review.whamcloud.com/#/c/26708. Done.
|hmm, there is no &quot;--yaml&quot; option.
|Done
|there is no &quot;--yaml&quot; option.
|Done
|Will change.
|Will do.
|Done
|Reported it to LU-9463
|Done
|Done
|Done
|Will change.
|Will add.
|Done
|Done
|Done
|Done
|Done
|Done
|Oops, this was used for test. I forgot to remove it.
|Done
|Done
|Done
|Done
|Because it is a kind of llite lprocfs function, I add &quot;ll&quot; to distinguish it from those ones in lprocfs_status.c
|sbi-&gt;ll_xattr_cache_changed is used to mark xattr_cache has been set during processing llog before here, and won't be set again, no matter it is 1 or 0.

Maybe I should call it &quot;ll_xattr_cache_set&quot; instead &quot;ll_xattr_cache_set&quot;?
|Done
|Sounds reasonable
|Yes, according to the original code, if llite/* fails to register, it will do this cleanup.
|Ah, true, I will remove it.
|Done
|Done
|(style): according to the command format used in the above lines, &quot;$&quot; should be removed because this is not an example, and &quot;&lt;replaceable&gt;&quot; should following &quot;=&quot; in the same line, right?
|(style): same line
|ditto
|(style): Please remove this &quot;$&quot;.
|(style): should follow the &quot;=&quot;
|(style): please follow the &quot;=&quot;
|(style): please following the &quot;:&quot;
|(style): Please remove this &quot;$&quot;
|(style): Please following the &quot;=&quot; in the same line.
|ditto
|ditto
|Patch Set 1: I would prefer that you didn't submit this

(5 inline comments)


|Patch Set 1: (2 inline comments)


|Patch Set 1: No score

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2:

The sanity-hsm.sh passed but was marked as failed due to TEI-1403. I just retriggered the test.
|Patch Set 2:

I don't know why conf-sanity test 32a,32b,32d always were skipped due to &quot;No applicable tarballs found&quot; on master&lt;-&gt;b2_4. But it did passed on b2_5&lt;-&gt;b2_4 https://testing.hpdd.intel.com/test_sessions/320d8322-2d26-11e4-b550-5254006e85c2 .
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Patch Set 4: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Oleg, this patch is blocking LU-5241. Could we land it to b2_5 ?
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 3: Commit message was updated
|Patch Set 4: Commit message was updated
|Patch Set 4:

sanity-lfsck.sh test_5 failed due to LU-5248.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1:

Kit, I agree with Andreas. What's more, could you please fix that style issue (line over 80 characters) when you get a chance to update this patch? Thanks.
|Patch Set 1:

Hi Kit, I saw you fix the nettype issue in the new patch http://review.whamcloud.com/#/c/13235/. If so, could you please merge these two patches together, and abandon one ?
|Patch Set 1: Code-Review-1

(1 comment)

This patch will conflict with http://review.whamcloud.com/#/c/13235/3 in line 1314. I still suggest to merge these two patches together.
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 4:

test
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Patch Set 2:

b2_1 port is at http://review.whamcloud.com/#change,4784
|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve

In the old lustre version, lprocfs_rd_fstype() was called by mds, mgs, obdfilter and others. But now, each component has its own rd_fstype function, e.g. ll_rd_fstype(), lprocfs_ofd_rd_fstype() and lprocfs_osd_rd_fstype().

I don't mind to link osd's there if we can't have a proper lprocfs_mgs_rd_fstype(). 

One suggestion: In order to avoid such error, can we add a sanity.sh test to check all the readable lustre proc entries?
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)

@@ -1664,9 +1823,12 @@ int mdt_close(struct mdt_thread_info *info)
                 rc = err_serious(rc);
         }

+       LASSERT(req-&gt;rq_export != NULL);
         med = &amp;req-&gt;rq_export-&gt;exp_mdt_data;
+       LASSERT(med != NULL);
         cfs_spin_lock(&amp;med-&gt;med_open_lock);
         mfd = mdt_handle2mfd(info, &amp;info-&gt;mti_ioepoch-&gt;handle);
+       LASSERT(mfd != NULL);
------------------------------ This line caused both recovery-small.test_23 and replay-single.test_14 failure.
|Patch Set 2: No score

I hit replay-single.sh test-14 failure on my local vm.
|Patch Set 2:

Sebastien, would you like to revise this patch?
|Patch Set 3:

Sebastien, could you please abandon this change since we have four sub-patches?
|Uploaded patch set 2.
|Patch Set 2: (1 inline comment)


|Uploaded patch set 3.
|Patch Set 3:

Let's see if the new test parameters format works.
|Patch Set 1: (1 inline comment)

I found in the patch of LU-1249 http://review.whamcloud.com/#change,2489,patchset=3 , the lines about &quot;not less then 10Mb, and limited by 512Mb in libcfs&quot; were deleted to &quot;Auto correct improper debug buffer size setting&quot;. I'm not sure if that patch should also be ported to b1_8.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Patch Set 2:

I am investigating this failure and will update the patch later.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Rebase the patch and apply &quot;lfs_df&quot; to the code introduced by sanity-quota.sh
|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

I replace spaces with tabs this time. Hope I understand the coding style rules right.
|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3:

I prefer you revise it per wangdi's suggestion since this patch is to use {get,set}_obdfilter_param.
|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1:

Could you please add &quot;Test-Parameters: testlist=lfsck&quot; in commit message? And you can add tabs to lfsck.sh if patch is refreshed. :) 

Thanks!
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve

After discussion with liwei, I think this patch is good for me. 

I prefer not to remove imports from the list, but probably there are some unforeseen problems in a large-scale system. As for how to set this parameter, I think we could find a better way to do it between server and client pair, instead of module parameter. But now I have no idea.

What's more, we can add a test for this feature in the future.
|Patch Set 7: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Rebase
|Patch Set 4: (1 inline comment)


|Uploaded patch set 5.
|Patch Set 5:

The massive failures in Rosso autotest are perhaps due to LU-2734,
|Patch Set 1:

port of master patch 43414bd6f25a4b207e13539414782ddb961fbf2a
|Uploaded patch set 2.
|Patch Set 2:

There is no definition of ext4_clear_inode_flag() and EXT4_INODE_EXTENTS in RHEL5-2.6.18, so I clear extent flag in an old way.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

This failure is related to sanity test_27y. I am looking at it, and will refresh the patch later.
|Patch Set 2:

Since this patch is blocked by LU-2899, can we add sanity test_27B in ALWAYS_EXCEPT list temporarily ? And once LU-2899 is fixed, move it out then?
|Uploaded patch set 3.
|Patch Set 3:

I update this patch based on the one of LU-2899, which is ready for landing.
|Patch Set 3:

The recovery-small test_19b failure was caused by LU-2194.
|Uploaded patch set 4.
|Patch Set 4:

Rebase the patch.
|Patch Set 1:

I will use tabs instead, but I see &quot;Indentation:
The indentation must use 8 spaces and not Tabs. For line continuation, an additional four spaces should be used.&quot; in http://wiki.whamcloud.com/display/ENG/Test+Coding+Style
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

The local manual test report is at https://maloo.whamcloud.com/test_sessions/faea9b32-66bb-11e2-a65f-52540035b04c

In this test, lfsck on client was renamed, so the test ran on MDS node instead.
|Patch Set 3: (1 inline comment)


|Patch Set 3: (1 inline comment)


|Uploaded patch set 4.
|Patch Set 4: (1 inline comment)

This patch probably could not pass maloo lfsck test as mentioned in LU-2694. My local test report is at https://maloo.whamcloud.com/test_sessions/a253099a-6b71-11e2-a7b9-52540035b04c
|Patch Set 4: (2 inline comments)


|Uploaded patch set 5.
|Patch Set 5:

Local test report is at https://maloo.whamcloud.com/test_sessions/f567a396-70ff-11e2-9241-52540035b04c
|Uploaded patch set 6.
|Patch Set 6:

Failed to upload the local test report this time. I compared the test logs created by auster, the format is same. I tried several times, all failed. 
It said &quot;Exception in import_tarball: #&lt;ArgumentError: syntax error on line 18, col 30: `centos6-1: lbats_build_id:'&gt; &quot;

I will try it later. Please look at the corresponding report for patch set 5 for reference.
|Patch Set 6:

The local test report is at https://maloo.whamcloud.com/test_sessions/b51a9518-712d-11e2-9241-52540035b04c
|Patch Set 6:

Oleg, could you please have a look at this patch? The customer is waiting for it.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

Update commit message per wangdi's advice.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: No score

Is this patch still needed by master?
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

I don't know how mdt helpers work, but I find the replacement is not complete.

For example, in mdt_connect_internal() there are still two places using mdt_md_dev.md_lu_dev.ld_obd-&gt;obd_name.

CWARN(&quot;%s: MDS requires FID support, but client not\n&quot;, mdt-&gt;mdt_md_dev.md_lu_dev.ld_obd-&gt;obd_name);
|Patch Set 3: I would prefer that you didn't submit this

I just tried the command &quot;grep &quot;mdt2obd_dev(&quot; * -n -R &#124; grep &quot;obd_name&quot;&quot; and found that a place can be replaced with mdt_obd_name in mdt_fini()
server_put_mount(mdt2obd_dev(m)-&gt;obd_name, NULL);

Could you please run grep to have a double check after running mdt helpers? Thanks.
|Patch Set 4: I would prefer that you didn't submit this

(1 inline comment)

The replacement with mdt_lu_site() is not complete. In mdt_handle.c: mdt_stack_init()

        LASSERT(mdt-&gt;mdt_md_dev.md_lu_dev.ld_site == NULL);
        mdt-&gt;mdt_md_dev.md_lu_dev.ld_site = site;

BTW, I don't think we need to replace all the &quot;obd-&gt;obd_name&quot;s with met_obd_name() if the variable &quot;obd&quot; is clean and clear enough.
|Patch Set 5: I would prefer that you didn't submit this

(4 inline comments)

Most of part looks good to me, but there are still some obd-&gt;obd_names which can be replaced in mdt_handle.c.

In mdt_stack_fini(),
{
        struct obd_device       *obd = mdt2obd_dev(m);
        ...
        lustre_cfg_bufs_reset(bufs, obd-&gt;obd_name); //can be replaced
        ...
}

In mdt_adapt_sptlrpc_conf()
{
        struct mdt_device       *m = mdt_dev(obd-&gt;obd_lu_dev);
        ....
        if (rc) {
                CERROR(&quot;mdt %s: failed get sptlrpc rules: %d\n&quot;,
                       obd-&gt;obd_name, rc);//can be replaced
                return rc;
        }
        ...
}

And in mdt_fid2path() and others.

Please have a full check if you want to replace them all.
|Patch Set 6:

Jacques-Charies, could you please rebase your patch? Thanks.
|Patch Set 7: Looks good to me, but someone else must approve

(1 inline comment)

There is a minor style issue. Please improve that if you get a chance to refresh the patch.
|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned

A new patch with a change-ID in http://review.whamcloud.com/6181
|Uploaded patch set 2.
|Patch Set 2:

Add testlist=lfsck .
|Patch Set 2: (1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: I would prefer that you didn't submit this

(17 inline comments)


|Patch Set 2: No score

I will update this patch later.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

Rebase the patch.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Patch Set 1:

This patch can fix &quot;failed to recreate obj&quot; problem on b1_8 described in LU-3132. I uploaded my local lfsck test report to maloo https://maloo.whamcloud.com/test_sessions/83905004-af9f-11e2-901b-52540035b04c .
|Patch Set 1:

Andreas, I received some messages like &quot;Change could not be merged because of a missing dependency.&quot; Do I need to resubmit this patch?
|Uploaded patch set 2.
|Patch Set 2:

Andreas, could you please have a look at this patch and see if it can be merged this time? Thanks.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

The previous maloo test reports show that this patch can make atime update properly with 2.x servers, but its b18 test is being blocked by TT-1072 &quot;tests failed: lustre-initialization-1&quot;. So, just have a try to remove Test-Parameters to let b18 test go smoothly.
|Patch Set 1:

I think the failure of replay-single.sh test_70b was caused by LU-1897.
|Patch Set 1: Looks good to me, but someone else must approve

(4 inline comments)

Minor style issues that could be improved if patch is refreshed.
|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)

One minor style issue.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve

We need another patch to make is_empty_fs() run correctly.
|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned
|Uploaded patch set 2.
|Patch Set 2:

Update Test-Parameters to do interop test.
|Uploaded patch set 3.
|Patch Set 3: (1 inline comment)


|Patch Set 3: (2 inline comments)

Will add server distro and arch in test parameters.
|Uploaded patch set 4.
|Patch Set 4:

Since the patch http://review.whamcloud.com/#change,5981 has not been landed, Maloo test failed due to remove_ost_objests() not found on server side.
|Patch Set 4:

I will update the patch to remove server*** from test-parameters because of the old buildno and the reason mentioned in my last comment.
|Uploaded patch set 5.
|Patch Set 5:

lfsck failed due to LU-3132, which I am working on too. This patch is to correct is_empty_fs() check and fix the way to remove objects.
|Patch Set 5: (1 inline comment)


|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Since LU-3132 was fixed, this patch should pass lfsck test if the latest e2fsprogs-1.42.7.wc1 has been installed on Toro. 

If no, I will upload my local test to Maloo later.
|Patch Set 7:

Johann, this is a backport of some master patches to fix lfsck test problems. Could you please have a look and land it because I'm afraid it will block interop test just like LU-3367. Thanks!
|Patch Set 1: Abandoned

dup of http://review.whamcloud.com/6796
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Yes, just because we specified tcp network type in the old test script, we are always hitting this failure on o2ib network.
|Patch Set 1: I would prefer that you didn't submit this

Most of the patch looks good to me but I find there is a place which doesn't use IS_ERR() to check the return entry. That is
int lprocfs_exp_setup()
{
        new_stat-&gt;nid_proc = lprocfs_register(buffer,
                                              obd-&gt;obd_proc_exports_entry,
                                              NULL, NULL);
        OBD_FREE(buffer, LNET_NIDSTR_SIZE);

        if (new_stat-&gt;nid_proc == NULL) {
                CERROR(&quot;Error making export directory for nid %s\n&quot;,
                       libcfs_nid2str(*nid));
                GOTO(destroy_new_ns, rc = -ENOMEM);
        }
}

Could you please have a double check for other return values? Thanks.
|Patch Set 4: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: (4 inline comments)

Thanks for rread's comments. 

Since wangdi made test_mkdir(), I also ask him to do a code review to see if he has any advice.
|Patch Set 1: (1 inline comment)


|Patch Set 1: (1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Update the patch to fix a typo introduced by http://review.whamcloud.com/4359
|Patch Set 6: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 9:

Artem, could you please rebase the patch? Thanks.
|Patch Set 10: I would prefer that you didn't submit this

Artem, your patch is always hitting several test failures. Please have a check and resubmit it. Thanks.
|Patch Set 12: I would prefer that you didn't submit this

conf-sanity.sh test_75 introduced by this patch can't pass maloo test https://maloo.whamcloud.com/test_sets/d2c56412-e914-11e2-a1b7-52540035b04c . Please have a check and resubmit the patch.
|Patch Set 15: Looks good to me, but someone else must approve


|Patch Set 18: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

The similar patches for b21 and b18 are ready, so push the ones for master/b24, so that interop test can go smoothly.

BTW, due to LU-3180, lfsck.sh still can't pass this test.
|Patch Set 1:

Yes, this patch will be cherry-picked to these branches.
|Uploaded patch set 2.
|Patch Set 2:

Part of the patch set#1 which comes from http://review.whamcloud.com/#/c/6206 has been landed. Rebase and refresh.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1:

Can we abandon this patch since we have http://review.whamcloud.com/#/c/7327/ instead?
|Patch Set 1: (3 inline comments)

I will update the patch later.
|Uploaded patch set 2.
|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1:

Yes, I think so. This replay-single.sh test_74b failure is related to LU-2297.
|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 5: Looks good to me, but someone else must approve


|Patch Set 18: Looks good to me, but someone else must approve

(5 inline comments)

There are some minor style problems. Please correct them if you have a chance to refresh the patch.
|Patch Set 19: Looks good to me, but someone else must approve


|Patch Set 1:

Linda, could you please help me review this doc patch? It hit build error. Probably something wrong with xml format. I am not familiar with xml.
Thanks!
|Patch Set 1: (6 inline comments)

Thanks for Richard's review! I will resubmit it later.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: I would prefer that you didn't submit this

(1 inline comment)

dm device should be considered per Niu's comment. I will update the patch.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: (1 inline comment)


|Patch Set 7:

I find this patch causes lustre-initialization-1 failure on zfs and dne-zfs test because it deleted 
/*  The device or pool/filesystem name */
strscpy(mop-&gt;mo_device, argv[optind], sizeof(mop-&gt;mo_device));
from mkfs_lustre.c, which is a pool/filesystem name for zfs.

Since mo_device in mkfs_lustre.c is used by tunefs, mkfs(ldiskfs and zfs) in the different situations for the different meanings, a simple check at the beginning is not enough. I will add this fix to the patch for LU-3991.

BTW, just as Andreas mentioned, &quot;there will be even more cases in the future where these checks do not work (e.g. ZFS pools, or ZFS on loop, or btrfs pools, or whatever). However, I don't have a better solution to offer right now.&quot; Neither do I. Let's make a better fix when we have a better idea.
|Patch Set 2: Looks good to me, but someone else must approve

(1 inline comment)


|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3: Abandoned

Will resubmit a patch to merge this one into lu-3682.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 4: (1 inline comment)


|Patch Set 8: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 7: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

Do we need add Test-Parameters: testlist=lfsck ?
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2:

The test is blocked by LU-3973 and LU-3764. Test it again.
|Patch Set 2: (3 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 2.
|Patch Set 2: Abandoned
|Patch Set 2: (1 inline comment)


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: (3 inline comments)

I agree to use fops only and remove read/write_proc_t, then this patch would be very large and hard to be split into some small ones. Probably client side patch and server side instead?
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: (2 inline comments)


|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6: I would prefer that you didn't submit this

osd-zfs has no such proc parameters writethough_cache_enable, readcache_max_filesize, read_cache_enable and brw_stats, so we should check and skip these unknown params setting for ZFS.
|Uploaded patch set 7.
|Patch Set 7: Verified


|Patch Set 7:

Could you please review this patch? It's a 2.6 blocker. Thanks.
|Uploaded patch set 2.
|Patch Set 2:

I should say thank you! You comments helped me much.
|Patch Set 2:

Thanks, john. I will have a look.
|Patch Set 2:

If this &quot;import&quot; is not urgent, I'd like to refresh it after the patch of LU-3319 is landed.
|Patch Set 2:

OK, I will contact with PengTao about this port work.
|Patch Set 2:

I have already prepared for a patch based on LU-3319. Now, all the modules related to lprocfs_rd_import() have been changed to seq_file, except osp. I'm not sure if lprocfs_rd_import() will be removed and replaced with lprocfs_import_seq_show() finally. If yes, I will delete all the code related to the old lproc function from my patch.
|Uploaded patch set 3.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

This is a client side patch, which is a direct port of  Linus' commit 73bb1da692d0dc3e93b9c9e29084d6a5dcbc37a6. It has no &quot;HAVE_ONLY_PROCFS_SEQ&quot;  defined in http://review.whamcloud.com/#/c/7135 .

Now it's just a fortestonly patch because I'm not sure if it can't pass Hudson build and can be landed without server side patch. It works well on my local VM(rhel6), and I want to know if it works as well on 3.10 kernel.
|Patch Set 3:

Bob, this patch is to adapt lustre client code to 3.10 upstream kernel proc_dir_entry change. As I said in my previous comment, it is a direct port of Linus'(PengTao's) commit 73bb1da692d0dc3e93b9c9e29084d6a5dcbc37a6. It has no &quot;HAVE_ONLY_PROCFS_SEQ&quot;.

Could you please do me a help to test it on your 3.10 kernel and see if it works? Thanks.
|Patch Set 3:

Bob, this patch is intended to be instead of those, but now it is client only. Since proc_subdir_lock is not exported in all kernels, we have to keep lproc_lock and lprocfs_srch() in server side.
|Patch Set 3:

Thanks! Let me rebase and update it.
|Abandoned

Similar patches have been landed by James Simmons.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Uploaded patch set 5.
|Patch Set 5:

Niu, could you please review this fortestonly patch for LU-4154?
This debug patch fixes the issue in http://review.whamcloud.com/#/c/8206, and it can pass my local DNE testing, but it always fails in maloo test, which can't report &quot;DNE mode isn't supported!&quot;. The e2fsck version 1.42.7.wc1 (12-Apr-2013) used by maloo is same to my VM. I don't know why.
|Patch Set 5:

Niu, thanks!
|Patch Set 5:

In my local testing, I used 2 nodes for the servers and client separately. It did work.
|Abandoned
|Patch Set 7: I would prefer that you didn't submit this

(2 inline comments)

There are some style problems, such as useless blank lines in code and test scripts. Please fix them. Thanks!
|Uploaded patch set 13.
|Uploaded patch set 14.
|Patch Set 14:

Rebase the patch and fix the conflicts.
|Patch Set 14:

The maloo test is blocked by LU-3791 and LU-3866.
|Patch Set 14:

I will do that.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 17: I would prefer that you didn't submit this

sanityn.sh test_75 added by this patch failed. I will have a check.
|Patch Set 17: (1 inline comment)


|Uploaded patch set 18.
|Patch Set 18: (1 inline comment)


|Patch Set 18: (1 inline comment)


|Patch Set 18: (1 inline comment)


|Uploaded patch set 19.
|Patch Set 19:

sanityn.sh test_75 passed, but test_41c, which is not related to this patch, failed. Test again.
|Patch Set 19:

The test failed in DNE mode, because the new directory fid is still kept in the open file list. 

I had a talk with wangdi about this problem and he is not sure if this is a DNE bug. He'd like to figure out the reason before we commit the patch.

I add him to the reviewer list.
|Uploaded patch set 20.
|Patch Set 20:

Yes, I got the same result to Swapnil by calling mdt_mfd_closed() in lprocfs_mdt_print_open_files().
|Uploaded patch set 21.
|Patch Set 4: Code-Review+1

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Abandoned
|Patch Set 2: I would prefer that you didn't submit this

(2 inline comments)

Should remove the part of seq_file support introduced by LU-3319, which was not landed to b2_5.
|Uploaded patch set 3.
|Patch Set 3: Code-Review-1

Seems this patch introduces a regression in sanity.sh test_133f. Let me have a check.
|Patch Set 3:

Sorry, due to something wrong with my git,  the b2_5 branch this patch based on was not pulled correctly. I will upload a new patch here.
|Uploaded patch set 4.
|Patch Set 7: Code-Review+1
|Patch Set 7:

For my side, I don't think we need anything else.
|Uploaded patch set 2.
|Patch Set 2:

Seems the current DNE test on maloo runs on ZFS by default. I need to refresh the patch to set xxxfilesystemtype=ldiskfs in Test-Parameters. Otherwise, we always see &quot;SKIP: lfsck  Only applicable to ldiskfs-based MDTs&quot;.
|Uploaded patch set 3.
|Patch Set 3:

The log showed that &quot;01:09:41:wtm-21vm3: error: get_param: /proc/{fs,sys}/{lnet,lustre}/osd-*/lustre-M*/mntdev: Found no match&quot;. I don't know why it didn't find mntdev on mds1.

Let me retest it.
|Uploaded patch set 4.
|Patch Set 4: Verified+1

The root cause of &quot;error: get_param: /proc/{fs,sys}/{lnet,lustre}/osd-*/lustre-M*/mntdev: Found no match&quot; is that we have already stopped all devices before we do generate_db(), so we should get master MDS parameters earlier. 

BTW, since e2fsck version in Rosso is older than Toro's, which has no DNE patch http://review.whamcloud.com/7532, this patch probably could not pass Maloo test the first time, so I verify it in https://maloo.whamcloud.com/test_sessions/01725a02-6f31-11e3-ad93-52540035b04c for reference.
|Patch Set 4:

Mike stok said e2fsprogs had been updated on Rosso in TEI-1335. I will trigger the build to verify it.
|Patch Set 4:

The updated e2fsprogs on Rosso does work. The patch passed lfsck test.
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 3: Commit message was updated
|Patch Set 4: Commit message was updated
|Patch Set 4:

This patch is only to correct the usage of wait_mds_ost_sync() to avoid the confusing error message&quot;test-framework.sh: line xxxx: [: mds1: integer expression expected&quot;.

However, even with this patch, repay-vbr.sh test_7g still fails due to some other reason. I will push another patch to fix that once I figure out the root cause.
|Uploaded patch set 5.
|Patch Set 5:

Refresh the patch to fix code style.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Abandoned

Another patch http://review.whamcloud.com/#/c/8973/ is better than this one.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 4: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 3.
|Patch Set 3:

I didn't replace OBD_ALLOC_SLAB_PTR_GFP(GFP_NOFS) with OBD_ALLOC_SLAB_PTR() in this update, since we are not sure if it is suitable for upstream per Andreas' comment.
|Patch Set 7: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: (1 inline comment)


|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 2: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

I think I can use &quot;lo*.*mdtlov*.qos_threshold_rr&quot; or &quot;*.*mdtlov*.qos_threshold_rr&quot; to resolve this problem, just like test_116a does.
|Uploaded patch set 2.
|Patch Set 2:

Yujian, backport to b2_5 is in http://review.whamcloud.com/9636
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Maloo reports showed that 2561.test always failed on ZFS, but it did pass in my local zfs testing environment. I will have a check.
|Uploaded patch set 3.
|Patch Set 1:

retest
|Patch Set 1: I would prefer that you didn't submit this

The version should be older than 2.5.52 now.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Maloo said &quot;Undefined variable serverjob used&quot;. Remove &quot;envdefinitions=ONLY=32&quot; from Test-Parameters and try again.
|Patch Set 4:

Just know that Chris changed some test parameters but the changes haven't been reflected to the wiki page yet. Seems the parameter serverjob is split into ossjob and mdsjob. Let me try with the new parameters again.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Yujian, I ever asked fanyong about this error. He said it was not related to this test script patch, it was some error during OI scrub startup. 

Fanyong, so we need another patch to fix that problem?
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Abandoned
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Thanks, Andreas! Now I know my patch set#1 is not proper. 

I just want to make sure that the misleading error message you saw in many test logs mentioned in LU-3410 is &quot;LustreError: 13a-8: Failed to get MGS log params and no local copy.&quot;. I notice that is printed every mount on master branch. 

If we are not on the same page, please correct me. Thanks.
|Patch Set 1: Code-Review-1
|Abandoned

This issue will be fixed by LU-4783 http://review.whamcloud.com/#/c/9737/
|Patch Set 2: Code-Review-1

The patch caused sanity.sh test_154d regression. Please modify the related  test script as well.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified+1

I have checked that this patch failed twice in conf-sanity due to LU-4769 and LU-4349. Let me rebase to include that fix.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Verified-1

This patch has an issue in lustre initialization. I am working on it and will update the patch later.
|Patch Set 1: Code-Review-1
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 1.
|Patch Set 1: Verified+1
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review-1

(1 comment)

The code looks good to me but please update the commit message to including the situations of write_max==1 and append_max==1.
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

Yes, I only replace those improper usages. I didn't change other obd_name because we already have that obd device, and obd-&gt;obd_name is easy and clear  enough to use and understand.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 1: Code-Review+1
|Patch Set 1:

Bob, do you mind I update this patch per Andrea's comment? Thanks.
|Uploaded patch set 2.
|Patch Set 2:

James, thanks for your mention. I will make an update.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Add &quot;Test-Parameters&quot; to commit message.
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Pure rebase.
|Uploaded patch set 3.
|Patch Set 3:

John, you are right. Thank you!
|Patch Set 3:

Looks this patch caused sanity_scrub.sh test_12 to fail. I will have a check.
|Patch Set 3:

(13 comments)

I will update the patch soon.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Change LIST_HEAD(foo) back to &quot;struct list_head foo = LIST_HEAD_INIT(foo)&quot;, and will add this warning in checkpatch.pl in LU-5160.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Commit message was updated
|Patch Set 4:

Rebase and update the version check code.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 2: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review-1

This patch introduced a regression to conf-sanity.sh test_30b and recovery-small.sh test_19a/b. I'm working on the fix in http://review.whamcloud.com/#/c/9264/ .
|Patch Set 1: I would prefer that you didn't submit this

(16 inline comments)

Thanks for your patch to consider rpc rate.
There are some style problems and other issues in the patch. Please fix them and resubmit it.
|Patch Set 1:

Liangzhen, could you please review this patch? I think you should know better if we have such a similar counter in lustre. Thanks.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)

Sounds wait_for_completion_interruptible() is more suitable than *_killable to terminate the user process. Andreas, do you think it's better?
|Uploaded patch set 4.
|Patch Set 4:

Sorry, I didn't see Andreas comment before I updated the patch. So, killable is better than interruptible now?
|Patch Set 4:

OK, I will rollback to &quot;killable&quot;.
|Uploaded patch set 5.
|Patch Set 2: Code-Review+1

Thanks for this fix.
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Abandoned

Wrong change-id.
|Patch Set 5: Code-Review+1
|Patch Set 6: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 13: Code-Review+1

(2 comments)

Please correct the two error messages if there is a chance to refresh the patch.
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Uploaded patch set 3.
|Patch Set 3:

Pure rebase to include the new patches to make the tests pass.
|Patch Set 3: Verified+1

The failure of conf-sanity.sh test_32a was caused by LU-5472, not related to this patch.
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Abandoned

This fix is merged into http://review.whamcloud.com/14925.
|Patch Set 1: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 3:

Re-trigger the test.
|Patch Set 3:

Please rebase the code to include some new patches. Thanks.
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 2: -Code-Review

(1 comment)
|Patch Set 2:

Wang, could you please rebase your code to include some new patches? Thanks.
|Patch Set 3: Code-Review+1
|Abandoned

Abandon this patch since http://review.whamcloud.com/#/c/11467/ has resolved this issue.
|Patch Set 8: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 7: Code-Review+1

(7 comments)

If there is a chance to update the patch, please fix these minor style issues.
|Patch Set 15: Code-Review+1
|Patch Set 16: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

Rebase the code to include the patch of LU-7586. Could you please review again? Thanks.
|Patch Set 8: Code-Review+1

The code looks good to me, but the style still needs to be improved. If there is a chance to refresh the patch, please fix the style issues.
|Patch Set 8: Code-Review+1
|Patch Set 8: -Code-Review

OK, I will update the patch to include the new fix to sanity.sh test_401.
|Uploaded patch set 9.
|Patch Set 11:

(1 comment)
|Patch Set 11:

(1 comment)
|Patch Set 11:

I will do it today.
|Patch Set 11:

Sorry, my macbook crashed suddenly this morning, so I'm afraid I can't update the patch until I get a temporary notebook.
|Patch Set 14:

Retest due to TEI-0000. Done.
|Patch Set 15: Code-Review+1
|Patch Set 15:

Retest due to LU-6684.
|Patch Set 1: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

Retest it due to TEI-4334.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4:

Reviewers, could you please review this patch? I just rebased and retested it for many times to make it pass Maloo tests.
|Patch Set 4:

Niu, since this is a user-space patch, do you think using strtod() directly in patch set 2 is easier than the curren one?
|Uploaded patch set 5.
|Patch Set 1: Code-Review+1
|Patch Set 3: Commit message was updated
|Patch Set 3: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 2:

I don't mind removing &quot;-w&quot; option for the new distro, but I have to say LU-4441 issue has gone away since this option was added, so is there any similar option in the new distro or could we add version check for the old distro to avoid that issue again?
|Patch Set 2: Code-Review+1
|Patch Set 11: Code-Review+1
|Patch Set 5: Verified-1 Code-Review-1

(1 comment)

There is a same issue to LU-7437. We shouldn't call lprocfs_param_pattern() inside {list/get}param_display(), otherwise it will add the prefix &quot;/proc/{fs,sys}/{lnet,lustre}&quot; each time so that the parameters can be listed recursively.
|Patch Set 7: Code-Review-1

(1 comment)
|Patch Set 7:

OK, I will do it later.
|Uploaded patch set 8.
|Patch Set 8:

Retest due to LU-7136.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)

OK, I will add a test case later.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 1:

Retest the patch due to LU-7329.
|Patch Set 1:

Retest the patch due to LU-5361.
|Patch Set 1:

Retest the patch due to LU-7411.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

Rebase the code to include the patch of LU-7221.
|Patch Set 2: Code-Review+1
|Patch Set 1: I would prefer that you didn't submit this

Sorry, I did a wrong backport in remove_ost_objects(). I will fix that and refresh the patch later.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Retest due to TEI-4005.
|Patch Set 1:

Retest due to LU-7036.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

Patch set 2 is just a pure rebase. Could you please review this patch again? Thanks.
|Patch Set 1:

Dongyang, could you please rebase your code to include the patch of LU-4499 to make maloo test pass? Thanks.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

I rebase the code instead.
|Patch Set 2:

Have resubmitted for testing due to LU-6638.
|Patch Set 3: Code-Review+1
|Patch Set 3:

Have resubmitted for testing due to LU-7084.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)

I know it's a little weird to use positive EINVAL on invalid record, because we do need three different kinds of return values on success, errors and invalid record.

If &quot;EINVAL&quot; can't pass, can we use &quot;1&quot; instead, something like the original code, proposed by http://review.whamcloud.com/#/c/10828/4 ?

Niu, could you please review this patch, any advice?
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

Actually we had been using 0 on success and non-0 on error since http://review.whamcloud.com/#/c/4095/3/lustre/osp/osp_sync.c, three years ago, until the patch http://review.whamcloud.com/#/c/10828/4/lustre/osp/osp_sync.c.

So now I just change it back.
|Patch Set 5:

Could you please review this patch? Thanks.
|Patch Set 5:

(5 comments)
|Uploaded patch set 6.
|Patch Set 6:

Retest due to LU-4499.
|Patch Set 6:

Could anyone review this patch? Thanks.
|Patch Set 8: Code-Review+1
|Patch Set 8: Code-Review-1

(1 comment)
|Uploaded patch set 9.
|Patch Set 9: Code-Review-1

(1 comment)
|Uploaded patch set 10.
|Patch Set 10:

I update the patch because there is a defect in sanity.sh test_60a. The test_log showed:
CMD: shadow-40vm3 grep 9_sub /tmp/f60a.sanity
shadow-40vm3: grep: /tmp/f60a.sanity: No such file or directory
CMD: shadow-40vm3 grep 9_sub /tmp/f60a.sanity
shadow-40vm3: grep: /tmp/f60a.sanity: No such file or directory
|Patch Set 10:

(1 comment)
|Uploaded patch set 11.
|Patch Set 11:

(1 comment)
|Patch Set 14: Code-Review+1
|Patch Set 15:

(2 comments)
|Patch Set 16: Code-Review-1

(1 comment)
|Patch Set 17: Code-Review+1
|Patch Set 3: Code-Review-1

(1 comment)

Please don't set ORR policy on MDS because there is no /proc/fs/lustre/ost directory (see LU-6688).  Other parts of this patch look good to me.
|Patch Set 4:

Henri, you have to rebase again since LU-6668 landed, sanityn.sh changed. Thanks.
|Patch Set 6:

(2 comments)

Please do some minor fixes if the patch is refreshed.
|Patch Set 6:

Henri, could you please rebase the code and update the patch per the comment as well? Thanks.
|Patch Set 7: Code-Review+1
|Patch Set 8: Code-Review+1
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Retest due to LU-4499.
|Patch Set 1:

Hit LU-4499 again. Retest.
|Patch Set 3: Code-Review+1
|Patch Set 7: Code-Review+1

Please correct those style issues if you get a chance to refresh the patch.

BTW, I'm wondering when we will support such tests by autotest.
|Uploaded patch set 2.
|Patch Set 1:

Do we need add anything to Test-Parameters to verify this interop test?
|Patch Set 2: Looks good to me, but someone else must approve

Niu, we need to retrigger this test. It has no any response since Sep 3.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4:

Retest, although there is no real issue in conf-sanity test.
|Patch Set 4:

I will rebase the code instead, since Andreas is on vacation.
|Uploaded patch set 5.
|Patch Set 5:

Have to rebase again to include LU-5638 patch.
|Uploaded patch set 6.
|Patch Set 6:

Retest due to TEI-3723.
|Patch Set 6:

This time it failed due to LU-6836.
|Uploaded patch set 7.
|Patch Set 7:

Rebase the code to include the patch of LU-6836.
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

conf-sanity.sh test_87 failed because every time only 6 or 7 out of 8 OSTs were used, so the expected left space is smaller the actual. Let me improve the test scripts.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 7:

Rebase the code to include the patch of LU-6802.
|Patch Set 1:

Seems something is wrong with autotest, no update since July 23. Do we need to retest this patch?  because this issue is blocking many Maloo tests.
|Uploaded patch set 1.
|Patch Set 1: Verified+1

These maloo testing failures were caused by LU-5638, LU-5245, LU-6430, LU-5872 and so on, not related to NRS ORR policy.

I can re-trigger this test, but seems it can't pass in a short time. Could you please review the patch first without respect of those failures? Thanks.
|Patch Set 1:

Retest due to LU-6802.
|Patch Set 1:

Could you please review this patch? Thanks.
|Patch Set 3: Code-Review-1

(3 comments)

Please correct the typos and skip this test for ZFS.
|Patch Set 4:

I just re-triggered the building.
|Patch Set 4:

Artem, could you please rebase your code ? Thanks.
|Patch Set 6:

Aterm, could you please rebase this patch again so that we can land it soon?
|Patch Set 6:

Thanks.
|Patch Set 7: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

Retest it due to LU-6839.
|Patch Set 3: Code-Review-1

(1 comment)
|Patch Set 4: Code-Review+1

Agree to create a separate patch to fix &quot;REFORMAT&quot; issue.
|Patch Set 5: Code-Review+1
|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 3: I would prefer that you didn't submit this

(1 inline comment)


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 8: Patch Set 7 was rebased
|Patch Set 11: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Abandoned

Abandon this patch since http://review.whamcloud.com/#/c/18703/ is ready to land to fix this issue.
|Patch Set 2: Code-Review-1

(2 comments)

We need to move &quot;strchr(value, '=')&quot; check before calling param_display(), otherwise, when running &quot;lctl set_param jobid_var=a=b&quot;, it won't give a warning.
|Patch Set 3: Code-Review+1

I agree to print this warning message for both two formats if there is an '=' in the value.
|Patch Set 3:

Could anyone review this patch? Thanks.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 2:

(1 comment)

I saw this patch failed to pass maloo testing due to LU-7903 and also I found a style issue in the commit message, so let me edit the message to retrigger the test at the same time.
|Patch Set 3: Commit message was updated
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1

Sorry, I forgot the interop issue. I will update the patch later.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

Rebased the code and fixed the conflicts.
|Patch Set 1: Code-Review-1

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3:

Retest due to LU-7117
|Patch Set 3:

Reviewers, could you please review this patch? It has passed Maloo testing.
|Patch Set 4: Code-Review+1
|Patch Set 8: Patch Set 7 was rebased
|Patch Set 8:

Rebase to get LU-8279 fix.
|Patch Set 11: Patch Set 10 was rebased
|Patch Set 11: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Patch Set 2:

Retest due to LU-7903.
|Patch Set 2: Code-Review+1
|Patch Set 2:

OK, done, retest due to LU-7791.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3: Code-Review+1

I rebased the code to make it pass maloo test.
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

Yujian &amp; Bobi, this is the same patch to http://review.whamcloud.com/#/c/15322/3, we need to land it to master first.
Please review it again, thanks!
|Patch Set 1:

Retest due to LU-7117.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

Rebased the code to include the patch of LU-6937.
|Patch Set 3:

Most of my patches are being blocked by LU-8139/8129/8135. I will rebase the code when those patches are landed.
|Patch Set 5:

Reviewers, the patch passed maloo testing, could you please review it? Thanks.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Rebased the code to include the patch of LU-6937.
|Patch Set 3: Verified+1

The maloo test is being blocked by LU-8135 and LU-8129. We will have to rebase again to have those patches when they are landed.

Or, Gatekeeper, can we land this patch directly? because it only makes doc changes, none of code business.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Rebased to get LU-8139 fix.
|Patch Set 3:

Reviewers, could you please review this patch again? Thanks.
|Patch Set 3:

(1 comment)

Henri, thanks for pointing this out. I will improve it if I get a chance to refresh the patch.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Patch Set 5:

Rebase to get LU-8279 fix.
|Uploaded patch set 6.
|Patch Set 6:

Updated the version check to 2.8.55.
|Patch Set 6:

Reviewers, could you please review this patch again? Thanks. Let's catch up this time.
|Patch Set 6: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 1: Code-Review+1

(2 comments)

Please fix the minor style issue if there is a chance to update the patch.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated
|Uploaded patch set 1.
|Patch Set 1:

Ping reviewers.
|Patch Set 1: Code-Review+1
|Patch Set 4:

(2 comments)

There are two issues in sanity.sh. I noticed them because the maloo testing results at https://testing.hpdd.intel.com/test_sets/5a6e6c66-8e89-11e6-a9b0-5254006e85c2 hit &quot;misses too much pages&quot; with this debug patch, and it showed
&quot;error: set_param: setting /proc/sys/lnet/debug=debug=: Invalid argument
error: set_param: param_path 'super': No such file or directory
error: set_param: param_path 'neterror': No such file or directory
error: set_param: param_path 'dlmtrace': No such file or directory
error: set_param: param_path 'emerg': No such file or directory
error: set_param: param_path 'rpctrace': No such file or directory
error: set_param: param_path 'config': No such file or directory&quot;
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review-1

I saw the following error in ldiskfs-based MDS console logs:
17:35:49:[  299.752074] Stack:
17:35:49:[  299.752074]  ffff880045b63ca0 ffffffffa07d3289 ffff880045b2bd00 ffff880079aff4d0
17:35:49:[  299.752074]  ffff880045b35840 ffff880045b63ce8 ffffffff811dc857 ffff880079aff4d0
17:35:49:[  299.752074]  ffffffffa07d3250 ffff880045b63f28 0000000000008000 ffff880045b63df0
17:35:49:[  299.752074] Call Trace:
17:35:49:[  299.752074]  [&lt;ffffffffa07d3289&gt;] obd_device_list_open+0x39/0x50 [obdclass]
17:35:49:[  299.752074]  [&lt;ffffffff811dc857&gt;] do_dentry_open+0x1a7/0x2e0
17:35:49:[  299.752074]  [&lt;ffffffffa07d3250&gt;] ? version_show+0x30/0x30 [obdclass]
17:35:49:[  299.752074]  [&lt;ffffffff811dca89&gt;] vfs_open+0x39/0x70
17:35:49:[  299.752074]  [&lt;ffffffff811ec07d&gt;] do_last+0x1ed/0x1270
17:35:49:[  299.752074]  [&lt;ffffffff812f9292&gt;] ? radix_tree_lookup_slot+0x22/0x50
17:35:49:[  299.752074]  [&lt;ffffffff811eede2&gt;] path_openat+0xc2/0x490
17:35:49:[  299.752074]  [&lt;ffffffff811f05ab&gt;] do_filp_open+0x4b/0xb0
17:35:49:[  299.752074]  [&lt;ffffffff811fd147&gt;] ? __alloc_fd+0xa7/0x130
17:35:49:[  299.752074]  [&lt;ffffffff811ddf53&gt;] do_sys_open+0xf3/0x1f0
17:35:49:[  299.752074]  [&lt;ffffffff811de06e&gt;] SyS_open+0x1e/0x20
17:35:49:[  299.752074]  [&lt;ffffffff81646d49&gt;] system_call_fastpath+0x16/0x1b


and the following error in zfs-based MDS logs:
16:56:30:[  254.183797] BUG: unable to handle kernel NULL pointer dereference at 0000000000000048
16:56:30:[  254.184081] IP: [&lt;ffffffff8124f06d&gt;] PDE_DATA+0xd/0x20
16:56:30:[  254.184081] PGD 7a14c067 PUD 4b086067 PMD 0 
16:56:30:[  254.184081] Oops: 0000 [#1] SMP
|Patch Set 1:

Seems #23428 fix this issue. Should we merge #23427 and #23428 into one patch?
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 1.
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 9: Commit message was updated
|Patch Set 9:

Wulibin, could you please rebase the patch? Thanks.
|Patch Set 9:

Wu Libin, could you please rebase the patch and update it per &quot;HPDD checkpatch&quot;'s comment? Thanks.
|Patch Set 9:

Shilong, could you please rebase the code so that we can land it ASAP? Thanks.
|Patch Set 10:

Shilong, could you please update the patch per HPDD Checkpatch's comment to fix some code style issues? (Seems the last round autotest hangs there, we can restart it by this way)
|Patch Set 12: Code-Review-1

(1 comment)

test_77e/f/g have already been included by Lixi's patch in LU-6668, landed. Please have a check if they are duplicate.
|Patch Set 13:

Retest due to LU-6844 and LU-4499.
|Patch Set 13: Code-Review+1

(1 comment)

Please correct the minor typo if you get a chance to update the patch.
|Patch Set 13:

Reviewers, could you please review this patch? Thanks.
|Patch Set 14: Code-Review-1

I mark this -1 because patch set 14 just rebased code, but didn't fix any issue mentioned in patch set 13. So, please have a update per the reviewers' comment. Thanks.
|Patch Set 16: Patch Set 15 was rebased
|Patch Set 16:

Rebased the code to include the patch of LU-6937.
|Patch Set 16:

(1 comment)

Qian, I post some comments to patch set 13 and patch set 16. Since this Maloo test is being blocked by LU-8139, we will have to rebase the code again when it is fixed. 

Could you please update the patch per our review comments during this time? Thanks.
|Patch Set 13:

(2 comments)
|Patch Set 24: Patch Set 23 was rebased
|Patch Set 24:

Rebase to get LU-8279 fix.
|Patch Set 25: Patch Set 24 was rebased
|Patch Set 27: Patch Set 26 was rebased
|Patch Set 27:

Rebased the code due to LU-4039.
|Patch Set 28:

The tests failed due to LU-8392 and LU-7782. Will rebase code after their patches are landed.
|Patch Set 29: Patch Set 28 was rebased
|Patch Set 30: Patch Set 29 was rebased
|Patch Set 30: Code-Review+1
|Patch Set 32: Code-Review+1
|Patch Set 33:

Retest due to LU-8062.
|Patch Set 33: Code-Review+1
|Patch Set 35: Code-Review+1
|Patch Set 36: Code-Review+1
|Patch Set 3:

Parinay, could you please update the patch to fix the code conflict? Thanks.
|Patch Set 3: Code-Review-1

(4 comments)

Besides the comments I posted on conf-sanity.sh test_88, I also found that test case always failed on ZFS, due to &quot;tunefs.lustre FATAL: Device lustre-mdt1/mdt1 has not been formatted with mkfs.lustre&quot;.

Please improve the patch per these comments, and fix code conflicts and style issue. Thanks.
|Patch Set 3:

Nikitas, thanks!
|Patch Set 3:

SEA-139 reported an issue related to this patch. I will update this patch with that fix, and then ask for review.
|Uploaded patch set 4.
|Patch Set 4: Code-Review-1

(1 comment)
|Patch Set 3:

(1 comment)

Why we don't erase each parameter that specified with &quot;--param&quot; option? Why we need to check the first one?
|Patch Set 4:

The patch can work on ZFS for me now. I will upload it here once I figure out if we need the check &quot;param_is_first()&quot; mentioned in my previous comment.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)

I prefer to running erase_param() each time when &quot;--param&quot; is used, no matter whether the parameter is specified in the command line at the first time or not. The reason is in the comment.
|Uploaded patch set 5.
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6:

Oops, forgot to change the author back to Nikitas.
BTW, Fanyong, could you please review this patch to see if zfs_prop_inherit() used to update property nvlist will cause a conflict with your snapshot? Thanks.
|Patch Set 6:

(13 comments)

Nikitas, here is a question for you. Why we need to set UPDATE flag after erase_param(). Could you explain it more? Thanks.
|Patch Set 6:

(4 comments)
|Uploaded patch set 7.
|Patch Set 7:

(6 comments)
|Uploaded patch set 8.
|Patch Set 8:

The maloo testing is being blocked by sanity.sh test_27D. I will rebase the code once the patch of LU-9123 is landed.
|Patch Set 9: Patch Set 8 was rebased
|Patch Set 9:

Reviewers, could you please review this patch? Thanks.
|Patch Set 9:

(4 comments)
|Uploaded patch set 10.
|Patch Set 4:

As we discussed yesterday, I will pick &quot;-e&quot; option out before parse other options because we have to erase all old parameters first to keep the right semantics.

I'm trying to find a way not to make the code ugly.
|Patch Set 10:

Oops, the previous comment is for patch set #10 not #4.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13:

My pleasure
|Uploaded patch set 14.
|Patch Set 14:

Updated the version code check. Please have a review.
|Uploaded patch set 15.
|Patch Set 14:

(1 comment)
|Uploaded patch set 16.
|Patch Set 16:

Rebased the code to fix the conflicts. Fanyong &amp; Bobi, could you please review this patch again? Thanks!
|Uploaded patch set 2.
|Patch Set 1: Code-Review-1

Lixi, we do cfs_hash_putref() in nrs_xxx_stop(), which will be called when policy fails to startup. Did you hit any memory leak?
|Patch Set 1:

You reminded me that besides TBF, other policies would have the same issue if 
nrs_policy_stop0 is called as long as  policy-&gt;pol_state == NRS_POL_STATE_STOPPING. If so, I suggest we should check the state setting in nrs_policy_start_locked().
|Patch Set 1:

Now I know NRS can't switch state from STARTING to STOPPING. So this patch is OK for TBF. However, could you please check other policies as well and make a thorough fix? Thanks.
|Patch Set 1:

Lixi,  do you mind I update this patch to include the fix for other policies? if you  have no time to do it.
|Patch Set 1:

Lixi, I saw nrs_crrn_start() and nrs_orr_start() have the same issue, right?
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Patch Set 4:

I have updated the patch per the comments. Could you please review the patch again? Thanks.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

Reviewers, could you please review this patch? Thanks.
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 6: Code-Review-1

(1 comment)

Please update sanityn.sh test_77h to support the new &quot;gerneric&quot; policy format.
|Patch Set 7: Code-Review-1

(2 comments)

The version check in sanityn.sh test_77j should be updated too.
|Patch Set 8:

Qian, could you please update the version check in test_77k again? Thanks.
|Patch Set 9: Code-Review+1
|Patch Set 13: Code-Review+1
|Patch Set 13: Code-Review-1

(1 comment)
|Uploaded patch set 14.
|Patch Set 14:

Updated the version check.
|Patch Set 14: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2:

Retest due to TEI-4215
|Patch Set 6: Commit message was updated
|Patch Set 6:

Added &quot;Test-Parameters: trivial testlist=sanity-hsm&quot; to the commit message to limit the testing cases.
|Patch Set 6: Code-Review+1
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 6: Patch Set 5 was rebased
|Patch Set 6: Code-Review+1

(12 comments)

Lixi, thanks for your patch again!

Please update the patch/commit message per the review comments based on the latest code, because some new changes have been landed since your last version.

BTW, if you'd like, you can split the patch into small ones, so that they can get a quick review to land.
|Patch Set 6: Code-Review-1

Sorry, wrong flag.
|Patch Set 7: Code-Review-1

(6 comments)

The patch looks good to me, except the part of conf-sanity.sh test_41c and 55.
|Patch Set 8: Code-Review-1

(3 comments)
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1

Should we merge this patch with #23427 together?
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

The maloo testing is being blocked by sanity.sh test_27D. I will rebase the code once the patch of LU-9123 is landed.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 1: Code-Review+1
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 2:

Rebase the code to include the patch of LU-9059 to fix conf-sanity.sh test_47 failure.
|Patch Set 2:

The maloo testing is being blocked by sanity.sh test_27D. I will rebase the code once the patch of LU-9123 is landed.
|Patch Set 1: Code-Review+1

(1 comment)
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 1: Code-Review+1 Verified+1
|Patch Set 2: Verified+1
|Patch Set 2:

Andreas, yes, I have a test case for this patch.
|Patch Set 4: Code-Review+1
|Patch Set 6:

I just found when the flag is not init or ^init, it will cause dead loop. Not sure if this is a bug of this patch.
|Patch Set 6:

Could you please add some description about +(&gt;) and -(&lt;) for --component-start/end to lfs.1 man page? in case the users are confused about their usage. Thanks.
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1: Code-Review-1

The wait_update condition is not right.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+1 Verified+1
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Patch Set 8: Code-Review+1

(1 comment)

As Bobi said, please use test_mkdir if you get a chance to refresh the patch.
|Patch Set 9: Code-Review+1

(6 comments)
|Patch Set 11: Code-Review+1
|Patch Set 1:

(2 comments)
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(10 comments)

Andreas, as I discussed with Eric, I need to convert the doc to xml format to be part of our lustre manual by the end of this week. So now I am working those style issues first. Then I will improve the content per your previous comments in email and here, and will finish the whole work by the end of May.
|Patch Set 2:

(17 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)

I can't compile lustre manual locally successfully, so have to push it here to verify if the format looks good. You can ignore this patch set #4, anyway, if you'd like, your any comments will be appreciated.
|Patch Set 4:

Joe, many thanks! That wiki page looks very helpful for me. I will try that.
|Patch Set 4:

My fop issue was fixed. I can compile the manual locally successfully now.
|Patch Set 2:

(8 comments)

Most of the doc was improved per review comments, except LU-9462 and LU-9463.
|Patch Set 2:

(3 comments)
|Patch Set 4:

(1 comment)
|Patch Set 2:

(2 comments)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

I improved the doc per the comments and rebased it on the change of https://review.whamcloud.com/#/c/27055.
Please have a review. Thanks.
|Patch Set 7:

Reviewers, could you please review this patch? Thanks.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(1 comment)
|Uploaded patch set 4.
|Patch Set 4:

(8 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(9 comments)
|Uploaded patch set 5.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Patch Set 2 was rebased
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 4: Code-Review-1

(11 comments)

There are some command line style issues. Please fix them.
|I am unsure how to resolve this line.
|In reply to earlier comment in patch 57, why should we use MAX_NAME_LEN as an argument to strndup ? Link-&gt;contents will contain a path which can be longer than MAX_NAME_LEN right? for example d/e/f/..and so on? Earlier we were using a length parameter which according to ext3 is 4096 bytes i suppose. Should i use that instead?
|Regarding earlier comment on why this change- network class argument is set here in NA_initialize and passed onto mcl_lookup in main function. i am already returning hg_class_t argument which is also required in main function to pass to client_init for registration. So i made this a double pointer. 

There can be some restructuring possible here though.
|I have hard coded arguments into client main for now. The reason is because obviously for now we only need to attach to one server. But also because fuse_main parses the command line and ends up parsing the entire command line including options that are irrelevant such as the ones we give fir process set and then starts complaining. this is minor change, and arguments need to be manually set into fuse main. Will tweak this in later patches.
|It might be difficult to expose Fuse struct through private data pointer. Private data pointer is available after init() function is called. Thats how fuse typically expects it. And in a single mount implementation- fuse struct gets created first and additional context can be specified in init which gets called after. For our case- we won't be able to get fuse struct in init, because it gets created first and i haven't found a fuse api that directly exposes struct fuse which i could call inside init. Nor does fuse secretly pass struct fuse to callbacks. (it does secretly passes a few things but those are encapsulated inside struct fuse and hence reverse retrieval not possible). I will think more if i am missing something.
|sorry, I did not look at source code carefully. Fuse struct can be obtained easily as it is one of the fields of fuse context. scratch this.
|Yes because the same server is being mounted on multiple directories currently kind of like bindFS. But yes this needs to be changed to mount multiple instances of server.
|This struct was always there so that we can send these arguments to Fuse callbacks. Dest_addr is needed so that callbacks can send RPC to correct servers and Id's are needed so that callbacks can create their own handles.
|Contents of this thread are initialized in the main function. rpc_id's at least as of today- only created once.
|I will still need to pack both of these in a struct, because fuse will only accept one argument. I will pack these in t_args then, and remove it from here.
|Done
|Done
|Done
|Done
|Looking at fuse API, they are declared void. They don't seem to be returning anything.
|in Fuse_unmount lib fuse decides to fork and hence first rank ( rank 0 in this case) gets correctly unmounted but forking hangs orterun.
|Why can't I call Atoi here?
|I am not clear on this but this means that if kernel mounted is not built with user_xattr option, then commands will fail.
|Actually let me verify this. if it can work without this flag.
|This is a requirement.
|Will try.
|This file doesn't need to go in product, just to describe usage. Because setting xattrs is different for OS X, and linux. Additionally I just wanted to highlight &quot;user.&quot; name space restriction. This was supposed to be an investigative effort anyway.
We can remove this file if you want. I just added this for simplicity for running on OSX. Your call.
|When line 70-75 executes, system calls would get interrupted. That WILL unmount the filesystem before the process gets killed. This is the behavior we were trying to achieve through signal handling if you remember. This change here- first checks if the directory is still mounted, by grepping mount. Only if its still mounted, does it go on to execute fuser mount. Otherwise it doesn't need to.
|the first entry earlier was the MCL's own context. In this case it is the last entry because i found it easier to use sys/queue interface that ways. It doesnt make much difference except in one place which is a security loophole. Basically any application using MCL can also delete MCL's own context. there is no guard against that. I ll add a check agains that.
|The thing is, this function calls join above. It can call join at line 327 as well. IF we are joining, means we want to wait for the progress/trigger threads to be done. Which also means, they might need the lock to make progress or trigger multiple contexts. So even though this function is called from one thread- there can still be multiple threads when this function is called. So releasing lock is necessary to avoid deadlock
|I am not sure, but ret was defined here earlier and is also what the function seems to be returning in line 1230.  so i decided to set ret. Should i just remove ret?
|Done
|Done
|Done
|Done
|Done
|Done
|I have now removed this- and directly used the sys/queue.h API.
|Done
|Done
|Done
|Done
|Done
|Done
|This is from the existing ping code. This changeset only ports the progress model to use in ping- so far I havent modified any existing ping functionality.
|I am not sure. Certainly no harm doing it, but dont see much benefit.
|Actually I was not going to store the configuration in a global variable. This function can simply be called whenever needed. And value returned to a local variable in whichever function that intends to use it.
|What do you mean by progress mode?
|This was supposed to be internal to implementation. i will remove it from here
|For the most part yes, but I have kept it in case during implementation i need to add more things here.
|thats what it will do yes, i ll make it descriptive.
|Thats what the man page I am seeing says, which man page are you referring to?
|Will fix
|Mcl_state is initialized by mcl init which returns a pointer to that struct. Mcl_state is malloced in mcl_init. We need to modify the contents of pointer to mcl_state, in this function, depending on configuration.
|No, master component does not have its own context, Because it doesn't need to create its own. Master component only need to access the head of the linked list. Which is why it will make progress on mcl_state and not on mcl_context.
|No I mean hg_context here. Sorry this needs to be a pointer. Mcl_state will not carry mcl_context variable. This is the linked list, which will be created for hg_context
|There are here- because- MCL_state only gets initialized once. I want to initialize these variables only once as well. Secondly- these variables carry state of the configuration which is in effect- global. MCL_context inherits mcl_state.
|*CNSS
|Based on these changes, is there a major reason why context is added here?
|Its actually called on both the times- during packing and unpacking the args.
|I can put this outside the loop.
|As far as I understand, respond wont invoke callbacks because none has been given to it. That entry in the function is NULL. Respond doesnt create any threads. When respond returns, it will be done with the list. Packing function does a calloc and a copy and its executed before respond returns
|My logic is - if the respond fails then that means RPC isnt sent successfully, and this function doesnt attempt to respond again. So after logging that, we dont need the list anymore
|If we register all RPC's outside of where we create the handle, then we will need to send those rpc_id's in the function paramaters, and store them in main. Is there a strong reason to keep registration only at one place? Its better to use it in conjuntion with creating the handle. we wont get a lot by saving on number of times this register gets called.
|These comments dont look like they need to be here- if they are unimportant- then can you remove these?
|Well I think we can do away with the loop. Because engine progress either succeeds in one go- or it returns with HG_TIMEOUT or HG_FAILURE, either of which will result in  fuse_session_exit being called. So while loop technically doesnt add anything. Because we are not overrriding the timeout or calling engine progress the second time. Do you want to do that?
|Yep. Thats a good catch.
|You mean IOF?
|When I tested this cnageset on linux and OSX, I had to create these directories. I think if the user needs to create these directories, then that needs to be in the commit message, otherwise this suite wont run. is that the intention however? Shouldnt the test suite create those directories?
|On my machine this created a huge timestamp, meaning the directory names were huge. again if the team finds that okay, I am okay with that, but I would prefer the date stamp to be shortened somehow. Not a necessity though
|I would really prefer this to be single case, but I can go with this if the team agrees with this.
|Whats the meaning of &quot;Simple&quot; mkdir in this case?
|&quot;Deletion is unsuccessful&quot; is more appropriate? :)
|That error typically comes when you mount on an non-empty directory. But this is teardown routine- so here no mounting can take place. The problem is- perhaps what you want to do is to clean up testDir/child_fs/Rank0

But this is trying to clean testDir/child_fs. Which will attempt to clean the rank0, rank1 etc which are mountpoints. You want to clean one level below. However that also is not necessary.
|I didnt get this part. Is this trying to delete mounted directories before attempting to unmount them? Why? This should be just done in line 267. any particular reason? We can avoid printing unnecessary error messages that dont aid in debugging/testing.
|Similar to above, we can add a check here to see if the directory is even mounted or not.  cost of doing an unmount on non existent mount point isnt high, but its just an unnecssary error message we can avoid which would make understanding the output easier. test_iof_clean currently does that, Unless we plan to keep test_iof_clean in use.
|will it help? Everywhere else in the code, we generally test for the failure case- so reversing this will make it different from everywhere else and might hurt readability. Is there any specific use case you have in mind?
|shared
|Not sure if it would work- but would you find it useful to use this to point to mcl_core_state_g instead of using a global in mcl_core.h? Looks like this might be used to pass args to callback.
|I would rather keep this, because I use it as well. At the least till the time python script starts outputting to the screen. Its more convenient for debugging.
|This needs to be reverse, but it would not make a whole lot of difference
|Its not, but thats the only correct way i could find to use mcl_progress as its written today. I ll take the idea from your other comment and write a wrapper around mcl_progress, to catch server dying and exit fuse.
|I think we are not supposed to use asserts? I should add some sort of exit statement here though.
|this log message doesnt specifically describe whats happening above it. Maybe something more descriptive of what this op_code is doing?
|mcl_cmd does return an error code, that can possibly be used here
|This is the reason why this changeset is failing. It seems to be failing in the singleton test, because singleton process exits here and doesnt do the remaining state initialization that is in line 571. As a result, its not able to get any of the values initialized below.
|We can move all the initializations and the registrations above the singleton exit. None of these initializations are dependent on any PMIX steps that happen above. (are they?)
|Done
|If the handler is not able to retrieve the input then this return code will indicate that the ping is unsuccessful. So i am passing this back as a reply.
|Done
|its not exactly the same. We pass the rank of the process participating in self test. But we pass the Hg_addr here so that we dont have to do lookups again and again. 

Size thats passed over the wire is the minimum and the maximum, but the size passed here is the size that this particular ping is going to be sent with. If min_size is 2, and max_size is 64, then this function is called log2(64) times with different sizes like 2, 4, 8, 16, 32 and so on.

So arguments still need to be processed.
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I ll think of a meaningful new name.
|Done
|Done
|This header file is not internal, because there are some functions such as registration functions, proc functions and packing functions that need to be availlable to self test binary as well as MCL. This the reason this is public. I dont think I can get away with exporting nothing. MCL will not be able to link with self test binary, if i am not wrong.
|i dont understand?
|i dont plan to run this on jenkins, just wanted to make sure that its not showing any memory leaks. Since GA run takes a lot of time. I ll remove this
|Done
|Done
|Done
|Done
|can you increase this/
|If script is setting looping to no, then is this even necessary? Either make it optional command line option or remove it altogether.
|is this change necessary? will the test work without this change? We probably should avoid making source code changes for running test code.
|Agreed, This needs to be CNSS wide and not plugin specific. Will change these names
|Done
|i can add a version call back that can set an environment variable to use fuse 2 or 3. Although i think we should be using fuse3 and not 2. IO forwarding might even not support fuse 2 in future. (an optimization we want to do in readdir is only usable in fuse 3)
|will that offer any significant advantage? if its a project wide syntax we are follwing then i can change this. Is that how you guys are doing in CPPR?
|Done
|Should we flush after detach? Then atleast RPC's get blocked
|Should i just call wait everywhere I call launch_test? Martin, which test scripts are you talking about?
|Done
|Done
|Done
|Done
|if i make this IOF_TEMPDIR, then it will become difficult to distinguish from other variables. This is an environment variable. I think we can keep this same. Or else I am open to calling this IONSS_PREFIX, similar to CNSS_PREFIX.
|Done
|Done
|i can move this to finish
|Done
|you have fixed this i suppose in your patch.
|list of fuse filesystems
|ok
|for now i think we can use this. I will need to do more research to understand how to set fuse flags.
|Why doesnt it look correct? We are using the functions that can be used. I dont understand what lower level functions you are referring to. This is using fuse high level API. But we are not calling a couple of baked fuse API's. This is the way it was done in prototype
|Yes. Its shutting it down. From inside the fuse loop. This is done because I am not able to shutdown multiple fuse filesystems by calling fuse_sessionb_exit sequentially. We have already experiemnted with this earlier. So this is how i make it interrupt any in-progress system call.
|same reason as jeff mentioned above
|Done
|Done

(not the crt_util part)
|no it doesnt. The first getattr fuse will do will be root which is &quot;/&quot;. So yes maybe i should do a reverse verificationt that mnt should not contain a trailing slash.
|getopt long is not working for this use case, so for now I have added a log message asking user to specify atleast one positional arg.
|Done
|in some cases, it could return success if some fuse filesystems fail. I could make it return a failure, but if we are not able to shut down the fuse filesystem, I doubt we will be able to do much other than just log.
|I ll set a default value for ret. But if some entries fail, we still want to shutdown the rest.
|Done
|yes
|There is no documentation anywhere. But I have used them. I ll check again to remove ones i am not using
|OK
|Agreed about getenv. Maybe we can cache it in projection state. but how do I override printf? I will still need to construct the path everytime. same goes for memory. Any suggesstion?
|Fixed this in the new patch. there have been a patch since this comment.
|This is temporary until we have a better solution. This is not even the actual implementation. In reality there are going to be no command line options and we are going to query burst buffer.
|AFAIK snprintf does add a new line when its done copying size bytes specified to the buffer
|Done
|i think we made this change because we used snprintf in this function call which adds the newline character
|yeah. I just noticed that, although its not pertaining to this changeset, but its a bug. I will fix it in next patch
|okay. This also for timeout however. Cart has fault tolerance built in so this might not be necessary.
|Yes we wont shutdown here actually. I think the actual use case here is that if ion is not responding, then we will check the liveness map and resend the RPC. Checking liveness map is in MCL but resending can be an issue esp if the call I/O is making any permanent changes on backend. This is a temporary fix for now, but we wont use this when we port to CaRT.
|Done
|My bad, I had completely forgottten I had defined these macros twice. I had to rmeove it from iof_plugin.h. so should we keep these here or on iof_plugin.h? If we keep these here they can be used for IONSS as well.
|I did not understand, we should use separate error codes for plugins?
|Yes. there is an mcl_progress loop inside it which blocks until there is a client attached. It wont work if the client hasnt attached. There could be a subtle race condition here but this is the only it can work in MCL at the moment.
|Done
|I have made ion_tempdir a global variable for now, for caching environment variable ION_TEMPDIR. This environment variable is strictly used only for testing purpose because we are not able to create dirs on HA/GA environment. I dont want to make permanent code base changes because this will likely go away with burst buffer API, and we can then add more meaningful structures. Additionally i am using iof_psr_query structure for sign-on RPC, so i cant cache this there.
|I have defined this twice because I am not able to include iof_common.h here. It causes linker errors. It only works if I include it in the C file. I havent looked into why that happens. If you find out a reason for that, please let me know too. I will try changing this to char *.
|Removing this is causing a compilation errors. Maybe MCL added this file and ctrl_fs relied on it so this got missed.
|We can. I will remove prototype testing as well.
|still havent ported the logging. Logging currently relies on MCL. I assumed we will be moving MCL logging to IOF. but looks like I have to use cart logging. so i will update the logging and remove this.
|Done
|Yes, destination ( service) process set name
|its needed for cart build as far as i know. but will verify.
|There are. I wasnt sure if we were changing the logging. I will use that.
|I am not able to remove mcl here, because our logging code depends on MCL it seems. Do we want to move that to IOF so we can completely get rid of MCL?
|mistake probably. Will fix.
|Yes it is a double pointer. I will put a comment on this and put better names.
|the callback provided to crt_progress gets invoked when it exits. Not sure how that would be any different. If you are talking about crt_req_send making on-demand progress, then i wont be able to add retries.
|you mean to crt_req_send?
|There is a comment right above that says &quot;on-demand progress&quot;
|agreed, will fix.
|I reveiwed errno.h and I could not find an -EINTERNAL. Any other error code did not seem appropriate. what to do then?
|done
|need some advise on the choice of these values.
|yes. Done
|Done
|mistake. will fix.
|okay
|so the iovec memory is allocated internally. I dont allocate it. I believe cart internally copies the contents of stbuf. Will verify though.
|you mean in main threads execution? I can do that, but in future i think we will require a thread anyway. This could be a regression then.
|good timing. I actually was just testing this change. Yes, argobots and mercury are both required here.
|I believe crt_api.h does include it. Does this provide additional benefit over that? One cannot use crt without including crt_api.h
|You are only using this struct in the self_test.c file to send callback arguments, so you dont need to include this here. You can move this inside the C file itself, since this struct need not be exported anywhere.
|Done
|Done
|Done
|Done
|Done
|are you sure you cannot somehow reuse this function instead of adding it here? This is function i believe is written in test_cget.py. I would vote against code repetition unless absolutely necessary, unless the team agrees.
|This is weird. I actually fixed this. But I fixed this online and updated it with my local copy on wolf-23 which resulted in reversal of this change. will fix it again.
|I had actually not added this here orginally but it was decided that python interface needs to be changed too. based on alex's suggestions Are you sure about this?
|I dont think that is needed for this patch. If i need to add more tests to add origin functionality then we can add restructuring
|now with the enumeration this is questionanble whether you want to consider this an error or not. Lseek should not fail because a file is corrupted.
|So now that we are doing what you wrote below- just clarifying that i am not making this a bool.
|I think i added these by mistake
|Done
|Done
|Done
|Done
|Done
|done
|Done
|I dont think this need an assert since its not a part of unit test and if the file fails to be opened then thats a setup issue unrelated to the unit being tested.
|Done
|Done
|Done
|i am not understanding what you want to see here. All the use cases are beign veirfied along with unit tests. Whats missing?
|I changed this to return cppr return codes and it sets val to indicate status of whether the file represented by fd, got stripped or not.
|this looks like bad commit on my part. will change this
|I added this function to test is RPATH is actually getting stripped. It takes a slightly different approach by traversing via program header instead of section header. But achieves the same thing.
|I made this into a function to because previously this was casuing &quot;too-many-statements&quot; exception from pylint.
|when you said internal flag, I assumed you meant a flag not specified in the header file. I can change this.
|will add a comment
|will do
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|I was getting compilation errors if I dont include these headers
|Done
|Done
|could possibly hide this.
|maximum size. If user doesnt set it, it becomes set to CPPR_TABLE_DEFAULT
|Done
|I think that is satisfied by the num_reserved paramater in table initialization. You can specify the number of reserved keys in a table and that will not be returned by this API.
|forgot to change it back before pushing for review. Will fix.
|Done
|Done
|This callback is for the user to delete the memory allocated for the value, of the key that is being removed. The table just returns the value stored at the key to the user. Adding key as a parameter doesnt help us since key is useless for the user. This  is a final cleanup step.
|the list link will be in the CPPR implementation of the structure right? I decided to create a generic API. Then when I use this for CPPR, I would point the void *data to another table which would then introduce the list. 

Is that what you mean?
|I made this non-generic because of pre-allocation of reserved routines which only would need to happen once in startup. 

for non-reserved entries, which can be initialized anytime during the lifetime of the application, I decided to use the init_entry_cb callback. 

I could theoretically combine both. Wont that be messy though?
|I mentioned the reason above. LMK if that makes sense.

Fetch_entry_cb could be removed, but for the nested table, it could be useful,.
|Done
|made it to relativepath. Abspath was causing dependency cycles.
|I'd rather get done with this change and not pile on low priority changes. I can add this to backlog if you feel its too important to ignore.
|Done
|removed
|Done
|Done
|do we need to add tests for crt_util related stuff?
|Done
|Done
|Done
|at this point, we dont know if its an ELF file. On relevant comment below: I have added a comment.
|Done
|its happening in the line below.
|Done
|Done
|Done
|Done
|Done
|fixed.
|I can remove this, but looks harmless to me. @Jeff: do you agree, that all log messages pertaining to non-elf files should be removed? Do understand that it still takes a couple of steps to find out if a file is an ELF or not.
|Done
|fixed.
|if all the reviwers agree, then I will remove.
|API will look inconsistent with that, since this is the only place where that enum will be used, and I can only think of one value for this enum which is- CPPR_NOT_AN_ELF. All other cases are cuurently satisfied by cppr_return_t. Is there another way I can communicate this to user?
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|fixed
|Done
|explained on PM. will remove comment.
|Done
|Done
|Done
|I will check
|i try and make it a point to memset after cppr_malloc, since it contains garbage and reused blocks, and then null checks fail.
|removed.
|Done
|I prefer memsetting all memory allocated, by cppr_malloc. In general its a good practise. I have encountered a situation before where i was checking for null, it wasnt null, because cppr_malloc reuses blocks.
|removed
|Done
|Done
|this is fixed in the patch, i will upload shortly.
|Done
|stated now as shared library dependencies
|decided to stick to cppr_elf_handle. But fixed the naming where it was called &quot;ELF Handle&quot;
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|we could hit it only when someone tries to set a value for a key thats removed prior. but yes, a usage issue.
|yes, that means the key's bucket wasnt initialized. If we gave the key to the user- then the bucket would be initialized to valid memory. If key does not exist, the this should be NULL.
|yeah. will fix.
|Done
|fixed a bunch of those, missed this one out. will fix
|I guess we could, but this also a corner case that will be resolved with a better solution in the next patches.
|yeah, wasnt sure if we want in this patch or next. I was thinking i will add ref counting to cppr table first?
|will fix
|i can create more API's to facilitate access, I need to know what alex needs.
|will fix
|Done
|Yeah. This function is passed as an argument in cppr_plugin.c and it needs access to internal structs in cppr_request.cpp
|what is this change for? seems unrelated to OFI?
|if delete flag changes between like 368 amd line 373- and then the instruction would fail because comparison between the ref and old_ref would fail right?
|Done
|Done
|Done
|Done
|Done
|I added one more check- a reference cannot be taken if deletion flag is set. I set the deletion flag above this call now. instead of later.
|its not different. I could set it in the beginning when initializing the table. Currently this field gets set for all values stored in the table. Could we have a use case where we want to remove individual keys differently, or provide different callback arguments? This gives us that flexibility- but if we dont need it- then i will move it to initialization and that will save some space as well.
|such as this one
|Done
|will rename
|Done
|just easier to grep in logs. will remove.
|we could check the return code here
|i wasnt sure if we are allowed to use asserts in CPPR code? did that rule change?
|doesnt sound that difficult. Can increase count in every get-val and can decrement count when i remove the value (after its been decref'd to 0). can check here for 0. Sounds better than traversing again.
|in this case it is the decref that will actually delete the table- since removal only marks the table for deletion and we have a reference on the table when it got created. There is another function called __check_client_status that gets called in finalize. So when a client has detached- and its operations get completed in finalize- we decref there (after checking if the table has emptied or not).
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Done
|Currently this flag just sets this value and i check it in create_request. Some ops could theoretically still pass through after this flag is set. this might need a better solution.
|my bad, careless mistake. fixed it.
|yeah i had forgotten its doing the same thing. removed.
|so i was holding a reference from create_request that i decref in finalize, but after the implementation of taking a reference on every __retreive_payload, older implementation can be removed. Removed now.
|Done
|Done
|Done
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 20.
|Patch Set 21: Commit message was updated
|Uploaded patch set 22.
|Uploaded patch set 23.
|Uploaded patch set 25.
|Uploaded patch set 26.
|Uploaded patch set 27.
|Uploaded patch set 28.
|Uploaded patch set 31.
|Uploaded patch set 32.
|Uploaded patch set 33.
|Uploaded patch set 34.
|Uploaded patch set 35.
|Uploaded patch set 36.
|Uploaded patch set 37.
|Uploaded patch set 38.
|Uploaded patch set 39.
|Uploaded patch set 40.
|Uploaded patch set 41.
|Uploaded patch set 42.
|Uploaded patch set 43.
|Uploaded patch set 44.
|Uploaded patch set 45.
|Uploaded patch set 46.
|Uploaded patch set 47.
|Uploaded patch set 48.
|Uploaded patch set 49.
|Patch Set 49:

(1 comment)
|Uploaded patch set 50.
|Uploaded patch set 51.
|Patch Set 52: Patch Set 51 was rebased
|Uploaded patch set 56.
|Uploaded patch set 57.
|Patch Set 58:

(1 comment)
|Uploaded patch set 59.
|Patch Set 60: Patch Set 59 was rebased
|Patch Set 1: Code-Review+1

Looks much cleaner than the earlier one!
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 3: Patch Set 2 was rebased
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 3: Code-Review+1
|Patch Set 2:

We should probably merge this quickly?
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Patch Set 2 was rebased
|Patch Set 3:

I actually couldnt merge this with 19199 because i couldnt figure out how to test it by killing a process by orterun. Ctr-C would kill random process.
|Uploaded patch set 4.
|Uploaded patch set 7.
|Patch Set 8: Patch Set 7 was rebased
|Uploaded patch set 9.
|Patch Set 10: Commit message was updated
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 16: Patch Set 15 was rebased
|Uploaded patch set 17.
|Patch Set 7: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

Is it necessary to rebase this now? If i rebase i won't be able to test it completely since i will be running it with orterun. I need to find a resolution to signal handlers first. and i cannot ctrl-C orterun properly. Can we hold off until COURTSHIP-80 is resolved?
|Patch Set 2:

&gt; Is it necessary to rebase this now? If i rebase i won't be able to
 &gt; test it completely since i will be running it with orterun. I need
 &gt; to find a resolution to signal handlers first. and i cannot ctrl-C
 &gt; orterun properly. Can we hold off until CORFSHIP-80 is resolved?
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 7: Patch Set 6 was rebased
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Patch Set 9: Patch Set 8 was rebased
|Uploaded patch set 10.
|Patch Set 11: Patch Set 10 was rebased
|Patch Set 11:

(1 comment)
|Patch Set 11:

(1 comment)
|Uploaded patch set 12.
|Patch Set 13: Patch Set 12 was rebased
|Uploaded patch set 14.
|Patch Set 15: Patch Set 14 was rebased
|Uploaded patch set 16.
|Patch Set 17: Patch Set 16 was rebased
|Uploaded patch set 18.
|Patch Set 19: Patch Set 18 was rebased
|Uploaded patch set 20.
|Patch Set 21: Patch Set 20 was rebased
|Uploaded patch set 22.
|Patch Set 23: Patch Set 22 was rebased
|Patch Set 24: Patch Set 23 was rebased
|Patch Set 24:

all Mercury handles are created once per thread i.e. per filesystem. They are re-used across  filesystem operations. But different projections have their own handles. I could theoretically separate mercury id's and create them once, but i found them to be pretty useless anyway. I haven't understood why they are exposed to the user or what we could do with them. But they are needed for creating handles, and i wanted to avoid making them global. Hence they are created once per mount point as well along with handles. I am creating mercury class only once in the whole process, and that i pass around to all threads (aka mount points). Mercury class only encapsulates the NA layer which is kept constant for all mount points anyway. So no point  duplicating that.
|Patch Set 24:

Regarding a thread seeing error on return from progress, it should interrupt the system call its executing and it should  execute fuse_teardown which will unmount the filesystem. I don't think we would need shutdown variable there. shutdown variable is just a temp variable i have put in to override fuse default signal handlers. I need to work on exit conditions after i figure out how to test this case of shutting down just one server with orterun.
|Patch Set 24:

About your earlier comment- if i have understood correctly- what you want is to pass one base mount point to fuse, and create directories with the name of rank its projecting? Meaning- if invocation is this-
./client_main a/

the inside a we should have more directories a/rank1 a/rank2 for projecting each rank?
|Patch Set 25: Patch Set 24 was rebased
|Uploaded patch set 26.
|Patch Set 27: Patch Set 26 was rebased
|Uploaded patch set 28.
|Uploaded patch set 29.
|Patch Set 30: Patch Set 29 was rebased
|Uploaded patch set 31.
|Patch Set 32: Patch Set 31 was rebased
|Patch Set 33: Patch Set 32 was rebased
|Uploaded patch set 34.
|Patch Set 34:

i rebased the changeset, i am not sure why its not showing up here. I resolved all conflicts. but no activity here.
|Uploaded patch set 35.
|Patch Set 35:

I tried doing it it doesn't show up. it added all these extra files which i didn't even touch.  Asks me to do a three way merge.
|Patch Set 35:

yes i need help
|Uploaded patch set 37.
|Uploaded patch set 38.
|Uploaded patch set 39.
|Uploaded patch set 40.
|Uploaded patch set 41.
|Uploaded patch set 42.
|Uploaded patch set 43.
|Uploaded patch set 44.
|Uploaded patch set 45.
|Patch Set 46: Patch Set 45 was rebased
|Uploaded patch set 47.
|Uploaded patch set 48.
|Uploaded patch set 49.
|Patch Set 49:

(4 comments)
|Uploaded patch set 50.
|Uploaded patch set 51.
|Uploaded patch set 52.
|Uploaded patch set 54.
|Uploaded patch set 55.
|Uploaded patch set 56.
|Uploaded patch set 57.
|Uploaded patch set 58.
|Patch Set 58:

(1 comment)
|Uploaded patch set 59.
|Uploaded patch set 60.
|Uploaded patch set 61.
|Patch Set 61:

(1 comment)
|Patch Set 61:

(1 comment)
|Patch Set 61:

(1 comment)
|Uploaded patch set 62.
|Patch Set 63: Patch Set 62 was rebased
|Uploaded patch set 64.
|Patch Set 16: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Abandoned

Not using
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Patch Set 3: Patch Set 2 was rebased
|Uploaded patch set 4.
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(5 comments)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Patch Set 10: Patch Set 9 was rebased
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 13: Patch Set 12 was rebased
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 18: Patch Set 17 was rebased
|Uploaded patch set 19.
|Uploaded patch set 20.
|Patch Set 21: Patch Set 20 was rebased
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(5 comments)
|Patch Set 4: Patch Set 3 was rebased
|Uploaded patch set 5.
|Patch Set 6: Patch Set 5 was rebased
|Uploaded patch set 7.
|Patch Set 8: Patch Set 7 was rebased
|Patch Set 8:

(4 comments)
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Patch Set 17:

(15 comments)
|Patch Set 18:

(1 comment)
|Uploaded patch set 19.
|Uploaded patch set 21.
|Uploaded patch set 24.
|Uploaded patch set 25.
|Patch Set 25:

(2 comments)
|Patch Set 25:

(1 comment)
|Uploaded patch set 26.
|Uploaded patch set 27.
|Uploaded patch set 28.
|Uploaded patch set 29.
|Uploaded patch set 30.
|Patch Set 1: Code-Review+1
|Patch Set 7: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 1:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 24:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

There are some error messages coming when application exits, even though jenkins passes the test. These error messages are because na_context_destroy is not able to destroy the context cleanly. I am still debugging these.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

Gen Proc macro creates routine that would generate the proc for the arguments to be packed. Here we are packing a dynamically allocated array. So that wouldnt work here.
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

(2 comments)
|Patch Set 10:

(1 comment)
|Uploaded patch set 11.
|Patch Set 10:

(1 comment)
|Uploaded patch set 12.
|Patch Set 4: Code-Review+1
|Patch Set 4: Code-Review+2
|Patch Set 6:

(1 comment)
|Patch Set 3:

Some functions in proto_common.c are removed. Is that for logging purposes? if not, does that need to be a separate changeset?
|Uploaded patch set 1.
|Patch Set 3:

(1 comment)
|Patch Set 3:

(1 comment)
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 6:

(8 comments)

Currently this does not include extended attributes-based unmounting. In test_iof its line 68-79. Can we include those tests here? Those test will unmount the filesystem. As a result the filesystem will be unmounted from within the application. So this is in line with my comment on line 267 about checking if the directory is mounted or not.
|Patch Set 6:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Abandoned

Not doing
|Patch Set 17:

(1 comment)
|Patch Set 17:

Martin, I have updated the wiki, please use those environment vairables and their values. Also, dont use configuration 2, 6 and 10 in ANY testing whatsoever. Even in ping. sorry for the confusion on this.
|Patch Set 11:

Orterun does not seem to run the liveness process set tests for me. do i need to update something to make it run? This is the output I get on my term-

 

orterun --tag-output --continuous -np 4 test_ps --name service_set --is_service 1 --hold : -np 4 test_ps --name client_set --is_service 0 --attach_to service_set
orterun: Error: unknown option &quot;--continuous&quot;
Type 'orterun --help' for usage.
|Patch Set 11:

(1 comment)
|Patch Set 11:

(1 comment)
|Patch Set 1: Code-Review+2

This does solve the problem of being able to make progress while in fence, but because singleton process doesnt go through fence, it doesnt solve the problem completely. As a result, a service set stops making progress when all processes reach fence and a singleton process could still remain waiting for a response, because it doesnt participate in the fence. However, it still looks like a useful feature
|Patch Set 10:

(1 comment)
|Patch Set 2: Code-Review+2

but probably cant commit this until it succeeds on jenkins.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Patch Set 1:

We can make it 9 as well. Do you want that?
|Uploaded patch set 2.
|Patch Set 2:

I was trying to post a comment, but gerrit hung and change got submitted before i could submit the comment. Anyway the issue, the usage is incorrect. This change uses MCL's own context for calling progress. the correct way is to first request a context and then call progress. If the MCL_CTX_UNIQUE = mcl_unique, then automatically mcl's own context will be picked up. But right now, basically you cannot use any configuration that progress model provides.
|Uploaded patch set 1.
|Patch Set 2:

yes, its supplied to mcl_progress, which is the intention
|Patch Set 2:

Okay yeah i think you are right. I read through the code, and looks like its just listening and it wont use the new context.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1:

is iof not picking up the mcl 0.0.4?
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 1.
|Patch Set 2: Patch Set 1 was rebased
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 10:

(2 comments)
|Patch Set 2:

(2 comments)
|Patch Set 8: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4:

Martin, could you please assist me as to why ping-test is failing on this changeset? This changeset does not affect any changes in ping. I cant seem to find out why its timing out after being given such a huge timeout.
|Patch Set 4:

I have currently not imported any changes to the test scripts, because i need to discuss that issue in the meeting.
|Patch Set 4:

(2 comments)
|Patch Set 5: Patch Set 4 was rebased
|Uploaded patch set 6.
|Patch Set 6:

Please dont review, as these changes are incomplete.
|Uploaded patch set 7.
|Patch Set 7: Code-Review-1
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 12: Patch Set 11 was rebased
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Patch Set 15:

(15 comments)
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Uploaded patch set 22.
|Uploaded patch set 23.
|Uploaded patch set 24.
|Uploaded patch set 25.
|Uploaded patch set 26.
|Uploaded patch set 27.
|Uploaded patch set 28.
|Uploaded patch set 29.
|Uploaded patch set 30.
|Uploaded patch set 31.
|Patch Set 32: Patch Set 31 was rebased
|Uploaded patch set 33.
|Patch Set 34: Patch Set 33 was rebased
|Uploaded patch set 35.
|Patch Set 35:

if things look alright with this changeset and is ready to merge, i will change the run_test back to not run self_test under valgrind. But just wanted to cross check that there are no memory leaks.
|Patch Set 35:

(2 comments)
|Uploaded patch set 36.
|Patch Set 14:

I wonder how it had been working so far!
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

(3 comments)
|Uploaded patch set 2.
|Patch Set 2: Code-Review+1
|Patch Set 2:

I can only do +1, but this looks good to me.
|Patch Set 3: Code-Review+2
|Patch Set 5: Code-Review+2
|Patch Set 8:

(1 comment)
|Patch Set 9: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 14:

(1 comment)
|Patch Set 3: Code-Review+1
|Patch Set 3:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(4 comments)
|Uploaded patch set 5.
|Patch Set 5:

I have made error codes positive for consistency
|Uploaded patch set 6.
|Patch Set 6:

fuse3 is availlable on linux packages. but not sure about its OSX version.
|Patch Set 6:

(1 comment)
|Patch Set 6:

This patch was stacked with corfship-176. abandoning this
|Abandoned

squahsed with corfship-176
|Patch Set 1: Code-Review+2
|Patch Set 1:

edit the commit message to correct spelling as it wont update on jira otherwsie
|Patch Set 6:

(1 comment)
|Patch Set 15: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 1:

not sure why node provisioning is failing
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(5 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Patch Set 7:

still working on adding the test setup
|Patch Set 7:

(3 comments)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(5 comments)
|Patch Set 9:

(1 comment)
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 13: Patch Set 12 was rebased
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Patch Set 20:

(1 comment)
|Uploaded patch set 21.
|Patch Set 22: Commit message was updated
|Patch Set 22:

(1 comment)
|Patch Set 22:

(1 comment)
|Patch Set 22:

(5 comments)
|Patch Set 22:

(3 comments)
|Uploaded patch set 23.
|Patch Set 24: Commit message was updated
|Patch Set 22:

(3 comments)
|Patch Set 24:

(5 comments)
|Uploaded patch set 25.
|Patch Set 24:

(6 comments)
|Patch Set 25:

(1 comment)
|Uploaded patch set 26.
|Patch Set 1: Code-Review+2
|Uploaded patch set 2.
|Patch Set 2:

Byron, This is some self test initial stuff i worked on. You can use this as a reference point. Its by any measure not clean and currently only measures throughput. Repetition count and inflight_rpc have been hard coded and you would need to make those things optional using getopt_long. You can use this to understand cart api somewhat. Ping me on skype if you have any questions and good luck !
|Patch Set 2:

Also this runs on top of CaRT but actually a lot of code here needs to be moved inside cart. in particular self_test.h. We have already gone through those details on F2F.
|Abandoned

handed over.
|Restored
|Abandoned
|Patch Set 2: Verified+1
|Uploaded patch set 1.
|Abandoned
|Patch Set 2: Code-Review+2
|Patch Set 1:

I havent checked why valgrind is failing (not able to view results from mac) but if you are able to figure it out, then please squash.
|Patch Set 3: Code-Review+2
|Patch Set 2:

I want the ability to be able to view the output on screen I could previously do that by commenting out the subprocess.devnull. If that ability is not there, then this patch will make things very difficult. Please explain how to view output on screen.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 4: Patch Set 3 was rebased
|Patch Set 4:

(1 comment)

The memory leaks are coming from cart code, as far as i can understand. We might need to add some suppressions.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(11 comments)
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 6:

(4 comments)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 13:

(1 comment)
|Patch Set 13:

(1 comment)
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 16: Published edit on patch set 15.
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Patch Set 3: Code-Review+1
|Patch Set 3:

i dont have +2 permission in cart.
|Patch Set 2:

(1 comment)
|Patch Set 5: Code-Review+1

Looking at comments, CPPR is compiling fine with this change. This might help remove pedantic warnings on my changeset. Can we land this then?
|Patch Set 1: Code-Review+1

I understand the need for this change and find that useful. But I am wondering if this change needs to be in the test script or the test C code itself with an elaborate TODO. The reason this change is a proof that cart does not fully satisfy function shipping HLD requirements. Its very easy to forget about this because its in the test script and more difficult to ignore if its in the C code. 
I am in favor of keeping test scripts used by the testing team strict and in consistency with HLD.
|Patch Set 1:

(1 comment)
|Patch Set 6:

I dont think jenkins/maloo is actually running this code, its only compiling it. There is no python/yml file to actually invoke self test on jenkins.
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+2
|Patch Set 1: -Code-Review

yes, ashley we can abandon this
|Patch Set 1:

in a lot of cases particularly for mkdir,rmdir, symlink you are going to have common return callbacks since args for them are same. Going to get confusing then.
|Patch Set 2: Code-Review+1
|Patch Set 7: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 3: Commit message was updated.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(3 comments)
|Patch Set 8: Commit message was updated.
|Uploaded patch set 9: Patch Set 8 was rebased.
|Uploaded patch set 10.
|Patch Set 10:

(2 comments)
|Uploaded patch set 11.
|Uploaded patch set 12.
|Patch Set 12:

Yes, I am going to add test. I can remove plugin test from the directory with the next update
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

Sorry, I had forgotten to make a simple change in how crt_init is called. I have made that change now. Basically CRT_FLAG_BIT_SERVER wasnt getting set.
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Patch Set 8:

(1 comment)
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 5:

(3 comments)
|Patch Set 5:

(1 comment)
|Uploaded patch set 6.
|Patch Set 6:

(3 comments)
|Patch Set 6:

(1 comment)
|Patch Set 6:

(8 comments)
|Uploaded patch set 7.
|Patch Set 7:

(4 comments)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 11: Published edit on patch set 10.
|Patch Set 12: Published edit on patch set 11.
|Patch Set 13: Published edit on patch set 12.
|Uploaded patch set 14.
|Patch Set 14:

(1 comment)
|Patch Set 15: Published edit on patch set 14.
|Patch Set 16: Published edit on patch set 15.
|Patch Set 3: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Patch Set 3:

comments arent as well written for now, will refine it in the next patch. only looking for the api feedback.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Patch Set 10:

(4 comments)
|Patch Set 10:

(13 comments)
|Uploaded patch set 11.
|Patch Set 11:

(11 comments)
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15: Patch Set 14 was rebased.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

about to push change to timers
|Uploaded patch set 2.
|Patch Set 2:

(3 comments)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(5 comments)
|Uploaded patch set 8.
|Patch Set 9: Commit message was updated.
|Uploaded patch set 1.
|Patch Set 2: Published edit on patch set 1.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Patch Set 4: Commit message was updated.
|Patch Set 5: Commit message was updated.
|Uploaded patch set 1.
|Patch Set 2: Commit message was updated.
|Patch Set 3: Commit message was updated.
|Patch Set 4: Commit message was updated.
|Patch Set 5: Commit message was updated.
|Patch Set 6: Commit message was updated.
|Patch Set 7: Commit message was updated.
|Patch Set 8: Commit message was updated.
|Abandoned

it doesnt help
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(29 comments)
|Uploaded patch set 5.
|Patch Set 5:

(9 comments)
|Uploaded patch set 6.
|Patch Set 6:

(7 comments)
|Uploaded patch set 7.
|Patch Set 6:

(2 comments)
|Uploaded patch set 8.
|Patch Set 4: Code-Review+2
|Patch Set 2: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Patch Set 3: Commit message was updated.
|Uploaded patch set 1.
|Abandoned

Alex is in process of making changes to this file. So this fix isnt necessary anymore.
|Patch Set 41: Code-Review+1
|Uploaded patch set 1.
|Abandoned

this contained some bad commits. Updated the changeset with a new commit.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(3 comments)
|Uploaded patch set 5.
|Patch Set 5:

(4 comments)
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

(1 comment)
|Patch Set 8:

(1 comment)
|Patch Set 9: Published edit on patch set 8.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Patch Set 3: Code-Review+2
|Patch Set 4:

(1 comment)
|Uploaded patch set 1.
|Patch Set 1:

(2 comments)
|Uploaded patch set 2.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 4:

(3 comments)
|Patch Set 3: Code-Review+1

(1 comment)

Just come comments that are not useful anymore can be removed - before merging.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

(7 comments)
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 1.
|Patch Set 1:

currently not fully functional, but this is what i intend to do. Just need to know what should be done with ctrl fs.
|Uploaded patch set 2.
|Abandoned

succeeded by: https://review.whamcloud.com/#/c/27692/6
|Patch Set 3: Code-Review+2
|Patch Set 1: Code-Review+2

we can add a suppression for the memory leak coming from CNSS. Not much information available from valgrind other than that it might be coming from fuse.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(7 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(11 comments)
|Uploaded patch set 8.
|Uploaded patch set 1.
|Should &quot;Test nodes&quot; at the beginning of this paragraph also have emphasis applied for consistency?
|Would it be helpful to say something like &quot;... a k? Lustre network driver found in the &lt;literal&gt;...(path).../klnd &lt;/literal&gt; directory...&quot;?
(I'm not sure what &quot;k&quot; stands for)
|Should new_session, end_session, show_session in parentheses above be &lt;literal&gt;?
|This table contains an entry for &quot;--force&quot;.  In the description ,&quot;-force&quot; appears several times.  Should it be &quot;--force&quot;. Also should &lt;literal&gt; be applied to each instance?
|Should &quot;add_batch&quot; have &lt;literal&gt; applied?
|Should &lt;literal&gt; be applied to &quot;bulkperf&quot;?
|A trademark compliance review was completed on the opening content and Section 1: Lustre Intro and a few additional minor edits were made.
|&quot;Maybe&quot; should changed to &quot;may be&quot; in two places:
-...a small risk data may be lost.&quot;
- The reason obdfilter_survey may be safe to run...&quot;

Verb missing in third sentence. Should be:
Thus, the best time to run obdfilter_survey is before...

Fourth sentence could possibly be reworded. Is this what it is trying to say?
It is safer to run obdfilter_survey before putting the Lustre file system into production to avoid destroying file system data, because objects are created with object sequence 2.
|Both Linux and Lustre are trademarks of other companies.  
They must be designated with a superscript asterisk (*): as follows
- In the first appearance in a headline, and/or the first prominent use
- In the first appearance in the body of text 
(These trademarks both most likely appear earlier, in the manual so an asterisk isn't needed here). 

The other thing to note is that any trademark must always be used with an appropriate noun (such as &quot;file system&quot; or &quot;software&quot; or &quot;OS&quot;). So &quot;Lustre&quot; should never be used by itself as a noun (it is used incorrectly in the previous paragraph). I have a Jira ticket to do a full trademark compliance review of the manual soon.
|Change &quot;...RPMs is in...&quot; to &quot;...RPMs are in...&quot;

Also, isn't the xref to the RPM procedure already included below?
|All links to supported platforms should go to the Test Matrix Table in the manual. 
&lt;xref xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; linkend=&quot;LustreTestMatrixTable&quot;/&gt;
Peter would prefer that we not link to the HPPD wiki.
|Change &quot;...to users home directory ...&quot; to &quot;...to the user's home directory...&quot;
|Looks like maybe an extra space in &quot;product ion&quot;
|Change &quot;distro&quot; to &quot;distribution&quot; for consistency
|Change &quot;an&quot; to &quot;a&quot;
|Should be &quot;distributions&quot;
|Replace &quot;a special command&quot; with &quot;a special command, &lt;literal&gt;replace_nids&lt;/literal&gt;,&quot;
|Add periods after items in this list.
|Replace &quot; the need to &quot;writeconf&quot; all servers &quot; with &quot;the need to execute the &lt;literal&gt;writeconf&lt;/literal&gt; command on all servers&quot;

Replace &quot;the &quot;writeconf&quot; method&quot; with &quot;the &lt;literal&gt;writeconf&lt;/literal&gt; command&quot;
|Replace &quot;(&lt;literal&gt;lctl list_nids&lt;/literal&gt;) is correct.&lt;/para&gt;&quot; with
&quot;is correct. Use &lt;literal&gt;lctl list_nids&lt;/literal&gt; to view the list of server NIDS.&quot;
|For consistency, replace period with colon.
|For consistency, replace period with colon.
|Replace &quot;myfs-OST0013&quot; with &quot;&lt;literal&gt;myfs-OST
0013&lt;/literal&gt;&quot;.
|Replace &quot; '.bak' &quot; with &quot;&lt;literal&gt;.bak&lt;/literal&gt;&quot;.
|In the first sentence above, are you saying this?
&quot;Prior to release 2.5, a conflict between equivalent entries was resolved in favor of the route with the shorter hopcount.&quot;

Delete second period (.) at end of sentence.
|In the ConfigurationFilesModuleParameters section, &quot;hopcount&quot; is one word.  It should be the same everywhere for consistency.

&quot;prioirty&quot; should be spelled &quot;priority&quot;
|&quot;LNet&quot; should be changed to &quot;LNET&quot; throughout for consistency throughout the manual, except in code, of course.  Eric Barton has declared LNET as the correct spelling (probably for historical reasons.)

Also, LNET = Lustre networking, so LNET should be followed by a noun unless you are specifically referring to Lustre networking (not LNET routers, LNET interfaces, LNET networks, etc.)
|LNET
|LNET

Change ...

including details on which NICs are to be configured and how routing among LNETs will take place.

..to

including details about which NICs are to be configured and how routing among LNET routers will take place.
|For clarity, change...

In some cases the parameters may have
been stored in &lt;literal&gt;/etc/modprobe.conf&lt;/literal&gt;, but this has been deprecated since RHEL5 and SLES10, and having a separate...

...to the following (if correct) or something similar

For distributions previous to Red Hat Enterprise Edition 5 and  SUSE Linux Enterprise Server 10, &lt;literal&gt;lnet&lt;/literal&gt; parameters may have been stored in &lt;literal&gt;/etc/modprobe.conf&lt;/literal&gt;, but this method of specifiying &lt;literal&gt;lnet&lt;/literal&gt; parameters is now deprecated. Having a separate ...
|Change...

for Lustre

...to

by the Lustre file system

(Lustre must always be used as an adjective, never as a stand-alone noun).
|Do you mean the LNET router(s)? the LNET network(s)? the LNET interfaces?
|LNET
Do you mean the LNET router? the LNET network? the LNET interface?
|What are &quot;LNET(s)&quot;? Can you provide a noun such as router, interface, network, or ???
|LNET
|... maps a network interface to an LNET network?
|...to the Ethernet interface...
|To map the LNET interface &lt;literal&gt;o2ib&lt;/literal&gt; to the Infiniband...
|LNET specification?
|...these settings ... (add &quot;s&quot; to setting)
|Server &lt;literal&gt;svr1&lt;/literal&gt; with three Ethernet ...
|Server &lt;literal&gt;svr2&lt;/literal&gt; with three Ethernet ...
|Ethernet
|Ethernet
|... need not be specified as &lt;literal&gt;ib0&lt;/literal&gt; will be assumed.
|LNET
|LNET
|LNET
|LNET
|LNET
|...from one LNET to one (or more) other LNETs.

Is this saying...?

...from one LNET network to one (or more) other LNET networks?

..............

at the LNET layer

....

.. are all in the same LNET network?
|Please either insert the illustration or remove this text before merging.
|&lt;literal&gt;&lt;/literal&gt; is missing on one instance of &quot;routes&quot;

in the &lt;literal&gt;lustre.conf&lt;/literal&gt; file (add the word &quot;file&quot;)
|Replace ...

There could be several reasons for doing this, namely, ...

...with...
Several reasons for doing this are that ...
|Made &quot;Fine-Grained&quot; lower case (&quot;fine-grained)
|Should the above two lines be included in one screen?
|You might italicize this phrase to make it stand out as the list item since it isn't a complete sentence.
|Shouldn't 'modprobe' be literal?

&quot;will include&quot; might be better than &quot;will have&quot;
|Add colon after 'nodes'
|Add colon after 'nodes'
|Again, italicize this phrase.
|Replace &quot;would be&quot; with &quot;is&quot;
|Italicize this phrase.
|Italicize phrase
|Make two sentences or separate with a semicolon (;)
|Italicize phrase
|LNET networks?
|Is there extra space between &quot;side&quot; and &quot;presuming&quot;?

To turn it on, enter:
|Remove &quot;-&quot; after &quot;called&quot;.
|&lt;literal&gt;dead_router_check_interval&lt;/literal&gt;
&lt;literal&gt;live_router_check_interval&lt;/literal&gt;
|Should &quot;LND&quot; be defined here?  Should it be formatted as &lt;literal&gt;?
|&lt;literal&gt;dead_router_check_interval&lt;/literal&gt;
|LNET x2
|LNET x2
|LNET x2
|LNET
|LNET
|LNET
|LNET
|LNET
|LNET x5

Add text to make this a complete sentence:
Setting? Modifying? LNET tunables may be necessary on some systems to improve performance.
|NI credit (credit should be lower case)
|To make a complete sentence, say something like:

In this example, 256 credits are applied to TCP connections.
|Lustre Release 2.3
LNET
NI credits
...and the administrator's request does not persist.
|Add l23 condition to sections that apply to 2.3 and more recent.
|CPU partitions
|LNET
|LNET

Add l23 condition to sections that apply to 2.3 and more recent.
|Remove &quot;-&quot; after parameter
|LNET x3

&lt;literal&gt;ptlrpc&lt;/literal&gt;
|LNET
|Are the other options missing here or just not displayed in gerrit?
|LNET
|LNET x4

...required by Lustre file systems is ....
|LNET

&quot;Remote Direct Memory Access&quot; should be &quot;Remote direct memory access&quot; (capital R only because it starts a sentence)

&quot;Lustre Network Driver&quot; should be &quot;Lustre network driver&quot;
|LNET x2
|LNET x3
|LNET
|...the Lustre software.

..can have multiple LNET interfaces?.
|Do we want to say &quot;LNET is ... unreliable&quot;?

LNET X3
|change &quot;indentifies&quot; to &quot;identifies&quot;

&quot;network identifier&quot; should be lower case

&quot;the the&quot; should be &quot;the&quot;
|LNET routing
|LNET x2
|In the built version of the manual, the mark after Lustre appears as a registered trademark (R).  Since Lustre is a third party trademark, it should have an asterisk (*) instead with a footnote somewhere stating: 
 * Other names and brands may be claimed as the property of others.

productname might better be used for Intel trademarks with some other designation for trademarks of other parties.

Also, I have been removing links in the manual that point to technical information on the wiki site and moving that information into the manual (per instructions from Peter Jones).  This link to doc patch instructions seems a little different, but you might want to check with Peter to see what he advises.
|A blank line above the revision history might provide a better visual transition from the text to the revision history data.
|We are calling the manual this now:
Lustre*Software Release 2.x Operations Manual&quot;
|Suggest changing &quot;all of the versions of the software in the 2.x series&quot; to something like &quot;all the 2.x Lustre software releases&quot;
|For Intel trademark compliance, &quot;Lustre 2.4&quot; should be changed to &quot;Lustre software release 2.4&quot;.
|For Intel trademark compliance, &quot;Lustre 2.4&quot; should be changed to &quot;Lustre software release 2.4&quot;.
|Change &quot;is&quot; to &quot;this&quot;
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 3: (6 inline comments)

Some of these are comments on your changes and others are additional minor cleanup changes in the same text that are similar to what you've already done. If you'd prefer I put those in a separate ticket, let me know.
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: I would prefer that you didn't submit this

(1 inline comment)

The content changes look OK but the commit message is incorrect.
|Patch Set 2: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned

Failed by Hudson.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Abandoned

Changes incorporated into another patch
|Patch Set 4: Looks good to me, approved


|Patch Set 4: I would prefer that you didn't submit this

See notes for typos and request for clarification
|Patch Set 5: (1 inline comment)


|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve

(1 inline comment)


|Patch Set 1: Looks good to me, approved


|Patch Set 1: Abandoned

Changes already checked in (http://review.whamcloud.com/#change,6545)
|Change has been successfully cherry-picked as 33888b67a8db94389bdb735d7797fc7b163a3b6b
|Patch Set 7: Looks good to me, approved


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 4.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: I would prefer that you didn't submit this

(6 inline comments)

My comments are mostly pointing out minor typos.
|Patch Set 2: I would prefer that you didn't submit this

(1 inline comment)

Sorry - One typo
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 3: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Patch Set 2: I would prefer that you didn't submit this

(8 inline comments)

Content looks good. My comments are primarily changes that will make the formatting of this section more consistent with the style standard that has been set for this manual.
|Patch Set 3: Looks good to me, but someone else must approve


|Patch Set 4: Looks good to me, but someone else must approve


|Patch Set 3: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 4: Looks good to me, but someone else must approve


|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 2.
|Patch Set 1: I would prefer that you didn't submit this

(77 inline comments)

Requires a number of changes to meet style standards for the Lustre manual.
|Uploaded patch set 2.
|Patch Set 1: I would prefer that you didn't submit this

These changes are not needed.  At this point we don't use any Intel trademarks (r) or (tm) in the manual.  All third party trademarks must be indicated by an * as described in the Intel trademark compliance standards.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1: I would prefer that you didn't submit this

(2 inline comments)


|Patch Set 3: Do not submit

(5 inline comments)

Richard - I made some notes in your patch and then realized that I've already rewritten this section. Take a look at what I did in the latest build of the manual. If it looks OK, you could abandon this patch as well.
|Shouldn't the launch_test method be called here to kill the cnss process?
|The vars testmsg and cmdstr are overwritten.
|Failure is due to the typo here, which ought to say: pkill test_group.
I have fixed it in my patch 23585 which is yet to be merged,
|No, it was accidental. I have removed it. Though I did a git submodule update before the commit it was picked up.
|Sorry, added the Else.
Also I got confused because the log files contain this information as well.
|Else has been omitted; the output goes to either the log file only OR the screen as well as the log file.
|Else has been omitted; the output goes to either the log file only OR the screen as well as the log file.
|Though not a part of this changeset; this should likely say CART now.
|Wouldn't setting this once (Line 63) be enough?
|Similarly, we are setting the var RESULTS on Line 66. can we skip this?
|The same change is reflected in the changeset# 24455; likely conflict.
|Done
|This file is being referenced from iof_multi_instance.yml
|Yes, we would like to keep it as a reference.
|Done
|Done
|Done
|Updated it to multi-instance
|Removed this key-value pair
|Done
|The description has been updated.
|Done
|Done
|Done
|Fixed the indent.
|Replaced the while with a for loop.
|Done
|Done
|The code stops the processes on the remote nodes; since the command is executed by the node_control module,
|Done
|Added a Intel header and doc string here.
|Explained the code (success/failure) returned by this method.
|Added a comment above to explain that this remain a placeholder and will be replaced by the temporary dir created by the test.
|Added the Intel header.
|Added a return on the alternate path as well.
|Added the Intel header.
|done.
|Removed the lines 35-38
|Removed line - loop:&quot;no&quot;
|The comments section seems to be copied from the echo_test. Excluding the command, the rest need to be changed to the cart_test_barrier.
|@Ashley: From your previous comment, I thought you wanted to poll for a few seconds to check if it is running. Thats why I used the while loop.
@Martin: If it just needs to be checked once, think it will be the same.
|I remembered reading super() is used to invoke the base class's methods. Hence I used it here. Is it wrong?
|Replaced super() with self.
|Yes, the server is stopped with stop_process (Line 101)
|We are waiting 5s for the server to be launched and then verifying if it did or not. So, I think the order is right here.
|In order to iterate through the list of file names, I am using a for loop.
|Done
|Done
|Done
|No, it starts the server, check it is up, waits for 2 seconds and verifies it is continuing to run.
|can we add a little more to this comments section to distinguish it from the execute_strategy below please?
|Yes, until we come up with a conclusive list of all the tools to install. We will work on the installs soon after.
|Done
|The existing code in iof_test_local does the former; but for the multi instance tests I needed to add this workaround.
|iof_test_local runs the setup and teardown for every test; wheras the multi-instance run the setupModule once and I needed a workaround to accomodate both and persist these values.
|Done
|Done
|Done
|I tried the Uppercase N; I still get the same error below for this test.
# NA -- Error -- /var/lib/jenkins/wolf-50vm4-jenkins-2-1-el7-x8664/workspace/mercury-update-scratch/mercury/src/na/na_cci.c:821
 # na_cci_addr_lookup(): cci_connect(sockets://10.8.1.24:18280) failed with CCI_EINVAL
wait failed.
main thread wait progress thread ...
06/02-15:28:03.37 wolf-24 CaRT[134414] CRT  ERR  src/crt/crt_context.c:567 crt_context_timeout_check() rpc_priv 0x24cb2d0 (opc 0xa1) timed out.
|Patch Set 1: Code-Review+2
|Change has been successfully cherry-picked as a3a8a436ce30ae9ee4dfad304ec3d9c2cd1b6087
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 20:

(1 comment)
|Patch Set 20:

(1 comment)
|Patch Set 20:

Maloo log seems to indicate the testiof is not executed. Hence the stop_process is unable to find the process and returns -1; the test_iof_ionss fails.
|Patch Set 12:

ORTE daemon failed to run on  GA. Probably, because the port was occupied. A re-trigger might help.
|Patch Set 12:

It can be re-triggered from Jenkins. Martin will re-trigger it shortly.
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Abandoned

Duplicate patch
|Patch Set 1:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Abandoned

Incorrectly added this changeset. Will submit a stacked one to correct the submittal.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned

Wrongly included scons_local. Fixed it in a consecutive one.
|Uploaded patch set 1.
|Abandoned

Missed a file
|Restored
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 1:

Maloo has passed and the logs show both the tests have passed. Where do you see the error?
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1:

(3 comments)
|Patch Set 1:

W.r.t documentation, I will document it in the file itself and additionally on the Functional testing wiki which lists all the env vars used. By default, the output will be displayed on the screen. The test runner will set it to redirect all the output to the logs only.
|Uploaded patch set 3.
|Patch Set 1:

(1 comment)
|Patch Set 1: Code-Review+2
|Patch Set 2: Code-Review+2
|Patch Set 12: Code-Review+1
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Patch Set 1:

The variable needs to be set by the GA to report the logs to Maloo. I have created a task CQE-24 (assigned to Martin) to set that. Once he sets it, we can submit this patch. The closer both are submitted the better.
|Patch Set 1: Code-Review+2
|Patch Set 1: Code-Review+2
|Patch Set 11: Code-Review+1

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 5:

(1 comment)
|Patch Set 5: Code-Review+1
|Patch Set 9:

(2 comments)
|Patch Set 9: Code-Review+1
|Patch Set 10: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Patch Set 4:

(2 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Patch Set 9:

(26 comments)
|Uploaded patch set 12.
|Uploaded patch set 13.
|Patch Set 2: Code-Review+1
|Patch Set 12:

(1 comment)
|Patch Set 4:

Doesn't this changeset require changes to run_test.sh; to invoke the tests using nosetests command?
|Patch Set 6: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

&gt; Is there a reason this change is needed?

Not necessary, just as a good practice.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

(1 comment)
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 14.
|Uploaded patch set 15.
|Uploaded patch set 16.
|Uploaded patch set 17.
|Patch Set 17:

(3 comments)
|Uploaded patch set 18.
|Uploaded patch set 19.
|Uploaded patch set 20.
|Uploaded patch set 21.
|Patch Set 20:

(1 comment)
|Uploaded patch set 22.
|Uploaded patch set 23.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 1.
|Patch Set 1:

We needn't remove test_iof_clean.sh. It is a simple clea up code beind retained for convenience to manually clean up after a run if necessary. No, it is not being referenced by Jenkins configurations.
|Patch Set 1:

I will create a ticket and remove test_iof_clean.sh.
I have used globs for py and yml files; since we require commontestsuite.py in addition to the tests (py and yml) and test_list.yml to be in the install/Linux/TESTING dir.
|Patch Set 1:

Created ticket IOF-422 and corresponding patchset https://review.whamcloud.com/#/c/25642/ to remove test_iof_clean.sh
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1:

(2 comments)
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 1: Code-Review+1

Please rebase the changeset and I can score it again.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 1: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 2:

(2 comments)
|Abandoned

The changeset has been pulled into the original barrier changeset.
|Patch Set 2: Code-Review+2

(1 comment)
|Patch Set 3: Code-Review+2
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5: Commit message was updated.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 4:

(3 comments)
|Uploaded patch set 8: Patch Set 7 was rebased.
|Uploaded patch set 9.
|Patch Set 9:

(1 comment)
|Patch Set 9:

(1 comment)
|Uploaded patch set 10.
|Patch Set 1: Code-Review+1
|Uploaded patch set 1.
|Abandoned

Will re-submit after infrastructure fix
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 7:

(1 comment)
|Uploaded patch set 1.
|yes right. will do the changes here.
|This change was done in IOC_LIBCFS_PING with &quot;lnetctl peer list&quot; patch. I replicated here so that both calls remain in sync
|yes comma separated string of nids. should be NIDs to ping
|yes it can be a list of nids like &lt;nid1&gt;,&lt;nid2&gt;,&lt;nidN&gt;.
let me put the pattern here
|Done
|the usage here says nids
|Done
|Done
|Done
|Done
|Done the changes to use h2nettype() here. I am just wondering for the use case for this test. I think lctl ping command doesn't support hostnames with hyphen.
|Done the changes for test_100()
For test_127(), there are 2 tests - 127a and 127b. Sorry, I don't see  any place in these test cases, where we are requiring the network name to use h2nettype(). some other test number?
|Done
|Done
|Done
|Done
|Done
|-v is to check if the variable NETTYPE is set. Is the error because of an older version of bash?
This should work with version 4.2 and above
|Ok, I will then create a new ticket and push a patch to make this change
|Done
|Done
|Uploaded patch set 1.
|Abandoned

failed build
|Uploaded patch set 1.
|Abandoned

Build failed
|Uploaded patch set 1.
|Abandoned

As per Andreas comment
|Uploaded patch set 1.
|Abandoned

As per Andrea's comment
|Uploaded patch set 1.
|Uploaded patch set 2.
|Abandoned
|Uploaded patch set 1.
|Abandoned

error test
|Uploaded patch set 1.
|Abandoned

just to test
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 11: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10: Commit message was updated.
|Uploaded patch set 10.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 8: Commit message was updated.
|Uploaded patch set 9: Commit message was updated.
|Uploaded patch set 7: Commit message was updated.
|Uploaded patch set 1.
|Abandoned

Build fail
|Restored

original patch
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 5:

(1 comment)

&gt; (1 comment)

In case a peer is already added with a prim_nid then even if other nids of that peer are pinged, then lnetctl ping should always display the prim_nid as primary irrespective of which nid is pinged.
|Patch Set 5:

&gt; (1 comment)

In case a peer is already added with a prim_nid then even if other nids of that peer are pinged, then lnetctl ping should always display the prim_nid as primary irrespective of which nid is pinged.
|Patch Set 6:

In case a peer is already added with a prim_nid then even if other nids of that peer are pinged, then lnetctl ping should always display the prim_nid as primary irrespective of which nid is pinged.
|Patch Set 6:

&gt; (1 comment)

Ok, I think it makes more sense what you suggested. Let me make changes here.
|Uploaded patch set 7.
|Patch Set 7:

(4 comments)

&gt; (8 comments)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Uploaded patch set 10.
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 13.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Abandoned
|Patch Set 4: Patch Set 3 was rebased
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3: Patch Set 2 was rebased.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5: Patch Set 4 was rebased.
|Patch Set 2:

&gt; Uploaded patch set 1.

Code looks fine. Why are we changing the location of lustre_routes.conf from /etc/sysconfig/ to /etc/ ?
|Patch Set 2: Code-Review+1
|Patch Set 3:

Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1

Patch Set 1 :
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)

&gt; (4 comments)
|Uploaded patch set 3.
|Uploaded patch set 4: Patch Set 3 was rebased.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 1.
|Patch Set 3: Code-Review+1
|Patch Set 4: Code-Review+1
|Patch Set 5: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(3 comments)
|Patch Set 3:

(7 comments)
|Uploaded patch set 4.
|Uploaded patch set 5.
|Uploaded patch set 6.
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

(3 comments)
|Patch Set 9:

(1 comment)
|Patch Set 9:

(1 comment)
|Patch Set 1: Code-Review+1
|Patch Set 2: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 2: Commit message was updated.
|Yes thats right , here &quot;de&quot; is the existing entry after which a new entry going to be added and that is &quot;de1&quot; . Now for new entry rec_len is calculated as :
de1-&gt;rec_len = ldiskfs_rec_len_to_disk(rlen - nlen, blocksize);
Later it copies the dirdata but doesnt update the rec_len accordingly for the new entry:
        if (data) {
                de-&gt;name[namelen] = 0;
                memcpy(&amp;de-&gt;name[namelen + 1], data, *(char *) data);
                de-&gt;file_type &#124;= LDISKFS_DIRENT_LUFID;
        }
So my understanding was , for new entry it doesnt update the rec_len including dirdata but when another file entry gets added after its record , that time it updates the rec_len correctly.
|My was thinking the rec_len would not always contain the dirdata length as i was looking at kernel function add_dirent_to_but() while creating new entry in the directory block:
       nlen = LDISKFS_DIR_REC_LEN(de);
        rlen = ldiskfs_rec_len_from_disk(de-&gt;rec_len, blocksize);
       if (de-&gt;inode) {
                struct ldiskfs_dir_entry_2 *de1 = (struct ldiskfs_dir_entry_2 *)((char *)de + nlen);
                de1-&gt;rec_len = ldiskfs_rec_len_to_disk(rlen - nlen, blocksize);
                de-&gt;rec_len = ldiskfs_rec_len_to_disk(nlen, blocksize);
                de = de1;
        }

Here it corrects the rec_len of existing entry with dirdata size and sets the rec_len of new entry with the remaining space. Please correct me if i am wrong here , this would happen for last entry in the directory block.
|Ok , now i got it correctly. Thanks.
|I agree using EXT2_DIR_REC_LEN() would solve the issue but as you mentioned in the previous comment wouldn't it break again if it contains data other than dirdata ?
|done
|Yes ,we can do that. I thought lets keep the changes simple for now.
|done
|Sure, thanks.
|done
|Sure
|vil_header which we are adding to zap as value is of 192 bytes. May be i should not hard code the value and get the size of zil_header_t .
|done
|Thats true . Its a good idea to merge these two functions.
|agree.
|True, i thought about it before. Will add the code to wait for any on going process here then.
|done
|done
|Oh yes ..will make that change.
|done
|done
|done
|This function gets called from two places , 1) At the time of shard setup. So it will read the VIL which are present in staging shard and will add it to the shard list. And any new IOs will be served from it.
2) After rollback, now we need to delete the VIL entries which were locked in snapshot.

About the conflicting epoch case: This is the scenario where VIL entry has same epoch number as current staging epoch.
This will only in following example:
Write on epoch 1 ,2 and 3. Commit epoch 1 . Now snapshot-1 will have vil_zap entries for 2 and 3. Now after commit epoch 2 becomes staging shard. But then discard comes on epoch 2 which will rollback it to snapshot-1.

Now after rollback , current staging epoch is 2 and vil_zap also has entry for epoch 2. We can not add two entries in shard list with same epoch number. 
So osd_shard_del_conflicting_vil() will remove this conflicting vil separately without adding to shard list.
|done
|sure
|ASSERT need to be changed to 
!BP_IS_HOLE(&amp;vil_header-&gt;zh_log)
|As abort will be called as part of shard open only , can we assume there will not be any other thread accessing the epoch ?
We can just add the assert that there should not be any threads accessing it while abort is in progress ?
|Actually osd_shard_epoch_del_from_list should never fail , may be i can add assert LASSERT(rc == 0);
|Oops.. thats by mistake. Will remove it.
|Yes , thats true..We thought about this issue. Gaurav gonna add vil_global_list per pool in another fix which needs some more investigation. In that fix we will take care of this scenario.
Is that ok ?
|Agreed , will make that change.
|done
|Yes, vil_release should be called if ref node is present on the list. Thanks for pointing out.
|done
|done
|agreed
|zil_destroy iterates through the zl_lwb_list and unmarks the fast write blocks.I guess if we call zil_destroy_sync directory , will miss the unmark and block log block accounting will go wrong.
|Shouldn't we call dmu_tx_abort on vil_init failure and GOTO out ?
|Yes , its a good suggestion. I will make this change.Thanks.
|dbuf_dirty() expects buffer data (db-&gt;db_buf) is present for the corresponding dbuf. db_buf represents the latest image of the buffer data.
For ZC , we need dummy arcbuf so we can follow dbuf_dirty() method as it is.
dbuf_dirty() assigns the db_buf to dr_data for the new dirty record. If for ZC this db_buf is NULL and there is conflicting write on the same buffer after ZC. In that case db_buf would be NULL and it would be a problem for this new write dirty record.
|Sure. I will do that.
Loaned buffers are not counted as in flight data by arc_tempreserve_space() until they are &quot;returned&quot;.We dont need to call arc_loan_buf() actually as we assign the arcbuf immediately to dbuf after allocating it.
For zc we can call arc_buf_alloc() itself.
|Aha ! i should call arc_return_buf() before dbuf_set_data.
Thanks for pointing out.
|True. No need of NULL check here.
|Yes , it should be with holding db_mtx.
The problem is for the previous ZC dirty record we have already detached the block from special dnode through vil_zc_detach().
If we have to replace the new zc dirty record with old zc dirty record , will have to again attach the block to special dnode. Otherwise it will not be part of any dnode and will never get freed. In short space accounting will go wrong.
|Sure.
We need to store special dnode number in the dirty record so that on conflicting write on the target block after ZC , we can read the special dnode block data and copy it to target blocks buffer.
|Done
|Oops .. that's wrong comment.
It should be &quot;linkage on vilog list&quot;
|Done
|Agreed.
|Aha..thats wrong. Will remove the assert and after kmem will check for error.
|Done
|That's correct. Rather it would be good to check the nzc value in for loop condition itself.
for (i = roff = 0, tsize = size, nzc = 0;
       tsize, nzc &lt; VIL_MAXBLKSPER_WRITE;
       roff += len, tsize -= len, i++)
|The comment is wrong. Will change it.
|This is just to get reservation in txg. In normal zfs code , while writing to intent log it passes the target dnode number. When writes are happening to higher epoch i.e we make sure all the writes belong to special dnode.
May be Gaurav can confirm this as its his old code (not part of this ZC patch)
|That assert was removed recently as we had disabled the zero copy. In that case all the writes would be WR_COPIED.
With ZC enabled this function would be called Only for WR_COPIED.
|The patch is actually to enable ZC. But i guess you are reviewing the whole patch i.e previous changes and ZC changes?
From OSD code depending on full block write or partial write:
osd_shard_vil_write_commit() calls vil_assign_arcbuf() and vil_write() respectively.
vil_zc_integrate() gets called from OSD to flatten the ZC blocks.
|Yeah .. I agree.
|I discussed with Gaurav, assumption was slog is used when intent log is stored on completely different device and in that case how the blocks can be swapped in flattening when it belongs to two different devices.
|Yes , thats right. But if we return before copying the data from special dnode , it will cause data corruption. And i am wondering how good is it to add assert on dnode_hold failure.
There are couple of places where return code of dnode_hold is ignored e.g dmu_object_set_checksum.
|The AVL tree for free range is protected by dn_mtx at other places. Thats the reason i had taken dn_mtx mutex.
And dbuf_whichblock() returns the blkid for particular offset. And only current thread would be accessing that offset as flattening is single threaded. So i was just wondering dn_struct_rwlock is needed? I might be wrong
|Aha .. Will add the return EINVAL.
|Done
|- There is no guarantee , will add the NULL check.
- Agree, We should use zl_lock.
|Yes , you are right. We should only go here if lwb_nused is non-zero.
|We are dividing one large record into two records here. And each of these new records will have its own metadata information. Thats why we are allocating different structure and filling up the newly created log record information in it.
|Yes , this is wrong. The write_done should be:
lwb-&gt;lwb_sz-lwb-&gt;lwb_nused - sizeof(*lrw)
|Agreed, it will be an issue. Actually there is no need of this bcopy at all. We can just assign lr_offset and there fields for this second log record.
|Yes , i guess adding write_done to (lrw+1) is wrong.
It should be:
bcopy((lrw+1), lr_buf + sizeof(*lrw), reclen);
I will confirm with gaurav once to see if there was any other assumption for it.
|Done
|I guess its wrong to retry. Even i am not sure about the reason for retry here. I will confirm with Gaurav.
|Yes, i will check the return code.
|Oh, that's correct.
We can decide using :
if (BP_GET_CHECKSUM(&amp;lwb-&gt;lwb_blk) == ZIO_CHECKSUM_ZILOG2) then lwb_nused &gt; sizeof(zil_chain_t) else lwb_nused &gt; 0 ??
|Sorry , my previous analysis was wrong. After looking at the code properly i realized the original statement is correct.
The original arithmetic is correct. lrw points to base address of lrc. lrc contains log record at the start and then complete data after that. We divide the data into two records (front and rare).
Now when 1st record got copied, 2nd record data will start from (lrw + log_record size + write_done).
Please correct me if i am wrong.
|Aha!, now i got it what were you saying.
Thanks for the explanation.
|dmu_tx_hold_zap() needs to be added here.
|We update zh_replay_seq to lr_blkoff + SPA_MAXBLOCKSIZE
and zh_replay and lr_blkoff are both at zero offset. In this scenario we will need &quot;&lt;=&quot;
|Done
|True , But we wanted the zap to get updated in the same transaction group in which flattening is done.
|In case of detach, we remove the block entry from special dnode and add that block to target object.
If we dont move the block from special dnode, it will remain part of special dnode. And on vil_destroy() when we will delete the special dnode , these blocks will get deleted.
|We flatten epochs one after the other. So at one point of time only one epoch is in flattening phase. So the dirty records for zero copy on the particular buffer would always be from same epoch.
|True , simply size == 0 is enough.
|Yes, i will make this change. Thanks.
|Uploaded patch set 2.
|Patch Set 2: Abandoned

The changes to remove &quot;patchless_client&quot; string are alredy done through patch: http://review.whamcloud.com/#change,4173
|Patch Set 1: (2 inline comments)

Thanks for reviewing the patch Andreas.
I will make changes as you suggested and submit the patch again.
I would appreciate if you could reply on the comments/doubts i added.
|Patch Set 1: (2 inline comments)

inline comment.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Patch Set 1:

(20 comments)
|Uploaded patch set 2.
|Patch Set 4:

(1 comment)
|Patch Set 4:

(3 comments)
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

(5 comments)
|Uploaded patch set 3.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 1.
|Patch Set 2:

(2 comments)
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 4:

(6 comments)
|Patch Set 4:

(1 comment)
|Patch Set 4:

(1 comment)
|Uploaded patch set 5.
|Patch Set 5:

(3 comments)
|Uploaded patch set 6.
|Uploaded patch set 7.
|Patch Set 6:

(5 comments)
|Patch Set 7:

(1 comment)
|Patch Set 6:

(2 comments)
|Patch Set 7:

(1 comment)
|Uploaded patch set 8.
|Uploaded patch set 9.
|Patch Set 9:

(13 comments)
|Uploaded patch set 10.
|Patch Set 10:

(2 comments)
|Patch Set 10:

(1 comment)
|Uploaded patch set 11.
|Uploaded patch set 12.
|Uploaded patch set 1.
|Patch Set 1:

(4 comments)
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 3.
|Patch Set 3:

(2 comments)
|Uploaded patch set 4.
|Patch Set 4:

(2 comments)
|Uploaded patch set 5.
|Uploaded patch set 6.
|Patch Set 2: Code-Review+1
|Done
|The patch for LU-7144 - http://review.whamcloud.com/#/c/17520/ ,(landed on 14th December, 2015) solves all the sanity-lfsck interop issues.
The issue can be closed.
Thanks.
|Right. So lookup will reject such open on disabling O_CREAT. We won't need to return EROFS right?
Since, the lookup opertion is supposed to return the valid dentry or NULL
|Hello Lai Siyao,
I think, for the lookup job, it is enough to disable intent create for a readonly fs.
Accordingly, the lookup opertion will return the valid dentry or NULL.
Lookup won't need to return EROFS.
|Done
|Hello Fan Yong,
root@COS1 lustre-wc-rel]# touch /root/work/f2
touch: cannot touch `/root/work/f2': Read-only file system
[root@COS1 lustre-wc-rel]# ls /root/work/
f2
Here, even though touch fails with EROFS error, the file is still created.
Hence a direct check with touch for simplification cannot be made.
The existence of the file needs to be checked after touch.
|Fix - https://review.whamcloud.com/#/c/25205/
|[root@COS1 lustre-wc-rel]# touch /root/work/f1 &#124;&#124; echo &quot;not created&quot;
touch: cannot touch `/root/work/f1': Read-only file system
not created
[root@COS1 lustre-wc-rel]# ls /root/work/
f1
|Uploaded patch set 1.
|Patch Set 1:

Please review this patch.
|Patch Set 1:

With 2 MDTs (MDT0000 AND MDT0001), test_404/sanity-hsm deactivates the last MDT(MDT0001) in the list of export targets, that is - &amp;target-&gt;ft_chain.
fld_client_lookup() retries for another target, if the remote target is deactive. This was introduced in http://review.whamcloud.com/#/c/14313/
While getting the next export target from the list using:
target = list_entry(target-&gt;ft_chain.next, struct lu_fld_target,ft_chain);
&amp;(target-&gt;ft_chain) is the last entry in the list, and the next of the last entry(target-&gt;ft_chain.next) is the head of the list.
Now, using the macro, ?list_entry?, maps the head of the list pointer back into a pointer to the structure that contains the list_head. Thus, it turns the head of the list into its containing structure(lu_fld_target). 
Now since the head of the list does not have any data associated with it, the containing structure(i.e. target) formed from the head of the list also does not have any data. Hence, an export target with no obd device data is generated.
This corrupted export target(generated from the head of the list) causes the assertion.
The fix is: While fld_client_lookup retries for another target,if the next entry in the export target list is the head of the list(&amp;fld-&gt;lcf_targets), move to the next entry after
the head(target-&gt;ft_chain.next-&gt;next) and retrieve the target. Else retrieve the next target entry(target-&gt;ft_chain.next).
|Uploaded patch set 2.
|Patch Set 1:

(1 comment)
|Patch Set 2:

The sanity-lfsck/test_32 test failure seen is not because of this patch. This failure is because of LU-6684.
Please enforce a retest.
Thanks.
|Uploaded patch set 3.
|Patch Set 3:

Please review
|Patch Set 3:

Please cherrypick
|Patch Set 3:

Ping reviewers
|Uploaded patch set 7.
|Uploaded patch set 1.
|Abandoned

Changing directory to /tmp does not help in this case.
We see these tar failures without Lustre mounted as well.
There is a problem with the tar utility, OS or VM (kvm or vmware).
This isn't a lustre problem.
Abandoning.
|Uploaded patch set 1.
|Patch Set 1:

Please review this skip patch.
|Patch Set 1:

(1 comment)

The patch for LU-7144 - http://review.whamcloud.com/#/c/17520/ ,(landed on 14th December, 2015) solves all the sanity-lfsck interop issues.
The issue can be closed.
Thanks.
|Abandoned
|Uploaded patch set 1.
|Abandoned

Wrongly pushed
|Uploaded patch set 1.
|Uploaded patch set 2.
|Uploaded patch set 1.
|Uploaded patch set 1.
|Patch Set 1:

The failure in conf-sanity has LU-4600 tagged against it.
The failure in sanity-quota has LU-4448 tagged against it.
Both are not related to the patch.
|Uploaded patch set 2.
|Patch Set 2:

(2 comments)
|Patch Set 2:

(1 comment)
|Uploaded patch set 3.
|Patch Set 2:

(1 comment)
|Uploaded patch set 4.
|Patch Set 5: Commit message was updated.
|Patch Set 5:

Please Review
|Uploaded patch set 6: Patch Set 5 was rebased.
|Patch Set 6:

Please Review.
|Patch Set 6:

(1 comment)
|Patch Set 6:

(1 comment)
|Uploaded patch set 7.
|Uploaded patch set 8.
|Patch Set 8:

Please review
|Uploaded patch set 9.
|Patch Set 9:

Please Review
|Uploaded patch set 10.
|Patch Set 10:

The above reported failures are not because of this patch.
Please review.
|Uploaded patch set 1.
|Patch Set 1:

&gt;Failed to provision nodes.
Setup issue not related to the patch.
|Uploaded patch set 2: Patch Set 1 was rebased.
|Patch Set 2:

The failure in sanity-quota has LU-4448 tagged against it.
The failure is not related to the patch.
|Abandoned

Merged the fix and the test case in one patch.
|Uploaded patch set 1.
|Abandoned

Debug Patch.
|The wait_event in first patch failed because there was no wake_up event when cll_holds was decremented. Jinshan provided a better patch (12080) that I'm going to use. 

Thanks for reviewing this.
|My goal was to change the ptlrpc state machine as little as possible and avoid introducing new bugs. Calling ptlrpc_client_wake_req in all cases changes the behavior when request_out_callback and reply_in_callback are executed in the normal order. Can you GUARANTEE that's safe? 

This patch has been shown to fix the bug with as yet no reported side effects. Instead of perfecting this patch, I think some further thought should be given to the overall design of the req and reply unlink flags and ptlrpc_unregister_reply. Preferably by someone with a better understanding of ptlrpc than me.
|How is this condition ever true? Won't exit from the while loop at line 1161 until thread_is_running(thread) is false so it won't be running when this while executes.
|Either fix the code if it is broken or fix the comment so it doesn't sound like the code is broken.
|Why were ll_sai_get and _put deleted? I think ll_agl_thread needs to increment sai_refcount so that the sai is not deallocated while ll_agl_thread might still be using it.
|Is it safe to reference sai_agl_valid before taking the lli_agl_lock? Looks like a race in shutdown of ll_sa and ll_agl threads. ll_agl_thread sets sai_agl_valid to 0 and continues to reference sai, but ll_sa_thread sees sai_agl_valid is 0 and it can call ll_sai_put (freeing the sai) before ll_agl thread is done. I think this could be the cause of the NULL reference pointer in the wake_up call at the end of ll_agl_thread. Maybe lock isn't the real problem. ll_agl_thread shouldn't set sai_agl_valid to 0 until it is done referencing the sai. What do you think, Lai?
|On further consideration: looks like the work the ll_sa thread does here is not needed if the ll_agl thread has already set the sai_agl_valid flag. If I'm reading the code correctly, it's the sai_refcount that protects the sai from being deallocated before all threads are done with it. Can you confirm?
|Add a CDEBUG message to indicate this condition was hit.
|Explicitly set rc = 0 here; makes the code more readable.
|Thanks for catching that. Would it be safe to simply move the ls_lru_total++ after the cfs_hash_bd_unlock and lock the site around the ++?
|Thanks for the feedback. I need to give the root performance problem some more consideration. The obvious solution isn't as obvious as I first thought.
|There's an infinite loop when unregister reply and unregister bulk are called in succession without an intervening change of phase (i.e. call to ptlrpc_rqphase_move). 

Unregister reply calls ptlrpc_rqphase_move which transitions from some phase X to UNREG_RPC. At the end of the call:
   rq_phase == UNREG_RPC, rq_next_phase == X

If unregister bulk is then called immediately, it changes the current phase from UNREG_RPC to UNREG_BULK. At the end of the call to ptlrpc_rqphase_move:
   rq_phase == UNREG_BULK, rq_next_phase == UNREG_RPC

When the call above is made, the phase fields in the req at the end of the call are:
   rq_phase == UNREG_RPC, rq_next_phase == UNREG_BULK

The next time this rpc is examined, this block of code will be executed again since rq_phase is UNREG_RPC. The call to ptlrpc_rq_move will set rq_phase to UNREG_BULK and next_phase to UNREG_RPC. Without outside intervention, the request is stuck toggling between UNREG_RPC and UNREG_BULK.
|I don't understand your comment. When/why is it okay to not wait for confirmation that all MDs have been unlinked?
|Is this logic still correct? Say ptlrpc_client_recv_or_unlink is still true when ptlrpc_unregister_bulk is called. rq_phase changes to UNREG_BULK. Next time ptlrpcd_check_set looks at the req, it won't check whether the reply unlink happened. 

The call to ptlrpc_unregister_bulk here was introduced as the fix to LU-5259.
|Same problem as above. When phase is changed to UNREG_BULK, nothing forces ptlrpc_check_set to wait for the receiving_reply, req_unlink, and reply_unlink flags to be cleared (ptlrpc_client_recv_or_unlink to return 0).
|Ditto
|Uploaded patch set 1.
|Abandoned

Test results say code is not designed to wakeup the cll waitqueue when cll_holds is decremented. Going to pursue a safer approach to yielding the CPU.
|Restored

Reworked the patch to sleep and poll.
|Uploaded patch set 2.
|Patch Set 2:

(1 comment)
|Abandoned

Replaced with review.whamcloud.com/12080
|Patch Set 2: Code-Review+1

Mod fixes bug with Cray reproducer.
|Patch Set 3: Code-Review+1
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Abandoned

The patch submitted for LU-5696 fixes the same bug and replaces this patch.
|Uploaded patch set 2.
|Patch Set 2: Looks good to me, but someone else must approve


|Uploaded patch set 1.
|Uploaded patch set 2.
|Patch Set 4: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 17: Looks good to me, but someone else must approve

Patch passes Cray's vers system testing.
|Patch Set 22: Code-Review-1

(2 comments)
|Patch Set 23:

(1 comment)
|Patch Set 23:

(2 comments)
|Patch Set 1: Code-Review+1
|Patch Set 1: Code-Review+1
|Patch Set 5: Code-Review+1
|Patch Set 1:

Is anyone working on this patch?
|Patch Set 2:

Passed a 2 hour regression test run on a small development system (8 node Cascade running SLES11 SP3). I'll try a longer I/O stress run tonight.
|Patch Set 3: Code-Review+1

No regressions found in a 6 hour IOStress run on 8 node system. We don't have a known reproducer for the bug so the testing doesn't provide evidence that the bug is actually fixed. But the patch looks good to me.
|Patch Set 1: Code-Review+1
|Patch Set 6: Looks good to me, but someone else must approve


|Patch Set 7: I would prefer that you didn't submit this

(2 inline comments)

See in line comments.
|Patch Set 11: Code-Review+1
|Patch Set 2: Code-Review+1

I agree with Chris Horn's comments but this patch should resolve the bug. Passed a small, 2 hour relrun without incident.
|Patch Set 5: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 2: Code-Review-1

This patch re-introduces LU-4300 or something very similar. I'll add the details I have to the LU-6390.
|Patch Set 2: -Code-Review

Initial results indicate that 12603 addresses the LU-4300 like deadlock that appeared after the LU-6390 patch was installed. The customer installed 12603 two days ago and has not seen the deadlock since. They had been hitting it quite often so this is a positive sign. But they don't have a known reproducer so I thought I'd let them run with the patch for a couple of more days before declaring success. But I have no objections to the LU-6390 patch landing.
|Uploaded patch set 1.
|Patch Set 1:

(1 comment)
|Patch Set 1:

Andreas, I don't know the customer's workload that gets a node into the state where the shrinker performance becomes an issue. But they do reproduce it with regularity. My intent is to give them this patch so they can measure what effect it has. I suspect there's more at play here than lu_cache_shrink. We're just whittling away at the problem bit by bit. I'll update the header with more info when I submit the next version of the patch.
|Patch Set 1:

(1 comment)
|Uploaded patch set 2.
|Patch Set 2:

See LU-6365 for performance stats with and without patch.
|Patch Set 2:

The code warnings may be correct but they have nothing to do with this patch. The warnings are in files not touched by this patch.
|Patch Set 2:

Ah, I misunderstood what you meant by percpu_counters in your PS1 comment. I agree using the kernel percpu_counter is cleaner. I assume since you gave PS2 a +1 that Intel will pick up the patch as is. I'll plan to submit a cleanup patch when my schedule allows.

FYI, we found that this patch also fixed a serious problem of CPU stalls with SLES12. Nearly every system test run hit several stalls along the try_to_free_pages path. lu_cache_shrink was in most of the stack traces, often waiting in osq_lock for the lu_sites_guard lock.
|Patch Set 3: Code-Review+1

Passed Cray system tests. No problems associated with this patch in 3 weeks. Can this patch please be landed?
|Patch Set 2: Code-Review-1

(3 comments)
|Patch Set 2:

(2 comments)
|Patch Set 6: Code-Review+1

The changes in PS6 resolve my earlier concerns.
|Patch Set 9: Code-Review+1
|Patch Set 2: Code-Review+1
|Patch Set 7: Code-Review+1

Patch has been installed in both development and release branches since April 2016 at Cray. No problems reported that are associated with this patch.
|Uploaded patch set 1.
|Patch Set 1:

Sigh...this is what I get for just porting the 2.7 version to master.
|Uploaded patch set 2.
|Patch Set 2:

Compile error is on el7: percpu_counter_init has 3 parameters instead of 2. It's going to take me awhile to figure out how to fix/test for that kernel.
|Uploaded patch set 3.
|Uploaded patch set 4.
|Patch Set 3: Code-Review-1

The fix for LU-7434 also needs to include http://review.whamcloud.com/18934/
|Patch Set 3: Code-Review+1

I missed that review.whamcloud.com/18934/ has already landed. Rest of mod is fine.
|Patch Set 1: Code-Review+1
|Patch Set 1: Looks good to me, but someone else must approve


|Patch Set 1: Abandoned

just a test...
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Patch Set 1: Abandoned
|Uploaded patch set 4.
|Patch Set 1: Verified; Looks good to me, but someone else must approve


|Patch Set 2:

test review comment...
|Patch Set 1:

&quot;testing code review message&quot;
|Patch Set 2: Code-Review+1

but get a second reviewer
